title,authors,abstract,pub_date,sections_list
One Cannot Stand for Everyone! Leveraging Multiple User Simulators to train Task-oriented Dialogue Systems,Yajiao Liu; Xin Jiang; Yichun Yin; Yasheng Wang; Fei Mi; Qun Liu; Xiang Wan; Benyou Wang,"User simulators are agents designed to imitate human users; recent advances have found that Task-oriented Dialogue (ToD) systems optimized toward a user simulator could better satisfy the need of human users. However, this might result in a sub-optimal ToD system if it is tailored to only one ad hoc user simulator, since human users can behave differently. In this paper, we propose a framework called MUST 1 to optimize ToD systems via leveraging Multiple User SimulaTors. The main challenges of implementing the MUST are 1) how to adaptively determine which user simulator to interact with the ToD system at each optimization step, since the ToD system might be over-fitted to some specific user simulators, and simultaneously underfitted to some others; 2) how to avoid catastrophic forgetting of the adaption for a simulator that is not selected for several consecutive optimization steps. To tackle these challenges, we formulate MUST as a Multi-armed bandits (MAB) problem and provide a method called MUST adaptive that balances i) the boosting adaption for adaptive interactions between different user simulators and the ToD system and ii) the uniform adaption to avoid the catastrophic forgetting issue. With both automatic evaluations and human evaluations, our experimental results on MultiWOZ show that the dialogue system trained by MUST achieves a better performance than those trained by a single user simulator. It also has a better generalization ability when testing with unseen user simulators.",,"['Introduction', 'Background', 'MUST: a Framework to Leverage', 'Some Preliminary Proposals for MUST', 'MUST as a MAB Problem', 'Formulating MUST as a MAB Problem', 'Training with MUST adaptive', 'Experiments', 'Experimental Setup', 'Implementations', 'Two new User Simulators', 'Dialogue Systems', 'Experimental Results', 'Analysis and Discussions', '(b)-2(e).', 'Conclusion', 'Limitation', 'Ethics Statement', 'A Multi-armed bandit problem', 'B More details about training dialogue systems B.1 The architectures of user simulators and dialogue systems', 'B.2 The implementations of the dialogue systems', 'B.3 The details of running policy gradient algorithm', 'B.4 The parameters of training Sys-MUST adaptive', 'B.5 Human Evaluation on dialogue systems', 'C Implement MUST with the MUST CRL strategy', 'D Sensitivity on different subsets of user simulators', 'E Ablation study for the modified UCB1 algorithm E.1 Necessity of the exploration term', 'E.2 Ablation study on the designed distribution', 'F Implementing MUST with more user simulators', 'G Modeling User Simulator with GPT', 'G.1 The architecture of U-GPT', 'G.2 Evaluations on U-GPT', 'G.3 Training details of user simulators', 'System Agent User Simulator', 'G.4 Experiments', 'Acknowledgements', '', 'C Did you run computational experiments?', 'See appendix']"
SAFECONV: Explaining and Correcting Conversational Unsafe Behavior,Mian Zhang; Jin ⋄ Lifeng; Linfeng Song; ⋄ Haitao; Wenliang Chen; Dong Yu,"One of the main challenges open-domain endto-end dialogue systems, or chatbots, face is the prevalence of unsafe behavior, such as toxic languages and harmful suggestions. However, existing dialogue datasets do not provide enough annotation to explain and correct such unsafe behavior. In this work, we construct a new dataset called SAFECONV for the research of conversational safety: (1) Besides the utterancelevel safety labels, SAFECONV also provides unsafe spans in an utterance, information able to indicate which words contribute to the detected unsafe behavior; (2) SAFECONV provides safe alternative responses to continue the conversation when unsafe behavior detected, guiding the conversation to a gentle trajectory. By virtue of the comprehensive annotation of SAFECONV, we benchmark three powerful models for the mitigation of conversational unsafe behavior, including a checker to detect unsafe utterances, a tagger to extract unsafe spans, and a rewriter to convert an unsafe response to a safe version. Moreover, we explore the huge benefits brought by combining the models for explaining the emergence of unsafe behavior and detoxifying chatbots. Experiments show that the detected unsafe behavior could be well explained with unsafe spans and popular chatbots could be detoxified by a huge extent. The dataset is available at https://github.com/mianzhang/SafeConv. Warning: This paper contains cases that may be offensive or upsetting.",,"['Introduction', 'Dataset', 'Source', 'Related Work', 'Data Collection', 'Data Sources', 'Data Selection', 'Human Annotation', 'Base Models', 'Results', 'Explainable Safety Checking', 'Correct Conversational Unsafe Behavior via Contextual Rewriting', 'Conclusion', 'Ethics Considerations', 'Limitations', 'Acknowledgements', '3', 'Left blank.']"
"Detecting and Mitigating Hallucinations in Machine Translation: Model Internal Workings Alone Do Well, Sentence Similarity Even Better",David Dale; Elena Voita; Loïc Barrault; Marta R Costa-Jussà; Meta Ai,"While the problem of hallucinations in neural machine translation has long been recognized, so far the progress on its alleviation is very little. Indeed, recently it turned out that without artificially encouraging models to hallucinate, previously existing methods fall short and even the standard sequence log-probability is more informative. It means that internal characteristics of the model can give much more information than we expect, and before using external models and measures, we first need to ask: how far can we go if we use nothing but the translation model itself ? We propose to use a method that evaluates the percentage of the source contribution to a generated translation. Intuitively, hallucinations are translations ""detached"" from the source, hence they can be identified by low source contribution. This method improves detection accuracy for the most severe hallucinations by a factor of 2 and is able to alleviate hallucinations at test time on par with the previous best approach that relies on external models. Next, if we move away from internal model characteristics and allow external tools, we show that using sentence similarity from cross-lingual embeddings further improves these results. We release the code of our experiments. 1",,"['Introduction', 'Background and Setting', 'Model', 'Hallucination Dataset', 'Reference-Based Oracles', 'Internal Measures', 'External models', 'Main results', 'Analysing Distributions of the Scores', 'Detected Pathology Types', 'Mitigating Hallucinations at Test Time', 'Evaluation methodology', 'Metrics.', 'Generation Strategies', 'The Impact of Generation Strategy', 'The Impact of Number of Hypotheses', 'Reranking Approaches', 'Automatic Evaluation', 'S. O.', 'Human evaluation', 'Conclusions', 'Limitations', 'Ethical statement', 'A Implementation and computing', 'B Mitigating Hallucinations at Test Time', 'C Manual Evaluation', '', 'C Did you run computational experiments?']"
Explainable Recommendation with Personalized Review Retrieval and Aspect Learning,Hao Cheng; Shuo Wang; Wensheng Lu; Wei Zhang; Mingyang Zhou; Kezhong Lu; Hao Liao,"Explainable recommendation is a technique that combines prediction and generation tasks to produce more persuasive results. Among these tasks, textual generation demands large amounts of data to achieve satisfactory accuracy. However, historical user reviews of items are often insufficient, making it challenging to ensure the precision of generated explanation text. To address this issue, we propose a novel model, ERRA (Explainable Recommendation by personalized Review retrieval and Aspect learning). With retrieval enhancement, ERRA can obtain additional information from the training sets. With this additional information, we can generate more accurate and informative explanations. Furthermore, to better capture users' preferences, we incorporate an aspect enhancement component into our model. By selecting the top-n aspects that users are most concerned about for different items, we can model user representation with more relevant details, making the explanation more persuasive. To verify the effectiveness of our model, extensive experiments on three datasets show that our model outperforms state-of-theart baselines (for example, 3.4% improvement in prediction and 15.8% improvement in explanation for TripAdvisor).",,"['Introduction', 'Explainable Recommendation with Generation', 'Retrieval Enhancement', 'Problem Statement', 'Input Data', 'Output Data', 'Methodology', 'Overview of Model', 'Retrieval Enhancement', 'Retrieval Encode', 'Retrieval Method', 'Aspect Enhancement', 'Joint Enhancement Transformers', 'Rating Prediction', 'Explanation Generation', 'Aspect Discriminator', 'Text Generation', 'Multi-Task Learning', 'Experiments', 'Datasets', 'Evaluation Metrics', 'Baseline Methods', 'Prediction', 'Explainability', 'Reproducibility', 'Explainability Study', 'Accuracy of Prediction', 'Ablation Analysis', 'Conclusion', 'Limitation', 'Acknowledgments', '']"
Binary and Ternary Natural Language Generation,Zechun Liu; Barlas Oguz; Meta Ai; Aasish Pappu; Yangyang Shi; Raghuraman Krishnamoorthi,"Ternary and binary neural networks enable multiplication-free computation and promise multiple orders of magnitude efficiency gains over full-precision networks if implemented on specialized hardware. However, since both the parameter and the output space are highly discretized, such networks have proven very difficult to optimize. The difficulties are compounded for the class of transformer text generation models due to the sensitivity of the attention operation to quantization and the noise-compounding effects of autoregressive decoding in the high-cardinality output space. We approach the problem with a mix of statistics-based quantization for the weights and elastic quantization of the activations and demonstrate the first ternary and binary transformer models on the downstream tasks of summarization and machine translation. Our ternary BART base achieves an R1 score of 41 on the CNN/DailyMail benchmark, which is merely 3.9 points behind the full model while being 16x more efficient. Our binary model, while less accurate, achieves a highly nontrivial score of 35.6. For machine translation, we achieved BLEU scores of 21.7 and 17.6 on the WMT16 En-Ro benchmark, compared with a full precision mBART model score of 26.8. We also compare our approach in the 8-bit activation setting, where our ternary and even binary weight models can match or outperform the best existing 8-bit weight models in the literature. Our code and models are available at: https://github.com/facebookresearch/ Ternary_Binary_Transformer.",,"['Introduction', 'Method', 'Preliminary', 'Ternarization', 'Binarization', 'Stats-based max-entropy isometric weight quantization', 'Learning-based activation quantization', 'Experiments', 'Experimental settings', 'Summarization', 'Machine translation', 'Ablations', 'Sequence length analysis', 'Weights Activations', 'Visualization', 'Conclusion', 'Limitations', 'Ethics Statement']"
Span-Selective Linear Attention Transformers for Effective and Robust Schema-Guided Dialogue State Tracking,Björn Bebensee; Haejun Lee,"In schema-guided dialogue state tracking models estimate the current state of a conversation using natural language descriptions of the service schema for generalization to unseen services. Prior generative approaches which decode slot values sequentially do not generalize well to variations in schema, while discriminative approaches separately encode history and schema and fail to account for inter-slot and intent-slot dependencies. We introduce SPLAT, a novel architecture which achieves better generalization and efficiency than prior approaches by constraining outputs to a limited prediction space. At the same time, our model allows for rich attention among descriptions and history while keeping computation costs constrained by incorporating linear-time attention. We demonstrate the effectiveness of our model on the Schema-Guided Dialogue (SGD) and Mul-tiWOZ datasets. Our approach significantly improves upon existing models achieving 85.3 JGA on the SGD dataset. Further, we show increased robustness on the SGD-X benchmark: our model outperforms the more than 30× larger D3ST-XXL model by 5.0 points.",,"['Introduction', 'Approach', 'Task Formulation', 'Joint Encoding with Linear Attention', 'Intent Classification', 'Span Pointer Module', 'Pre-Training via Recurrent Span Selection', 'Experimental Setup', 'Benchmark Datasets', 'Evaluation Metrics', 'Implementation Details', 'Evaluation', 'Baselines', '""[ACTION] Offer [SLOT] location [VALUE]', 'Main Results', 'Robustness', 'Generalization to unseen domains', 'Ablation Study', 'Related Work', 'Conclusion', 'Limitations', 'Ethics Statement', ' [INTENT] ', 'C Did you run computational experiments?']"
EM Pre-training for Multi-party Dialogue Response Generation,Yiyang Li; Hai Zhao,"Dialogue response generation requires an agent to generate a response according to the current dialogue history, in terms of which twoparty dialogues have been well studied, but leaving a great gap for multi-party dialogues at the same time. Different from two-party dialogues where each response is a direct reply to its previous utterance, the addressee of a response utterance should be specified before it is generated in the multi-party scenario. Thanks to the huge amount of two-party conversational data, various pre-trained language models for two-party dialogue response generation have been proposed. However, due to the lack of annotated addressee labels in multi-party dialogue datasets, it is hard to use them to pre-train a response generation model for multi-party dialogues. To tackle this obstacle, we propose an Expectation-Maximization (EM) approach that iteratively performs the expectation steps to generate addressee labels, and the maximization steps to optimize a response generation model. Theoretical analyses and extensive experiments have justified the feasibility and effectiveness of our proposed method. The official implementation of this paper is available at https://github.com/EricLee8/MPDRG.",,"['Introduction', 'Pre-training for Response Generation', 'Human Response:', 'Multi-party Dialog Response Generation', 'Methodology', 'Task Formulation', 'Addressee Modeling', 'Latent Variable Prediction', 'Expectation-Maximization Process', 'Proof of Feasibility', 'Experiments', 'Datasets and Experimental Setups', 'Baseline Models and Evaluation Metrics', 'Automatic Evaluation Results', 'Human Evaluation Results', 'Analysis', 'Ablation Study', 'Response Generation vs. Addressee Prediction', 'Case Studies', 'Response Parser: A Byproduct for Free', 'Limitations', '', 'C Did you run computational experiments?']"
ACLM: A Selective-Denoising based Generative Data Augmentation Approach for Low-Resource Complex NER,Sreyan Ghosh; Utkarsh Tyagi; Manan Suri; ♣ Sonal,"Complex Named Entity Recognition (NER) is the task of detecting linguistically complex named entities in low-context text. In this paper, we present ACLM (Attention-map aware keyword selection for Conditional Language Model fine-tuning), a novel data augmentation approach, based on conditional generation, to address the data scarcity problem in lowresource complex NER. ACLM alleviates the context-entity mismatch issue, a problem existing NER data augmentation techniques suffer from and often generates incoherent augmentations by placing complex named entities in the wrong context. ACLM builds on BART and is optimized on a novel text reconstruction or denoising task -we use selective masking (aided by attention maps) to retain the named entities and certain keywords in the input sentence that provide contextually relevant additional knowledge or hints about the named entities. Compared with other data augmentation strategies, ACLM can generate more diverse and coherent augmentations preserving the true word sense of complex entities in the sentence. We demonstrate the effectiveness of ACLM both qualitatively and quantitatively on monolingual, crosslingual, and multilingual complex NER across various low-resource settings. ACLM outperforms all our neural baselines by a significant margin (1%-36%). In addition, we demonstrate the application of ACLM to other domains that suffer from data scarcity (e.g., biomedical). In practice, ACLM generates more effective and factual augmentations for these domains than prior methods.",,"['Introduction', 'Background and Related Work', 'Methodology', 'Keyword Selection', 'Generated Samples:', 'Template Creation', 'Fine-tuning ACLM', 'Data Generation', 'Post-Processing', 'Experiments and Results', 'Dataset', 'Algorithm 1 ACLM: Our proposed augmentation framework', 'Baselines', 'Experimental Results', 'Original', 'LwTR', 'MELM', 'ACLM w/o mixner', 'Conclusion', 'Limitations', 'A Hyperparameter Tuning', 'C Templates and Attention Maps', 'D Qualitative Analysis of Augmentations D.1 Augmentation Examples', 'Original', 'LwTR', 'MELM', 'ACLM w/o mixner', 'ACLM w/ mixner', 'Original', 'LwTR', 'MELM', 'ACLM w/o mixner', 'ACLM w/ mixner', '']"
Natural Language to Code Generation in Interactive Data Science Notebooks,Pengcheng Yin; Wen-Ding Li; Kefan Xiao; Abhishek Rao; Yeming Wen; Kensen Shi; Joshua Howland; Paige Bailey; Michele Catasta; Henryk Michalewski; Alex Polozov; Charles Sutton; Jacob Andreas; Johannes Bufe; David Burkett; Charles C Chen; Joshua Clausman; Jean Crawford; Kate Crim; Jordan Deloach; Leah Dorner; Jason Eisner; Hao Fang; Alan Guo; David Leo; Wright Hall; Kristin Delia Hayes; Kellie Hill; Diana Ho; Wendy Iwaszuk; Smriti Jha; Dan Klein; Theo Lanman; Percy Liang; C H Lin; Ilya Lintsbakh; Andy Mcgovern; Aleksandr Nisnevich; Adam Pauls; Dmitrij Petters; Brent Read; Dan Roth; Subhro Roy; Jesse Rusak; Beth Ann Short; Div Slomin; B Snyder; Stephon Striplin; Yu Su; Zachary Tellman; Sam Thomson; A A Vorobev; Izabela Witoszko; Jason Wolfe; A G Wray; Yuchen Zhang; Jacob Austin; Augustus Odena; Maxwell Nye; Maarten Bosma; David Dohan; Ellen Jiang; Carrie Cai; Michael Terry; Tom Brown; Benjamin Mann; Nick Ryder; Melanie Subbiah; Jared D Kaplan; Prafulla Dhariwal; Arvind Neelakantan; Pranav Shyam; Girish Sastry; Bei Chen; Fengji Zhang; A Nguyen; Daoguang Zan; Zeqi Lin; Jian-Guang Lou; Weizhu Chen; Mark Chen; Jerry Tworek; Heewoo Jun; Qiming Yuan; Henrique Ponde; Harrison Edwards; Yura Burda; Nicholas Joseph; Greg Brockman; Alex Ray; Raul Puri; Gretchen Krueger; Michael Petrov; Heidy Khlaaf; Pamela Mishkin; Xinyun Chen; Petros Maniatis; Rishabh Singh; Hanjun Dai; Max Lin; Denny 2022 Zhou;  Spreadsheetcoder; Qinyu Cheng; Linyang Li; Guofeng Quan; Feng Gao; Xiaofeng Mou; Xipeng 2022a Qiu; Zhoujun Cheng; Tianbao Xie; Peng Shi; Chengzu Li; Rahul Nadkarni; Yushi Hu; Caiming 2022 Xiong; Dragomir R Radev; Mari Ostendorf; Luke Zettlemoyer; Matthias Feurer; Aaron Klein; Katharina Eggensperger; Daniel Fried; Armen Aghajanyan; Jessy Lin; Sida I Wang; Eric Wallace; Freda Shi; Ruiqi Zhong; Yujian Gan; Qiuping Huang; Matthew Purver; John R Woodward; Jinxia Xie; Peng- Sheng Huang; Luyu Gao; Aman Madaan; Shuyan Zhou; Uri Alon; Ehsan Hosseini-Asl; Bryan Mccann; Chien-Sheng Wu; Semih Yavuz; Richard 2020 Socher; Junjie Huang; Chenglong Wang; Jipeng Zhang; Cong Yan; Haotian Cui; Jeevana Priya Inala; Colin Clement; Nan Duan; Jianfeng Gao; Sean Kandel; Andreas Paepcke; Joseph Hellerstein; Jeffrey Heer 2011 Wrangler; Shubhra ( Santu; ) Karmaker; Micah J Hassan; Lei Smith; Chengxiang Xu; Kalyan Veeramachaneni Zhai; Thomas Kluyver; Benjamin Ragan-Kelley; Fer- Nando Pérez; Brian Granger; Matthias Bussonnier; Jonathan Frederic; Kyle Kelley; Jessica Hamrick; Jason Grout; Sylvain Corlay; Paul Ivanov; Damián Avila; Safia Abdalla; Yuhang Lai; Chengxi Li; Yiming Wang; Tianyi Zhang; Scott Wen; Daniel Yih; Sida Fried; Tao Wang;  Yu; Chia-Hsuan Lee; Oleksandr Polozov; Matthew Richardson;  Kaggledbqa; Zi Lin; Jeremiah Liu; Jingbo Shang;  Neural; Reginald Long; Panupong Pasupat; Arpit Narechania; Arjun Srinivasan; John T Stasko;  Nl4dv; Alfredo Nazabal; Christopher K I Williams; Gio- Vanni Colavizza; Camila Rangel Smith; Erik Nijkamp; Bo Pang; Hiroaki Hayashi; Lifu Tu; Huan Wang; Yingbo Zhou; Silvio Savarese; Anders Andreassen; Guy Gur-Ari; David Bieber; Aitor Lewkowycz; David Luan; David A Patterson; Joseph Gonzalez; Quoc V Le; Chen Liang; Lluís-Miquel Munguía; Daniel Rothchild; David R So; Jianlin Su; Yu Lu; Shengfeng Pan; Bo Wen; Yunfeng Liu;  Roformer; April Yi Wang; Dakuo Wang; Jaimie Drozdal; Michael Muller; Soya Park; Justin D Weisz; Xuye Liu; Lingfei Wu; Casey Dugan;  Documen; Yu Feng; Rastislav Bodik; Josh Andres; Erick Oduor;  Autods; Vera Liao; Yunfeng Zhang; Udayan Khurana; Horst Samulowitz; Lisa Amini; Jason Wei; Xuezhi Wang; Dale Schuurmans; Ed Chi; Zhengkai Wu; Vu Le; Ashish Tiwari; Sumit Gulwani; Arjun Radhakrishna; Ivan Radicek; Gustavo Soares; Chen Henry Wu; Torsten Scholak; Michihiro Yasunaga; Chien-Sheng Wu; Ming Zhong; Vic- Tor Zhong; Bailin Wang; Chengzu Li; Connor Boyle; Ansong Ni; Ziyu Yao; Lingpeng Kong; Rui Zhang; Noah A Smith; Yunyi Yang; Yunhao Li; Xiaojun 2020 Quan; Tao Yu; Yang Er; Suyi Li; Eric Xue; Victoria Xi; Yi Chern Lin; Tianze Tan; Zihan Shi; Youxuan Li; Michihiro Jiang; Sun- Grok Yasunaga; Tao Shim; Alexander R Chen; Zifan Fabbri; Luyao Li; Yuwen Chen; Shreya Zhang; Vincent Dixit; Caiming Zhang; Richard Xiong; Walter S Socher; Dragomir R Lasecki;  Radev;  Cosql; Yi Chern Tan; Victoria Lin; Irene Z Li; Tao Chen; Emily Ji; Shreya Dixit; David Proctor; Sungrok Shim; Jonathan Kraft; Vin- Cent Zhang; R 2019b Radev,"Computational notebooks, such as Jupyter notebooks, are interactive computing environments that are ubiquitous among data scientists to perform data wrangling and analytic tasks. To measure the performance of AI pair programmers that automatically synthesize programs for those tasks given natural language (NL) intents from users, we build ARCADE, a benchmark of 1,078 code generation problems using the pandas data analysis framework in data science notebooks. AR-CADE features multiple rounds of NL-to-code problems from the same notebook. It requires a model to understand rich multi-modal contexts, such as existing notebook cells and their execution states as well as previous turns of interaction. To establish a strong baseline on this challenging task, we develop PACH-INCO, a 62B code language model (LM) for Python computational notebooks, which significantly outperforms public code LMs. Finally, we explore few-shot prompting strategies to elicit better code with step-by-step decomposition and NL explanations, showing the potential to improve the diversity and explainability of model predictions. ARCADE is publicly available at https://github.com/ google-research/arcade-nl2code/.",,"['Introduction', 'Problem Statement', 'ARCADE: A Benchmark of pandas', 'Creating Notebooks for Novel ML Datasets', 'Dataset Analysis', 'Evaluation by Fuzzy Output Matching', 'PACHINCO: Adapting Code LMs to Computational Notebooks', 'LM Prompting Strategies', 'Main Results', 'Few-shot Prompting Results', 'Step-by-Step Prompting Diversifies Solutions', 'Case Study: How Useful is Predicted', 'Related Work', 'Conclusion', 'Limitations', 'Supplementary Materials A Details of Dataset Construction', 'A.1 Mining Examples from Existing Notebooks', 'A.2 Creating Notebooks with Examples from Scratch', 'A.3 Annotation Process and Quality Assurance', 'B Outline of ARCADE Annotation Guideline', 'For each code snippet identified in', 'What Tasks to Create', 'Complexity of Tasks', 'C Descriptions of Existing Data Science Code Generation Dataset', 'D Details of Fine-tuning PACHINCO', 'E Inference Setup', 'F CODEGEN Scaling Curve on ARCADE', 'G Break-down Analysis of pass@k on ARCADE', 'H Additional Few-shot Prompting Results', 'I Further Analysis of Solution Diversity', 'J Error Analysis J.1 Summary of Error Types', 'J.2 Case Study', 'Case Study for Executable but Incorrect Predictions', 'K Data Card for the Training Data of PACHINCO', 'Motivation', 'Composition', 'Is any information missing from individual instances?', 'Collection Process', 'Preprocessing, cleaning, and labeling', 'Uses', 'Distribution', 'Acknowledgements', '']"
Program Chairs' Report on Peer Review at ACL 2023,Anna Rogers; Marzena Karpinska ~jordan Boyd-Graber; Naoaki Okazaki,"We present a summary of the efforts to improve conference peer review that were implemented at ACL'23. This includes work with the goal of improving review quality, clearer workflow and decision support for the area chairs, as well as our efforts to improve paper-reviewer matching for various kinds of nonmainstream NLP work, and improve the overall incentives for all participants of the peer review process. We present analysis of the factors affecting peer review, identify the most problematic issues that the authors complained about, and provide suggestions for the future chairs. We hope that publishing such reports would (a) improve transparency in decision-making, (b) help the people new to the field to understand how the *ACL conferences work, (c) provide useful data for the future chairs and workshop organizers, and also academic work on peer review, and (d) provide useful context for the final program, as a source of information for meta-research on the structure and trajectory of the field of NLP.",,"['Introduction', 'Tracks and Acceptance Statistics', 'Resubmissions', ""Authors and Reviewers at ACL'23"", 'Efforts towards improving review quality', 'Reviewer training', 'ACL paper-reviewer matching: Area-Contribution-Language', 'Review issue flagging', 'Reviewer discussion', 'Improving decision support for the chairs', 'Updated SAC and AC guidelines', 'Support for checking assignments', 'Paper-reviewer match rationales', 'Soundness/Excitement scores', 'What Factors Contribute to ACL Peer Review Outcome?', 'Review Scores: Overall Distribution', 'The Impact of Other Submission Properties', 'Variable Importance', 'Short/long papers', 'Types of contribution', 'How Much do ACL Reviewers Agree?', '26', 'Analysing Reviews and Review Scores', 'Do the Area-Contribution-Language matches impact reviewer scores?', 'Do the Area-Contribution-Language matches impact the reviewer activity?', 'Do reviewer confidence scores reflect their experience?', 'Do the reviewer scores correlate with length of the reviews?', 'What factors are associated with review issues?', 'Do we have bad actors?', 'Can the reviewers tell who the authors are?', 'Ethics review', 'Best paper selection', 'Improving Incentives for Reviewers: Reviewer Awards', 'Improving Incentives for Chairs: Peer Review Reports', 'Recommendations', '', '']"
