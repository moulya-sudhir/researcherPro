{
    "A Comparative Study on Textual Saliency of Styles from Eye Tracking, Annotations, and Language Models": {
        "authors": "Karin De Langis; Dongyeop Kang",
        "pub_date": "",
        "abstract": "There is growing interest in incorporating eyetracking data and other implicit measures of human language processing into natural language processing (NLP) pipelines. The data from human language processing contain unique insight into human linguistic understanding that could be exploited by language models. However, many unanswered questions remain about the nature of this data and how it can best be utilized in downstream NLP tasks. In this paper, we present eyeStyliency, an eye-tracking dataset for human processing of stylistic text (e.g., politeness). We develop a variety of methods to derive style saliency scores over text using the collected eye dataset. We further investigate how this saliency data compares to both human annotation methods and model-based interpretability metrics. We find that while eyetracking data is unique, it also intersects with both human annotations and model-based importance scores, providing a possible bridge between human-and machine-based perspectives. We propose utilizing this type of data to evaluate the cognitive plausibility of models that interpret style. Our eye-tracking data and processing code are publicly available. 1  ",
        "sections": [
            {
                "heading": "Introduction",
                "text": [
                    "Human perception and understanding of text is critical in NLP. Typically, this understanding is leveraged in the form of ground-truth human annotations in supervised learning pipelines, or in the form of human evaluations of generated text. However, human language understanding is complex; multiple cognitive processes work together to enable reading, many of which occur automatically and unconsciously (DeVito, 1970).",
                    "Because of the complexity, disciplines concerned with understanding and modeling how humans read -e.g., psycholinguistics and cognitive science -heavily utilize implicit measures of the Figure 1: Salient words for impoliteness from three different perspectives. We find that eye tracking data contains some overlap between machine and human-annotated salience.",
                    "human reading experience that capture signals from these automatic processes in real time. Examples of implicit measures include event-related potential, reaction times, and eye movements. In contrast, explicit measures include surveys and other methods that directly ask people to report their perceptions and experiences. We posit that traditional NLP pipelines, which have widely used explicit measures of human understanding, can also benefit from implicit measures. In this paper, we focus specifically on the use of eye movements as an implicit measure of textual saliency.",
                    "Recent research in NLP has demonstrated the feasibility of incorporating various types of eye movement data into NLP models in order to improve performance on a number of tasks (see Table 2 for an overview). However, this is still an underexplored area: best practices remain unclear, and it's not obvious whether there are tasks that are unsuitable for eye movement data, or how eye movement data should be balanced with traditional annotation data. In this work, we address two main research questions: RQ1: Does eye-tracking-based saliency meaningfully differ from simply gathering word-level human annotations, or from modelbased word importance measures? RQ2: How can we measure eye movements specific to a high-level textual feature like style, and which eye tracking metrics and data processing methods are best suited to capturing textual saliency?",
                    "To address these questions, we conduct an eye tracking case study in which participants read texts the HummingBird dataset (Hayati et al., 2021). We choose this dataset because it contains lexicallevel human annotations indicating which words contribute to the text's style and because its domain (textual styles) has not to our knowledge been widely explored for eye tracking applications -although prior work investigates eye tracking and sentiment analysis, it does not extend to other linguistic styles such as politeness.",
                    "We collect style-specific eye movements through a carefully designed experiment (see Section 3 for details), and we use these eye movements to derive saliency scores over the text. We compare this eye-based saliency to human annotations as well as two large language model (LLM)-derived importance scores: integrated gradient scores from a BERT model fine-tuned on style datasets (Hayati et al., 2021), and word-surprisal scores from GPT-2 (Radford et al., 2019) (see Figure 1 for an example). Our findings indicate that eye-trackingbased saliency highlights some unique areas of the text, but it also intersects with both saliency from model-based metrics and saliency from human annotations, making a bridge of sorts between the human-and machine-based perspectives. We discuss some implications of these findings for NLP research.",
                    "Specifically, our contributions are:",
                    "\u2022 An experimental paradigm for obtaining eye tracking-based signals for specific features of text (in our case, textual style). \u2022 A first-of-its-kind eye movement dataset on style saliency, collected from 20 participants and consisting of both control readings and style-focused readings for polite, impolite, positive, and negative textual styles. \u2022 An illustration of the distinction between this dataset's explicit human annotations and implicit human eye data through a unique comparison between salient text obtained via annotation and via eye tracking."
                ],
                "publication_ref": [
                    "b7",
                    "b11",
                    "b11",
                    "b27"
                ],
                "figure_ref": [
                    "fig_4",
                    "fig_4"
                ],
                "table_ref": []
            },
            {
                "heading": "Related Work",
                "text": [
                    "Eye tracking has been a staple of psycholinguistic investigations of reading for decades (Rayner, 1978;Just and Carpenter, 1980). Eye movement data is compelling because it provides realtime information about how people process language in a natural, ecologically valid setting (i.e., there is no Most prior research has focused on either (a) comparing and contrasting eye movements with various models' attention mechanisms, or (b) using eye movements for multi-task learning, where NLP task performance can be improved by a model that jointly learns to predict eye movements in addition to the relevant NLP task. To our knowledge, there have not been three-way comparisons between attention mechanisms from eye tracking, large language models, and manual human annotations.",
                    "explicit experimental task, such as question answering, for participants to complete) (Kaiser, 2013).",
                    "Eye data provides insight into cognitive processes through the eye-mind assumption, which posits that (1) our eyes fixate on whatever our brains are currently processing, and (2) as cognitive effort to process an item increases, the amount of time that the eyes fixate on that item also increases (Just and Carpenter, 1980). Analysis of eye data under this framework has led to important insights into many unconscious phenomena in human language comprehension, e.g. the mechanisms involved in ambiguity resolution during reading (Traxler and Frazier, 2008).",
                    "Eye Tracking in NLP. Due to the eye-mind assumption, eye-tracking data is particularly wellsuited to inferring patterns of reader attention, or saliency, over text. This saliency information has so far shown promising results when integrated into NLP models for question answering (e.g. Malkin et al. (2022); Sood et al. (2020a); Malmaud et al. (2020)). However, this is still a developing research area: there is limited available data, and there is little consensus regarding how to effectively collect data and incorporate it into NLP pipelines. To our knowledge there is no previous research that investigates saliency for style via eye tracking, nor any previous research that compares saliency from eye tracking to human annotations (Table 1 compares our work with the prior work).",
                    "Outside of textual saliency, eye-tracking data has been leveraged for a variety of NLP tasks. Mishra et al. (2013) quantify the difficulty of sentences in machine translation tasks using eye movement data; Mishra et al. (2016) determine whether a reader understands sarcasm in text, and S\u00f8gaard (2016) evaluate the quality of word embeddings and text generations, respectively. Other work uses existing datasets, sometimes augmenting the data with a learned gaze predictor model, and uses this eye movement data as an additional signal when training models for various NLP tasks, including named entity recognition (Hollenstein et al., 2019;Tokunaga et al., 2017), paraphrasing (Sood et al., 2020b), part-of-speech tagging (Barrett et al., 2018), and sentiment analysis (see also Mathias et al. (2020) for a review).",
                    "Saliency in Linguistic Styles. People apply styles to language in order to express attitudes, reflect interpersonal intentions or goals, or convey social standings of the speaker or listener. (Note that while many sociolinguistics theories distinguish between textual style and textual attributes, in this work, we follow the common convention in recent NLP papers of broadly using 'style' to encompass both of these ideas (Jin et al., 2022).) The meaning expressed by textual styles can be significant; in fact, there is strong evidence that effective communication requires an understanding of both style and literal semantic meaning (Hovy, 1987). Although BERT (Devlin et al., 2018) based fine-tuned models show strong performance on style classification, there are notable differences between how BERT perceives style at the lexical level and how humans perceive it, and that using data about these differences during training improves model performance (Hayati et al., 2023)."
                ],
                "publication_ref": [
                    "b28",
                    "b16",
                    "b17",
                    "b16",
                    "b37",
                    "b21",
                    "b33",
                    "b22",
                    "b24",
                    "b25",
                    "b32",
                    "b13",
                    "b36",
                    "b34",
                    "b1",
                    "b23",
                    "b15",
                    "b14",
                    "b8",
                    "b12"
                ],
                "figure_ref": [],
                "table_ref": [
                    "tab_0"
                ]
            },
            {
                "heading": "eyeStyliency: A Dataset of Eye Movement for Textual Saliency",
                "text": [
                    "We describe the data collection procedure for eye-Styliency dataset from 20 participants and methods for computing saliency scores over text."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Data Setups",
                "text": [
                    "Our dataset consists of items from the Hummingbird dataset (Hayati et al., 2021) in the following stylistic categories: polite, impolite, positive sentiment, and negative sentiment. 2 We chose this subset because of the small correlation between categories (other categories, e.g. anger, disgust, and negative sentiment are all highly correlated). In this study, we limit participants' total time commitment to one hour. To achieve this, the dataset size is 90 items across the four style categories. (The average word count per item in the dataset is 21.6 overall; for the impolite, polite, negative, and positive styles average word count is 21.3, 22.8, 21.4, and 20.8, respectively.) Most participants finished the experiment in 40-60 minutes, depending on both the individual's reading speed and the time needed to calibrate the individual to the eye tracker."
                ],
                "publication_ref": [
                    "b11"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Eye-Tracking Measures",
                "text": [
                    "Monocular eye movement data is collected with an EyeLink 1000 Plus 3 at a rate of 1000Hz. We look at the following eye-tracking metrics:",
                    "\u2022 First Fixation Duration (FFD): The duration of the first fixation in an interest area. \u2022 First Run Dwell Time (FRD): The time interval beginning with the first fixation in the interest area and ending when the eye exits an interest area (whether to the right or left). \u2022 Go Past Time (GP): The time interval beginning with the first fixation in an interest area and ending when the eye exits the interest area to the left (i.e., to reread). \u2022 Dwell Time (DT): The total fixation duration for all fixations in an interest area. Also known as gaze duration. \u2022 Reread Time (RR): The total fixation duration for all fixations in an interest area after the area has already been entered and exited once. \u2022 Pupil Size (PS): The average pupil size over all fixations in an interest area.",
                    "(Note that First Run Dwell Time + Reread Time = Dwell Time.) These measures can broadly be categorized into early measures (first fixation duration, pupil size) that reflect more low-level reading processes and",
                    "Applications N FFD FC FRD DT RR RC PL eyeStyliency (Ours) Textual Style 20 \u2713 \u2717 \u2713 \u2713 \u2713 \u2717 \u2713 Kuribayashi et al. (2021) Language model perplexity \u2717 \u2717 \u2717 \u2717 \u2713 \u2717 \u2717 \u2717 Malmaud et al. (2020) Question Answering 269 \u2717 \u2717 \u2717 \u2713 \u2717 \u2717 \u2717 Bolotova et al. (2020) Question Answering 20 \u2717 \u2713 \u2717 \u2713 \u2713 \u2717 \u2717 Sood et al. (2020b) Paraphrasing \u2717 \u2717 \u2713 \u2717 \u2717 \u2717 \u2717 \u2717 Sood et al. (2020a) Question Answering 23 \u2717 \u2717 \u2717 \u2713 \u2717 \u2717 \u2717 Hollenstein et al. (2019) NER, Sentiment/Relation Classification \u2717 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 Barrett et al. (2018) PoS tagging \u2717 \u2713 \u2717 \u2717 \u2713 \u2713 \u2713 \u2717 Tokunaga et al. (2017) Named entity recognition (NER) \u2717 \u2717 \u2717 \u2717 \u2713 \u2717 \u2717 \u2717 Mishra et al. (2016) Sarcasm detection 7 \u2717 \u2717 \u2717 \u2713 \u2717 \u2717 \u2717 Klerke et al. (2015) NLG evaluation 24 \u2717 \u2713 \u2717 \u2713 \u2713 \u2713 \u2713 Green (2014) Phrase-structure parsing 40 \u2717 \u2717 \u2717 \u2717 \u2713 \u2717 \u2717",
                    "Table 2: A comparison of prior works with respect to the eye tracking metrics studied, data processing techniques, and number of participants whose eye tracking data is collected. FFD = first fixation duration, FC = fixation count, RC = regression count, RR = reread time, PL = pupil size, N = number of participants if new eye data collected. late measures (go past time, dwell time, reread time) that reflect higher-level processing and meaning integration (Conklin et al., 2021). Previous eye tracking applications for NLP have commonly used dwell time, but a variety of measures have been examined (see Table 2). In this study, we aim to compare a wide variety of measures in order to estimate which may be best-suited to capturing textual saliency. Note that to avoid redundancy, we chose to omit fixation counts from our analysis after finding high correlations between this measure and dwell time (pearson's r = 0.93, p < 0.01).",
                    "We also chose to omit regression counts from our analysis after finding that regression counts were extremely sparse -specifically, 1.8% of the dataset had a non-zero regression count."
                ],
                "publication_ref": [
                    "b5"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Experimental Procedure",
                "text": [
                    "The experiment follows a between-subjects, blocked design. The key part of our experiment is the technique to isolate eye movements that are specifically relevant to the text's style. In order to do this, we inform participants at the beginning of each block that the block will contain only stimuli that share a style (polite, impolite, positive, or negative) and source (Twitter, IMdB, or Stack Exchange/Wikipedia forums) -but in fact, we will occasionally present an incongruent style in the block (e.g., present an impolite Tweet during the polite Tweet block). We expect that incongruency to cause readers to pay more attention to stylespecific aspects of the text, as they are unexpected. We are interested in comparing the eye movements of participants who read a stimulus in the congruent condition with those of participants who read that stimulus in the incongruent condition. Note that the experiment has a between-subjects design, i.e. the same participant does not see the same text in both conditions. The congruent reading of the text provides a control. Figure 2 shows a concrete example of these two conditions, while Figure 3 shows a visualization of these contrasted eye movements.",
                    "Figure 4 shows a procedure of our experiments. The experimental procedure is as follows (more details in Appendix A). Participants complete nine blocks. At the beginning of block, the participant is informed of the style and source, and asked to pay attention to the style of the following texts. Each block contains 10 items, eight of which are congruent with the target style. The remaining two items are incongruent with the target style. Incongruent items are counterbalanced across participants. Blocks are presented in a random order, and items within the blocks are pseudorandomized to ensure adequate spacing between congruent and incongruent trials (Egner, 2007) (there is also a context-free text as an added control). Participants are asked True/False comprehension questions pseudorandomly after 30% of the items in order to maintain motivation to read carefully. After the experiment concludes, participants complete the Perceived Awareness of Research Hypothesis Scale (PARH) (Rubin, 2016) to evaluate whether demand characterstics (Nichols and Maner, 2008) of the experiment may have influenced reading behavior. The study procedure was approved by the"
                ],
                "publication_ref": [
                    "b9",
                    "b29",
                    "b26"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Congruent Setup",
                "text": [
                    "A densely constructed, highly referential film, and an audacious return to form that can comfortably sit among Jean-Luc Godard's finest work."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Incongruent Setup Context",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Stimuli",
                "text": [
                    "Watching its rote plot points connect is about as exciting as gazing at an egg timer for 93 minutes. "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Eye-based saliency",
                "text": [
                    "The following movie reviews were written by critics who disliked the film.",
                    "The following movie reviews were written by critics who liked the film.",
                    "incongruent gaze congruent gaze (control) Figure 2: Illustrative example of congruent vs incongruent presentation of the same stimulus. We rely on expectation effects to induce participants to attend to the unexpected style (in this case, positive sentiment); in other words, we assume that the surprise regarding the style will result in longer gaze durations for words that contribute to the perception of that style -in this case, words relating to positive sentiment.",
                    "institutional review board (IRB).",
                    "Participants We collect data from 20 participants (12 male, 7 female, 1 non-binary; median age 23 years) recruited from the University community and word-of-mouth. An additional 6 participants were recruited but unable to complete the study due to problems with eye calibration. Participants were compensated with a $15 Amazon gift card.",
                    "Apparatus Monocular eye movement data is collected with an EyeLink 1000 Pro, using the desktop mount, at a rate of 1000Hz. Participants use a chinrest while reading in order to stabilize the head. We use the Experiment Builder software to present stimuli to participants in a 16pt serif font with 1.5 line spacing, on our display monitor with a 508mm display area and a 1680x1050 resolution. Participants are seated with their eyes 50-60cm away from the display monitor.",
                    "Study Design Rationale Based on the welldocumented phenomenon of expectancy effects in cognition (see Schwarz et al. (2016) for further discussion), we assume that the incongruent texts that subvert the stylistic expectation will lead to participants reacting with surprise and increased processing difficulty in response to parts of the text associated with the unexpected style.",
                    "Alternative designs that explicitly ask participants to classify an item's style were strongly considered, but were rejected for two reasons: first, we are interested in observing a relatively natural read- ing process and introducing a classification task runs counter to that goal; second, the style classification task could increase the saliency of not only the target style but also its opposing style, as both can be relevant to the decision (e.g., the presence of an impolite word is relevant to the decision of whether a statement is polite). We also considered designs in which congruency is established via explicit text labels rather than implicit expectations, but decided to instead choose an experimental paradigm that adheres as closely as possible to an ecologically valid reading task."
                ],
                "publication_ref": [
                    "b30"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Pre-processing Eye Tracking Data",
                "text": [
                    "Eye data was delineated into fixations and saccades using the DataViewer software with EyeLink's standard algorithm and default velocity and acceleration thresholds. We further cleaned the data by removing trials with significant track loss (i.e. trials with track loss in over 50% of the text area); 1.5% of trials were removed due to track loss. An outlier analysis showed that 0.5% of fixations were outliers and were removed in our analysis."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Calculating Saliency Scores",
                "text": [
                    "We divide the text into interest areas (IAs) and calculate saliency scores for each IA. We do not segment the IAs such that each IA contains a single word, because in a single fixation people can read a span of about 21 surrounding characters (Rayner, 1978), meaning that many short words are not fixated on, leading to difficulties with our desired analyses. Instead, we use the natural language processing toolkit (NLTK)'s stopwords list (Bird et al., 2009) to define each IA such that stopwords share an IA with the closest non-stopword. Specifically, each stopword is combined with the closest nonstopword, with non-stopwords to the right being preferred in the case of a tie. We also ensure that no IA contains a line break. We utilize two techniques for calculating each eye tracking-based metric for each IA i . Note that these techniques are applied across all eye tracking measures x \u2208 {DT, FRD, GP, DT, RR, PS} as defined in Section 3.2.",
                    "\u2022 z-score: For each participant p k , denote the eye tracking measurement in IA i as x ki . We calculate the participant-specific z-score of eye tracking measurement from IA i as z k (IA i ) =",
                    "x ki \u2212\u00b5 k \u03c3 k , where \u00b5 k and \u03c3 k are the participantspecific arithmetic mean and standard deviation, respectively. Then, the saliency score for IA i is given by 4 Experimental Results"
                ],
                "publication_ref": [
                    "b28",
                    "b2"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Comparison with Other Saliency Metrics",
                "text": [
                    "We investigate how eye tracking metrics compare with other existing measures for lexical-level significance -namely, human annotations, integrated gradient scores, and large language model surprisal scores (see Figure 5 for a visualization of these scores):",
                    "\u2022 Surprisal scores: For the text in the i th interest area, denoted IA i , the surprisal is P (IA i |IA 0 , IA 1 , ...IA i\u22121 ). We obtain this probability estimate from the pre-trained GPT-2 model (Radford et al., 2019). 4 In the event that an IA includes multiple tokens, we sum the surprisal of those tokens. \u2022 Model gradient scores: The integrated gradient method (Sundararajan et al., 2017) is often used to obtain scores over the input tokens to a deep neural network, where a token's score reflects how much that token influenced the network's final output. We obtain these scores with the Captum codebase (Kokhlikyan et al., 2020), using the fine-tuned BERT model from Hayati et al. (2021). For IA i , the integrated gradient score is the average of the individual tokens within IA i . \u2022 Human annotations: Human annotations come from the Hummingbird dataset (Hayati et al., 2021). Three annotators per item were asked to highlight words that contribute to the text's style. We averaged these binary highlighting scores over each annotator to arrive at a saliency score for each interest area.",
                    "Throughout the comparison, we answer the following two questions: How much do the salient IAs derived from each measure overlap and how much does each measure agree on the saliency strength of each IA?",
                    "To find the overlap between salient interest areas derived from different measures, we compute a binary saliency map over the dataset for each measure. We then compute the pairwise Jaccard similarity coefficient for each possible pairing of salient text sets (Fig 6), where the Jaccard similarity coefficient is their intersection over union. We use the median saliency score as the threshold that determines whether the IA is labeled \"salient\" so that each measure results in the same number of salient words, allowing a more straightforward comparison between measures.",
                    "We find that the intersection over union of salient interest areas from eye tracking methods and both integrated gradient scores and human annotations falls between 0.26 and 0.31. Critically, the threeway intersection over union between salient text from integrated gradients, human annotations, and eye tracking metrics falls between 0.05 and 0.06, indicating that each metric captures a relatively unique set of text within the dataset (see Fig 7).",
                    "We also investigate what types of words are selected as salient by each method by performing part-of-speech (POS) tagging on the salient interest areas for each measure, finding that while distributions of parts of speech are similar, humans select proportionally more adjectives while eye tracking metrics select proportionally more verbs and adverbs (Figure 9). This discrepancy may be explained by human annotators focusing more on single words with high stand-alone style (oftentimes these are adjectives such as happy, gracious), while people's eyes attend to the context surrounding that word (oftentimes this context includes verbs and adverbs). For example, in the polite phrase \"Thank you for removing...,\" human annotators highlight   It's one of those baseball pictures where the hero is stoic, the wife is patient, the kids are as cute as all get-out and the odds against success are long enough to intimidate, but short enough to make a dream seem possible.",
                    "It's one of those baseball pictures where the hero is stoic, the wife is patient, the kids are as cute as all get-out and the odds against success are long enough to intimidate, but short enough to make a dream seem possible.",
                    "It's one of those baseball pictures where the hero is stoic, the wife is patient, the kids are as cute as all get-out and the odds against success are long enough to intimidate, but short enough to make a dream seem possible.",
                    "It's one of those baseball pictures where the hero is stoic, the wife is patient, the kids are as cute as all get-out and the odds against success are long enough to intimidate, but short enough to make a dream seem possible.   only \"thank you\" whereas eye gaze also focuses on the gerund verb \"removing.\"",
                    "To measure agreement between different measures with respect to saliency strength, we compute a saliency score for each IA in the dataset derived from each measure. We then compute the pairwise Pearson's r correlation coefficient, finding most coefficients are near 0 (see Appendix). In other words, while there is some agreement across human-, machine-, and eye-based methods with respect to which IAs are above median saliency, there is little correlation with respect to the saliency scores themselves."
                ],
                "publication_ref": [
                    "b27",
                    "b35",
                    "b19",
                    "b11",
                    "b11"
                ],
                "figure_ref": [
                    "fig_11"
                ],
                "table_ref": []
            },
            {
                "heading": "Qualitative Results",
                "text": [
                    "For a qualitative visualization of saliency over the politeness style, see Figure 8. In general, human annotations have a tendency to focus on segments of text with clear style markers. For instance, phrases such as \"please\" are consistently highlighted by human annotators. Our eye tracking data indicates that these phrases do not reliably draw the reader's gaze during the realtime reading process. We notice that the eyes often focus on the object of the politness marker rather than the politeness marker itself: For instance, the polite text \"Thank you for your kind comment,\" human annotators highlight only \"thank you\" whereas gaze data focuses on \"your kind comment.\"   We also observe that eye data, and in particular dwell time, shows high attention to certain nouns -i.e., names, usernames, and movie titles. This cannot be explained by word frequency effects, as participants in the control condition did not spend as long attending to these nouns."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_10"
                ],
                "table_ref": []
            },
            {
                "heading": "\"Eye-in-the-loop\" few-shot learning",
                "text": [
                    "We utilize \"eye-in-the-loop\" few-shot learning in order to roughly probe the cognitive plausibility of GPT-3 (Brown et al., 2020). Our prompts present a classification task and include zero to four examples from our dataset, including an \"important words\" section that contains the salient text as defined by each eye-tracking measure, human annotations, and integrated gradient scores (see Section 3.5 for details). As a baseline, we omit the \"important words.\" We expect that if GPT-3 has a particularly strong cognitive understanding of style   processing, \"important words\" from eye movement data may improve its task performance (in these experiments, we use the text-davinci-002 model).",
                    "Results are relatively inconsistent across each of the four shots, but in most cases, it seems that including salient words has little effect on the model accuracy on the style classification task. A subset of the results are shown in Figure 10; see Appendix for full results and prompt details."
                ],
                "publication_ref": [
                    "b4"
                ],
                "figure_ref": [
                    "fig_12"
                ],
                "table_ref": []
            },
            {
                "heading": "Key Findings and Discussion",
                "text": [
                    "Here we discuss the relationship between our results and our research questions: RQ1: Does eye tracking data for saliency meaningfully differ from simply gathering word-level human annotations, or from model-based word importance measures? Our data show a substantial difference between eye-tracking-based saliency, model-based saliency, and human annotations. It is perhaps unintuitive that reading behavior would differ from self-reports after reading, but this is consistent with findings in psycholinguistics that establish strong distinctions between explicit measures (i.e., human annotations) and implicit measures (i.e., eye tracking) of human language processing. Interestingly, there is some intersection between eye tracking-based saliency and model-based saliency that is not shared with human annotators. This suggests that some automatic aspects of human language processing, accessible through eye tracking but not necessarily survey methods, may be shared with large language models.",
                    "RQ2: How can we measure eye movements specific to a high-level textual feature like style, and which eye tracking metrics and data processing methods are best suited to capturing textual saliency? The results from our experiment indicate that our experimental paradigm exploiting congruency effects may be effective in finding eye movements specific to certain text features. In a linear mixed effect model analyzing the data, we find significant effects of the congruency condition on dwell time and pupil size (see Appendix A.2). This suggests that the congruency effect does impact reading patterns -whether this impact is directly linked to the textual style is difficult to definitively answer, but given the overlap between eye-tracking-based style saliency and other style saliency measures, it seems reasonable to believe that the experimental manipulation resulted in an implicit measure of style perception. Experiments based on congruency effects may be a promising route for capturing eye movements related to other high-level textual features such as sarcasm and metaphor. We find that dwell time appears to be the strongest eye-tracking metrics for capturing textual saliency, as it has both the highest overlap with human-and machine-based saliency and most strongly responded to the experimental manipulation. Using the same criteria, we also find that using participant-level z-scores to represent the eye movement data yields the best results."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Limitations",
                "text": [
                    "In this exploratory study, our dataset and sample size are both small, limiting the possibilities for a more thorough evaluation of the data e.g. by fine-tuning a language model. We also note that by design, our experiment presents incongruent items rarely, and consequently we have considerably more congruent datapoints than incongruent datapoints -an inherent limitation of the proposed experimental paradigm. In light of our results, which suggest that eye-tracking data contains useful and unique information, we plan to develop methods for collecting this kind of real-time human reading data at scale -i.e., without the constraints of costly in-person eye tracking -in future work.",
                    "Finally, eye tracking analysis in general is limited by the eye-mind assumption, which holds that the eye fixates on what the mind is currently processing. While there is strong evidence supporting the eye-mind assumption during reading, there is a notable exception: retrieval processes (i.e. accessing memory) are not reflected in eye movements (Anderson et al., 2004).  pupil size 1 0.17 1 0.058 0.038 1 -0.0055-0.013 0.064 1 -0.019 -0.042 0.04 0.19 1 -0.027 -0.034 0.041 0.23 0.98 1 -0.056 0.015 0.038 0.22 -0.012 0.14 1 -0.037 -0.035 0.065 0.076 0.01 0.046 0.28 1 -0.019 -0.053 -0.066 -0.072 -0.021 -0.023 -0.031 -0.013 1 "
                ],
                "publication_ref": [
                    "b0"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Acknowledgements",
                "text": [
                    "We would like to thank Jeffrey Bye, Andrew Elfenbein, Charles Fletcher, Shirley Hayati, Brooke Lea, Andreas Schramm, and Mariya Toneva for their valuable feedback and insightful suggestions regarding the experimental procedure and data analysis. We would also like to thank Miguel Miguelez Diaz, Risako Owan, Faziel Khan, and Josh Spitzer-Resnick for testing and critiquing the initial experimental pipeline. This research received funding from the Sony Research Innovation Award."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A Appendix",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.1 Experimental Materials",
                "text": [
                    "The following materials were presented to participants during the experiment. Informed consent was obtained from each participant before the experiment began. Instructions were displayed as shown in Figure 11.",
                    "The practice items, which participants completed after reading the instructions and before beginning the experiment, were as follows: See also Figure 11 for screenshots of the display shown to participants at various points in the experiment."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.2 Mixed Effect Modeling",
                "text": [
                    "We fit linear mixed effect models to predict our eye tracking measures, using the R packages lme4 and lmetest. Our fixed effects are the number of characters in the interest area, the HAL frequency of the interest area, whether the previous interest area was viewed, and whether the interest area is in the congruent or incongruent condition. Our random effect is the participant ID. All variables are normalized prior to analysis.",
                    "The Dwell Time and Pupil Size eye tracking measure showed significance for the the fixed congruency effect. The other eye tracking measures -First Run Dwell Time, First Fixation Duration, Reread Time, and Go Past Time -result in a singular fit, likely because they are considerably more sparse (i.e., many interest areas have a null values for these metrics).  We tested variables for collinearity using the variance inflation factor (VIF) (Zuur et al., 2010) (none exceeded the recommended threshold of 3)."
                ],
                "publication_ref": [
                    "b39"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.3 Additional Saliency Comparisons",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.3.1 Saliency Scores",
                "text": [
                    "Figure 12 shows the Pearson's r value for saliency score over interest areas derived from each method. We also include more example items from the dataset with associated saliency scores in Figure 5b."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.4 Few-Shot Learning Experiment Details and Results",
                "text": [
                    "The full few-shot learning results can be found in Table 5. The experiment was conducted with the OpenAI API 5 completion endpoint and the following parameters: the text-davinci-002 model, a temperature of 0, and a top_p of 1. We generated in-context learning prompts over our dataset by including important words as follows: Table 5: Accuracy results on few-shot learning experiments over dataset. For 1-, 2-, and 4-shot learning, five different randomly selected prompts were chosen and the average accuracy is reported (the 95% confidence interval is reported in parentheses after the accuracy score)."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            }
        ],
        "references": [
            {
                "ref_id": "b0",
                "title": "Eye movements do not reflect retrieval processes: Limits of the eye-mind hypothesis",
                "journal": "Psychological Science",
                "year": "2004",
                "authors": "Dan John R Anderson; Scott Bothell;  Douglass"
            },
            {
                "ref_id": "b1",
                "title": "Sequence classification with human attention",
                "journal": "Association for Computational Linguistics",
                "year": "2018",
                "authors": "Maria Barrett; Joachim Bingel; Nora Hollenstein; Marek Rei; Anders S\u00f8gaard"
            },
            {
                "ref_id": "b2",
                "title": "Natural language processing with Python: analyzing text with the natural language toolkit",
                "journal": "Reilly Media, Inc",
                "year": "2009",
                "authors": "Steven Bird; Ewan Klein; Edward Loper"
            },
            {
                "ref_id": "b3",
                "title": "Do people and neural nets pay attention to the same words: Studying eye-tracking data for nonfactoid QA evaluation",
                "journal": "",
                "year": "2020",
                "authors": "Valeria Bolotova; Vladislav Blinov; Yukun Zheng; Bruce Croft; Falk Scholer; Mark Sanderson"
            },
            {
                "ref_id": "b4",
                "title": "Language models are few-shot learners",
                "journal": "",
                "year": "2020",
                "authors": "Tom Brown; Benjamin Mann; Nick Ryder; Melanie Subbiah; Jared Kaplan; Prafulla Dhariwal; Arvind Neelakantan; Pranav Shyam; Girish Sastry; Amanda "
            },
            {
                "ref_id": "b5",
                "title": "Meta-learning to compositionally generalize",
                "journal": "Long Papers",
                "year": "2021",
                "authors": "Henry Conklin; Bailin Wang; Kenny Smith; Ivan Titov"
            },
            {
                "ref_id": "b6",
                "title": "A computational approach to politeness with application to social factors",
                "journal": "ACL",
                "year": "2013",
                "authors": "Cristian Danescu-Niculescu-Mizil; Moritz Sudhof; Dan Jurafsky; Jure Leskovec; Christopher Potts"
            },
            {
                "ref_id": "b7",
                "title": "The Psychology of Speech and Language: An Introduction to Psycholinguistics. Random House",
                "journal": "",
                "year": "1970",
                "authors": "A Joseph;  Devito"
            },
            {
                "ref_id": "b8",
                "title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
                "journal": "",
                "year": "2018",
                "authors": "Jacob Devlin; Ming-Wei Chang; Kenton Lee; Kristina Toutanova"
            },
            {
                "ref_id": "b9",
                "title": "Congruency sequence effects and cognitive control",
                "journal": "Cognitive, Affective, & Behavioral Neuroscience",
                "year": "2007",
                "authors": "Tobias Egner"
            },
            {
                "ref_id": "b10",
                "title": "An eye-tracking evaluation of some parser complexity metrics",
                "journal": "",
                "year": "2014",
                "authors": "J Matthew;  Green"
            },
            {
                "ref_id": "b11",
                "title": "Does BERT learn as humans perceive? Understanding linguistic styles through lexica",
                "journal": "",
                "year": "2021",
                "authors": "Shirley Hayati; Dongyeop Kang; Lyle Ungar"
            },
            {
                "ref_id": "b12",
                "title": "Stylex: Explaining style using human lexical annotations",
                "journal": "",
                "year": "2023",
                "authors": "Kyumin Shirley Anugrah Hayati; Dheeraj Park; Lyle Rajagopal; Dongyeop Ungar;  Kang"
            },
            {
                "ref_id": "b13",
                "title": "Advancing NLP with cognitive language processing signals",
                "journal": "",
                "year": "2019",
                "authors": "Nora Hollenstein; Maria Barrett; Marius Troendle; Francesco Bigiolli; Nicolas Langer; Ce Zhang"
            },
            {
                "ref_id": "b14",
                "title": "Generating natural language under pragmatic constraints",
                "journal": "Journal of Pragmatics",
                "year": "1987",
                "authors": "Eduard Hovy"
            },
            {
                "ref_id": "b15",
                "title": "Deep learning for text style transfer: A survey",
                "journal": "Computational Linguistics",
                "year": "2022",
                "authors": "Di Jin; Zhijing Jin; Zhiting Hu; Olga Vechtomova; Rada Mihalcea"
            },
            {
                "ref_id": "b16",
                "title": "A theory of reading: From eye fixations to comprehension",
                "journal": "Psychological Review",
                "year": "1980",
                "authors": "A Marcel; Patricia A Just;  Carpenter"
            },
            {
                "ref_id": "b17",
                "title": "Experimental paradigms in psycholinguistics",
                "journal": "",
                "year": "2013",
                "authors": "Elsi Kaiser"
            },
            {
                "ref_id": "b18",
                "title": "Looking hard: Eye tracking for detecting grammaticality of automatically compressed sentences",
                "journal": "",
                "year": "2015",
                "authors": "Sigrid Klerke; Anders H\u00e9ctor Mart\u00ednez Alonso;  S\u00f8gaard"
            },
            {
                "ref_id": "b19",
                "title": "Captum: A unified and generic model interpretability library for pytorch",
                "journal": "",
                "year": "2020",
                "authors": "Narine Kokhlikyan; Vivek Miglani; Miguel Martin; Edward Wang; Bilal Alsallakh; Jonathan Reynolds; Alexander Melnikov; Natalia Kliushkina; Carlos Araya; Siqi Yan"
            },
            {
                "ref_id": "b20",
                "title": "Lower perplexity is not always human-like",
                "journal": "Long Papers",
                "year": "2021",
                "authors": "Tatsuki Kuribayashi; Yohei Oseki; Takumi Ito; Ryo Yoshida; Masayuki Asahara; Kentaro Inui"
            },
            {
                "ref_id": "b21",
                "title": "Boosting coherence of language models",
                "journal": "",
                "year": "2022",
                "authors": "Nikolay Malkin; Zhen Wang; Nebojsa Jojic"
            },
            {
                "ref_id": "b22",
                "title": "Bridging information-seeking human gaze and machine reading comprehension",
                "journal": "",
                "year": "2020",
                "authors": "Jonathan Malmaud; Roger Levy; Yevgeni Berzak"
            },
            {
                "ref_id": "b23",
                "title": "A survey on using gaze behaviour for natural language processing",
                "journal": "",
                "year": "2020",
                "authors": "Sandeep Mathias; Diptesh Kanojia; Abhijit Mishra; Pushpak Bhattacharya"
            },
            {
                "ref_id": "b24",
                "title": "Automatically predicting sentence translation difficulty",
                "journal": "Short Papers",
                "year": "2013",
                "authors": "Abhijit Mishra; Pushpak Bhattacharyya; Michael Carl"
            },
            {
                "ref_id": "b25",
                "title": "Harnessing cognitive features for sarcasm detection",
                "journal": "Long Papers",
                "year": "2016",
                "authors": "Abhijit Mishra; Diptesh Kanojia; Seema Nagar; Kuntal Dey; Pushpak Bhattacharyya"
            },
            {
                "ref_id": "b26",
                "title": "The good-subject effect: Investigating participant demand characteristics",
                "journal": "The Journal of general psychology",
                "year": "2008",
                "authors": "Austin Lee Nichols; Jon K Maner"
            },
            {
                "ref_id": "b27",
                "title": "Language models are unsupervised multitask learners",
                "journal": "",
                "year": "2019",
                "authors": "Alec Radford; Jeff Wu; Rewon Child; David Luan; Dario Amodei; Ilya Sutskever"
            },
            {
                "ref_id": "b28",
                "title": "Eye movements in reading and information processing",
                "journal": "Psychological Bulletin",
                "year": "1978",
                "authors": "Keith Rayner"
            },
            {
                "ref_id": "b29",
                "title": "The perceived awareness of the research hypothesis scale: Assessing the influence of demand characteristics",
                "journal": "Figshare",
                "year": "2016",
                "authors": "Mark Rubin"
            },
            {
                "ref_id": "b30",
                "title": "Rethinking explicit expectations: connecting placebos, social cognition, and contextual perception",
                "journal": "Trends in cognitive sciences",
                "year": "2016",
                "authors": "A Katharina; Roland Schwarz; Christian Pfister;  B\u00fcchel"
            },
            {
                "ref_id": "b31",
                "title": "Recursive deep models for semantic compositionality over a sentiment treebank",
                "journal": "",
                "year": "2013",
                "authors": "Richard Socher; Alex Perelygin; Jean Wu; Jason Chuang; D Christopher;  Manning; Y Andrew; Christopher Ng;  Potts"
            },
            {
                "ref_id": "b32",
                "title": "Evaluating word embeddings with fmri and eye-tracking",
                "journal": "",
                "year": "2016",
                "authors": "Anders S\u00f8gaard"
            },
            {
                "ref_id": "b33",
                "title": "Interpreting attention models with human visual attention in machine reading comprehension",
                "journal": "",
                "year": "2020",
                "authors": "Ekta Sood; Simon Tannert; Diego Frassinelli; Andreas Bulling; Ngoc Thang Vu"
            },
            {
                "ref_id": "b34",
                "title": "Improving natural language processing tasks with human gaze-guided neural attention",
                "journal": "",
                "year": "2020",
                "authors": "Ekta Sood; Simon Tannert; Philipp Mueller; Andreas Bulling"
            },
            {
                "ref_id": "b35",
                "title": "Axiomatic attribution for deep networks",
                "journal": "PMLR",
                "year": "2017",
                "authors": "Mukund Sundararajan; Ankur Taly; Qiqi Yan"
            },
            {
                "ref_id": "b36",
                "title": "An eye-tracking study of named entity annotation",
                "journal": "",
                "year": "2017",
                "authors": "Takenobu Tokunaga; Hitoshi Nishikawa; Tomoya Iwakura"
            },
            {
                "ref_id": "b37",
                "title": "The role of pragmatic principles in resolving attachment ambiguities: Evidence from eye movements",
                "journal": "Memory & cognition",
                "year": "2008",
                "authors": "J Matthew; Lyn Traxler;  Frazier"
            },
            {
                "ref_id": "b38",
                "title": "On the predictive power of neural language models for human real-time comprehension behavior",
                "journal": "",
                "year": "2020",
                "authors": "Ethan Gotlieb Wilcox; Jon Gauthier; Jennifer Hu; Peng Qian; Roger Levy"
            },
            {
                "ref_id": "b39",
                "title": "A protocol for data exploration to avoid common statistical problems",
                "journal": "Methods in ecology and evolution",
                "year": "2010",
                "authors": "Elena N Alain F Zuur; Chris S Ieno;  Elphick"
            },
            {
                "ref_id": "b40",
                "title": "Metric for Saliency Data aggregation",
                "journal": "",
                "year": "",
                "authors": ""
            }
        ],
        "figures": [
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_0",
                "figure_caption": "The movie, directed by Mick Jackson, leaves no cliche unturned, from the predictable plot to the characters straight out of central casting.An entertaining, colorful, action-filled crime story with an intimate heart.The mesmerizing performances of the leads keep the film grounded and keep the audience riveted.",
                "figure_data": ""
            },
            {
                "figure_label": "34",
                "figure_type": "figure",
                "figure_id": "fig_1",
                "figure_caption": "Figure 3 :Figure 4 :34Figure 3: Exemplary eye-tracking data showing saliency for polite style, with comparison to human word-level style importance highlighting. The eye-tracking data is visualized as a heat map showing gaze data from the incongruent style condition, with the gaze data from the congruent style (control) condition subtracted.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_2",
                "figure_caption": "n k=0 z k (IA i ) n . \u2022 raw: We aggregate the raw values of the eye tracking measurements from each IA. The saliency score for IA i is given by n k=0 x ki n.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_3",
                "figure_caption": "Thank you for your kind comment. Do you have a suggestion where the portals should be placed in the article? Thank you for your kind comment. Do you have a suggestion where the portals should be placed in the article? Thank you for your kind comment. Do you have a suggestion where the portals should be placed in the article? Thank you for your kind comment. Do you have a suggestion where the portals should be placed in the article? Saliency scores for politeness.",
                "figure_data": ""
            },
            {
                "figure_label": "1",
                "figure_type": "figure",
                "figure_id": "fig_4",
                "figure_caption": "- 1 :1For not specifying what is to be done later with the data. If you claim the question is open-ended (interview and all) then why accept an answer? -1: For not specifying what is to be done later with the data. If you claim the question is open-ended (interview and all) then why accept an answer? -1: For not specifying what is to be done later with the data. If you claim the question is open-ended (interview and all) then why accept an answer? -1: For not specifying what is to be done later with the data. If you claim the question is open-ended (interview and all) then why accept an answer? Saliency scores for impoliteness.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_5",
                "figure_caption": "The movie, directed by Mick Jackson, leaves no cliche unturned, from the predictable plot to the characters straight out of central casting.The movie, directed by Mick Jackson, leaves no cliche unturned, from the predictable plot to the characters straight out of central casting.The movie, directed by Mick Jackson, leaves no cliche unturned, from the predictable plot to the characters straight out of central casting.The movie, directed by Mick Jackson, leaves no cliche unturned, from the predictable plot to the characters straight out of central casting. Saliency scores for negative sentiment.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_6",
                "figure_caption": "Saliency scores for positive sentiment.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_7",
                "figure_caption": "Figure 5: A comparison of saliency scores from various methods: manual human annotations, language model introspection, and eye tracking. Darker highlights indicate stronger saliency scores.",
                "figure_data": ""
            },
            {
                "figure_label": "6",
                "figure_type": "figure",
                "figure_id": "fig_8",
                "figure_caption": "Figure 6 :6Figure 6: Confusion matrix of the Jaccard similarity score for salient text derived from each metric. (See Appendix for the correlation coefficient for saliency scores derived from each metric.)",
                "figure_data": ""
            },
            {
                "figure_label": "7",
                "figure_type": "figure",
                "figure_id": "fig_9",
                "figure_caption": "Figure 7 :7Figure 7: Venn diagram illustrating the intersection of sets of salient interest areas derived from Dwell Time (blue), integrated gradients (green), and human annotations (red).",
                "figure_data": ""
            },
            {
                "figure_label": "8",
                "figure_type": "figure",
                "figure_id": "fig_10",
                "figure_caption": "Figure 8 :8Figure 8: Venn diagram showing interest areas salient to the polite style. For each section of the Venn diagram, the interest areas with the top five highest saliency scores are shown.",
                "figure_data": ""
            },
            {
                "figure_label": "9",
                "figure_type": "figure",
                "figure_id": "fig_11",
                "figure_caption": "Figure 9 :9Figure 9: Top 5 most common parts of speech for each measure's salient IA set. IN: prepositions and subordinating conjunctions, JJ: adjectives, NN: nouns, RB: adverbs, VB: verbs.",
                "figure_data": ""
            },
            {
                "figure_label": "10",
                "figure_type": "figure",
                "figure_id": "fig_12",
                "figure_caption": "Figure 10 :10Figure 10: Few-shot learning classification experiment accuracy scores, averaged over 5 rounds with randomly selected demonstrations. Error bars indicate 95% confidence interval.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_13",
                "figure_caption": "(a) Experiment instructions screen. (b) One of the \"context\" screens shown at the beginning of each block. This information makes participants aware of what type of text to expect in the following screens. (c) One of the screens displaying an item from the dataset. (d) One of the comprehension question screens.",
                "figure_data": ""
            },
            {
                "figure_label": "11",
                "figure_type": "figure",
                "figure_id": "fig_14",
                "figure_caption": "Figure 11 :11Figure 11: Screenshots from the experiment program.",
                "figure_data": ""
            },
            {
                "figure_label": "12",
                "figure_type": "figure",
                "figure_id": "fig_15",
                "figure_caption": "Figure 12 :12Figure 12: Correlations (Pearson's r) between the saliency scores derived from each method.",
                "figure_data": ""
            },
            {
                "figure_label": "1",
                "figure_type": "table",
                "figure_id": "tab_0",
                "figure_caption": "",
                "figure_data": "NLP Area H M learningfrom eyedataOursTextual Style\u2713 \u2713\u2717Kuribayashi et al. (2021) Perplexity\u2717 \u2713\u2717Malmaud et al. (2020)QA\u2717 \u2717 Joint learningBolotova et al. (2020)QA\u2717 \u2713\u2717Sood et al. (2020b)QA\u2717 \u2713\u2717Sood et al. (2020a)Paraphrasing \u2717 \u2717 Joint learningHollenstein et al. (2019)Sentiment Clf., NER\u2717 \u2717 Joint learningBarrett et al. (2018)PoS tagging \u2717 \u2717HMMTokunaga et al. (2017)NER\u2717 \u2717\u2717Klerke et al. (2015)Summarization \u2713 \u2717\u2717Green (2014)Parsing\u2717 \u2717\u2717"
            }
        ],
        "formulas": [
            {
                "formula_id": "formula_0",
                "formula_text": "Applications N FFD FC FRD DT RR RC PL eyeStyliency (Ours) Textual Style 20 \u2713 \u2717 \u2713 \u2713 \u2713 \u2717 \u2713 Kuribayashi et al. (2021) Language model perplexity \u2717 \u2717 \u2717 \u2717 \u2713 \u2717 \u2717 \u2717 Malmaud et al. (2020) Question Answering 269 \u2717 \u2717 \u2717 \u2713 \u2717 \u2717 \u2717 Bolotova et al. (2020) Question Answering 20 \u2717 \u2713 \u2717 \u2713 \u2713 \u2717 \u2717 Sood et al. (2020b) Paraphrasing \u2717 \u2717 \u2713 \u2717 \u2717 \u2717 \u2717 \u2717 Sood et al. (2020a) Question Answering 23 \u2717 \u2717 \u2717 \u2713 \u2717 \u2717 \u2717 Hollenstein et al. (2019) NER, Sentiment/Relation Classification \u2717 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 Barrett et al. (2018) PoS tagging \u2717 \u2713 \u2717 \u2717 \u2713 \u2713 \u2713 \u2717 Tokunaga et al. (2017) Named entity recognition (NER) \u2717 \u2717 \u2717 \u2717 \u2713 \u2717 \u2717 \u2717 Mishra et al. (2016) Sarcasm detection 7 \u2717 \u2717 \u2717 \u2713 \u2717 \u2717 \u2717 Klerke et al. (2015) NLG evaluation 24 \u2717 \u2713 \u2717 \u2713 \u2713 \u2713 \u2713 Green (2014) Phrase-structure parsing 40 \u2717 \u2717 \u2717 \u2717 \u2713 \u2717 \u2717",
                "formula_coordinates": [
                    4.0,
                    70.87,
                    77.13,
                    450.37,
                    193.71
                ]
            }
        ],
        "doi": "10.18653/v1/K18-1030"
    },
    "On the Effects of Structural Modeling for Neural Semantic Parsing": {
        "authors": "Xiang Zhang; Shizhu He; Kang Liu; Jun Zhao; Mohammad Kaiser; Clemens Bavarian; Philippe Winter; Felipe Petroski Tillet; Dave Such; Matthias Cum- Mings; Fotios Plappert; Eliza- Beth Chantzis; Ariel Barnes; William Hebgen Herbert-Voss; Alex Guss; Alex Nichol; Nikolas Paino; Jie Tezak; Igor Tang; Suchir Babuschkin; Shantanu Balaji; William Jain; Christopher Saunders; Andrew N Hesse; Jan Carr; Josh Leike; Vedant Achiam; Evan Misra; Alec Morikawa; Matthew Radford; Miles Knight; Mira Brundage; Katie Murati; Peter Mayer; Bob Welinder; Dario Mcgrew; Sam Amodei; Ilya Mccandlish; Wojciech Sutskever;  2021 Zaremba; David Chiang; Jacob Andreas; Daniel Bauer; Karl Moritz; Bevan Jones; De Gruyter; Mouton Kevin Clark; Minh-Thang Luong; Quoc V Le; Christopher D 2020 Manning;  Electra",
        "pub_date": "",
        "abstract": "Semantic parsing aims to map natural language sentences to predefined formal languages, such as logic forms and programming languages, as the semantic annotation. From the theoretic views of linguistic and programming language, structures play an important role in both languages, which had motivated semantic parsers since the task was proposed in the beginning. But in the neural era, semantic parsers treating both natural and formal language as sequences, such as Seq2Seq and LLMs, have got more attentions. On the other side, lots of neural progress have been made for grammar induction, which only focuses on natural languages. Although closely related in the sense of structural modeling, these techniques hadn't been jointly analyzed on the semantic parsing testbeds. To gain the better understanding on structures for semantic parsing, we design a taxonomy of structural modeling methods, and evaluate some representative techniques on semantic parsing, including both compositional and i.i.d. generalizations. In addition to the previous opinion that structures will help in general, we find that (1) structures must be designed for the specific dataset and generalization level, and ( 2) what really matters is not the structure choice of either source or target side, but the choice combination of both sides. Based on the finding, we further propose a metric that can evaluate the structure choice, which we believe can boost the automation of grammar designs for specific datasets and domains.",
        "sections": [
            {
                "heading": "Introduction",
                "text": [
                    "Semantic parsing is the task to transduce source sentences in natural languages (NL), into the target representations, which are usually artificial formal languages (FL), such as Lisp, \u03bb-calculus, and SQL. Theoretically natural languages are processed in structures (Chomsky, 2009), and the formal languages are also defined to have a context-free syntax (Linz and Rodger, 2022). Therefore inevitably semantic parsers such as the CCG-based are aware of source structures, and adopt the compositional semantics 1 of the targets. But they usually parse to \u03bb-calculus (Venant and Koller, 2019)  In the neural era, Seq2Seq based parsers add supports to any sequential languages, but they can make grammar errors despite the effectiveness. Grammar-based parsers are proposed to ensure the grammatical correctness by decoding the rule sequences of the target AST. Recently, the development of the Text-to-SQL has motivated specialized parsers to support the SQL language. But the NL structures on the source side are seldom handled and left to pretrained large models.",
                    "On the contrary, NL structures are the key issues of treebanks like PTB and supervised parsers. The grammar induction field has also invented many methods to induce grammars with restricted forms from unsupervised training data. These parsers can infer trees for new sentences, but don't process the semantic annotations obviously.",
                    "Unfortunately, no investigations had been conducted on the combination of the success of the two fields. Our research question (RQ) is thus as follows: Is structural modeling of the natural language or the formal language useful for neural semantic parsing? To answer the question, we use the encoder-decoder architecture with the attention mechanism to connect structures of two sides, due to its success of modeling token-level correlations. Our investigations are kept diverse in several important factors, such as the dataset variety, categories of structures, and generalization levels (I.I.D., compositional, or zero-shot). Under every possible combination of these factors, results are believed more faithful than single datasets (Finegan-Dollak et al., 2018).",
                    "Our evaluations add new knowledge to prior insights (Oren et al., 2020). We find it's not safe to claim the effectiveness for specific structural models for either NL or FL. The structures of NL and FL must be evaluated as a whole, and their effects even vary across datasets and generalization levels. Therefore, we make the conclusion that the combination of structural choices are more important than the structural choice on either the source or target side. The result is consistent with the one of the findings from Guo et al. (2020) in that different grammars, leading to different tree structures, have significantly different performance when keeping the same semantic representations and datasets.",
                    "These arguments in total suggest we can expect improvements from searching for better structural combinations on specific application domains. However, grammar search is not trivial but can be highly expensive. Inspired by the recent works in Large Language Models (LLMs) which can handle the code inputs well, we propose the metric, Dis-Struct, for evaluating the structural combination of the source and target sides based on the representations given by the LLMs and the optimal transport. The metric can be interpreted as the discrepancy between the specific training and testing splits under the structural choices. The metric is shown negatively correlated with the parser performance. It thus will help the automation of the grammar search theoretically.",
                    "In summary, we make three contributions as:",
                    "\u2022 We're the first to classify and compare representative structural models for neural semantic parsing, to our best knowledge.",
                    "\u2022 By evaluating the models against a few diverse testbeds, we find that structural combinations are more important than structural choice of either the natural or formal languages.",
                    "\u2022 We propose a metric of the structural combinations that is negatively correlated with the model performance which can speed up the structure searching.",
                    "2 Evaluation Framework"
                ],
                "publication_ref": [
                    "b41",
                    "b53",
                    "b16",
                    "b43",
                    "b23"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Datasets",
                "text": [
                    "As suggested by Finegan-Dollak et al. (2018), we conduct the experiments on a variety of datasets, which are different in sizes, anonymized query amounts, nested query depths, and involved SQL table amounts. We use the ATIS, GEO, Scholar, Advising (Oren et al., 2020), COGS (Kim and Linzen, 2020), and SMCalFlow-CS (Yin et al., 2021). The selection also covers several semantic representations. eralization levels, three have been proposed for the Question Answering task, i.e., the I.I.D., compositional, and zero-shot generalization (Gu et al., 2021). For semantic parsing, usually only the first two levels are considered. The I.I. "
                ],
                "publication_ref": [
                    "b16",
                    "b43",
                    "b32",
                    "b64",
                    "b22"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Problem Formalization",
                "text": [
                    "We are focusing on encoder-decoder models to map a source sentence X into the target formal language Y . Basic forms of X, Y are provided as linear sequences, i.e. X = (x 1 , x 2 , . . . , x n ) and Y = (y 1 , y 2 , . . . , y m ), where each x i and y j are tokens.",
                    "Trees of source and target sides are denoted as S, T with respectively X and Y as their leaf nodes. For both S, T , three structural choices are available: absent, latent, and given. An absent structure is a pure sequence. Latent structure means the tree is not observed and jointly learned from the training data. Given structures rely on external parsers. The combination of choices of S, T yields a total of 9 probabilistic models as in Table 2. Note we only consider the deterministic parsers instead of the generative ones. The models must predict at least one variable of the target side, given at least one variable of the source side. We've noticed several works using generative grammars (Qiu et al., 2021;Kim, 2021;Shaw et al., 2021) based on the notions of synchronized and quasisynchronized CFGs. Due to the prevalence of deterministic semantic parsers, we leave generative models in the future work."
                ],
                "publication_ref": [
                    "b46",
                    "b33"
                ],
                "figure_ref": [],
                "table_ref": [
                    "tab_3"
                ]
            },
            {
                "heading": "Selected Structural Models",
                "text": [
                    "We briefly list the concrete models for structural choices in Table 3. The implementations and hyperparameters are left in the Appendix. Referring the original papers is also recommended for details.  Among the S choices, PnP gives a latent dependency tree, while others including the Berkeley Parser (Kitaev et al., 2019;Kitaev and Klein, 2018) produce constituency trees. For the T choices, all methods are focusing on constituency trees because formal languages have been defined with CFGs."
                ],
                "publication_ref": [
                    "b36",
                    "b37"
                ],
                "figure_ref": [],
                "table_ref": [
                    "tab_5"
                ]
            },
            {
                "heading": "S Model",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Absent",
                "text": [
                    "Note if T is given, we manually construct the grammar for COGS and SMCalFlow-CS, and use the grammar induced by Oren et al. (2020) for other datasets 3 . We use a parser generator to load grammars and follow the grammar-based parsing (Krishnamurthy et al., 2017;Yin and Neubig, 2018) to use LSTM to model the production rule sequence."
                ],
                "publication_ref": [
                    "b43",
                    "b38",
                    "b66"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Evaluation Method",
                "text": [
                    "We use the Exact Match (EM) to measure accuracies. For absent and latent T choices, the generation target must be the same tokens as Y . When the oracle T is given, the model must similarly generate the same rule sequences of that T .",
                    "We have to report the aggregated results because the experiment number is proportional to #datasets \u00d7 #generalization-levels \u00d7 #S-models \u00d7 #T -models \u00d7 #random-seeds 4 . The merit of results aggregation is its robustness. For example, once we find the ON-LSTM as the decoder useful, it is expected to generalize and work well under a variety of settings. Winning or losing on one setting is not critical.",
                    "For analysis, we assign each experiment result with factor labels, and the results will be aggregated under the perspective of factors. The factors we considered are representation types, S-choices, T-choices, and syntactic tree types. For example, when focusing on T-choices, we can compare accuracies of the 3 labels on a specific dataset and split. Each number is mean-aggregated over all S models, like the \"GROUP BY\" in SQL. The aggregation view will help us focus on what we're interested in and not get lost in enormous results."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Results Analysis",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Lateral Structural Modeling",
                "text": [
                    "We first focus on aggregations for single factors on compositional generalization (CG). Each factor label corresponds to aggregated accuracies on 9 datasets, which are plotted as a single box.  Figure 2 shows the absent S structure outperforms others, followed with given S then the latent. The constituency trees are also better than dependency trees. On the target side, the latent T is on a par with absent T , beating the given T by a large margin. Results on both sides suggest no structural bias is the best choice. Furthermore, when we zoom in the aggregation as in Figure 3, it's clearly the low performance of the latent S is caused by many poor latent models. Incredibly, among the latent S, the ON-LSTM works even as well as the Electra, and only falls behind BERT perhaps due to the parameter scales.",
                    "Takeaway Structural modeling CAN be useful. But finding a good discrete structure is not trivial. While handcrafted grammars of formal languages can be harmful, supervised parsers for natural languages are not that bad. Overall, a latent structural bias like ON-LSTM is the most promising. We further analyze results of each S and T choice combination in Figure 4. The accuracy relations are similar to the S and T choices in Figure 2, with a few exceptions. First, when T structure is given, there's not much difference between the given and latent S choices. Therefore, the handcrafted grammars (the given T) are proven poor such that no trivial structural bias for the NL can be found to cooperate with it. Only with absent S structures can the performance be improved at this time. Second, when S is the latent dependency tree, the latent T is the worst, contrary to the right boxplot in Fig- ure 2. This suggests that a latent dependency tree for S and a latent constituency tree for T are not compatible."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_0",
                    "fig_1",
                    "fig_2",
                    "fig_0"
                ],
                "table_ref": []
            },
            {
                "heading": "Combinations of Source and Target",
                "text": [
                    "Takeaway Some incompatible combinations of the source and target choices of structural biases can lead to a performance below the average of any choice on its own."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Latent Source Structures",
                "text": [
                    "Section 3.1 shows that there're big discrepancies among the latent S models. We first compare the PCFGs in Figure 5. The Compound PCFG (Kim et al., 2019a) and TD-PCFG (Yang et al., 2021) are chosen as two basic PCFG variants. In addition, we build a reduced version for each of them by summing out the non-terminals at each cell in the parsing chart with a learnt prior, such that the cell will only store the representation of a span, instead of the representations of a span of every possible non-terminal. This trick can reduce the chart size from O(n 2 K) to O(n 2 ), where K is the number of nonterminals. Appendix A lists more details. In general, the full rank C-PCFG performs better than its counterpart TD-PCFG with decomposed and less parameters. The reduced PCFGs can also outperform the basic ones. With latent and given T choices the C-PCFG works also well, but is not as good as the reduced version. This suggests a less constrained structural bias like the reduced PCFGs not storing non-terminals in the chart can be much better than the fully-fledged PCFGs. We therefore only evaluates the reduced PCFGs on other datasets because they have higher accuracies and less memory consumption.",
                    "Figure 6 shows only the performance of latent S models against different T choices. The ON-LSTM clearly beats other encoders, followed by  the DIORA encoder. Altogether with the Figure 5, we can make some interesting conclusions. First, by summing out non-terminals, reduced PCFGs have outperformed the basic models. Then, the DIORA discards non-terminals in its parameterization, and only considers compositions over spans with a chart-based parsing and an inside-outside algorithm. And it has beaten the PCFGs, Finally, the ON-LSTM which does not forcing syntactic trees being of Chomsky Normal Form, has achieved the best performance.",
                    "Takeaway Latent structural biases with less constraints would be better choices. Enforcing syntactic categories may not be suitable for neural semantic parsing."
                ],
                "publication_ref": [
                    "b34",
                    "b62"
                ],
                "figure_ref": [
                    "fig_3",
                    "fig_4",
                    "fig_3"
                ],
                "table_ref": []
            },
            {
                "heading": "Differences between Accuracies",
                "text": [
                    "The above findings tell us we have to find the compatible structural biases in general. In this section we compare the structural choices among different datasets. We focusing on the T choices and do not aggregate results of datasets and S choices. Specifically, we subtract the number of absent and latent T accuracies with the number of given T accuracies. As long as the differences are positive, the absent and latent T will be considered outperforming the given T that is constructed from handcrafted grammars. For the latent T, we only consider the best 3 models from previous analysis, i.e., the ON-LSTM, DIORA, and PnP. We consider both the I.I.D. and compositional generalizations, as shown in Figure 7.",
                    "The most intuitive result in Figure 7 is that among various datasets the given T is not consistently bad. On the SMCalFlow, the given T is outperformed by the absent and latent T , but the margins are not that large on other datasets in the  I.I.D. setting. For the compositional generalization (the lower subfigure), we can even see the given T has not been outperformed on ATIS and GEO, but is poor on Advising and Scholar. Moreover, on the same dataset like ATIS and GEO, the handcrafted grammar is harmful on I.I.D. but useful on C.G. Also, the results on T choices are slightly different under different S choices, which again supports the compatibility argument in previous sections.",
                    "Takeaway Grammars of the formal languages can't be simply classified as useful or not. There must be an optimal grammar, depending on the datasets and generalization levels."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_5",
                    "fig_5"
                ],
                "table_ref": []
            },
            {
                "heading": "Discussions",
                "text": [
                    "After analyzing the structural modeling methods in different views, we're trying to answer our basic research question (RQ) based on the findings to make the answers and even the question itself much clearer. RQ: Is structural modeling of the natural language or the formal language useful for neural semantic parsing? Yes AND no. It depends on the models. In general we find that models with-out structures (BERT) and with latent structures (ON-LSTM) are better for the natural language, but other structures are not useful. Specifically, the ON-LSTM is even better than the finetuned Electra as the encoder. For the formal languages, we find the latent structural model (ON-LSTM) is much better, but the handcrafted grammar-based decoding is poor (Section 3.1).",
                    "Why are the structural models that different? We hypothesize that the differences are rooted in the strictness of structural constraints of the models. For constituency trees, we find the more structural restrictions required by the model, the worse performance it would be (Section 3.3). Among these models, ON-LSTM neither differentiates syntactic categories, nor requires the Chomsky Norm Form tree, and has outperformed other models.",
                    "Since the ON-LSTM is proven effective, can we use it all the time? No. We're not recommending ON-LSTM for all situations. Because the compatibility of structural choices is more important. If the encoder is a structural model based on dependency trees, the ON-LSTM decoder will not perform well neither. What is really crucial is the encoder-decoder choices combined as a whole (Section 3.2).",
                    "Shall we use the best combination, the ON-LSTM for both the encoder and decoder? Not always. We further find the same structural combination could be not the same effective on all datasets and all generalization levels (Section 3.4). On the GEO with the compositional generalization, ON-LSTM performs worse than handcrafted grammars. In fact, the absent T can be seen a special structure, the right-branching tree with autoregressive decoders like RNNs. For example, an SQL query sequence is equivalent to the tree like (SELECT (* (FROM (tableA (WHERE (...))))). Therefore, the question is in fact asking what kind of trees are better, for the natural and formal languages, combined as a whole, under a specific dataset and a generalization level. We're going to handle this in Section 4. But, if the datasets and generalizations are not our concerns, the BERT or ON-LSTM as the encoder with the ON-LSTM decoder is recommended according to the above findings."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Metric for Structural Evaluation",
                "text": [
                    "Taking sequences as the right-branching trees, the models we've discussed can all parse an example (x, y) to its structures (s(x), t(y)). But the gener-alization performance is not only determined by some smart structural choices. It also depends on the dataset and the generalization level. However, it's expensive to manually design good structures, or to optimize a parameterized structural policy. Because on one hand we have to train and then evaluate a parser every time we need to confirm the effectiveness of that policy. On the other hand, even a parser jointly learning mappings and latent structures may work poorly according to above findings.",
                    "Inspired by the recent success on large language models (LLMs) (Sun et al., 2022) such as the Codex (Chen et al., 2021) which can read and write programming source codes well, we propose a learning-free metric for the structures based on the representations generated by LLMs, such that it's correlated with the performance.",
                    "Specifically, to evaluate a pair of structural models (s, t) for a dataset D = (x, y) i , we first define the distance between a parallel sequence (x, y), e x , e y =LLM (x), LLM (y)",
                    "(1) e s , e t =f (s(x), e x ), f (t(y), e y )",
                    "(2)",
                    "d s,t,D =E (x,y)\u2208D [emd(u s , u t , cost(e s , e t ))] (3)",
                    "where e x \u2208 R n\u00d7k , e y \u2208 R m\u00d7k are the kdimensional representations generated by some LLM that can understand both natural and formal languages, s(\u2022), t(\u2022) are the parsers or policies that output tree structures for x, y, and the f computes the representation of each tree node. We define the leaf nodes have the same representations in e x , e y , and internal nodes get their representations by mean-pooling of its children nodes. u s \u2208 R l and u t \u2208 R r are discrete uniform distributions, where l, r are node numbers of s(x), t(y) respectively. The emd function returns the Earth Moving Distance (Peyr\u00e9 et al., 2019) of u s , u t under the cost matrix defined by euclidean distances of e s , e t . d s,t,D is the minimal transport cost from X to Y for the entire dataset D. We utilize the POT toolbox (Flamary et al., 2021) to compute the optimal transport. Then given the training and testing sets D train , D test , the DisStruct metric is defined as",
                    "M (s, t) = |E[d s,t,D train ] \u2212 E[d s,t,Dtest ]| \u03c3[d s,t,D train ]\u03c3[d s,t,Dtest ](4)",
                    "where the expectation E and standard deviation \u03c3 are implemented by re-running with a few random seeds. In our evaluation, we sample 50 examples for the expectation in Eq.( 3), and rerun 10 times for Eq.( 4). Intuitively, given structural choices (s, t), the DisStruct evaluates the distances of x and y of a single example, and computes the distance discrepancies between D train , D test . Therefore, we can expect higher performance by finding lower metric values from some (s, t) pair. Figure 8 illustrates the correlations. Although every (s, t) can yield a metric value, we plot only two kinds of pairs (absent, absent) and (absent, given) and investigate whether the metric can tell apart the differences between the grammar-based and the sequence-based structures. With three recent LLMs 5 that we can load with less than 24GB GPU, the metrics are shown all negatively correlated with the performance as expected.",
                    "Since each fitted linear model has a low R 2 value (i.e., plots far from the fitted line), we examine the results by datasets. As long as the metric can indicate performance for datasets, it'll be possible to probe or search structural choices for a specific dataset we're interested in. For each dataset under a generalization level, we only have 2 points. We computed the slope of the line determined by the two points, and plot the histogram of the slopes in Figure 9. Hopefully, the slopes are negative at more than 50% times, and are also relatively small even it's positive. We also find the metrics based on ChatGLM-6B and Falcon-7B are more ideal than Baichuan-7B."
                ],
                "publication_ref": [
                    "b51",
                    "b42",
                    "b45"
                ],
                "figure_ref": [
                    "fig_6",
                    "fig_7"
                ],
                "table_ref": []
            },
            {
                "heading": "Related Works",
                "text": [
                    "Many representations have been used for semantic parsing. Popular representations include semantic roles, FOL or \u03bb-calculus (Zettlemoyer andCollins, 2005, 2007;Wong and Mooney, 2007), \u03bb-DCS (Liang et al., 2013), FunQL (Kate et al., 2005;Guo et al., 2020), application-specialized query graphs (Yih et al., 2015;Chen et al., 2018;Hu et al., 2018), and programming languages like SQL (Xu et al., 2018), Java (Iyer et al., 2018;Alon et al., 2020), and Python (Yin and Neubig, 2017;Rabinovich et al., 2017). Linguists also design meaning representations such as AMR (Banarescu et al., 2013), ERS (Flickinger et al., 2014), and UMR (Van Gysel et al., 2021). Abend and Rappoport (2017) had reviewed many semantic representations in a linguistic-centric perspective, and Li et al. (2022) had proposed a metric to evaluate different representations. Our discussions are not at representation level (only the lispress, \u03bb-calculus, and SQL are used), but on structure effects under maybe a fixed representation. Classic semantic parsers used to assign categories to linguistic or semantic fragments, and com-pose them in a bottom-up fashion. Some typical implementations are based on CCG (Zettlemoyer and Collins, 2005), SCFG (Wong andMooney, 2006), Hyperedge Replacement Grammar (Chiang et al., 2013), and AM Algebra (Groschwitz et al., 2017(Groschwitz et al., , 2018;;Wei\u00dfenhorn et al., 2022). Other parsers do not define linguistic categories, but use feature engineering or types to guide composing algorithms (Liang et al., 2013;Pasupat and Liang, 2015).",
                    "Neural parsers like Seq2Seq (Xiao et al., 2016) adopt end-to-end mappings but can make grammar errors. Seq2Tree (Dong and Lapata, 2016) is then proposed to generate grammatically valid trees for untyped \u03bb-calculus. Grammar-based decoding (Krishnamurthy et al., 2017;Yin and Neubig, 2018) turns to generate rule sequences converted from the target AST. Some parsers design intermediate patterns for an easier abstraction over the targets (Zhang et al., 2017;Dong and Lapata, 2018;Guo et al., 2019;Ding et al., 2019;Iyer et al., 2019;Choi et al., 2021;Chen et al., 2020). The abstraction layer can be seen as handcrafted structures for the targets. We only consider CFG-based structures due to their generality. Similarly, graph-based targets and parsers are also beyond our discussing. LLMs as semantic parsers (Qiu et al., 2022;Zhuo et al., 2023) are found not performing well on the COGS dataset before structural discussions. We leave some results and discussions in Appendix C.",
                    "Recently the compositional generalization has attracted much focus (Jambor and Bahdanau, 2022;Liu et al., 2021;Herzig and Berant, 2021). But they either devise special parsers other than the encoder-decoder architecture, or handle representations like FunQL, therefore not direct applicable to other general parsers. Zheng and Lapata (2022) reports the entanglement problem where Seq2Seq models entangle irrelevant semantic factors during generation. Yin et al. (2021) induces token and span level alignments. Our structural discussions are orthogonal to their model improving works."
                ],
                "publication_ref": [
                    "b58",
                    "b40",
                    "b23",
                    "b63",
                    "b5",
                    "b26",
                    "b61",
                    "b28",
                    "b2",
                    "b65",
                    "b48",
                    "b3",
                    "b19",
                    "b0",
                    "b39",
                    "b68",
                    "b20",
                    "b21",
                    "b55",
                    "b40",
                    "b44",
                    "b60",
                    "b10",
                    "b38",
                    "b66",
                    "b69",
                    "b11",
                    "b24",
                    "b9",
                    "b27",
                    "b4",
                    "b29",
                    "b42",
                    "b25",
                    "b70",
                    "b64"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Conclusion",
                "text": [
                    "By evaluations on a variety of settings, we find the structural modeling is not guaranteed to give better performance. We conclude that structural biases for sources and targets must be chosen as a whole, and that choices also depend on the specific dataset and generalization level. We propose the DisStruct metric to facilitate structure finding, which is negatively correlated with the performance."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Limitations",
                "text": [
                    "We've discussed a variety of structural models, but may lack the tuning of hyperparameters for each model to work at its best. For example, the number of nonterminals and preterminals are important for PCFGs, but we use a small number compared with the grammar induction task on PTB due to our small dataset size. Also, it is a reasonable guess that BERT and ELECTRA as encoders are inferior than large language models such as T5, Falcon, and ChatGPT. We have not conduct experiments on datasets simply because of limited computation resources. Also we note that LLMs can be used as the decoder-only models, and generate targets via in-context learning or zero-shot prompts. We left the results in the Appendix C because structural models or representations we concerning are not involved in the paradigm.",
                    "Furthermore, our study is all English-based datasets. Considering the large differences between language families, the structure model of constituency and dependency trees in our study may have different effects. Universal structures such as the Universal Dependencies (de Marneffe et al., 2021) may be considered for future research.",
                    "Finally, DIORA and PCFGs in our study require approximately 4 times more GPU memories than other encoders (excluding the BERT and ELEC-TRA of course). This may be caused by the CKYstyle computation which is O(n 3 s 2 ) in time where n is the sentence length and s is the number of syntactic categories. This will leads to more GPU consumption to compute the tensor graph. We're also wondering if a sample-based learning algorithm could work instead of the inside algorithm."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Ethics Statement",
                "text": [
                    "Since our study is objective, we have reviewed our datasets. The contents of the datasets are publicly available for years and obtainable without checking the membership of any group. In addition, some datasets had adopted careful preprocessing such as anonymization which replaced real-world entity names with placeholders. The dependent code resources are managed in public repositories. And so will ours. So far we believe our work does not have ethical concerns.",
                    "Terry Yue Zhuo, Zhuang Li, Yujin Huang, Fatemeh Shiri, Weiqing Wang, Gholamreza Haffari, and Yuan-Fang Li. 2023. On robustness of prompt-based semantic parsing with large pre-trained language model: An empirical study on codex. In Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, pages 1090-1102, Dubrovnik, Croatia. Association for Computational Linguistics."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A Structure Modeling",
                "text": [
                    "We'll make extensions for Seq2Seq models. In the classical Seq2Seq, the encoder module is in charge of encoding source input X = {x i } n i=1 and prepares for the attention mechanism a memory H = {h i } n i=1 of states, where each h i are usually aligned to each input token x i . The decoder is obliged to generate tokens Y = {y j } m j=1 by referring the memory H for each y j . The last state h n in memory is usually chosen to initialize autoregressive decoders. We will explain how H is constructed for encoders, and how Y is chosen for decoders."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.1 Encoders",
                "text": [
                    "If the source structure is Absent, we take the input X as a plain sequence and choose the BiLSTM as the encoder. Due to their impressive performance, we also use the BERT (Devlin et al., 2019) and ELECTRA (Clark et al., 2020) language models from the Transformers library (Wolf et al., 2020). The encoder memory H is then the encoder outputs of each word in X.",
                    "If the source structure is Given, we use Berkeley Parser to get the constituency tree T of X. After removing the POS tags, T consists of words x i as leaf nodes and the syntactic categories as internal nodes, such as NP, PP, and WHNP. We use twolayer GCN to encode nodes following the structure, and collect all the node hidden states as the attention memory H.",
                    "For latent structures, we choose representative grammar induction methods, namely ONL-STM (Shen et al., 2019), DIORA (Drozdov et al., 2019), PCFGs (Kim et al., 2019a;Yang et al., 2021), and Perturb-and-Parse (Corro and Titov, 2019b) Both constituency and dependency trees are considered. And most latent structures are learnt in two ways, by relaxation or sampling (Wu, 2022), where the former is usually optimized by maximizing the marginal probability of X as Eq.5, and the latter is optimized by sampling a structure S and passing to the downstream decoders (Eq.6). max \u03b8 P \u03b8 (X) = S P \u03b8 (S, X)",
                    "(5)",
                    "max \u03b8 P \u03b8 (Y | X) = E S\u2208P (S|X) P (Y | S, X) (6)",
                    "To wrap these up, the Perturb-and-Parse will give a sampling-based dependency trees, while others are the relaxation-based constituency trees.",
                    "ONLSTM Specifically, ONLSTM 6 shares the interface with classical RNNs, and invents the ordered neuron that can be interpreted as hierarchical structures. So we use it just as the replacement for BiLSTM. The memory H is also the states of sequence X, and the optimization only uses gradients from the decoders.",
                    "DIORA DIORA 7 aims to learn latent binary trees following the inside-outside algorithm. Embeddings of X are composed bottom-up for filling the inside chart with inside states. The composition c ijk of two sub-span states h(x i:j ) and h(x j:k ) is parameterized by an MLP f h . Every possible composition is scored with another MLP f s . As DIORA falls into the relaxation-based category, each span state is a summation (Eq. 7) of all possible compositions with the normalized scores (Eq. 8).",
                    "h in (x i:k ) = j s ik j f h h in (x i:j ), h in (x j:k ) (7)",
                    "s ik j = sof tmax f s h in (x i:j ), h in (x j:k ) j (8)",
                    "where sof tmax(\u2022) j means the j-th normalized score after the softmax function. Similarly, the outside pass will fill the outside chart to given any span x j:k an outside state h out (x i:k ), which is composed by each possible parent and sibling span and summed up with the normalized score. The outside composer and scorer are different MLPs. The attention memory H for DIORA encoders is full of representations of X, where each word is represented by the concatenation of inside and outside states as",
                    "h i = [h in (x i:i+1 ); h out (x i:i+1 )],",
                    "where the inside state of one-word spans h(x i:i+1 ) are actually the word embeddings. Note that DIORA comes up with its own training objective, which maximizes the reconstruction probabilities from each one-word span as Eq.9.",
                    "max \u03b8 L diora = i log P \u03b8 (x i |h out (x i:i+1 )) (9)",
                    "PCFGs Two notable modern PCFGs 8 are C-PCFG (Kim et al., 2019a) and TD-PCFG (Yang et al., 2021). Rules are restricted to Chomsky normal form, including S \u2192 A, A \u2192 BC, and P \u2192 x, where S is the fixed start token, A is a nonterminal, P generating a single terminal word x is called a preterminal, and B, C can be either nonterminal or preterminal. Embeddings and neural networks are used to parameterize the rule distributions as \u03c0 S\u2192A , \u03c0 P \u2192x , \u03c0 A\u2192BC . C-PCFG adopted a novel variational model to infer a global state z of X, and let the neural nets predict \u03c0 by concatenation z to each symbol embeddings. We use BiLSTM for the variational model. And TD-PCFG decomposed the large tensor of \u03c0 A\u2192BC into the sum of products of lower rank tensors, largely extending the number of nonterminals and preterminals.",
                    "To use PCFGs as encoders, we first build up the PCFG models on the source sequence X. Since C-PCFG is built with a variational inference model, the loss involves a reconstruction loss as Eq.5 and a KL divergence. The former with a summation can be computed efficiently by the inside algorithm, and the latter is easy to obtain because the prior of z is kept Gaussian.",
                    "We choose to include all the span representations h i:k in the attention memory H. The representations are computed similar to the bottom-up inside algorithm. The algorithm fills an inside chart with probability scores s ikA . = P (x i:k | A) for every span x i:k with each nonterminal A.",
                    "s ikA = B C j w ijkABC(10)",
                    "w ijkABC = \u03c0 A\u2192BC \u2022 s ijB \u2022 s jkA(11)",
                    "Similarly, the span representation h i:k is also a weighted sum (Eq.12) of all h ijkABC , which means the compositional representation for span x i:k as the category A, split at the point j, with left and right sub-spans being categories B and C.",
                    "h i:k = A,B,C,j h ijkABC \u2022 w ijkABC \u2022 \u03c0 s (A) (12)",
                    "8 https://github.com/sustcsonglin/TN-PCFG Note that we uses \u03c0 s , s \u2208 N as a prior to sum over A, which can be interpreted as treating the span x i:k as a valid sentence.",
                    "To compute compositions of span h i:j and h j:k , Instead of concatenating embeddings of A, B, C, h i:j , h j:k and transforming with an MLP, we factorize the computation of h ijkABC with different MLPs to avoid broadcasting to the unrelated dimensions as Eq.13.",
                    "h ijkABC = f h (A) + f ls (B) + f rs (C) + f l (h i:j ) + f r (h j:k )(13)",
                    "Note that we can rearrange Eq.12 and Eq.13 jointly to save up space, by moving items together and summing out irrelevant dimensions in advance. And for TD-PCFG which decomposes the tensor",
                    "\u03c0 A\u2192BC = l u l A \u2022 v l B \u2022 w l C",
                    ", the similar form of Eq.12 and Eq.13 and the efficiency trick can also be adopted. Formulae related to TD-PCFG are omitted here to save up space.",
                    "Perturb-and-Parse The model (abbr. PnP) focuses on sampling trees from the distribution of dependency structures. Words embeddings e(X) \u2208 R n\u00d7d of X \u2208 R n are transformed to arc weights as Eq. 14, from which the Eisner's algorithm (Eisner, 1996) infers the tree S. The gumbel-softmax trick is adopted for differentiable sampling (Eq.15), and the argmax operation in Eisner's algorithm is replaced with the softmax following Corro and Titov (2019a). In this way, during training the output of Eisner's algorithm is not yet a valid but soft dependency tree, indicating the probabilities that there's an arc between two words x i and x j . But we switch to the default argmax during testing.",
                    "W = f head (e(X)) \u2022 f tail (e(X)) T (14) Z \u223c G(0, 1) (15) S = Eisner(W + Z)(16)",
                    "After the source tree S is inferred, we use two GCN layers to pass messages among nodes following the structures, where each node is a word in X. We use all the node representations to build the attention memory H. The PnP model is simply trained with the downstream tasks (Corro and Titov, 2019b)."
                ],
                "publication_ref": [
                    "b8",
                    "b56",
                    "b50",
                    "b12",
                    "b34",
                    "b62",
                    "b59",
                    "b34",
                    "b62",
                    "b15"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.2 Decoders",
                "text": [
                    "If the target structure is Absent, we simply model it with an LSTM. And we do not use any pretrained language model as the decoder. For datasets with very long targets and slow for training, such as I.I.D. setting, we find this performance not acceptable. We have sampled and analyzed the errors of ChatGLM, and there're some typical errors, such as (1) missing declarations of a variable; (2) output too long sequences which can be over ten times than the gold target;",
                    "(3) inventing undefined the neo-davidsonian predicates; (4) misunderstanding the passive and active roles. We hypothesize that LLMs must be finetuned on these unseen representations like neo-davidsonian \u03bb-calculus. And at least there're still much study to do before discussing the structural biases for LLMs."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "D Accuracies for Model Combinations",
                "text": [
                    "We list the complete accuracies for each encoder and decoder combinations in Table 5 and Table 6.",
                    "For the encoders, rcpcfg and rtdpcfg are the reduced version of C-PCFG and TD-PCFG respectively. The pnp is the Perturb-and-Parse model. The syn-parser is the supervised Berkeley Parser with a GCN to encode. For the decoders, the seq denotes an LSTM as the decoder, and the prod denotes the grammar-based decoding of rule sequences modeled by an LSTM. Please refer to Appendix A and Section 2 for an introduction. We've defined several S and T choices. For encoders, the bilstm, bert, and electra are absent S. The ON-LSTM, DIORA, R-C-PCFG, R-TD-PCFG, and PnP are latent S. And only the synparser belongs to given S. For decoders, the seq, ON-LSTM, and prod represent the absent, latent, and given T, respectively."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_9",
                    "tab_10"
                ]
            },
            {
                "heading": "E EBNF Grammar for SQL",
                "text": [
                    "For grammar-based decoding, AST parses of SQLs are required. We use the Lark Python package which is a parser generator like the classical flex and bison. We use the grammar induced by Oren et al. (2020) and manually convert it to the Lark format, which is an implementation of EBNF. Other grammars from MySQL and SQLite are not used in this work.",
                    "The lexer definitions we use are as follows. "
                ],
                "publication_ref": [
                    "b43"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Acknowledgements",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "",
                "text": [
                    "the ATIS and Advising, we use the Transformer decoder instead of LSTM.",
                    "For latent target structures, we only use ONL-STM as the source side because it shares the same interface with RNNs. Other extensive works are not tested, because the SQLs are usually much longer than the natural language, and the grammar induction works are seldom evaluated on such long sentences (Drozdov et al., 2019). Furthermore, semantic representations are born with well-defined structures, it's not intuitive to learn latent structures from data.",
                    "For target structures that are given, we use the grammar induced by Oren et al. (2020) as discussed in Section 2. We manually convert the grammar into ENBF form and use the parser generator Lark to parse SQLs in the dataset. After that, we follow the order of left-most derivation to traverse the AST parses of SQLs as in TranX (Yin and Neubig, 2018), and the rule sequences are modeled by an LSTM. We denoted this method as Grammar-based Decoders as Oren et al. (2020).",
                    "Although the models above are enough to fulfill the taxonomy in Section 2, we've also tried but failed to use C-PCFG and RNNG (Dyer et al., 2016) as decoders. The generative RNNG is such expressive that make SQL grammar errors often, like a WHERE clause followed by another. URNNG (Kim et al., 2019b) requires an external (UCB Parser specifically) inference model to constrain the expressive power of RNNG. For C-PCFG, we hypothesize lacking of attention mechanism is crucial. We hypothesize the execution guided decoding might be helpful and necessary, but it's beyond our discussion in structures."
                ],
                "publication_ref": [
                    "b12",
                    "b43",
                    "b66",
                    "b43",
                    "b14",
                    "b35"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "B Experiment Hyperparameters",
                "text": [
                    "We explain the details of models and hyperparameters here. We use the same setting for all datasets, and keep most parameters the same across models.",
                    "For hyperparameters applicable to all models, we use AdaBelief optimizer (Zhuang et al., 2020), and set the learning rate to 1e-3, and betas to 0.9 and 0.999. We do not use weight decays for all models. We fix the batch size to 16. The learning rate scheduler is based on NoamLR from the Al-lenNLP package, with the model size set to 400 and warmup steps to 50. We use the pretrained GloVe embeddings of 100 dimensions for the source side. For BERT hyperparameters, the learning rate is set 1e-5 and no LR schedulers.  We set the encoder hidden size to 300 for most models, except 150 for Diora and PnP, and 200 for PCFGs and Tree encoders. Sequence encoders and the inference model of C-PCFG are bidirectional (BiLSTM and ONLSTM). All encoders are 1-layer except the 2-layer GCN used for Tree and PnP encoders. Decoder is fixed to LSTM but Transformer for PCFGs/BERT/Electra. LSTM decoder is 1-layer and the hidden size is 200 for PCFGs models and 300 for others.The attention scores are computed by dot products. Transformer decoders are 2-layers and uses 300 for hidden size, and 10 for attention heads. All encoder dropout is 0 and decoder dropout is 0.5.",
                    "Training on GEO and Scholar uses 150 epochs for PCFGs and Tree encoders, 300 for tree encoders and 400 for others. All models trained for ATIS and Advising uses 30 epochs. On COGS and SMCalFlow-CS datasets, the models are trained for 15 epoches because of the large size. In practice, most models are trained in 4 to 12 hours, with an Xeon E5-2680 CPU and a single GeForce RTX 3090 GPU."
                ],
                "publication_ref": [
                    "b71"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "C Few-shot Parsing with LLMs",
                "text": [
                    "We just use the LLMs on the I.I.D. generalization of COGS dataset. We first build an index on the natural language of the training set, and then search for the closest 10 examples (x \u2032 , y \u2032 ), with each testing x. The prompt is typically built as \"Input: x \u2032 . Output: y \u2032 .\" for each example (x \u2032 , y \u2032 ), appended by the testing example as \"Input: x. Output:\". In this way we're trying to utilize the in-context learning ability of LLMs for semantic parsing. and the accuracy is evaluated by Exact Match (EM) of the outputs against the gold targets. However, the performance is not ideal.",
                    "The lower two LLMs with the similar scale even have a pretty much performance difference. Note a plain Seq2Seq model can generalize well in the The parser definitions are as follows. We put values in the grammar definition follow-ing Oren et al. (2020). This good enough for our usage. Note in a formal SQL grammar, the values for entities, tables, and columns are usually included in the lexer definition and defined with regular expressions. We leave the other definitions in our code release because it's too long (hundreds of lines), including the nonterminals of value, COL_ALIAS, SUBQ_ALIAS, TABLE_NAME, and COLUMN_NAME."
                ],
                "publication_ref": [
                    "b43"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "F EBNF Grammar for COGS",
                "text": [
                    "We list our handcrafted grammar for COGS here. "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "G EBNF Grammar for Lispress",
                "text": [
                    "We list our handcrafted grammar for SMCalFlow-CS, which uses the Lispress language. Although the Lispress has an official parser in Python, we still use a handcrafted grammar for consistency with our work.",
                    "VALID_CHAR: /[a-zA-Z\\d\\\"\\#\\(\\)\\+/ | /\\.\\:\\<\\>\\=\\?\\[\\]\\~]/ QUOTE: \"\\\"\" LPAR: \"(\" RPAR: \")\" LBRA: \"[\" RBRA: \"]\" COLON: \":\" DOT: \".\" LET: \"let\" DO: \"do\" META: \"^\" MACRO: \"#\" "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            }
        ],
        "references": [
            {
                "ref_id": "b0",
                "title": "The state of the art in semantic representation",
                "journal": "Association for Computational Linguistics",
                "year": "2017",
                "authors": "Omri Abend; Ari Rappoport"
            },
            {
                "ref_id": "b1",
                "title": "Badreddine Noune, Baptiste Pannier, and Guilherme Penedo. 2023. Falcon-40B: an open large language model with state-of-the-art performance",
                "journal": "",
                "year": "",
                "authors": "Ebtesam Almazrouei; Hamza Alobeidli; Abdulaziz Alshamsi; Alessandro Cappelli; Ruxandra Cojocaru; Merouane Debbah; Etienne Goffinet"
            },
            {
                "ref_id": "b2",
                "title": "Structural language models of code",
                "journal": "PMLR",
                "year": "2020",
                "authors": "Uri Alon; Roy Sadaka; Omer Levy; Eran Yahav"
            },
            {
                "ref_id": "b3",
                "title": "Abstract Meaning Representation for sembanking",
                "journal": "Association for Computational Linguistics",
                "year": "2013",
                "authors": "Laura Banarescu; Claire Bonial; Shu Cai; Madalina Georgescu; Kira Griffitt; Ulf Hermjakob; Kevin Knight; Philipp Koehn; Martha Palmer; Nathan Schneider"
            },
            {
                "ref_id": "b4",
                "title": "Learning to map frequent phrases to sub-structures of meaning representation for neural semantic parsing",
                "journal": "",
                "year": "2020",
                "authors": "Bo Chen; Xianpei Han; Ben He; Le Sun"
            },
            {
                "ref_id": "b5",
                "title": "Sequenceto-action: End-to-end semantic graph generation for semantic parsing",
                "journal": "Association for Computational Linguistics",
                "year": "2018",
                "authors": "Bo Chen; Le Sun; Xianpei Han"
            },
            {
                "ref_id": "b6",
                "title": "Girish Sastry",
                "journal": "",
                "year": "",
                "authors": "Mark Chen; Jerry Tworek; Heewoo Jun; Qiming Yuan; Henrique Ponde De Oliveira Pinto; Jared Kaplan; Harri Edwards; Yuri Burda; Nicholas Joseph; Greg Brockman; Alex Ray; Raul Puri; Gretchen Krueger; Michael Petrov; Heidy Khlaaf"
            },
            {
                "ref_id": "b7",
                "title": "Universal Dependencies",
                "journal": "Computational Linguistics",
                "year": "2021",
                "authors": "Marie-Catherine De Marneffe; Christopher D Manning; Joakim Nivre; Daniel Zeman"
            },
            {
                "ref_id": "b8",
                "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
                "journal": "Association for Computational Linguistics",
                "year": "2019",
                "authors": "Jacob Devlin; Ming-Wei Chang; Kenton Lee; Kristina Toutanova"
            },
            {
                "ref_id": "b9",
                "title": "Leveraging frequent query substructures to generate formal queries for complex question answering",
                "journal": "",
                "year": "2019",
                "authors": "Jiwei Ding; Wei Hu; Qixin Xu; Yuzhong Qu"
            },
            {
                "ref_id": "b10",
                "title": "Language to logical form with neural attention",
                "journal": "Long Papers",
                "year": "2016",
                "authors": "Li Dong; Mirella Lapata"
            },
            {
                "ref_id": "b11",
                "title": "Coarse-to-fine decoding for neural semantic parsing",
                "journal": "Association for Computational Linguistics",
                "year": "2018",
                "authors": "Li Dong; Mirella Lapata"
            },
            {
                "ref_id": "b12",
                "title": "Unsupervised latent tree induction with deep inside-outside recursive auto-encoders",
                "journal": "Association for Computational Linguistics",
                "year": "2019",
                "authors": "Andrew Drozdov; Patrick Verga; Mohit Yadav; Mohit Iyyer; Andrew Mccallum"
            },
            {
                "ref_id": "b13",
                "title": "Glm: General language model pretraining with autoregressive blank infilling",
                "journal": "Long Papers",
                "year": "2022",
                "authors": "Zhengxiao Du; Yujie Qian; Xiao Liu; Ming Ding; Jiezhong Qiu; Zhilin Yang; Jie Tang"
            },
            {
                "ref_id": "b14",
                "title": "Recurrent neural network grammars",
                "journal": "Association for Computational Linguistics",
                "year": "2016",
                "authors": "Chris Dyer; Adhiguna Kuncoro; Miguel Ballesteros; Noah A Smith"
            },
            {
                "ref_id": "b15",
                "title": "Three new probabilistic models for dependency parsing: An exploration",
                "journal": "",
                "year": "1996",
                "authors": "Jason M Eisner"
            },
            {
                "ref_id": "b16",
                "title": "Improving textto-SQL evaluation methodology",
                "journal": "Association for Computational Linguistics",
                "year": "2018",
                "authors": "Catherine Finegan-Dollak; Jonathan K Kummerfeld; Li Zhang; Karthik Ramanathan; Sesh Sadasivam; Rui Zhang; Dragomir Radev"
            },
            {
                "ref_id": "b17",
                "title": "",
                "journal": "",
                "year": "",
                "authors": "R\u00e9mi Flamary; Nicolas Courty; Alexandre Gramfort; Z Mokhtar; Aur\u00e9lie Alaya;  Boisbunon"
            },
            {
                "ref_id": "b18",
                "title": "Pot: Python optimal transport",
                "journal": "Journal of Machine Learning Research",
                "year": "2021",
                "authors": "T H Gayraud; Hicham Janati; Alain Rakotomamonjy; Ievgen Redko; Antoine Rolet; Antony Schutz; Vivien Seguy; Danica J Sutherland; Romain Tavenard; Alexander Tong; Titouan Vayer"
            },
            {
                "ref_id": "b19",
                "title": "Towards an encyclopedia of compositional semantics: Documenting the interface of the English Resource Grammar",
                "journal": "",
                "year": "2014",
                "authors": "Dan Flickinger; Emily M Bender; Stephan Oepen"
            },
            {
                "ref_id": "b20",
                "title": "A constrained graph algebra for semantic parsing with AMRs",
                "journal": "",
                "year": "2017",
                "authors": "Jonas Groschwitz; Meaghan Fowlie; Mark Johnson; Alexander Koller"
            },
            {
                "ref_id": "b21",
                "title": "AMR dependency parsing with a typed semantic algebra",
                "journal": "Association for Computational Linguistics",
                "year": "2018",
                "authors": "Jonas Groschwitz; Matthias Lindemann; Meaghan Fowlie; Mark Johnson; Alexander Koller"
            },
            {
                "ref_id": "b22",
                "title": "Beyond i.i.d.: Three levels of generalization for question answering on knowledge bases",
                "journal": "",
                "year": "2021",
                "authors": "Yu Gu; Sue Kase; Michelle Vanni; Brian Sadler; Percy Liang; Xifeng Yan; Yu Su"
            },
            {
                "ref_id": "b23",
                "title": "Benchmarking meaning representations in neural semantic parsing",
                "journal": "Online. Association for Computational Linguistics",
                "year": "2020",
                "authors": "Jiaqi Guo; Qian Liu; Jian-Guang Lou; Zhenwen Li; Xueqing Liu; Tao Xie; Ting Liu"
            },
            {
                "ref_id": "b24",
                "title": "Towards complex text-to-SQL in cross-domain database with intermediate representation",
                "journal": "Association for Computational Linguistics",
                "year": "2019",
                "authors": "Jiaqi Guo; Zecheng Zhan; Yan Gao; Yan Xiao; Jian-Guang Lou; Ting Liu; Dongmei Zhang"
            },
            {
                "ref_id": "b25",
                "title": "Spanbased semantic parsing for compositional generalization",
                "journal": "Long Papers",
                "year": "2021",
                "authors": "Jonathan Herzig; Jonathan Berant"
            },
            {
                "ref_id": "b26",
                "title": "Answering natural language questions by subgraph matching over knowledge graphs",
                "journal": "IEEE Transactions on Knowledge and Data Engineering",
                "year": "2018",
                "authors": "S Hu; L Zou; J X Yu; H Wang; D Zhao"
            },
            {
                "ref_id": "b27",
                "title": "Learning programmatic idioms for scalable semantic parsing",
                "journal": "Association for Computational Linguistics",
                "year": "2019",
                "authors": "Srinivasan Iyer; Alvin Cheung; Luke Zettlemoyer"
            },
            {
                "ref_id": "b28",
                "title": "Mapping language to code in programmatic context",
                "journal": "Association for Computational Linguistics",
                "year": "2018",
                "authors": "Srinivasan Iyer; Ioannis Konstas; Alvin Cheung; Luke Zettlemoyer"
            },
            {
                "ref_id": "b29",
                "title": "LAGr: Label aligned graphs for better systematic generalization in semantic parsing",
                "journal": "Long Papers",
                "year": "2022",
                "authors": "Dora Jambor; Dzmitry Bahdanau"
            },
            {
                "ref_id": "b30",
                "title": "Learning to transform natural to formal languages",
                "journal": "AAAI Press",
                "year": "2005",
                "authors": "J Rohit; Yuk Wah Kate; Raymond J Wong;  Mooney"
            },
            {
                "ref_id": "b31",
                "title": "Measuring compositional generalization: A comprehensive method on realistic data",
                "journal": "",
                "year": "2020",
                "authors": "Daniel Keysers; Nathanael Sch\u00e4rli; Nathan Scales; Hylke Buisman; Daniel Furrer; Sergii Kashubin; Nikola Momchev; Danila Sinopalnikov; Lukasz Stafiniak; Tibor Tihon; Dmitry Tsarkov; Xiao Wang; Olivier Marc Van Zee;  Bousquet"
            },
            {
                "ref_id": "b32",
                "title": "COGS: A compositional generalization challenge based on semantic interpretation",
                "journal": "",
                "year": "2020",
                "authors": "Najoung Kim; Tal Linzen"
            },
            {
                "ref_id": "b33",
                "title": "Sequence-to-sequence learning with latent neural grammars",
                "journal": "Curran Associates, Inc",
                "year": "2021",
                "authors": "Yoon Kim"
            },
            {
                "ref_id": "b34",
                "title": "Compound probabilistic context-free grammars for grammar induction",
                "journal": "Association for Computational Linguistics",
                "year": "2019",
                "authors": "Yoon Kim; Chris Dyer; Alexander Rush"
            },
            {
                "ref_id": "b35",
                "title": "Unsupervised recurrent neural network grammars",
                "journal": "Association for Computational Linguistics",
                "year": "2019",
                "authors": "Yoon Kim; Alexander Rush; Lei Yu; Adhiguna Kuncoro; Chris Dyer; G\u00e1bor Melis"
            },
            {
                "ref_id": "b36",
                "title": "Multilingual constituency parsing with self-attention and pre-training",
                "journal": "Association for Computational Linguistics",
                "year": "2019",
                "authors": "Nikita Kitaev; Steven Cao; Dan Klein"
            },
            {
                "ref_id": "b37",
                "title": "Constituency parsing with a self-attentive encoder",
                "journal": "Association for Computational Linguistics",
                "year": "2018",
                "authors": "Nikita Kitaev; Dan Klein"
            },
            {
                "ref_id": "b38",
                "title": "Neural semantic parsing with type constraints for semi-structured tables",
                "journal": "",
                "year": "2017",
                "authors": "Jayant Krishnamurthy; Pradeep Dasigi; Matt Gardner"
            },
            {
                "ref_id": "b39",
                "title": "Exploring the secrets behind the learning difficulty of meaning representations for semantic parsing",
                "journal": "Association for Computational Linguistics",
                "year": "2022",
                "authors": "Zhenwen Li; Jiaqi Guo; Qian Liu; Jian-Guang Lou; Tao Xie"
            },
            {
                "ref_id": "b40",
                "title": "Learning dependency-based compositional semantics",
                "journal": "Computational Linguistics",
                "year": "2013",
                "authors": "Percy Liang; Michael I Jordan; Dan Klein"
            },
            {
                "ref_id": "b41",
                "title": "An introduction to formal languages and automata",
                "journal": "Jones & Bartlett Learning",
                "year": "2022",
                "authors": "Peter Linz; H Susan;  Rodger"
            },
            {
                "ref_id": "b42",
                "title": "Learning algebraic recombination for compositional generalization",
                "journal": "Association for Computational Linguistics",
                "year": "2021",
                "authors": "Chenyao Liu; Shengnan An; Zeqi Lin; Qian Liu; Bei Chen; Jian-Guang Lou; Lijie Wen; Nanning Zheng; Dongmei Zhang"
            },
            {
                "ref_id": "b43",
                "title": "Improving compositional generalization in semantic parsing",
                "journal": "Online. Association for Computational Linguistics",
                "year": "2020",
                "authors": "Inbar Oren; Jonathan Herzig; Nitish Gupta; Matt Gardner; Jonathan Berant"
            },
            {
                "ref_id": "b44",
                "title": "Compositional semantic parsing on semi-structured tables",
                "journal": "Association for Computational Linguistics",
                "year": "2015",
                "authors": "Panupong Pasupat; Percy Liang"
            },
            {
                "ref_id": "b45",
                "title": "Computational optimal transport: With applications to data science. Foundations and Trends\u00ae in Machine Learning",
                "journal": "",
                "year": "2019",
                "authors": "Gabriel Peyr\u00e9; Marco Cuturi"
            },
            {
                "ref_id": "b46",
                "title": "Improving compositional generalization with latent structure and data augmentation",
                "journal": "CoRR",
                "year": "2021",
                "authors": "Linlu Qiu; Peter Shaw; Panupong Pasupat; Pawel Krzysztof Nowak; Tal Linzen; Fei Sha; Kristina Toutanova"
            },
            {
                "ref_id": "b47",
                "title": "Evaluating the impact of model scale for compositional generalization in semantic parsing",
                "journal": "Association for Computational Linguistics",
                "year": "2022",
                "authors": "Linlu Qiu; Peter Shaw; Panupong Pasupat; Tianze Shi; Jonathan Herzig; Emily Pitler; Fei Sha; Kristina Toutanova"
            },
            {
                "ref_id": "b48",
                "title": "Abstract syntax networks for code generation and semantic parsing",
                "journal": "Long Papers",
                "year": "2017",
                "authors": "Maxim Rabinovich; Mitchell Stern; Dan Klein"
            },
            {
                "ref_id": "b49",
                "title": "Compositional generalization and natural language variation: Can a semantic parsing approach handle both?",
                "journal": "",
                "year": "2021",
                "authors": "Peter Shaw; Ming-Wei Chang; Panupong Pasupat; Kristina Toutanova"
            },
            {
                "ref_id": "b50",
                "title": "Ordered neurons: Integrating tree structures into recurrent neural networks",
                "journal": "",
                "year": "2019",
                "authors": "Yikang Shen; Shawn Tan; Alessandro Sordoni; Aaron Courville"
            },
            {
                "ref_id": "b51",
                "title": "Paradigm shift in natural language processing",
                "journal": "Machine Intelligence Research",
                "year": "2022",
                "authors": "Tian-Xiang Sun; Xiang-Yang Liu; Xi-Peng Qiu; Xuan-Jing Huang"
            },
            {
                "ref_id": "b52",
                "title": "Vallejos, and Nianwen Xue. 2021. Designing a uniform meaning representation for natural language processing",
                "journal": "KI -K\u00fcnstliche Intelligenz",
                "year": null,
                "authors": "Jens E L Van Gysel; Meagan Vigus; Jayeol Chun; Kenneth Lai; Sarah Moeller; Jiarui Yao; O' Tim; Andrew Gorman; William Cowell; Chu-Ren Croft;  Huang"
            },
            {
                "ref_id": "b53",
                "title": "Semantic expressive capacity with bounded memory",
                "journal": "",
                "year": "2019",
                "authors": "Antoine Venant; Alexander Koller"
            },
            {
                "ref_id": "b54",
                "title": "Association for Computational Linguistics",
                "journal": "",
                "year": "",
                "authors": "Italy Florence"
            },
            {
                "ref_id": "b55",
                "title": "Compositional generalization requires compositional parsers",
                "journal": "",
                "year": "2022",
                "authors": "Pia Wei\u00dfenhorn; Yuekun Yao; Lucia Donatelli; Alexander Koller"
            },
            {
                "ref_id": "b56",
                "title": "Transformers: State-of-the-art natural language processing",
                "journal": "Association for Computational Linguistics",
                "year": "2020",
                "authors": "Thomas Wolf; Lysandre Debut; Victor Sanh; Julien Chaumond; Clement Delangue; Anthony Moi; Pierric Cistac; Tim Rault; Remi Louf; Morgan Funtowicz; Joe Davison; Sam Shleifer; Clara Patrick Von Platen; Yacine Ma; Julien Jernite; Canwen Plu; Teven Le Xu; Sylvain Scao; Mariama Gugger; Quentin Drame; Alexander Lhoest;  Rush"
            },
            {
                "ref_id": "b57",
                "title": "Learning for semantic parsing with statistical machine translation",
                "journal": "Association for Computational Linguistics",
                "year": "2006",
                "authors": "Yuk Wah Wong; Raymond Mooney"
            },
            {
                "ref_id": "b58",
                "title": "Learning synchronous grammars for semantic parsing with lambda calculus",
                "journal": "Association for Computational Linguistics",
                "year": "2007",
                "authors": "Yuk Wah Wong; Raymond Mooney"
            },
            {
                "ref_id": "b59",
                "title": "Learning with latent structures in natural language processing: A survey",
                "journal": "",
                "year": "2022",
                "authors": "Zhaofeng Wu"
            },
            {
                "ref_id": "b60",
                "title": "Sequence-based structured prediction for semantic parsing",
                "journal": "Long Papers",
                "year": "2016",
                "authors": "Chunyang Xiao; Marc Dymetman; Claire Gardent"
            },
            {
                "ref_id": "b61",
                "title": "Sqlnet: Generating structured queries from natural language without reinforcement learning",
                "journal": "",
                "year": "2018",
                "authors": "Xiaojun Xu; Chang Liu; Dawn Song"
            },
            {
                "ref_id": "b62",
                "title": "PCFGs can do better: Inducing probabilistic contextfree grammars with many symbols",
                "journal": "Online. Association for Computational Linguistics",
                "year": "2021",
                "authors": "Songlin Yang; Yanpeng Zhao; Kewei Tu"
            },
            {
                "ref_id": "b63",
                "title": "Semantic parsing via staged query graph generation: Question answering with knowledge base",
                "journal": "Association for Computational Linguistics",
                "year": "2015",
                "authors": "Ming-Wei Wen-Tau Yih; Xiaodong Chang; Jianfeng He;  Gao"
            },
            {
                "ref_id": "b64",
                "title": "Compositional generalization for neural semantic parsing via spanlevel supervised attention",
                "journal": "",
                "year": "2021",
                "authors": "Pengcheng Yin; Hao Fang; Graham Neubig; Adam Pauls; Yu Emmanouil Antonios Platanios; Sam Su; Jacob Thomson;  Andreas"
            },
            {
                "ref_id": "b65",
                "title": "A syntactic neural model for general-purpose code generation",
                "journal": "Association for Computational Linguistics",
                "year": "2017",
                "authors": "Pengcheng Yin; Graham Neubig"
            },
            {
                "ref_id": "b66",
                "title": "TRANX: A transition-based neural abstract syntax parser for semantic parsing and code generation",
                "journal": "Association for Computational Linguistics",
                "year": "2018",
                "authors": "Pengcheng Yin; Graham Neubig"
            },
            {
                "ref_id": "b67",
                "title": "Online learning of relaxed CCG grammars for parsing to logical form",
                "journal": "",
                "year": "2007",
                "authors": "Luke Zettlemoyer; Michael Collins"
            },
            {
                "ref_id": "b68",
                "title": "Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars",
                "journal": "AUAI Press",
                "year": "2005",
                "authors": "Luke S Zettlemoyer; Michael Collins"
            },
            {
                "ref_id": "b69",
                "title": "Macro grammars and holistic triggering for efficient semantic parsing",
                "journal": "",
                "year": "2017",
                "authors": "Yuchen Zhang; Panupong Pasupat; Percy Liang"
            },
            {
                "ref_id": "b70",
                "title": "Disentangled sequence to sequence learning for compositional generalization",
                "journal": "Association for Computational Linguistics",
                "year": "2022",
                "authors": "Hao Zheng; Mirella Lapata"
            },
            {
                "ref_id": "b71",
                "title": "Adabelief optimizer: Adapting stepsizes by the belief in observed gradients. Advances in Neural Information Processing Systems",
                "journal": "",
                "year": "2020",
                "authors": "Juntang Zhuang; Tommy Tang; Yifan Ding; C Sekhar; Nicha Tatikonda; Xenophon Dvornek; James Papademetris;  Duncan"
            }
        ],
        "figures": [
            {
                "figure_label": "2",
                "figure_type": "figure",
                "figure_id": "fig_0",
                "figure_caption": "Figure 2 :2Figure 2: Accuracies viewed in S and T choices. Each bar is a distribution across all 9 CG datasets.",
                "figure_data": ""
            },
            {
                "figure_label": "3",
                "figure_type": "figure",
                "figure_id": "fig_1",
                "figure_caption": "Figure 3 :3Figure 3: Accuracies viewed in S models. Each bar is the distribution of accuracies on 9 CG datasets.",
                "figure_data": ""
            },
            {
                "figure_label": "4",
                "figure_type": "figure",
                "figure_id": "fig_2",
                "figure_caption": "Figure 4 :4Figure 4: Accuracies viewed in combinations of each S and T choice, on 9 CG datasets.",
                "figure_data": ""
            },
            {
                "figure_label": "5",
                "figure_type": "figure",
                "figure_id": "fig_3",
                "figure_caption": "Figure 5 :5Figure 5: Accuracies for different PCFGs as encoders against different T choices on the GEO datasets with compositional generalization.",
                "figure_data": ""
            },
            {
                "figure_label": "6",
                "figure_type": "figure",
                "figure_id": "fig_4",
                "figure_caption": "Figure 6 :6Figure 6: Accuracies for latent S models with different target T choices. Each bar is the distribution of accuracies on 9 CG datasets.",
                "figure_data": ""
            },
            {
                "figure_label": "7",
                "figure_type": "figure",
                "figure_id": "fig_5",
                "figure_caption": "Figure 7 :7Figure 7: Differences subtracted the given T accuracies from the latent and absent T, under each dataset and each S-choice, with I.I.D. (Top) and compositional generalization (Down). Positive values mean that the latent or absent T outperforms the given T, while negative values suggest the given T is better.",
                "figure_data": ""
            },
            {
                "figure_label": "8",
                "figure_type": "figure",
                "figure_id": "fig_6",
                "figure_caption": "Figure 8 :8Figure8: Fitting the metrics of different (S, T) choices to the accuracies on different datasets and generalizations. We include the absent S and both absent and given T, showing whether the metric can reflect the differences between the grammar-based and the sequence-based structures of the formal languages. Metrics computed with 3 chosen LLMs are all shown negatively correlated with the performance.",
                "figure_data": ""
            },
            {
                "figure_label": "9",
                "figure_type": "figure",
                "figure_id": "fig_7",
                "figure_caption": "Figure 9 :9Figure9: On each dataset and generalization level (totally 13 here), we compute metrics for two pairs, i.e. (absent, absent) and (absent, given), corresponding to two points in Figure8. We plot the histogram for the slope of each line determined by the two points. The slopes are negative and are also low when positive, suggesting the metrics are possibly indicative for specific datasets and generalization level.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "table",
                "figure_id": "tab_0",
                "figure_caption": "and do not support programming languages.",
                "figure_data": "Semantic ParsingEncoderDecoderMake me a meeting with( Yield :output ( Create-my team . We need a roomCommitEventWrapper :event ( \u2026Make meWe need\u2026Yield :outputa \u2026Create\u2026Grammar InductionFigure 1: Structural modeling in two tasks. We're goingto analyze how the progress in grammar induction couldhelp neural semantic parsing."
            },
            {
                "figure_label": "",
                "figure_type": "table",
                "figure_id": "tab_1",
                "figure_caption": "Table 1 gives the statistics. For the gen-",
                "figure_data": "DatasetSplit# Examples (train / dev / test)ATIS (SQL)I.I.D.3014 / 405 / 402ATIS (SQL)Program3061 / 375 / 373Advising (SQL)I.I.D.3440 / 451 / 446Advising (SQL)Program3492 / 421 / 414Geo (SQL)I.I.D.409 / 103 / 95Geo (SQL)Program424 / 91 / 91Scholar (SQL)I.I.D.433 / 111 / 105Scholar (SQL)Program454 / 97 / 98COGS (\u03bb-calculus)I.I.D.24160 / 3000 / 3000COGS (\u03bb-calculus) Linguistic 24160 / 3000 / 21000SMC16 (Lispress)Domain25424 / 1324 / 1325SMC32 (Lispress)Domain25440 / 1324 / 1325SMC64 (Lispress)Domain25472 / 1324 / 1325SMC128 (Lispress)I.I.D.25536 / 1324 / 1325SMC128 (Lispress)Domain25536 / 1324 / 1325Table 1: The number of examples in each dataset. Dif-ferent kinds of generalizations are explained in Sec-tion 2.1. SMCk denotes the SMCalFlow-CS datasetwith k few-shot examples added into the training set.We manually shuffle the SMC-128 to build an I.I.D. split.The representation of each dataset is in the parenthesis."
            },
            {
                "figure_label": "2",
                "figure_type": "table",
                "figure_id": "tab_3",
                "figure_caption": "",
                "figure_data": ": Probabilistic forms for all Seq2Seq-style mod-els in comparison. Structures of both side can be oneof three choices. If S is latent, training another modelP (S | X) is necessary to infer S."
            },
            {
                "figure_label": "3",
                "figure_type": "table",
                "figure_id": "tab_5",
                "figure_caption": "Models for corresponding S and T choices.",
                "figure_data": ""
            },
            {
                "figure_label": "5",
                "figure_type": "table",
                "figure_id": "tab_9",
                "figure_caption": "The accuracies of each datasets on their compositional generalization levels. For the ATIS, GEO, Scholar and Advising, average results of 5 random seeds are reported.",
                "figure_data": "encoderdecoder smc16 smc32 smc64 smc128 advising atis cogs geo scholarseq28.419.840.052.65.915.10.026.226.1bilstmonlstm28.226.234.748.25.215.37.422.925.7prod14.127.631.126.97.816.30.026.621.6seq32.132.520.252.36.822.86.225.931.0onlstmonlstm31.439.746.348.85.024.73.126.232.4prod9.727.332.731.36.322.23.030.827.4seq29.237.942.251.19.129.82.629.533.1bertonlstm27.342.044.855.89.819.30.035.833.3prod16.228.332.442.37.631.20.031.027.8seq29.437.750.041.74.729.00.023.721.0electraonlstm27.531.832.053.37.018.60.018.521.8prod13.118.225.436.76.030.90.925.517.5seq26.919.328.533.33.918.5 27.3 24.226.1dioraonlstm28.118.227.647.95.117.9 21.1 25.127.3prod8.521.822.532.13.315.48.229.719.6seq23.221.423.740.22.811.00.017.614.9rcpcfgonlstm22.218.332.326.20.014.712.9prod17.316.220.212.21.711.80.017.815.5seq21.524.119.923.20.71.40.016.916.1rtdpcfgonlstm9.423.326.632.10.012.512.9prod6.317.314.515.71.53.40.013.213.2seq19.520.129.624.86.312.30.018.522.9pnponlstm17.119.220.521.96.217.10.020.920.4prod6.812.518.924.53.316.40.025.719.8seq23.827.228.839.211.416.40.022.030.4syn-parseronlstm24.327.637.440.99.316.00.021.330.6prod6.817.121.131.77.817.40.023.721.4"
            },
            {
                "figure_label": "6",
                "figure_type": "table",
                "figure_id": "tab_10",
                "figure_caption": "The accuracies of each datasets with the I.I.D. generalization. Similar to the CG level, average results of 5 random seeds are reported for the ATIS, GEO, Scholar, and Advising datasets",
                "figure_data": ""
            }
        ],
        "formulas": [
            {
                "formula_id": "formula_0",
                "formula_text": "d s,t,D =E (x,y)\u2208D [emd(u s , u t , cost(e s , e t ))] (3)",
                "formula_coordinates": [
                    7.0,
                    78.84,
                    404.39,
                    211.02,
                    11.22
                ]
            },
            {
                "formula_id": "formula_1",
                "formula_text": "M (s, t) = |E[d s,t,D train ] \u2212 E[d s,t,Dtest ]| \u03c3[d s,t,D train ]\u03c3[d s,t,Dtest ](4)",
                "formula_coordinates": [
                    7.0,
                    85.05,
                    697.92,
                    204.82,
                    26.49
                ]
            },
            {
                "formula_id": "formula_2",
                "formula_text": "max \u03b8 P \u03b8 (Y | X) = E S\u2208P (S|X) P (Y | S, X) (6)",
                "formula_coordinates": [
                    14.0,
                    315.18,
                    130.05,
                    209.96,
                    16.35
                ]
            },
            {
                "formula_id": "formula_3",
                "formula_text": "s ik j = sof tmax f s h in (x i:j ), h in (x j:k ) j (8)",
                "formula_coordinates": [
                    14.0,
                    314.89,
                    504.28,
                    210.25,
                    15.81
                ]
            },
            {
                "formula_id": "formula_4",
                "formula_text": "h i = [h in (x i:i+1 ); h out (x i:i+1 )],",
                "formula_coordinates": [
                    14.0,
                    348.19,
                    668.4,
                    144.68,
                    12.58
                ]
            },
            {
                "formula_id": "formula_5",
                "formula_text": "max \u03b8 L diora = i log P \u03b8 (x i |h out (x i:i+1 )) (9)",
                "formula_coordinates": [
                    15.0,
                    82.3,
                    111.48,
                    207.57,
                    24.58
                ]
            },
            {
                "formula_id": "formula_6",
                "formula_text": "s ikA = B C j w ijkABC(10)",
                "formula_coordinates": [
                    15.0,
                    126.9,
                    596.22,
                    162.96,
                    22.26
                ]
            },
            {
                "formula_id": "formula_7",
                "formula_text": "w ijkABC = \u03c0 A\u2192BC \u2022 s ijB \u2022 s jkA(11)",
                "formula_coordinates": [
                    15.0,
                    106.95,
                    625.42,
                    182.92,
                    10.77
                ]
            },
            {
                "formula_id": "formula_8",
                "formula_text": "h i:k = A,B,C,j h ijkABC \u2022 w ijkABC \u2022 \u03c0 s (A) (12)",
                "formula_coordinates": [
                    15.0,
                    79.68,
                    730.46,
                    210.19,
                    22.26
                ]
            },
            {
                "formula_id": "formula_9",
                "formula_text": "h ijkABC = f h (A) + f ls (B) + f rs (C) + f l (h i:j ) + f r (h j:k )(13)",
                "formula_coordinates": [
                    15.0,
                    331.75,
                    205.66,
                    193.39,
                    27.31
                ]
            },
            {
                "formula_id": "formula_10",
                "formula_text": "\u03c0 A\u2192BC = l u l A \u2022 v l B \u2022 w l C",
                "formula_coordinates": [
                    15.0,
                    306.14,
                    297.34,
                    125.4,
                    14.18
                ]
            },
            {
                "formula_id": "formula_11",
                "formula_text": "W = f head (e(X)) \u2022 f tail (e(X)) T (14) Z \u223c G(0, 1) (15) S = Eisner(W + Z)(16)",
                "formula_coordinates": [
                    15.0,
                    341.71,
                    557.12,
                    183.43,
                    45.38
                ]
            }
        ],
        "doi": "10.18653/v1/P17-1008"
    },
    "Humans and language models diverge when predicting repeating text": {
        "authors": "Aditya R Vaidya; Javier Turek; Alexander G Huth; U T Austin",
        "pub_date": "",
        "abstract": "Language models that are trained on the nextword prediction task have been shown to accurately model human behavior in word prediction and reading speed. In contrast with these findings, we present a scenario in which the performance of humans and LMs diverges. We collected a dataset of human next-word predictions for five stimuli that are formed by repeating spans of text. Human and GPT-2 LM predictions are strongly aligned in the first presentation of a text span, but their performance quickly diverges when memory (or in-context learning) begins to play a role. We traced the cause of this divergence to specific attention heads in a middle layer. Adding a power-law recency bias to these attention heads yielded a model that performs much more similarly to humans. We hope that this scenario will spur future work in bringing LMs closer to human behavior. 1  ",
        "sections": [
            {
                "heading": "Introduction",
                "text": [
                    "Transformer-based language models (LMs) are neural networks that are trained to predict upcoming words from their preceding context. These models flexibly retrieve and combine information across a context that might span thousands of words, enabling them to learn from in-context examples (Dai et al., 2022;Xie et al., 2022;Olsson et al., 2022), tell coherent stories (Lee et al., 2022), and perform many other advanced language tasks (Tiedemann and Thottingal, 2020;Brown et al., 2020).",
                    "These abilities far surpass any previous computational models or linguistic theories (Yang and Piantadosi, 2022), leading many to use LMs as models of human cognition. For example, LM surprisal-a measure of how well it can predict the next word-has been found to be highly correlated with both how long humans spend reading each word (Goodkind and Bicknell, 2018;Hao et al., 2020;Wilcox et al., 2020) and the accuracy of human next-word predictions (Goldstein et al., 2021;Jacobs and McCarthy, 2020). These results suggest that LMs and humans might be using similar mechanisms to structure and recall information from memory. However, these seeming parallels have not gone unchallenged. Oh and Schuler (2023), for example, showed that LM surprisal and human reading time become decorrelated as models grow in size and power, suggesting a more superficial relationship than previously thought.",
                    "In this work we test whether apparent similarities between LM and human next-word prediction accuracy reflect true similarities in memory mechanisms. To accomplish this we introduce a new task that combines memory with next-word prediction using repeating natural text stimuli. Comparing human behavioral performance with an LM, we found that LM surprisal decorrelates from human predictions in this scenario. While human performance improves modestly with each repetition, the transformer-based LM GPT-2 (Radford et al., 2019) reaches near-perfect performance after just one presentation. To better understand this behavior, we examined the patterns of memory access (via attention) in the model, revealing how the model solves this task. We then showed that the model can be made to perform more like the humans by adjusting these patterns to mimic human memory (Donkin and Nosofsky, 2012).",
                    "This work demonstrates an important way in which human and LM memory mechanisms diverge, casting doubt on the use of existing LMs as a model of human cognition. However, the framework we developed for making the model more human-like also provides a potential way forward. Directly optimizing LMs for human-like behaviorincluding but not limited to memory tasks like that used here-could lead to much better computational models of human cognition and memory. It is also possible that investigating the relationship between human and model memory could provide guidance for developing better, more efficient neural network models."
                ],
                "publication_ref": [
                    "b6",
                    "b29",
                    "b16",
                    "b26",
                    "b30",
                    "b28",
                    "b11",
                    "b24",
                    "b9"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Related works",
                "text": [
                    "Human performance on recall tasks, like the experiment we propose here, is primarily limited by shortterm memory (Baddeley, 1992). In these tasks, humans show both recency biases (i.e. better recall for the most recent items) and primacy biases (better for the first items) (Tzeng, 1973;Jefferies et al., 2004). Recall tasks often show repetition effects; presenting a stimulus multiple times successively decreases the recall error rate (Kintsch, 1965;Baddeley and Ecob, 1973;Amlund et al., 1986). Some have suggested a link between language deficits and the number of presentations needed to reach perfect verbatim sentence recall (Miles et al., 2006). Many studies have also shown that human memory decay follows a power law (Donkin and Nosofsky, 2012), where, for example, the number of items accurately recalled from a list will decrease over time t proportional to t \u2212d for some constant decay rate d.",
                    "Transformers neural networks, in contrast with humans, can attend to exact token identities hundreds or thousands of tokens in the past at no additional cost, subject only to the context length. One limitation of the standard attention implementation is that memory and runtime scale quadratically with the number of tokens, making longer inputs prohibitively expensive. Recently, significant work has gone into extending the maximum context length for transformers while avoiding these computational issues. Transformer-XL caches hidden states to allow attention to tokens beyond the immediate input (Dai et al., 2019). FlashAttention is an optimized attention algorithm that exploits the hardware architecture to train models with context lengths up to 64K tokens (Dao et al., 2022). The ALiBi method (Press et al., 2022) replaces sinusoidal positional embeddings with a recency bias on the attention scores, such that closer query-key pairs are weighted higher than more distant pairs. Using ALiBi necessitates retraining a model with the new attention mechanism, though once trained it can generalize to longer lengths."
                ],
                "publication_ref": [
                    "b2",
                    "b27",
                    "b12",
                    "b14",
                    "b3",
                    "b0",
                    "b19",
                    "b9",
                    "b7",
                    "b8",
                    "b23"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Human behavioral study",
                "text": [
                    "We first designed an experiment to evaluate human memory in a next-word prediction task with repeated word sequences. We then compared the humans against an LM on the same stimuli to evaluate the LM's memory."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Setup for humans",
                "text": [
                    "We collected human next-word predictions on repeating stimuli from a corpus of spoken story transcripts (LeBel et al., 2023). To construct the stimuli, we chose five phrase-aligned spans of between 40 and 100 words (without punctuation) from the corpus and repeated each span between one and three times, for a total of between 2 and 4 presentations of the span. One span was repeated once; three spans were repeated twice; and one span was repeated three times. The stimuli can be seen in Section A in the Appendix. Subjects were presented words one-at-a-time via rapid serial visual presentation (RSVP; Potter, 1984) at a fixed duration of 400 ms per word, with 1.5 s pauses at the end of each presentation. At predetermined moments, subjects were prompted to predict the next word given the previous 10 words. Prompts appeared roughly every 13 words, giving the subjects time to process the story naturally between interruptions. Figure 1 shows the presentation of the stimuli and an example prompt screen.",
                    "To ensure that we could measure memory effects robustly, 50% of a given subject's prompts were at the same position in all presentations of a stimulus, while the other 50% were only prompted on a single presentation. Within each presentation, prompts were selected by taking a weighted random sample of the words to provide a balanced selection of low-and high-frequency words. Weights were calculated as the average of two values: the complement of the unigram probability and the reciprocal of the unigram probability. Both weights were normalized to sum over words to 1 before being averaged. Subjects were told at the beginning of the experiment that the word sequences will repeat, but were not told where. Human performance P human (correct) was calculated as the proportion of participants whose responses exactly match the ground-truth next word, ignoring case and leading or trailing whitespace.",
                    "In total, 100 online participants were recruited through Prolific (www.prolific.co). Subjects were required to be fluent in English and were given G iv e n t h e c o n t e x t : P r e d ic t t h e n e x t w o r d :",
                    "e v e r y th in g w a it in g fo r th e li g h t to c h a n g e w e 'r e a t th is",
                    "we're at this farmhouse and it was like a scene out of a big buffet and everything [...] waiting for the light to change we're at this farmhouse and it was like a scene out of a big buffet and everything [...] waiting for the light to change we're at this farmhouse and it was like a scene out of a big buffet and everything [...]   performance-based bonus compensation. The online experiment was constructed using the Gorilla Experiment Builder (www.gorilla.sc). The experimental protocol was approved by the Institutional Review Board at The University of Texas at Austin. Written consent was obtained from all subjects."
                ],
                "publication_ref": [
                    "b22"
                ],
                "figure_ref": [
                    "fig_0"
                ],
                "table_ref": []
            },
            {
                "heading": "Setup for language models",
                "text": [
                    "We used a pre-trained GPT-2 Small (Radford et al., 2019) model, which we fine-tuned to change its tokenization from BPE (Sennrich et al., 2016) to word-level (i.e., whitespace-delimited) so that its tokenization scheme would match the experimental protocol for the human participants. We used nonrepeating story transcripts as training data for finetuning and excluded the stories used to construct the behavioral stimuli. To get model prediction probabilities for comparison with the human data, we fed the entire repeating stimulus into the model and calculated the top-1 accuracy for each token."
                ],
                "publication_ref": [
                    "b24",
                    "b25"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Behavioral study results",
                "text": [
                    "Figure 2a shows human performance on one text span; as they are shown more words, human accuracy generally increases. Many stop words are predicted well even during the first presentation, while non-stop words improve more linearly with the number of presentations. Humans consistently improve as they are shown more presentations of the same text span, as seen in Figure 2b. While the model accuracy is similar to humans on the first presentation, it quickly jumps to a much higher level thereafter.",
                    "A more detailed view appears in Figure 2c, where we show accuracy for both model and human on each probe word. GPT-2 accuracy is strongly correlated with human accuracy for the initial presentation of this span (r = 0.87), replicating earlier findings (Goldstein et al., 2021). However, model and human accuracies markedly diverge thereafter, with the correlation dropping to r = 0.24 in the second presentation and r = 0.05 in the third.",
                    "These results provide a potent counterexample to previous claims of alignment: Humans and LMs only seem to behave similarly in the initial presentation of a stimulus, but produce uncorrelated behavior once short-term memory comes into play. This suggests that the model and humans are exploiting very different memory mechanisms to solve this task. The humans must rely on lossy short-term memory, while the model can leverage in-context learning to provide super-human, near-perfect recall. While earlier reports suggested that such detailed recall might mimic human working memory (Armeni et al., 2022), these results suggest that the models go well beyond human capabilities."
                ],
                "publication_ref": [
                    "b11",
                    "b1"
                ],
                "figure_ref": [
                    "fig_1",
                    "fig_1",
                    "fig_1"
                ],
                "table_ref": []
            },
            {
                "heading": "Patterns in model attention",
                "text": [
                    "Our behavioral results show that human and LM next-word prediction diverge sharply when short- term memory is involved, suggesting that the two systems use substantially different memory mechanisms. To gain insight into the cause of these differences, we next sought to understand how exactly the model was able to achieve such high performance on this task. \"Memory\" in transformer models is implemented by using dot-product attention over previous words. Each of the 12 layers in this model contains 12 attention heads, each of which looks for specific features in the content or location of previous words. The action of each attention head can be summarized in an attention matrix, A, which shows how much attention token i is paying to token j for all j < i. Attention weights are normalized so that each row A i of the attention matrix sums to 1. The values in the attention matrix can thus show us how and where the model is \"recalling\" past information.",
                    "Previous work on simplified transformer models has identified the emergence of specific attention heads that recognize patterns in the input and produce outputs that complete those patterns (Elhage et al., 2021;Olsson et al., 2022). These induction heads specifically attend to the token after the previous presentation of the current (input) token, essentially allowing the model to read out the completion from a previous instance of the same pattern. For inputs that are constructed from repeating sequences-like those used in our behavioral experiment-induction heads should thus produce a highly stereotypical attention matrix: If a stimulus consists of repeating spans of length k, the head attends to the token k \u2212 1 tokens in the past.",
                    "We examined the attention matrices of GPT-2 Small for our stimuli and found multiple heads across many layers that exhibit induction behavior. Figure 3a depicts example attention matrices for four heads in layer 6. While attention values are non-negative and sum to 1 in each row, we use log-scaled values here to highlight subtle effects. For this test the stimulus consisted of three presentations of a 65-word span, so an induction head should attend to the word appearing 64 positions ago, which is exactly the word that the model should output at each point. This should manifest as strong diagonals in the attention matrix. This is exactly the pattern that we see for attention heads 1 and 2. Further, when processing tokens in the third presentation, these heads attend to previous instances in both of the first two presentations (64 and 129 tokens in the past). To illustrate that this pattern is not found everywhere in the model, we also show two other attention heads (3 and 4) from the same layer, which exhibit no induction-like behavior, but instead attend to recent words.",
                    "To more efficiently find induction-like behavior in the model, we can summarize how well the attention matrix for each head matches a few different patterns. For each layer, we quantified the average probability mass attributable to the heads attending to:",
                    "\u2022 the first token in the input, often thought to represent a sort of \"default\" attention state (Olsson et al., 2022),",
                    "\u2022 the 5 most recent tokens (likely capturing local syntactic effects),",
                    "\u2022 the current token,",
                    "\u2022 past instances of the current token,",
                    "\u2022 the token after each past instance of the current token (induction), and",
                    "\u2022 all other tokens.",
                    "Figure 3b shows the probability mass given to each attention pattern in each layer, averaged across all 12 heads. We see that the induction attention pattern arises sharply and specifically in layer 6 and continues through the output layer (layer 12). These results suggest that these layers-and especially layer 6-have a causal role in copying words from previous repetitions of the text span, and thus may be the source of the divergence in human-LM accuracy. In the next section, we test this hypothesis by selectively disrupting each layer in an attempt to make the model more human-like."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_2",
                    "fig_2"
                ],
                "table_ref": []
            },
            {
                "heading": "Attention optimization",
                "text": [
                    "Our previous results showed that human and LM next-word prediction accuracy diverge when shortterm memory comes into play, suggesting that human and model memory mechanisms behave very differently. We then showed this divergence might be caused by the model's induction heads, which we hypothesized enable it to identify and recall patterns with superhuman accuracy. We next asked if it is possible to modify the model so that its memory behaves more like the human. Because the LM is superhuman, such a modification will selectively hurt the LM's performance.",
                    "Since memory in this model is implemented through attention, we approached this problem by modifying the attention matrices of the model. We learn an additive bias B h for the attention matrix of each head h in one layer such that adding this bias to the pre-softmax attention weights will produce outputs that are more human-like. Namely, we modify the attention mechanism in the model to be",
                    "Attn(Q, K, V ) = softmax QK T \u221a d +B h V (1)",
                    "Each stimulus consists of an S-token span presented R times, for a total stimulus length T = SR. Human and model top-1 accuracy for prompted word i is denoted P human (correct i ) and P model (correct i ), respectively, and N i is the number of participants that responded to that prompt. Let B h \u2208 R T \u00d7T be the additive bias for head h, and H = 12 be the number of attention heads in each layer of GPT-2. We optimize over {B 1 , . . . , B H } to minimize the mean squared error (MSE) between P human (correct) and P model (correct), weighted by the number of subjects who responded to each prompt (N i ). W is the number of words that were prompted for at least one subject.",
                    "min",
                    "{B 1 ,...,B H } 1 W W i=1 N i P human (correct i )\u2212 P model (correct i ) 2 (2)",
                    "What form should B h take? The model is superhuman in its long-distance memory, so we sought to reduce the impact of long-distance attention by giving the model a recency bias. Much earlier work has shown that human memory tends to decay as a power law with time (Donkin and Nosofsky, 2012). A similar form of decay is also seen in mutual information between words as a function of their separation (Lin and Tegmark, 2017), and this has been previously exploited in designing efficient language models (Mahto et al., 2020). To capture this type of behavior, we parameterized B h with \u03b1 h , \u03b2 h \u2208 R:",
                    "B h = T \u22121 k=0 diag k (\u03b1 h \u2022 k \u2212 exp(\u03b2 h ) )(3)",
                    "where diag k (d) constructs a T \u00d7 T matrix that places the scalar d along the k-th diagonal below the main diagonal. Figure 4a shows an example matrix with this form. This form of B h is advantageous because the effect of \u03b1 h , \u03b2 h can be evaluated on stimuli of any form or length, including those that are non-repeating. We initialize \u03b1 h , \u03b2 h by sampling from a standard normal distribution. We optimize the attention matrix biases B h to match human data from one stimulus over 2000 epochs via gradient descent with the Adam optimizer (Kingma and Ba, 2017), and then evaluated human-model similarity with the other four stim-uli. For each training stimulus, we repeated this procedure with five initializations using different random seeds. We set the learning rate to 5 \u00d7 10 \u22123 ."
                ],
                "publication_ref": [
                    "b9",
                    "b17",
                    "b18"
                ],
                "figure_ref": [
                    "fig_3"
                ],
                "table_ref": []
            },
            {
                "heading": "Optimization results",
                "text": [
                    "Because the long-range copying behavior seems to initiate in layer 6 (Figure 3b), we began by only optimizing the attention bias for that layer.",
                    "We first examine the post-optimization timecourse of P model (correct) by averaging the held-out accuracies for a single stimulus (Figure 4b). While the model's predictions are largely unchanged in the initial presentation, performance significantly deviates toward human values in later presentations. This is summarized in Figure 4c, where the model's average performance within the later presentations is closer to humans after optimization. Importantly, this optimization procedure produces B h that generalize across stimuli because we do not fit on the human data for the held-out stimulus.",
                    "Additionally, these B h generalize within the stimulus. To measure within-stimulus generalization, we randomly selected 30% of the prompts from each presentation of the span and calculated the MSE on this subset separately from the rest of the stimulus. Figure 4d shows the training and heldout (validation) loss curves for the train stimulus, averaged across all five stimuli and five random initializations. Training loss decreases on average 52.9%, while validation loss decreases 40.4%; most of the improvement for held-out prompts occurs in the first 1000 epochs.",
                    "We next examined the effects of the layer 6 intervention on the summarized attention patterns of each layer, similar to Figure 3b. Figure 4e shows the log-ratio of post-and pre-optimization probability mass for each attention pattern, averaged across all held-out stimuli. The learned bias increases attention on the current token at the expense of all other measured patterns in layer 6, including (importantly) the induction pattern that would directly copy the correct token from a previous presentation. Even though we only intervened in layer 6, the induction pattern is weaker in all following layers, and the model is attending more to the current and recent tokens.",
                    "Finally, we repeated the entire optimization procedure independently on each layer and evaluated the change in human-LM correlation. We had hypothesized that our intervention should only work to create human-like behavior when applied to lay-ers 6-12, which contained induction heads. However, the intervention improved model-human correlation on repeated spans regardless of the layer on which optimization was performed (Figure 4f, brown line). Effects were strongest for layers 4-9, but small improvements were seen in every layer. This might suggest that induction heads are not the only important memory mechanism for this problem, or that the same effects can be achieved by modifying the inputs to induction heads.",
                    "Our results show that the recency bias intervention was effective at rescuing the divergence between human and model performance, but it is possible that this improvement comes at the cost of much worse model performance in other ways. For example, it could reduce the high correlation between human and model in scenarios lacking short-term memory, or make the model worse overall at next-word prediction. To test for the first effect, we computed the human-model correlation for the first presentation of each held-out stimulus (Figure 4f, orange line). We found that the correlation did fall, but by a much smaller amount than the correlation on subsequent presentations improved. For example, in layer 6 human-model correlation on the first presentation decreased by about 0.03, but the correlation on later presentations increased by 0.2.",
                    "We also tested whether our intervention increased LM perplexity on an unseen set of nonrepeating text from the story corpus in order to measure how general LM abilities change due to the intervention. No stories that were used for finetuning or constructing the repeating stimuli were used to measure perplexity. We computed the average perplexity for the modified and un-modified model, and reported their ratio (Figure 4f, blue line). We found that perplexity did increase due to the intervention, meaning that it generally harmed next-word prediction performance. However, the degree of increase varied substantially depending on which layer was modified, with the largest effect found in layer 6 (a more than 40% increase) and smaller effects in the earliest and latest layers (roughly 10% increase). This suggests that at least part of the model's general next-word prediction performance stems from its superhuman recall, and not its ability to mimic human cognition. Taking these three results together, we would suggest that the best layer to modify actually appears to be layer 9, which yields the largest improvement in human-model correlation with memory, a modest decline in human-model correlation without memory, and only a roughly 15% increase in overall model perplexity."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_2",
                    "fig_3",
                    "fig_3",
                    "fig_3",
                    "fig_2",
                    "fig_3",
                    "fig_3",
                    "fig_3",
                    "fig_3"
                ],
                "table_ref": []
            },
            {
                "heading": "Conclusions",
                "text": [
                    "Despite widely published results showing that human and LM prediction performance is comparable, we have found a scenario wherein humans and GPT-2 show a substantial divergence. By examining the model's attention maps for non-initial presentations, we identify specific attention heads and layers that attend across presentation boundaries to copy the next token. We finally demonstrate a procedure that augments these heads' attention maps with a recency bias, disrupting their copying behavior. The intervention reliably improves human-LM similarity across held-out stimuli in later presentations, at the cost of increased perplexity.",
                    "With the behavioral data we collected, we have used an LM to build an explicit model of human memory. Our findings here show that human memory has a stronger recency bias than GPT-2, and in the future we hope to use this model to learn more about human memory. Additionally, it suggests that attending over long distances may result in diminishing returns-an alternate form of attention may be able to exploit this phenomenon for increased efficiency.",
                    "Further work must be done to describe the change in model states during repeated presentations of a stimulus. Characterizing this experiment as a test of in-context learning (ICL), we may be able to exploit recent work (Dai et al., 2022) that suggests ICL is analogous to finetuning model weights. "
                ],
                "publication_ref": [
                    "b6"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A Stimuli",
                "text": [
                    "Below are the stimuli in their entirety. Bolded words are those which at least one subject is asked to predict, given the previous ten words. Presentation boundaries are marked with //, but this token is never presented to the subject or LM. Stimulus 1 (3 presentations of a 65-word span): we start to trade stories about our lives we're both from up north we're both kind of newish to the neighborhood this is in florida we both went to college not great colleges but man we graduated and i'm actually finding myself a little jealous of her because she has this really cool job washing dogs she had horses back home and she really loves // we start to trade stories about our lives we're both from up north we're both kind of newish to the neighborhood this is in florida we both went to college not great colleges but man we graduated and i'm actually finding myself a little jealous of her because she has this really cool job washing dogs she had horses back home and she really loves // we start to trade stories about our lives we're both from up north we're both kind of newish to the neighborhood this is in florida we both went to college not great colleges but man we graduated and i'm actually finding myself a little jealous of her because she has this really cool job washing dogs she had horses back home and she really loves Stimulus 2 (3 presentations of a 61-word span): get out to the hamptons and we're at this farmhouse and it was like a scene out of christopher isherwood the berlin stories all these blonde boys about ten of us running around doing push ups so that our muscles would swell and in and out of the pool and a big buffet and everything waiting for the light to change // get out to the hamptons and we're at this farmhouse and it was like a scene out of christopher isherwood the berlin stories all these blonde boys about ten of us running around doing push ups so that our muscles would swell and in and out of the pool and a big buffet and everything waiting for the light to change // get out to the hamptons and we're at this farmhouse and it was like a scene out of christopher isherwood the berlin stories all these blonde boys about ten of us running around doing push ups so that our muscles would swell and in and out of the pool and a big buffet and everything waiting for the light to change year during the seventies my four aunts would take me and my two cousins on their dream vacation a rented beach house in hyannis on the very cove sharing beachfront with the kennedy compound every day for an entire week my aunt pat would roll up her sisters' hair my aunts would apply sunscreen to the back of their necks the backs of the hands and the tops of their feet and then they would drag their beach chairs down to the beach and they would set them up perfectly not facing the water not into the sun for tanning but perfectly for spying on the kennedys // year during the seventies my four aunts would take me and my two cousins on their dream vacation a rented beach house in hyannis on the very cove sharing beachfront with the kennedy compound every day for an entire week my aunt pat would roll up her sisters' hair my aunts would apply sunscreen to the back of their necks the backs of the hands and the tops of their feet and then they would drag their beach chairs down to the beach and they would set them up perfectly not facing the water not into the sun for tanning but perfectly for spying on the kennedys pastor was this forty something british guy and he really wanted to attract twenty somethings so we were a hot commodity we were right in the demographic and we started to get promoted up into higher and higher echelons of leadership so we were invited to the leadership team meeting and then the core leadership team meeting // pastor was this forty something british guy and he really wanted to attract twenty somethings so we were a hot commodity we were right in the demographic and we started to get promoted up into higher and higher echelons of leadership so we were invited to the leadership team meeting and then the core leadership team meeting // pastor was this forty something british guy and he really wanted to attract twenty somethings so we were a hot commodity we were right in the demographic and we started to get promoted up into higher and higher echelons of leadership so we were invited to the leadership team meeting and then the core leadership team meeting // pastor was this forty something british guy and he really wanted to attract twenty somethings so we were a hot commodity we were right in the demographic and we started to get promoted up into higher and higher echelons of leadership so we were invited to the leadership team meeting and then the core leadership team meeting"
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "B Additional GPT-2 experiments",
                "text": [
                    "Our human-LM comparisons were limited by the amount of data we could collect from our behavioral experiment, but GPT-2 has no such limitation.",
                    "We further tested the LM on 100 random, nonphrase-aligned spans of text of different lengths (10 to 570 words, in increments of 40) from the corpus of annotated spoken narratives (LeBel et al., 2023). For each text span, we form a stimulus by repeating the span 15 times, or until the resulting text exceeds the maximum input length of the modelin this case, 1024 tokens for GPT-2.",
                    "We feed each stimulus into the model and calculate the perplexity for every token in the input. For each span length, we average the perplexity across the 100 random spans, yielding a single perplexity measure per token position. We finally average the perplexity within the tokens of each presentation."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "B.1 Results",
                "text": [
                    "Figure 5 shows results for the repeated span experiment for GPT-2. GPT-2's perplexity on the initial presentation improves with longer spans. After only a few presentations, however, the perplexity for GPT-2 quickly plateaus to near-perfect performance. The model effectively memorizes the span, and has learned when to regurgitate the previously seen tokens. These results confirm the observations in Figure 2 on a significantly larger set of stimuli. For smaller spans at higher repeats, though the mean perplexity across spans remains stable with more presentations, the standard deviation increases substantially.",
                    "These results extend the findings for LMs in Figure 2 to more presentations. "
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_4",
                    "fig_1",
                    "fig_1"
                ],
                "table_ref": []
            }
        ],
        "references": [
            {
                "ref_id": "b0",
                "title": "Repetitive Reading and Recall of Expository Text",
                "journal": "",
                "year": "1986",
                "authors": "Jeanne T Amlund; Anne M Kardash; Raymond W Kulhavy"
            },
            {
                "ref_id": "b1",
                "title": "Characterizing Verbatim Short-Term Memory in Neural Language Models",
                "journal": "",
                "year": "2022",
                "authors": "Kristijan Armeni; Christopher Honey; Tal Linzen"
            },
            {
                "ref_id": "b2",
                "title": "Working memory",
                "journal": "Science",
                "year": "1992",
                "authors": "Alan Baddeley"
            },
            {
                "ref_id": "b3",
                "title": "Reaction time and short-term memory: Implications of repetition effects for the high-speed exhaustive scan hypothesis",
                "journal": "Quarterly Journal of Experimental Psychology",
                "year": "1973",
                "authors": "Alan D Baddeley; Russell J Ecob"
            },
            {
                "ref_id": "b4",
                "title": "Natural Language Processing with Python",
                "journal": "",
                "year": "2009",
                "authors": "Steven Bird; Ewan Klein; Edward Loper"
            },
            {
                "ref_id": "b5",
                "title": "Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners",
                "journal": "",
                "year": "",
                "authors": "Tom B Brown; Benjamin Mann; Nick Ryder; Melanie Subbiah; Jared Kaplan; Prafulla Dhariwal; Arvind Neelakantan; Pranav Shyam; Girish Sastry; Amanda Askell; Sandhini Agarwal; Ariel Herbert-Voss; Gretchen Krueger; Tom Henighan; Rewon Child; Aditya Ramesh; Daniel M Ziegler; Jeffrey Wu; Clemens Winter; Christopher Hesse; Mark Chen; Eric Sigler; Mateusz Litwin"
            },
            {
                "ref_id": "b6",
                "title": "Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient Descent as Meta-Optimizers",
                "journal": "",
                "year": "2022",
                "authors": "Damai Dai; Yutao Sun; Li Dong; Yaru Hao; Zhifang Sui; Furu Wei"
            },
            {
                "ref_id": "b7",
                "title": "Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context",
                "journal": "",
                "year": "2019",
                "authors": "Zihang Dai; Zhilin Yang; Yiming Yang; Jaime Carbonell; Quoc V Le; Ruslan Salakhutdinov"
            },
            {
                "ref_id": "b8",
                "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness",
                "journal": "",
                "year": "2022",
                "authors": "Tri Dao; Daniel Y Fu; Stefano Ermon; Atri Rudra; Christopher R\u00e9"
            },
            {
                "ref_id": "b9",
                "title": "A Power-Law Model of Psychological Memory Strength in Short-and Long-Term Recognition",
                "journal": "Psychological Science",
                "year": "2012",
                "authors": "Chris Donkin; Robert M Nosofsky"
            },
            {
                "ref_id": "b10",
                "title": "",
                "journal": "",
                "year": "",
                "authors": "Nelson Elhage; Neel Nanda; Catherine Olsson; Tom Henighan; Nicholas Joseph; Ben Mann; Amanda Askell; Yuntao Bai; Anna Chen; Tom Conerly; Nova Dassarma"
            },
            {
                "ref_id": "b11",
                "title": "",
                "journal": "",
                "year": "2021",
                "authors": "Ariel Goldstein; Zaid Zada; Eliav Buchnik; Mariano Schain; Amy Price; Bobbi Aubrey; Samuel A Nastase; Amir Feder; Dotan Emanuel; Alon Cohen; Aren Jansen; Harshvardhan Gazula; Gina Choe; Aditi Rao; Catherine Se; Colton Kim; Lora Casto; Werner Fanda; Daniel Doyle; Patricia Friedman; Lucia Dugan; Roi Melloni; Sasha Reichart;  Devore"
            },
            {
                "ref_id": "b12",
                "title": "Automatic and controlled processing in sentence recall: The role of long-term and working memory",
                "journal": "Journal of Memory and Language",
                "year": "2004",
                "authors": "Elizabeth Jefferies; Matthew A Lambon Ralph; Alan D Baddeley"
            },
            {
                "ref_id": "b13",
                "title": "Adam: A Method for Stochastic Optimization",
                "journal": "",
                "year": "2017",
                "authors": "P Diederik; Jimmy Kingma;  Ba"
            },
            {
                "ref_id": "b14",
                "title": "The effects of repetition on the short-term memory function",
                "journal": "Psychonomic Science",
                "year": "1965",
                "authors": "Walter Kintsch"
            },
            {
                "ref_id": "b15",
                "title": "2023. A natural language fMRI dataset for voxelwise encoding models",
                "journal": "Scientific Data",
                "year": "",
                "authors": "Amanda Lebel; Lauren Wagner; Shailee Jain; Aneesh Adhikari-Desai; Bhavin Gupta; Allyson Morgenthal; Jerry Tang; Lixiang Xu; Alexander G Huth"
            },
            {
                "ref_id": "b16",
                "title": "CoAuthor: Designing a Human-AI Collaborative Writing Dataset for Exploring Language Model Capabilities",
                "journal": "",
                "year": "2022",
                "authors": "Mina Lee; Percy Liang; Qian Yang"
            },
            {
                "ref_id": "b17",
                "title": "",
                "journal": "Critical Behavior in Physics and Probabilistic Formal Languages. Entropy",
                "year": "2017",
                "authors": "Henry Lin; Max Tegmark"
            },
            {
                "ref_id": "b18",
                "title": "Multi-timescale Representation Learning in LSTM Language Models",
                "journal": "",
                "year": "2020",
                "authors": "Shivangi Mahto; Ai Vy; Javier S Vo; Alexander Turek;  Huth"
            },
            {
                "ref_id": "b19",
                "title": "Verbatim and gist recall of sentences by dyslexic and non-dyslexic adults",
                "journal": "Dyslexia",
                "year": "2006",
                "authors": "T R Miles; Guillaume Thierry; Judith Roberts; Josie Schiffeldrin"
            },
            {
                "ref_id": "b20",
                "title": "Why Does Surprisal From Larger Transformer-Based Language Models Provide a Poorer Fit to Human Reading Times?",
                "journal": "Transactions of the Association for Computational Linguistics",
                "year": "2023",
                "authors": "Doh Byung-; William Oh;  Schuler"
            },
            {
                "ref_id": "b21",
                "title": "",
                "journal": "",
                "year": "",
                "authors": "Catherine Olsson; Nelson Elhage; Neel Nanda; Nicholas Joseph; Nova Dassarma; Tom Henighan; Ben Mann; Amanda Askell; Yuntao Bai; Anna Chen; Tom Conerly; Dawn Drain; Deep Ganguli; Zac Hatfield-Dodds; Danny Hernandez"
            },
            {
                "ref_id": "b22",
                "title": "Rapid Serial Visual Presentation (RSVP): A Method for Studying Language Processing",
                "journal": "",
                "year": "1984",
                "authors": "Mary C Potter"
            },
            {
                "ref_id": "b23",
                "title": "Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation",
                "journal": "",
                "year": "2022",
                "authors": "Ofir Press; Noah Smith; Mike Lewis"
            },
            {
                "ref_id": "b24",
                "title": "Language Models are Unsupervised Multitask Learners",
                "journal": "",
                "year": "2019",
                "authors": "Alec Radford; Jeffrey Wu; Rewon Child; David Luan; Dario Amodei; Ilya Sutskever"
            },
            {
                "ref_id": "b25",
                "title": "Neural Machine Translation of Rare Words with Subword Units",
                "journal": "Long Papers",
                "year": "2016",
                "authors": "Rico Sennrich; Barry Haddow; Alexandra Birch"
            },
            {
                "ref_id": "b26",
                "title": "OPUS-MT -Building open translation services for the World",
                "journal": "European Association for Machine Translation",
                "year": "2020",
                "authors": "J\u00f6rg Tiedemann; Santhosh Thottingal"
            },
            {
                "ref_id": "b27",
                "title": "Positive recency effect in a delayed free recall",
                "journal": "Journal of Verbal Learning and Verbal Behavior",
                "year": "1973",
                "authors": "J L Ovid;  Tzeng"
            },
            {
                "ref_id": "b28",
                "title": "On the Predictive Power of Neural Language Models for Human Real-Time Comprehension Behavior",
                "journal": "",
                "year": "2020",
                "authors": "Ethan Gotlieb Wilcox; Jon Gauthier; Jennifer Hu; Peng Qian; Roger Levy"
            },
            {
                "ref_id": "b29",
                "title": "An Explanation of In-context Learning as Implicit Bayesian Inference",
                "journal": "",
                "year": "2022",
                "authors": "Sang Michael Xie; Aditi Raghunathan; Percy Liang; Tengyu Ma"
            },
            {
                "ref_id": "b30",
                "title": "One model for the learning of language",
                "journal": "Proceedings of the National Academy of Sciences",
                "year": "2022",
                "authors": "Yuan Yang; Steven T Piantadosi"
            }
        ],
        "figures": [
            {
                "figure_label": "1",
                "figure_type": "figure",
                "figure_id": "fig_0",
                "figure_caption": "Figure 1 :1Figure 1: Paradigm for collecting human next-word predictions. A span of text is presented three times without break. Each presentation of the stimulus is denoted with a different color. Subjects are shown words one-at-a-time with RSVP. When prompted to predict the next word, subjects are shown the previous 10 words and are given 10 seconds to type their prediction. After submitting a response, presentation of the stimulus resumes. If incorrect, they are first shown the correct word and must acknowledge before continuing.",
                "figure_data": ""
            },
            {
                "figure_label": "2",
                "figure_type": "figure",
                "figure_id": "fig_1",
                "figure_caption": "Figure 2 :2Figure 2: Behavioral and model results. (a) Human next-word prediction accuracy for one stimulus. Prompted words are split into stop words and non-stop words using the stop word list from NLTK (Bird et al., 2009). Dotted vertical lines indicate the boundaries between presentations. (b) Human and model performance, averaged within each presentation, for three different stimuli. Stimuli 1 and 2 were presented three times, while Stimulus 5 was presented four times. Both model and human accuracy improve over presentations, but model performance improves much faster and reaches a higher level. (c) Timecourse for human (green) and model (purple) performance for the stimulus from (a).",
                "figure_data": ""
            },
            {
                "figure_label": "3",
                "figure_type": "figure",
                "figure_id": "fig_2",
                "figure_caption": "Figure 3 :3Figure 3: Attention patterns. (a) Attention matrices for four heads in layer 6 for Stimulus 1 (65-word span presented 3 times). Plotted is the log-attention. Dotted gray lines indicate boundaries between presentations. Strong diagonals demonstrating induction from previous presentations are present in heads 1 and 2, but not 3 and 4. (b) Summarized attention patterns across layers. Probability mass of each category is averaged across all tokens, all heads for the given layer, and all stimuli. Induction-like attention emerges sharply at layer 6 and is present in each subsequent layer.",
                "figure_data": ""
            },
            {
                "figure_label": "4",
                "figure_type": "figure",
                "figure_id": "fig_3",
                "figure_caption": "Figure 4 :4Figure 4: Attention bias optimization. (a) An example bias matrix that would give the attention head a recency bias (\u03b1 h = 0.373, \u03b2 h = 0.0049). (b) Example timecourse that shows human performance (green), original model performance (purple), and post-optimization held-out model performance (pink). Error bars indicate SEM across initializations. (c) Human and model performance, averaged within presentations, for the same stimulus. (d) Average training and validation curves. The validation curve is the MSE on a randomly selected, held-out subset of the prompts of the training stimulus. Error bars show standard error of the mean (SEM) across training stimuli and initializations. (e) Change in mass of each attention category. (f) Change in correlation with human predictions and LM perplexity on unseen text. After optimization, human-model correlation increases after the first presentation of the stimulus (brown), but slightly decreases in the initial presentation (orange). Perplexity (blue), plotted here as the ratio of post-and pre-optimization performance, is hurt most in the middle layers.",
                "figure_data": ""
            },
            {
                "figure_label": "5",
                "figure_type": "figure",
                "figure_id": "fig_4",
                "figure_caption": "Figure 5 :5Figure 5: Model results for GPT-2. (a) shows the average perplexity for each presentation. (b) changes the x-axis to show the total number of tokens.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "table",
                "figure_id": "tab_0",
                "figure_caption": "waiting for the light to change",
                "figure_data": "Presentation 1Presentation 2w e 'r ea tth isfa r m h o u s eth eli g h ttoc h a n g ew e 'r ea tth is1000 ms400 ms400 ms1.9 s400 ms10 sTime"
            },
            {
                "figure_label": "",
                "figure_type": "table",
                "figure_id": "tab_2",
                "figure_caption": "Stimulus 3 (3 presentations of a 52-word span): nine hours i find myself nine hours later back in the situation room looking through the glass window at the operations people hoping this works when i see people start cheering and erupting in cheers and excited and i hear alice bowman's voice over the intercom we are back on the prime // nine hours i find myself nine hours later back in the situation room looking through the glass window at the operations people hoping this works when i see people start cheering and erupting in cheers and excited and i hear alice bowman's voice over the intercom we are back on the prime // nine hours i find myself nine hours later back in the situation room looking through the glass window at the operations people hoping this works when i see people start cheering and erupting in cheers and excited and i hear alice bowman's voice over the intercom we are back on the prime Stimulus 4 (2 presentations of a 107-word span):",
                "figure_data": ""
            }
        ],
        "formulas": [
            {
                "formula_id": "formula_0",
                "formula_text": "Attn(Q, K, V ) = softmax QK T \u221a d +B h V (1)",
                "formula_coordinates": [
                    5.0,
                    313.26,
                    729.46,
                    211.88,
                    27.87
                ]
            },
            {
                "formula_id": "formula_1",
                "formula_text": "{B 1 ,...,B H } 1 W W i=1 N i P human (correct i )\u2212 P model (correct i ) 2 (2)",
                "formula_coordinates": [
                    6.0,
                    86.21,
                    642.26,
                    203.66,
                    51.87
                ]
            },
            {
                "formula_id": "formula_2",
                "formula_text": "B h = T \u22121 k=0 diag k (\u03b1 h \u2022 k \u2212 exp(\u03b2 h ) )(3)",
                "formula_coordinates": [
                    6.0,
                    343.68,
                    557.16,
                    181.46,
                    33.98
                ]
            }
        ],
        "doi": "10.2307/747959"
    },
    "PROPRES: Investigating the Projectivity of Presupposition with Various Triggers and Environments": {
        "authors": "Daiki Asami; Saku Sugawara",
        "pub_date": "",
        "abstract": "What makes a presupposition of an utteranceinformation taken for granted by its speakerdifferent from other pragmatic inferences such as an entailment is projectivity (e.g., the negative sentence the boy did not stop shedding tears presupposes the boy had shed tears before). The projectivity may vary depending on the combination of presupposition triggers and environments. However, prior natural language understanding studies fail to take it into account as they either use no human baseline or include only negation as an entailment-canceling environment to evaluate models' performance. The current study attempts to reconcile these issues. We introduce a new dataset, projectivity of presupposition (PROPRES), which includes 12k premise-hypothesis pairs crossing six triggers involving some lexical variety with five environments. Our human evaluation reveals that humans exhibit variable projectivity in some cases. However, the model evaluation shows that the best-performed model, DeBERTa, does not fully capture it. Our findings suggest that probing studies on pragmatic inferences should take extra care of the human judgment variability and the combination of linguistic items.",
        "sections": [
            {
                "heading": "Introduction",
                "text": [
                    "It is an open question as to whether language models can learn a human-like pragmatic inference (Pavlick, 2022). A speaker does not always explicitly say everything in an utterance, but a hearer can infer what is implicit in it. One notable case concerns a presupposition that refers to information taken for granted by a speaker of an utterance (Stalnaker, 1974;Beaver, 1997). Presuppositions are prevalent in our everyday communication; hence, a comprehensive investigation of whether models can understand them in the same way as humans can contribute to the development of a better language understanding system.",
                    "Presupposition triggers introduce presuppositions (e.g., again in Figure 1  sition of (a) is the doctor had cut the tree before (f). What makes the presupposition different from an entailment (in this case, the doctor cut the tree one more time) is projectivity: the presupposition projects out of entailment-canceling environments (e.g., negative (b), interrogative (c), conditional (d), and modal (e) sentences) while the entailment does not. 1 In other words, the presupposition (f) holds in the environments (b-e), but the entailment (the doctor cut the tree one more time) does not.",
                    "Crucially, linguistic studies suggest that the projectivity can vary depending on many factors (Karttunen, 1971;Simons, 2001;Sevegnani et al., 2021;Tonhauser et al., 2018Tonhauser et al., , 2019;;Degen and Tonhauser, 2021b). Previous probing studies in natural language processing examine models' performance on presuppositions in the natural language inference (NLI) task (Jeretic et al., 2020;Parrish et al., 2021). However, they do not fully take into account the variable aspect of the projectivity. For instance, Jeretic et al. (2020) obtain no human baseline, which makes models' performance hard to  This study attempts to reconcile these issues. We first evaluate recent pretrained language models against a presupposition portion of IMPPRES (Jeretic et al., 2020). Specifically, we conduct a human evaluation on its subset (900 pairs), each of which ends up receiving 9.4 labels on average, and then evaluate RoBERTa (Liu et al., 2019) and DeBERTa (He et al., 2020). We find that humans exhibit relatively weak projectivity in some examples but the best-performed model, DeBERTa, does not perform in a human-like way.",
                    "IMPPRES is imperfect in terms of comprehensiveness: the nine triggers that it uses are not exhaustive (cf. Levinson (1983) and Potts (2015) list a total of 27 triggers) and are lexically limited. Thus, using six new triggers with some lexical variety (Table 1) and five environments (Table 2), we construct an extensive evaluation dataset: projectivity of presupposition (PROPRES), which consists of 12,000 sentence pairs. We evaluate four models (bag-of-words, InferSent (Conneau et al., 2017), RoBERTa, and DeBERTa) with PROPRES against human judgments on its subset (600 pairs) Each pair has more than 50 human labels on average. This second evaluation reveals that human data exhibit variable projectivity not only in previously attested cases such as manner adverbs in interrogative and negative environments (Stevens et al., 2017;Tonhauser et al., 2018) but also in unattested cases such as those in conditional and modal environments. Additionally, we find some within-trigger-type variation. However, the bestperformed model, DeBERTa, shows poor performance on controls and does not fully capture the variable projectivity patterns, indicating that it does not learn the pragmatic knowledge necessary to understand presuppositions. These findings suggest that the combination of the various linguistic items in PROPRES and the human evaluation allow us to probe the model's behavior more adequately.",
                    "The results from our two evaluations suggest that studies evaluating language understanding systems and creating datasets targeting pragmatic inferences should take extra care of the human judgment variability and the combination of linguistic items. In conclusion, this study makes the following contributions: 2",
                    "\u2022 We introduce PROPRES using six novel presupposition triggers embedded under five environments, which enables a comprehensive investigation of the projectivity of presupposition.",
                    "\u2022 Our human evaluation provides evidence for the variable projectivity depending on the combination of triggers and environments.",
                    "\u2022 Our model evaluation against human results re-2 Our dataset with the human labels and codes used to generate it are available at https://github.com/nii-cl/ projectivity-of-presupposition.",
                    "veals that the models and humans behave differently in the understanding of presuppositions."
                ],
                "publication_ref": [
                    "b22",
                    "b30",
                    "b1",
                    "b15",
                    "b29",
                    "b28",
                    "b33",
                    "b6",
                    "b13",
                    "b21",
                    "b13",
                    "b13",
                    "b18",
                    "b11",
                    "b17",
                    "b25",
                    "b3",
                    "b31",
                    "b33"
                ],
                "figure_ref": [
                    "fig_0"
                ],
                "table_ref": [
                    "tab_0",
                    "tab_1"
                ]
            },
            {
                "heading": "Background",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Presupposition in Linguistics",
                "text": [
                    "Linguistic items or constructions introducing a presupposition are referred to as presupposition triggers (e.g., again in Figure 1; Stalnaker, 1974;Beaver, 1997). One property that makes presuppositions distinct from other pragmatic inferences such as an entailment is projectivity: presuppositions survive in entailment-canceling environments such as negation (Karttunen, 1973;Heim, 1983). For instance, a presupposition of the affirmative sentence with the presupposition trigger again ((f) given (a)) holds when embedded under negation (b). In contrast, the same environment cancels an entailment (here, the doctor cut the tree one more time).",
                    "Importantly, previous linguistic studies show that the projectivity of presupposition can vary depending on factors such as context, lexical items, prior beliefs, a speaker's social identity, and prosodic focus (Karttunen, 1971;Simons, 2001;Stevens et al., 2017;Tonhauser et al., 2018Tonhauser et al., , 2019;;Degen and Tonhauser, 2021b). This variability is in line with the observation that humans make unsystematic judgments about projectivity on both natural (Ross and Pavlick, 2019;de Marneffe et al., 2019) and controlled (White and Rawlins, 2018) sentences. One remaining question here is whether the variable projectivity has to do with the interaction of triggers and environments (e.g., is a presupposition triggered by again more likely to project over the negation (b) than the conditional (d)?). To tackle this question comprehensively, this study collects human judgments on presuppositions using a wide range of triggers and environments."
                ],
                "publication_ref": [
                    "b30",
                    "b1",
                    "b16",
                    "b12",
                    "b15",
                    "b29",
                    "b31",
                    "b33",
                    "b6",
                    "b27"
                ],
                "figure_ref": [
                    "fig_0"
                ],
                "table_ref": []
            },
            {
                "heading": "Presupposition in NLI",
                "text": [
                    "Previous studies introduce NLI datasets to evaluate model performance on presuppositions (Jeretic et al., 2020;Parrish et al., 2021). One example is a template-based dataset: IMPPRES (Jeretic et al., 2020). Using this dataset, Jeretic et al. (2020) conclude that models (e.g., BERT (Devlin et al., 2019)) learn the projectivity of presuppositions triggered by only, cleft existence, possessive existence, and question. However, there is one problem with them, that is, no human evaluation. As discussed in Section 2.1, it is possible that projectivity varies de-pending on the combination of triggers and environments. Thus, it is unknown whether the results of the model evaluation reported by Jeretic et al. (2020) align with human data. To solve this issue, following Parrish et al. (2021), we conduct human evaluation on a subset of IMPPRES as well as our dataset, PROPRES.",
                    "Another dataset relevant to our study is NOPE (Parrish et al., 2021), which consists of naturallyoccurring sentences with presupposition triggers. With this dataset, Parrish et al. (2021) evaluate transformer-based models against human performance, finding that models behave similarly to humans. One limitation of NOPE is that it includes only negation as an entailment-canceling environment. As a result, the generalizability of the findings by Parrish et al. (2021) is unclear beyond negation. To draw a more general conclusion, it is necessary to include various types of environments. Following Jeretic et al. (2020), the entailment-canceling environments in PROPRES, include not only negation but also an interrogative, conditional, and modal.",
                    "3 Experiment 1: Reevaluating IMPPRES One limitation in Jeretic et al. (2020) is no human evaluation, which leaves it open whether models capture any variable projectivity exhibited by humans. To overcome it, we collect human labels on a subset of IMPPRES, testing the performance of the two models, RoBERTa and DeBERTa, against the human results."
                ],
                "publication_ref": [
                    "b13",
                    "b21",
                    "b13",
                    "b13",
                    "b7",
                    "b13",
                    "b21",
                    "b21",
                    "b21",
                    "b21",
                    "b13",
                    "b13"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Setup",
                "text": [
                    "Human Evaluation Our human evaluation targets a subset of IMPPRES, which uses nine triggers (all N, both, change of state verbs (CoS), cleft existence, only, possessive definites, possessive uniqueness, and question). Specifically, we focus on conditions where triggers occur in one of the five environments (the affirmative sentence (unembedded), negative sentence (negation), conditional antecedent (conditional), modal sentence (modal), and interrogative) 3 and where a hypothesis is either an affirmative or negative sentence. We randomly extract ten items from each condition (a total of 900 sentences).",
                    "Using Amazon Mechanical Turk, 4 we conduct 125  the human evaluation run on PCIbex. 5 Figure 3 shows an example prompt that we use in the human evaluation. We adopt and modify the instruction for the human evaluation from Parrish et al. (2021).",
                    "As a result of the human evaluation, each of the extracted items receives 9.4 labels on average. 6",
                    "Model Evaluation We evaluate Huggingface's (Wolf et al., 2020) pretrained RoBERTa-base (Liu et al., 2019) and DeBERTa-v3-large (He et al., 2020) fine-tuned on MNLI (Williams et al., 2018).",
                    "We do not evaluate a bag-of-words (BOW) model and an InferSent model (Conneau et al., 2017) because Jeretic et al. (2020) show that their accuracy for control conditions is below chance (33.3%)."
                ],
                "publication_ref": [
                    "b21",
                    "b38",
                    "b18",
                    "b11",
                    "b37",
                    "b3",
                    "b13"
                ],
                "figure_ref": [
                    "fig_2"
                ],
                "table_ref": []
            },
            {
                "heading": "Results and Discussion",
                "text": [
                    "Unembedded Triggers We use accuracy for the unembedded triggers as criteria to exclude triggers from the analysis of entailment-canceling environments. When a trigger occurs in an affirmative sentence (unembedded), a presupposition equals an entailment (e.g., Bob only ran presupposes and entails Bob ran) (Jeretic et al., 2020). If humans show low accuracy for any unembedded triggers, we manually analyze the relevant triggers to identify their cause. We interpret models' low accuracy as lack of knowledge of relevant triggers if humans show high accuracy for the same triggers.",
                    "The results of the human evaluation (Figure 2) show lower accuracy for CoS (66.3%), cleft uniqueness (74.1%), and possessed uniqueness (71.9%), examples of which are provided below, compared to the other triggers (acc. > 87.3%). 7",
                    "(1) CoS: Omar is hiding Ben.",
                    "\u2192 Ben was out in the open.",
                    "(2) Cleft uniqueness: It is that doctor who left. \u0338\u2192 More than one person left.",
                    "(3) Possessive uniqueness: Tom's car that broke bored this committee.",
                    "\u2192 Tom has exactly one car that broke.",
                    "We reason that the low accuracy for CoS is due to lexical ambiguity. For instance, people might label the pair (1) as neutral or contradiction because Ben was not necessarily exposed before being hidden. Regarding the other two conditions, we do not understand the exact source of the low accuracy at this point. In linguistics, results from human judgment experiments sometimes contradict generalizations made by theoreticians (Gibson and Fedorenko, 2013). Additionally, NLI research reports disagreements in human labels (Pavlick and Kwiatkowski, 2019;Nie et al., 2020; Zhang and de Marneffe, 2021; Jiang and de Marneffe, 2022). Thus, the current results suggest that judgments on presuppositions of cleft and possessive uniqueness are not as robust as Jeretic et al. ( 2020) might assume. Consequently, we remove CoS, cleft uniqueness, and possessed uniqueness from the following analysis as they might confound the results.",
                    "The results of the model evaluation reveal that both RoBERTa and DeBERTa achieve high accuracy for most triggers (acc. > 89.5%). Two exceptions are all N and both. RoBERTa shows lower accuracy for all N (71.0%) than DeBERTa (89.5%) (e.g., all four men that departed telephoned \u2192 exactly four men departed). With respect to both (e.g., both guys who ran jumped \u2192 exactly two guys ran), neither DeBERTa nor RoBERTa performs well (39.0% and 49.0%, respectively). Otherwise, the two models are roughly comparable in performance. Thus, we analyze only DeBERTa.",
                    "Based on the human and model results, our analysis of entailment-canceling environments includes the five triggers: all N, cleft existence, only, possessive existence, and question. 8",
                    "Entailment-Canceling Environments To analyze results on entailment-canceling environments, we use the term, projectivity, instead of accuracy. Since human judgments on projectivity can vary, as discussed in Section 2.1, we should not define gold labels for sentence pairs involving presupposition. We calculate projectivity based on whether presupposition holds when embedded under an entailment-canceling environment. For instance, if one classifies the pair, did Tom only terrify Ken? and Tom terrified Ken, as entailment, we consider it as projective. Taking another example, if one judges the hypothesis Tom did not terrify Ken as contradiction given the same premise, it counts as projective. Otherwise, we take these two examples as non-projective.",
                    "Figure 4 presents results on the four environments: negation, conditional, interrogative, and modal. Overall, DeBERTa and humans behave similarly. For instance, they show relatively low projectivity in only in conditional (e.g., if Mary only testifies, ... \u2192 Mary testifies) and modal (e.g., Mary might only testify \u2192 Mary testifies) (61.8% and 69.8% for humans and 41.5% and 72.0% for DeBERTa, respectively).",
                    "A closer look at the results reveals that DeBERTa takes some conditions less projective than humans. Humans take cleft existence in negation (e.g., it isn't that guest who complained \u2192 someone complained) as projective (89.7%) while DeBERTa pre-dicts it as less projective (65.0%). In addition, humans judge all N in conditional (e.g., if all nine actors that left slept, ... \u2192 exactly nine actors left) and in interrogative (e.g., did all nine actors that left sleep? \u2192 exactly nine actors left) as projective (91.8% and 82.6%, respectively) but DeBERTa takes them as less projective (45.0% and 49.5%, respectively). These results indicate DeBERTa's lack of knowledge of cleft existence in negation and all N in conditional and interrogative.",
                    "In summary, humans take most presupposition cases as projective except only embedded under conditional and modal. This finding adds to the previous research on variable projectivity in other cases (Stevens-Guille et al., 2020;Tonhauser et al., 2018Tonhauser et al., , 2019;;Degen and Tonhauser, 2021a,b). Additionally, DeBERTa and humans show not only similarities but also differences in projectivity."
                ],
                "publication_ref": [
                    "b13",
                    "b8",
                    "b23",
                    "b20",
                    "b32",
                    "b33"
                ],
                "figure_ref": [
                    "fig_1",
                    "fig_3"
                ],
                "table_ref": []
            },
            {
                "heading": "Experiment 2: PROPRES",
                "text": [
                    "An investigation of the projectivity of presupposition with IMPPRES is far from comprehensive because we can find more triggers in the literature (e.g., 27 triggers in Levinson (1983) and Potts (2015) in total) and none of the six triggers which we analyze in IMPPRES has lexical variation. Using six additional triggers with some lexical variety, we create a new dataset, PROPRES, which allows us to investigate the variable projectivity and models' behavior more comprehensively."
                ],
                "publication_ref": [
                    "b17",
                    "b25"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Data Generation",
                "text": [
                    "Triggers and Environments PROPRES has six types of presupposition triggers: (1) the iterative again, (2) aspectual verbs, (3) manner adverbs, (4) factive verbs, (5) comparatives, and (6) temporal adverbs, as presented in Table 1. We select these triggers from Levinson (1983) and Potts (2015) because they are not included in IMPPRES and can be easily incorporated into templates. Crucially, these triggers allow us to use different lexical items (e.g., we use seven verbs and nine adverbs for aspectual verbs and manner adverbs, respectively). One exception is again, but it is a standard presupposition trigger investigated by theoretical linguistic (von Stechow, 1995;Bale, 2007) and natural language processing (Cianflone et al., 2018) research. Thus, it is worth including this trigger in the dataset.",
                    "PROPRES uses five environments: (1) affirmative sentences (unembedded), (2) negative sentences (negation), (3) polar questions (interrogative), (4) counterfactual conditional antecedents (conditional), and (5) modal sentences (modal), as exemplified in Table 2. We include the unembedded environment to test whether humans and models can identify presupposition as entailment when triggers occur in affirmative sentences. The counterfactual conditional antecedent is not a typical entailment-canceling environment, but we include it to ensure that conditional controls have clear gold labels (entailment or contradiction) as we discuss in the following paragraph. We generate affirmative and negative hypotheses for each premise sentence. Combining six trigger types, five environment types, and two hypothesis polarity types results in 60 conditions. Generating 100 premise-hypothesis pairs for each condition yields 6,000 pairs. 9",
                    "We make a control condition corresponding to each target condition where a hypothesis is either an affirmative or negative version of its premise, as shown in Table 2. The control conditions serve as a sanity check in a human evaluation. They are also important to test whether the models rely on lexical overlap (McCoy et al., 2019) or negation (Gururangan et al., 2018) heuristics. For instance, models should label the affirmative hypothesis in Table 2 as entailment if they rely on the lexical overlap heuristic because of the high lexical overlap between the premise and hypothesis. Additionally, they should label the negative hypothesis with not as contradiction if they use the negation heuristic. Only if models predict correctly in the control conditions, we can say that their predictions about the corresponding target conditions indicate projectivity rather than heuristics. Creating 100 pairs for each control condition results in 6,000 pairs. In total, PROPRES comprises 12,000 sentence pairs.",
                    "Templates We make templates and generate sentences with them using the codebase developed by 9 We provide examples for each condition in Appendix B. Yanaka and Mineshima (2021). 10 Following are examples of templates and sentences. 11 (4) The N did not VP again.",
                    "(The girl did not hurt others again.) \u2192 ( \u0338\u2192) The N had (not) VP before.",
                    "(The girl had (not) hurt others before.)",
                    "In VP, we use verbs having the same form in past tense and past participle forms (e.g., hurt) to make the morphological difference between a premise and hypothesis as small as possible. This is crucial to check whether models rely on the lexical overlap heuristic in the control conditions. The use of templates has three advantages. First, it allows us to systematically test whether models rely on the lexical overlap (McCoy et al., 2019) and negation (Gururangan et al., 2018) heuristics. In addition, it enables us to conduct a targeted evaluation with a large number of sentences including presupposition triggers embedded under particular environments. Preparing the same number of data might be impossible if we use corpora. Finally, we can rule out the effect of plausibility. Previous linguistic work shows that the projectivity of presupposition varies depending on its content (Karttunen, 1971;Simons, 2001;Tonhauser et al., 2018). For instance, the sentence John didn't stop going to the restaurant leads to the inference John had been going to the restaurant before. In contrast, the sentence John didn't stop going to the moon is less likely to yield the inference John had been going to the moon before. This difference might stem from our world knowledge: it is more plausible for one to go to a restaurant than the moon. As the plausibility effect is not the focus of this study, we use templates to control it."
                ],
                "publication_ref": [
                    "b17",
                    "b25",
                    "b35",
                    "b0",
                    "b2",
                    "b19",
                    "b10",
                    "b39",
                    "b19",
                    "b10",
                    "b15",
                    "b29",
                    "b33"
                ],
                "figure_ref": [],
                "table_ref": [
                    "tab_0",
                    "tab_1",
                    "tab_1",
                    "tab_1"
                ]
            },
            {
                "heading": "Setup",
                "text": [
                    "Human Evaluation We randomly select ten out of 100 pairs from each target condition and two pairs from each control condition, extracting 600 and 120 pairs in total, respectively. The human evaluation procedure is identical to the one reported in Section 3.1: using Amazon Mechanical Turk, we conduct the evaluation run on PCIbex. As a result, each of the extracted pairs has 56.7 labels on average. Due to some revision of PROPRES during the dataset creation, we collect judgments on the modal environment and comparative trigger in Experiment 1 (200 pairs in total). As a consequence, they receive 9.4 labels on average."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Model Evaluation",
                "text": [
                    "We evaluate four models: BOW, InferSent (Conneau et al., 2017), RoBERTabase (Liu et al., 2019), and DeBERTa-v3-large (He et al., 2020). For the first two models, we follow Parrish et al. ( 2021)'s implementation 12 and use MNLI (Williams et al., 2018) to fine-tune the parameters. We use the GloVe embeddings for the word-level representations (Pennington et al., 2014). For the two transformer-based models, we use RoBERTa-base and DeBERTa-v3-large finetuned on MNLI as in Experiment 1."
                ],
                "publication_ref": [
                    "b3",
                    "b18",
                    "b11",
                    "b37",
                    "b24"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Results and Discussion",
                "text": [
                    "Control Conditions Figure 5 shows results on control conditions in which a hypothesis is either an affirmative or negative version of its premise. The performance of InferSent and BOW models is poor, which makes their performance on target conditions hard to analyze. Thus, we exclude them from our analysis below. Similar to humans, RoBERTa and DeBERTa perform well on the unembedded, negation, and conditional (e.g., P 1 -P 3 in ( 5)), indicating that they do not rely on the lexical overlap heuristic or negation heuristic in these cases.",
                    "(5) P 1 : The boy cut the tree again. P 2 : The boy did not cut the tree again. P 3 : If the boy had cut the tree again, ... P 4 : Did the boy cut the tree again?",
                    "12 https://github.com/nyu-mll/nope P 5 : The boy might cut the tree again.",
                    "H 1(2) : The boy (did not) cut the tree again.",
                    "RoBERTa, DeBERTa, and humans perform poorly on the interrogative and modal (e.g., P 4 and P 5 in ( 5)) in which the correct label is supposed to be neutral (Jeretic et al., 2020) (31.8%, 50.0%, and 51.1% for interrogative and 3.5%, 16.7%, and 48.1% for modal, respectively). Distributions of labels in these conditions (Figure 6) show that the majority of labels in humans are neutral, which is consistent with the view that a yes/no question does not have a truth value and thus one cannot decide whether its affirmative or negative version is true or not (Groenendijk and Stokhof, 1984;Roberts, 2012). One exception is the interrogative with an affirmative hypothesis (e.g., P 4 and H 1 in ( 5)): distributions of entailment and neutral are comparable (46.5% and 52.4%, respectively). We suspect that some people interpret this condition as a confirmation question in which the affirmative counterpart of the interrogative (in this case, H 1 ) is presupposed, resulting in a high percentage of entailment.",
                    "In the same condition, the label distributions of DeBERTa and RoBERTa do not mirror those of humans. RoBERTa shows a relatively high percentage of contradiction (57.5%) whereas DeBERTa shows a very high percentage of neutral (97.1%). In the interrogative with the negative hypothesis (e.g., P 4 and H 2 ), RoBERTa and DeBERTa assign contradiction to the hypothesis the majority of the time (93.7% and 97.1%, respectively), indicating the negation heuristic: models are likely to label a given hypothesis as contradiction if it includes not (Gururangan et al., 2018).",
                    "The two models do not mirror humans in performance on the modal, either. Their majority labels in the modal with affirmative and negative hypotheses (e.g., P 5 with H 1 and H 2 ) are entailment and contradiction, respectively. These results suggest that in the modal, they rely on the lexical overlap heuristic if a hypothesis is affirmative but they adopt a negation heuristic if it is negative, overriding the lexical overlap heuristic. Specifically, they label a hypothesis as entailment if it is affirmative whereas if not is present in it, they label it as contradiction.",
                    "These variable results for DeBERTa and RoBERTa are inconsistent with Jeretic et al. (2020), who find that BERT achieves high accuracy for the interrogative and modal controls by correctly assigning them the neutral label. The discrepancy between our results and Jeretic et al. ( 2020)'s indicates that the combination of the two environments with new triggers in PROPRES makes a more thorough model evaluation possible.",
                    "Overall, the performance of RoBERTa and De-BERTa is interpretable regarding the three environments: unembedded, negation, and conditional; hence, we omit model results on the interrogative and modal below. 13 Additionally, since the two models are comparable in accuracy, we only report DeBERTa's performance in what follows.",
                    "Unembedded Triggers Figure 8 shows results on the unembedded triggers. Overall, DeBERTa and humans achieve high accuracy for all triggers. One exception is DeBERTa's poor performance on the comparative (e.g., the girl read the letter better than the boy \u2192 the boy read the letter) (14.5%), indicating its limited knowledge of this trigger. Hence, we exclude DeBERTa's predictions about the comparative when we report results on 13 We report all results including excluded conditions in Appendix E. entailment-canceling environments.",
                    "Entailment-Canceling Environments Figure 7 shows results on the entailment-canceling environments. Our human results provide evidence for variable projectivity (range 55.1-99.8%).",
                    "First, the human results indicate that the iterative again weakly projects over the negation (75.8%) compared to the other three environments (86.3% on average). We provide the example sentence pairs for again embedded under negation below.",
                    "(6) P : The man did not shed tears again.",
                    "H 1(2) : The man had (not) shed tears before.",
                    "We reason that this apparent low projectivity is attributable to the fact that the negative sentence with again is ambiguous as to whether again takes scope over the proposition with negation or without negation (Bale, 2007). In the first reading, the presupposition is that the man had shed tears before; in the second reading, it is that the man had not shed tears before. If humans infer the second presupposition, they should label the hypotheses such as H 1 and H 2 as entailment and contradiction, respectively, giving rise to the seemingly low projectivity rates. Since this ambiguity itself has nothing to do with the projectivity, we leave it open whether the observed rate (75.8%) truly reflects the projectivity or not. Contrary to humans, the DeBERTa judges the same condition as projective (95%), indicating that it virtually always predicts the second presupposition (e.g., the man had shed tears before).",
                    "Next, manner adverbs exhibit relatively weak projectivity over the negation (e.g., P 1 in ( 7)) and interrogative (e.g., P 2 ) (58.3% and 66.6%, respectively).",
                    "(7) P 1 : The man did not hurt others seriously.",
                    "P 2 : Did the man hurt others seriously? P 3 : If the man had hurt others seriously, ... P 4 : The man might hurt others seriously.",
                    "H 1(2) : The man (did not) hurt others.",
                    "According to Stevens et al. (2017) and Tonhauser et al. (2019), a focalized element in the utterance affects the projectivity of the presupposition introduced by manner adverbs in interrogatives and negation. For instance, the presupposition (H 1 ) is more likely to project when the focus falls into the manner adverb (did the man hurt others SERI-OUSLY?) than when it falls into the subject (did the MAN hurt others seriously?). Since our human evaluation provides no prosodic information signaling focus, humans might find these conditions ambiguous, yielding weak projectivity. Furthermore, our item-by-item analysis with human data reveals that in the manner adverbs embedded under negation, the projectivity ranges between 43.3% (for angrily) and 66.6% (for easily), indicating the within-trigger-type variability.",
                    "Adding to Stevens et al. (2017) and Tonhauser et al. (2019), we find that the manner adverbs are weakly projective in the conditional (e.g., P 3 ) and modal (e.g., P 4 ) (62.0% and 55.1%, respectively). This suggests that information structural cues such as prosodic focus play a role in the projectivity of presupposition introduced by the manner adverbs embedded under the conditional and modal.",
                    "Third, in the modal, temporal adverbs (e.g., P 1 in (8)) and comparatives (e.g., P 2 ) have weaker projectivity (54.7% and 57.4%, respectively) than the other three triggers excluding the manner adverbs (92.5% on average). These two triggers are projective in the other three environments (79.7% and 93.4% on average for the temporal adverbs and comparatives, respectively). This indicates that the projectivity of presuppositions of these triggers varies depending on the environment.",
                    "(8) P 1 : Tom might sing after reading.",
                    "P 2 : The lady might sing better than Tom. H 1(2) : Tom (did not) read.",
                    "DeBERTa's performance does not mirror humans' in some cases. It predicts that the manner adverbs in the negation and conditional (P 1 and P 3 in (7), respectively) are not projective (8.5% and 14%, respectively), contrary to humans (58.3% and 62.0%, respectively). This indicates that either De-BERTa lacks the knowledge of these two cases or processes them as if the subject is focalized (e.g., did the MAN hurt others seriously?).",
                    "In summary, the human evaluation in Experiment 2 shows variable projectivity in six out of the 24 new conditions, contrary to the first one, in which we observe it in two out of 24 conditions. This contrast highlights that the combination of various triggers and environments can lead to the discovery of new cases of variable projectivity. In addition, we find that DeBERTa does not capture variable projectivity in some cases, suggesting that DeBERTa's ability to process presupposition is not necessarily human-like."
                ],
                "publication_ref": [
                    "b13",
                    "b9",
                    "b26",
                    "b10",
                    "b13",
                    "b0",
                    "b31",
                    "b31"
                ],
                "figure_ref": [
                    "fig_4"
                ],
                "table_ref": []
            },
            {
                "heading": "Conclusion",
                "text": [
                    "Our experiments reveal that humans exhibit the variable projectivity of presupposition in some conditions (two out of 24 and six out of 24 conditions in Experiments 1 and 2, respectively), but the bestperformed model, DeBERTa, does not capture it most of the time, indicating that it does not generalize pragmatic inferences for presuppositions.",
                    "In our experiments, quite a few conditions are excluded from the analysis for various reasons such as lexical ambiguity in some items, disagreements in human judgments, and the models' lack of knowledge. To tease apart these factors carries us well beyond the scope of this study. However, this fact suggests that we need to be careful with dataset creation so that we can train or evaluate models on well-designed datasets targeting pragmatic inferences."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A Limitations",
                "text": [
                    "One of the limitations of our study is that not all data have human labels. However, it is not feasible to get many judgments for all the data in IMPPRES and PROPRES in terms of cost. Extending this study, we hope to conduct a targeted human evaluation with some of the triggers that exhibit the variable projectivity (e.g., manner adverbs).",
                    "The second limitation has to do with humans' low accuracy in control modal and question conditions. We attribute this to the procedure of our evaluation. The participants are asked to judge whether the hypothesis contradicts, entails, or is neutral to the question or modal premise. Since it is hard to imagine the situation in which the modal and question sentences are true or false, people might be confused with the instruction. We hope to collect more valid data using a better instruction in our future study.",
                    "The third limitation is that we do not conduct the thorough analyses of between-item variability and between-participant variability in data from the two human evaluations. It is likely that the projectivity of the presupposition depends on lexical items and participants. We take these into consideration in the future study.",
                    "The final limitation is that this study investigates presuppositions without any context. Taking John did not stop cutting trees as an example, whether the presupposition John had cut trees before projects over negation depends on a context. For instance, the presupposition does not project over negation if we associate the sentence with the appropriate context. Consider the following example: Mary liked cutting trees but never smoked. In contrast, John never cut trees but liked smoking. One day Mary and John stopped cutting trees and smoking, respectively. Later Bob said to Ken \"John stopped cutting trees.\" Then Ken responded \"wait, John didn't stop cutting trees but he stopped smoking\". In this example, the sentence John did not stop cutting trees does not presuppose John had cut trees before. It remains to be seen how the contextual information affects each trigger embedded under different environments."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "B Templates",
                "text": [
                    "Tables 3-7 contain templates of premises and hypotheses for six triggers crossed with five environments in PROPRES."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "C Crowdsourcing Human Evaluation",
                "text": [
                    "Before the experiment, each participant is asked to read a written instruction about the NLI task carefully. All data are collected anonymously except workers' ID.",
                    "Evaluation 1 Using Amazon Mechanical Turk, we recruit 116 people with the requirements of having an approval rating of 99.0% or higher, having at least 5,000 approved tasks, being located in the US, the UK, or Canada, and having passed a qualification task. We make sure that the workers are paid at least $12.0 USD per hour. Among them, we exclude the responses of 46 participants from the analysis because their accuracy rates for a sanity check are below 80.0%. We analyze the data of the remaining 71 participants.",
                    "Evaluation 2 Using Amazon Mechanical Turk, we recruit 635 people with the requirements of having an approval rating of 99.0% or higher, having at least 5,000 approved tasks, and being located in the US, the UK, or Canada. We make sure that the workers are paid at least $12.0 USD per hour. Among them, we exclude the responses of 352 participants whose accuracy for the control conditions is less than 90% based on the distributions of accuracy in Figure 9. The control results include results for unembedded, negation, and conditional conditions. The interrogative control condition is not included in the mean calculation, because its mean accuracy is around chance (36.0% over the chance level 33.3%). As a result, we analyze the data of the remaining 283 participants."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_6"
                ],
                "table_ref": []
            },
            {
                "heading": "D Triggers and Environments in IMPPRES",
                "text": [
                    "Tables 8 and 9 present triggers and environments used in IMPPRES, respectively. "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "E Results without Exclusion",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Acknowledgments",
                "text": [
                    "We would like to thank the anonymous reviewers for their helpful comments. This work was supported by JST PRESTO Grant Number JP-MJPR20C4 and JSPS KAKENHI Grant Number 22K17954."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            }
        ],
        "references": [
            {
                "ref_id": "b0",
                "title": "Quantifiers and verb phrases: An exploration of propositional complexity",
                "journal": "Natural Language & Linguistic Theory",
                "year": "2007",
                "authors": "Alan Clinton Bale"
            },
            {
                "ref_id": "b1",
                "title": "Presupposition",
                "journal": "MIT Press",
                "year": "1997",
                "authors": "David I Beaver"
            },
            {
                "ref_id": "b2",
                "title": "Let's do it \"again\": A first computational approach to detecting adverbial presupposition triggers",
                "journal": "Long Papers",
                "year": "2018",
                "authors": "Andre Cianflone; Yulan Feng; Jad Kabbara; Jackie Chi Kit Cheung"
            },
            {
                "ref_id": "b3",
                "title": "Supervised learning of universal sentence representations from natural language inference data",
                "journal": "",
                "year": "2017",
                "authors": "Alexis Conneau; Douwe Kiela; Holger Schwenk; Lo\u00efc Barrault; Antoine Bordes"
            },
            {
                "ref_id": "b4",
                "title": "The CommitmentBank: Investigating projection in naturally occurring discourse",
                "journal": "",
                "year": "2019",
                "authors": "Marie-Catherine De Marneffe; Mandy Simons; Judith Tonhauser"
            },
            {
                "ref_id": "b5",
                "title": "Are there factive predicates? an empirical investigation",
                "journal": "Ling-Buzz",
                "year": "2021",
                "authors": "Judith Degen; Judith Tonhauser"
            },
            {
                "ref_id": "b6",
                "title": "Prior beliefs modulate projection",
                "journal": "Open Mind",
                "year": "2021",
                "authors": "Judith Degen; Judith Tonhauser"
            },
            {
                "ref_id": "b7",
                "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
                "journal": "Association for Computational Linguistics",
                "year": "2019",
                "authors": "Jacob Devlin; Ming-Wei Chang; Kenton Lee; Kristina Toutanova"
            },
            {
                "ref_id": "b8",
                "title": "The need for quantitative methods in syntax and semantics research",
                "journal": "Language and Cognitive Processes",
                "year": "2013",
                "authors": "Edward Gibson; Evelina Fedorenko"
            },
            {
                "ref_id": "b9",
                "title": "Studies on the semantics of questions and the pragmatics of answers",
                "journal": "",
                "year": "1984",
                "authors": "Jeroen Groenendijk; Martin Stokhof"
            },
            {
                "ref_id": "b10",
                "title": "Annotation artifacts in natural language inference data",
                "journal": "",
                "year": "2018",
                "authors": "Swabha Suchin Gururangan; Omer Swayamdipta; Roy Levy; Samuel Schwartz; Noah A Bowman;  Smith"
            },
            {
                "ref_id": "b11",
                "title": "DeBERTa: Decoding-enhanced BERT with disentangled attention",
                "journal": "",
                "year": "2020",
                "authors": "Pengcheng He; Xiaodong Liu; Jianfeng Gao; Weizhu Chen"
            },
            {
                "ref_id": "b12",
                "title": "On the conversational basis of some presuppositions",
                "journal": "Stanford Linguistics Association",
                "year": "1983",
                "authors": "Irene Heim"
            },
            {
                "ref_id": "b13",
                "title": "Are natural language inference models IMPPRESsive? Learning IMPlicature and PRESupposition",
                "journal": "Online. Association for Computational Linguistics",
                "year": "2020",
                "authors": "Paloma Jeretic; Alex Warstadt; Suvrat Bhooshan; Adina Williams"
            },
            {
                "ref_id": "b14",
                "title": "Investigating reasons for disagreement in natural language inference",
                "journal": "Transactions of the Association for Computational Linguistics",
                "year": "2022",
                "authors": "Nan-Jiang Jiang; Marie-Catherine De Marneffe"
            },
            {
                "ref_id": "b15",
                "title": "Some observations on factivity",
                "journal": "Papers in Linguistics",
                "year": "1971",
                "authors": "Lauri Karttunen"
            },
            {
                "ref_id": "b16",
                "title": "Presuppositions of compound sentences",
                "journal": "Linguistic inquiry",
                "year": "1973",
                "authors": "Lauri Karttunen"
            },
            {
                "ref_id": "b17",
                "title": "Pragmatics",
                "journal": "Cambridge University Press",
                "year": "1983",
                "authors": "C Stephen;  Levinson"
            },
            {
                "ref_id": "b18",
                "title": "RoBERTa: A robustly optimized BERT pretraining approach",
                "journal": "",
                "year": "2019",
                "authors": "Yinhan Liu; Myle Ott; Naman Goyal; Jingfei Du; Mandar Joshi; Danqi Chen; Omer Levy; Mike Lewis; Luke Zettlemoyer; Veselin Stoyanov"
            },
            {
                "ref_id": "b19",
                "title": "Right for the wrong reasons: Diagnosing syntactic heuristics in natural language inference",
                "journal": "Association for Computational Linguistics",
                "year": "2019",
                "authors": "Tom Mccoy; Ellie Pavlick; Tal Linzen"
            },
            {
                "ref_id": "b20",
                "title": "What can we learn from collective human opinions on natural language inference data?",
                "journal": "Online. Association for Computational Linguistics",
                "year": "2020",
                "authors": "Yixin Nie; Xiang Zhou; Mohit Bansal"
            },
            {
                "ref_id": "b21",
                "title": "NOPE: A corpus of naturally-occurring presuppositions in English",
                "journal": "",
                "year": "2021",
                "authors": "Alicia Parrish; Sebastian Schuster; Alex Warstadt; Omar Agha; Soo-Hwan Lee; Zhuoye Zhao; Samuel R Bowman; Tal Linzen"
            },
            {
                "ref_id": "b22",
                "title": "Semantic structure in deep learning",
                "journal": "Annual Review of Linguistics",
                "year": "2022",
                "authors": "Ellie Pavlick"
            },
            {
                "ref_id": "b23",
                "title": "Inherent disagreements in human textual inferences",
                "journal": "",
                "year": "2019",
                "authors": "Ellie Pavlick; Tom Kwiatkowski"
            },
            {
                "ref_id": "b24",
                "title": "GloVe: Global vectors for word representation",
                "journal": "Association for Computational Linguistics",
                "year": "2014",
                "authors": "Jeffrey Pennington; Richard Socher; Christopher Manning"
            },
            {
                "ref_id": "b25",
                "title": "Presupposition and implicature",
                "journal": "Wiley-Blackwell",
                "year": "2015",
                "authors": "Christopher Potts"
            },
            {
                "ref_id": "b26",
                "title": "Information structure: Towards an integrated formal theory of pragmatics",
                "journal": "Semantics and pragmatics",
                "year": "2012",
                "authors": "Craige Roberts"
            },
            {
                "ref_id": "b27",
                "title": "How well do NLI models capture verb veridicality?",
                "journal": "Association for Computational Linguistics",
                "year": "2019",
                "authors": "Alexis Ross; Ellie Pavlick"
            },
            {
                "ref_id": "b28",
                "title": "OTTers: One-turn topic transitions for open-domain dialogue",
                "journal": "Long Papers",
                "year": "2021",
                "authors": "Karin Sevegnani; David M Howcroft; Ioannis Konstas; Verena Rieser"
            },
            {
                "ref_id": "b29",
                "title": "On the conversational basis of some presuppositions",
                "journal": "CLC Publications",
                "year": "2001",
                "authors": "Mandy Simons"
            },
            {
                "ref_id": "b30",
                "title": "Pragmatic presuppositions",
                "journal": "New York University Press",
                "year": "1974",
                "authors": "Robert Stalnaker"
            },
            {
                "ref_id": "b31",
                "title": "Rational use of prosody predicts projection in manner adverb utterances",
                "journal": "",
                "year": "2017",
                "authors": "Jon Stevens; Marie-Catherine De Marneffe; Shari R Speer; Judith Tonhauser"
            },
            {
                "ref_id": "b32",
                "title": "Neural NLG for methodius: From RST meaning representations to texts",
                "journal": "Association for Computational Linguistics",
                "year": "2020",
                "authors": "Symon Stevens-Guille; Aleksandre Maskharashvili; Amy Isard; Xintong Li; Michael White"
            },
            {
                "ref_id": "b33",
                "title": "How projective is projective content? gradience in projectivity and at-issueness",
                "journal": "Journal of Semantics",
                "year": "2018",
                "authors": "Judith Tonhauser; David I Beaver; Judith Degen"
            },
            {
                "ref_id": "b34",
                "title": "On the information structure sensitivity of projective content",
                "journal": "",
                "year": "2019",
                "authors": "Judith Tonhauser; Marie-Catherine De Marneffe; Shari R Speer; Jon Stevens"
            },
            {
                "ref_id": "b35",
                "title": "Lexical decomposition in syntax",
                "journal": "Amsterdam/Philedelphia",
                "year": "1995",
                "authors": "Stechow Arnim Von"
            },
            {
                "ref_id": "b36",
                "title": "The role of veridicality and factivity in clause selection",
                "journal": "",
                "year": "2018",
                "authors": "S Aaron; Kyle White;  Rawlins"
            },
            {
                "ref_id": "b37",
                "title": "A broad-coverage challenge corpus for sentence understanding through inference",
                "journal": "Long Papers",
                "year": "2018",
                "authors": "Adina Williams; Nikita Nangia; Samuel Bowman"
            },
            {
                "ref_id": "b38",
                "title": "Transformers: State-of-the-art natural language processing",
                "journal": "Association for Computational Linguistics",
                "year": "2020",
                "authors": "Thomas Wolf; Lysandre Debut; Victor Sanh; Julien Chaumond; Clement Delangue; Anthony Moi; Pierric Cistac; Tim Rault; Remi Louf; Morgan Funtowicz; Joe Davison; Sam Shleifer; Clara Patrick Von Platen; Yacine Ma; Julien Jernite; Canwen Plu; Teven Le Xu; Sylvain Scao; Mariama Gugger; Quentin Drame; Alexander Lhoest;  Rush"
            },
            {
                "ref_id": "b39",
                "title": "Assessing the generalization capacity of pre-trained language models through Japanese adversarial natural language inference",
                "journal": "",
                "year": "2021",
                "authors": "Hitomi Yanaka; Koji Mineshima"
            },
            {
                "ref_id": "b40",
                "title": "Identifying inherent disagreement in natural language inference",
                "journal": "Online. Association for Computational Linguistics",
                "year": "2021",
                "authors": "Frederick Xinliang; Marie-Catherine Zhang;  De Marneffe"
            }
        ],
        "figures": [
            {
                "figure_label": "1",
                "figure_type": "figure",
                "figure_id": "fig_0",
                "figure_caption": "Figure 1 :1Figure 1: Projectivity of presupposition. A presupposition can project out of entailment-canceling environments. The dashed arrows indicate that the projectivity varies depending on the combination of triggers and environments.",
                "figure_data": ""
            },
            {
                "figure_label": "2",
                "figure_type": "figure",
                "figure_id": "fig_1",
                "figure_caption": "AFigure 2 :2Figure 2: Results on the unembedded triggers in IMP-PRES. The dashed lines indicate chance performance (33.3%).",
                "figure_data": ""
            },
            {
                "figure_label": "3",
                "figure_type": "figure",
                "figure_id": "fig_2",
                "figure_caption": "Figure 3 :3Figure 3: An example prompt in the human evaluation.",
                "figure_data": ""
            },
            {
                "figure_label": "4",
                "figure_type": "figure",
                "figure_id": "fig_3",
                "figure_caption": "QQQQFigure 4 :4Figure 4: Results on entailment-canceling environments in IMPPRES. DeBERTa's results on both are not presented.",
                "figure_data": ""
            },
            {
                "figure_label": "6",
                "figure_type": "figure",
                "figure_id": "fig_4",
                "figure_caption": "Figure 6 :6Figure 5: Results on control conditions in PROPRES.",
                "figure_data": ""
            },
            {
                "figure_label": "78",
                "figure_type": "figure",
                "figure_id": "fig_5",
                "figure_caption": "Figure 7 :Figure 8 :78Figure7: Results on entailment-canceling environments in PROPRES. DeBERTa's results on the interrogative and modal environments and the comparative trigger are not shown due to its unstable performance on their control counterparts.",
                "figure_data": ""
            },
            {
                "figure_label": "9",
                "figure_type": "figure",
                "figure_id": "fig_6",
                "figure_caption": "Figure 9 :9Figure 9: Distributions of accuracy in the control conditions in PROPRES.",
                "figure_data": ""
            },
            {
                "figure_label": "1011",
                "figure_type": "figure",
                "figure_id": "fig_7",
                "figure_caption": "FiguresFigure 10 :Figure 11 :1011Figures 10 and 11 present results without exclusion of triggers and environments in IMPPRES and PROPRES, respectively.",
                "figure_data": ""
            },
            {
                "figure_label": "1",
                "figure_type": "table",
                "figure_id": "tab_0",
                "figure_caption": "Presupposition triggers with an affirmative (unembedded) premise in PROPRES.",
                "figure_data": "Trigger TypeExample TriggersExample PremiseIterativeagainThe assistant split the log again.Aspectual verbstop, quit, finishThe assistant stopped splitting the log.Manner adverbquietly, slowly, angrilyThe assistant split the log quietly.Factive verbremember, regret, forgetThe assistant remembered splitting the log.Comparativebetter than, earlier thanThe assistant split the log better than the girl.Temporal adverbbefore, after, whileThe assistant split the log before bursting into the room.EnvironmentPremiseHypothesis (target and control)Label (target/control)UnembeddedThe doctor shed tears again.E (C) / E (C)NegationThe doctor did not shed tears again.Target: The doctor had (not) shed tears before.E (C) / C (E)InterrogativeDid the doctor shed tears again?E (C) / N (N)Conditional If the doctor had shed tears again, ...Control: The doctor (did not) shed tears again.E (C) / C (E)ModalThe doctor might shed tears again.E (C) / N (N)"
            },
            {
                "figure_label": "2",
                "figure_type": "table",
                "figure_id": "tab_1",
                "figure_caption": "",
                "figure_data": ""
            }
        ],
        "formulas": [],
        "doi": "10.1007/s11049-007-9019-8"
    },
    "ToMChallenges: A Principle-Guided Dataset and Diverse Evaluation Tasks for Exploring Theory of Mind": {
        "authors": "Xiaomeng Ma; Lingyu Gao; Qihui Xu",
        "pub_date": "",
        "abstract": "Theory of Mind (ToM), the capacity to comprehend the mental states of distinct individuals, is essential for numerous practical applications. With the development of large language models (LLMs), there is a heated debate about whether they are able to perform ToM tasks. Previous studies have used different tasks and prompts to test the ToM on LLMs and the results are inconsistent: some studies asserted that these models are capable of exhibiting ToM, while others suggested the opposite. In this study, we present TOMCHALLENGES, a dataset for comprehensively evaluating the Theory of Mind based on the Sally-Anne and Smarties tests with a diverse set of tasks. In addition, we also propose an auto-grader to streamline the answer evaluation process. We tested three models: davinci, turbo, and gpt-4. Our evaluation results and error analyses show that LLMs have inconsistent behaviors across prompts and tasks. Performing the ToM tasks robustly remains a challenge for the LLMs. In addition, our paper wants to raise awareness in evaluating the ToM in LLMs and we want to invite more discussion on how to design the prompts and tasks for ToM tasks that can better assess the LLMs' ability. 1",
        "sections": [
            {
                "heading": "Introduction",
                "text": [
                    "With the recent advancement of large language models (LLMs; Devlin et al., 2019;Brown et al., 2020;Raffel et al., 2020), expectations for artificial intelligence systems to effectively interact with people have significantly increased. This may necessitate the development of human-like capabilities in these systems, such as reasoning not only about their own observations and beliefs but also understanding the mental states of others. This ability, termed as Theory of Mind (ToM), refers to the capacity to attribute mental states-such as beliefs, 1 The data and code are available at https://github.com/xiaomeng-ma/ToMChallenges. emotions, and intentions-to oneself and others (Wimmer and Perner, 1983;Gallese and Sinigaglia, 2011). In psychology, it is an essential milestone in the social development of a child. However, the challenges that persist are whether LLMs have already developed ToM capabilities and how to identify the appropriate tool to accurately assess these capabilities.",
                    "Recent studies addressing those issues often draw inconsistent conclusions, some studies asserting that models exhibit ToM (Kosinski, 2023;Wu et al., 2023;Bubeck et al., 2023), some suggest the opposite (Le et al., 2019;Nematzadeh et al., 2018;Sap et al., 2022;Ullman, 2023a;Shapira et al., 2023), and others maintain caution and questions (Sileo and Lernould, 2023;Aru et al., 2023).",
                    "These varied results could be due to different evaluation methods. First, these studies have tested the models on different tasks, ranging from tasks of perspective-taking reasoning (i.e., does the other person know what I know; e.g., Kosinski, 2023) to intention ascription (i.e., what does a movie character intend to do at the end of an open-ended movie; e.g., Shapira et al., 2023). Additionally, the type of prompts varies across studies. For in-stance, Le et al. (2019) and Sap et al. (2022) used question answering prompts, while Kosinski (2023) employed sentence completion prompts. This lack of clear principles in approaches poses challenges to the validity of ToM assessments for LLMs. If only specific prompts lead to high-performance results while others do not, it becomes questionable whether the correct responses truly reflect ToM or are simply the result of algorithmic shortcuts. Similarly, if some tasks are not valid for assessing ToM, the results cannot be interpreted in terms of models' ToM capability regardless of the conclusions drawn.",
                    "What is considered a valid ToM test? A valid test should be both theoretically grounded and methodologically validated to ensure it measures the intended subject, and the results are not skewed by other factors. From a theoretical standpoint, ToM theories in child development (Wellman et al., 2001;Quesque and Rossetti, 2020;Navarro, 2022) suggest that valid tests should focus on assessing the respondent's ability to a) represent mental states of one's own and others based on physical events (but not other factors such as emotions and intentions) (mentalizing), and b) differentiate one's own mental state and other's (false-belief understanding). Tasks not meeting these criteria might not be considered valid assessments because they either introduce confounding factors such as emotional or social ascription or fail to contrast the respondent's mental state and other's mental state.",
                    "From a methodological perspective, both psychology and NLP studies demand rigorous evaluation to ensure measurement validity. Unlike psychology studies where individual subjects can be randomly assigned to experimental and control conditions to yield reproducible results, LLMs like GPT-4, being a single 'subject', lack the capacity for reproducibility in the traditional sense. Therefore, any claims about an LLM possessing humanlike capabilities must be substantiated after validation with a variety of prompts and tasks, provided these tasks align with the theoretical framework of the intended measurement."
                ],
                "publication_ref": [
                    "b6",
                    "b3",
                    "b17",
                    "b26",
                    "b7",
                    "b12",
                    "b27",
                    "b4",
                    "b15",
                    "b18",
                    "b23",
                    "b21",
                    "b22",
                    "b0",
                    "b12",
                    "b21",
                    "b18",
                    "b12",
                    "b25",
                    "b16",
                    "b14"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Validity issues of current neural ToM tests",
                "text": [
                    "Testing a few examples on a single format, as done by Kosinski (2023) and Bubeck et al. (2023), raises methodological questions and uncertainty about whether responses are shortcut-driven. In fact, Shapira et al. (2023) recently showed LLMs' inconsistent performance across ToM tasks, further indicating possible shortcuts and the idiosyncrasy of specific prompts. If relied upon singularly, these could lead to misinterpretations.",
                    "Meanwhile, several tasks from previous studies (e.g., Ullman, 2023b;Shapira et al., 2023) may not sufficiently adhere to Mentalizing and False-Belief Understanding criteria, casting doubt on whether these tasks genuinely reflect ToM or other capacity such as social ascription. In the study conducted by Ullman (2023b), adversarial variations such as transparent access and uninformative labels were used to evaluate the robustness of LLMs' ToM capability. For example, when the model is presented with a context where a transparent bag is filled with popcorn, but the label on the bag reads \"chocolate,\" the model was likely to suggest that a person seeing the bag for the first time would believe it's full of chocolate, not popcorn, despite the bag's transparency. However, this variation might not be directly related to ToM. Successfully answering those questions may also require conceptual knowledge (e.g., what information can a transparent bag provide) and inferential biases (will the person trust the label or rely on their direct observation through the transparent bag?). Such issues could lead to evaluations straying from the Mentalizing and False-Belief Understanding criteria.",
                    "Likewise, certain tasks implemented in the Shapira et al. (2023) study, such as inferring another person's intention, did not distinguish between representations of self and others. Consequently, the model may depend on empathy (see Section 2 for differences between empathy and ToM) rather than ToM to accomplish the task, thereby failing to fulfill the Nonmerging criteria.",
                    "Auto-grader: Enabling diverse and large-scale evaluations One potential challenge to establishing a principle-guided yet diverse evaluation system is the intense human labor involved in evaluating models' responses. It may not be a significant issue when the task is in a constrained format such as true or false questions. However, when the diversity and the amount of tasks increase, which is necessary for a valid ToM test (e.g., ask models to provide reasoning so that one can better understand how the model reaches such a conclusion), a more efficient evaluation method becomes essential.",
                    "Present study To improve the validity of ToM tests, we propose a principle-guided dataset with a diverse set of tasks. In an effort to dissect the underpinnings of incorrect responses, we also conducted error analyses, particularly focusing on questions demanding reasoning. This approach offers a deeper insight into the cognitive process of the models when they arrive at incorrect conclusions. Finally, addressing the need for efficient evaluations, we have developed an autograder based on GPT-4 to streamline the evaluation process. This tool allows us to efficiently evaluate models' responses across a broader spectrum of tasks and on a larger scale, bringing a higher degree of accuracy and efficiency to the ToM testing process.",
                    "Our evaluations and error analyses show that current LLMs struggle to perform robustly on ToM tasks or reason in a manner characteristic of subjects possessing ToM. Moreover, we demonstrate that our auto-grader is highly proficient at automatically evaluating LLMs' responses across various tasks, paving the way for more efficient, largerscale analyses for neural ToM."
                ],
                "publication_ref": [
                    "b12",
                    "b4",
                    "b21",
                    "b24",
                    "b21",
                    "b24",
                    "b21"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Related Work",
                "text": [
                    "ToM in humans ToM in children significantly influences various facets of their development, including social competence, peer acceptance, and academic achievement (Carlson et al., 2013). Research has revealed substantial changes in children's understanding of mental states by the age of five (Wellman et al., 2001). Although ToM is often linked to cognitive abilities like empathy and visual-spatial attention, it's crucial to note that these are separate constructs involving distinct neurological and cognitive processes (Kanske et al., 2015;Schurz et al., 2021;Zaki and Ochsner, 2012). These abilities also yield largely divergent effects on other aspects of social and cognitive development (Happ\u00e9 et al., 2017). Take for instance an individual with ToM but not empathy. They have the intellectual ability to interpret and understand the thoughts, intentions, and beliefs of others. Nevertheless, when tasked with sharing or connecting with others' emotions, they may encounter difficulty.",
                    "ToM tasks Quesque and Rossetti (2020) reviewed tasks frequently employed to assess ToM. Among these, the False Belief task, one of the most widely utilized tasks in human and language model studies, fulfills the criteria. This task requires participants to infer the belief of a character who holds a false belief about a particular scenario, which contrasts with the participants' updated belief of the same scenario. The Smarties and the Sally-Ann tests are the two most frequently employed False Belief tasks. For instance, in the Smarties Test, a child is shown a box labeled as 'candies'. After revealing that the box indeed contains crayons rather than candies, the child is asked what another person, unaware of the box's contents, would guess is inside. Younger children often answer 'crayons', while older children, understanding others would base their belief on the box's label, answer 'candies' (Gopnik and Astington, 1988).",
                    "On the other hand, several tasks either do not demand the distinction between one's own mental state and that of others or they actually measure processes not directly related to ToM. The tasks in Shapira et al. ( 2023) -Intention Ascription (included in the SOCIAL IQA dataset; Sap et al., 2019) and Animated Shapes -fall under this category. These tasks often foster shared representations between self and others, rather than creating a distinction (Brass et al., 2009). For example, in the Animated Shapes task, participants watch short animated films featuring geometrical shapes, and they are then asked to interpret the thoughts or feelings of these shapes. However, this task probes more into empathy rather than ToM.",
                    "Evaluations of ToM in LLMs ToM evaluations in LLMs vary greatly in terms of tasks and prompts. Nematzadeh et al. (2018) was the first work for evaluating ToM in LLMs, finding all models unsuccessful. In 2019, Le et al. (2019) found that the question-answer benchmarks of the time were prone to data biases, allowing models to develop corner-cutting heuristics due to a rigid event sequence template for each task type. To mitigate this, they introduced new evaluation methods along with a novel dataset. Sap et al. (2022) later evaluated GPT-3 (Brown et al., 2020) on this dataset, reporting only 55 -60% accuracy, even after fewshot fine-tuning with GPT-3-Davinci.",
                    "Recent two studies tested GPT-4 on a few False Belief examples using sentence completion Kosinski (2023) and question-answer prompts Bubeck et al. (2023). Both studies reported GPT-4 achieving \u2265 90% accuracy, leading to suggestions of spontaneous ToM emergence in LLMs. However, this claim was disputed by subsequent research (Ullman, 2023a;Shapira et al., 2023). As noted in Section 1, Ullman (2023a) introduced adversarial variations to the false belief questions used in Kosinski (2023), which resulted in a significant decrease in LLMs' performance. Shapira et al. (2023) evaluated LLMs across a range of tasks ToM, finding that current LLMs, including GPT-4, struggled to perform consistently. The tasks included the False Belief task from Kosinski (2023), the False Belief task with adversarial variations (Ullman, 2023a), the Animated Shapes task adapted from Heider and Simmel (1944), and a set of common sense reasoning tasks including the Intention Ascription task (Sap et al., 2019). Their findings indicated that current LLMs struggle to consistently perform well on these tasks. The high performance of GPT-4 observed in the initial studies (Kosinski, 2023;Bubeck et al., 2023) may reflect shallow heuristics, not robust ToM capabilities."
                ],
                "publication_ref": [
                    "b5",
                    "b25",
                    "b11",
                    "b20",
                    "b28",
                    "b9",
                    "b8",
                    "b19",
                    "b2",
                    "b15",
                    "b18",
                    "b3",
                    "b12",
                    "b4",
                    "b23",
                    "b21",
                    "b12",
                    "b21",
                    "b12",
                    "b23",
                    "b10",
                    "b19",
                    "b12",
                    "b4"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "TOMCHALLENGES and Tasks",
                "text": [
                    "We aim to build a corpus based on two types of tests: Sally-Anne Test and Smarties Test, which fit the ToM test criteria. Below we describe how we construct TOMCHALLENGES data, and how we design our evaluation tasks."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Dataset Construction",
                "text": [
                    "While Le et al. (2019) proposed the inclusion of distractors to prevent models from adopting cornercutting heuristics, it is important to note that distractors are more relevant for fine-tuning rather than zero-shot probing. Given the ongoing discussions surrounding the zero-shot performance of models in recent studies (Kosinski, 2023;Ullman, 2023b) and we care more about the model's inherent capabilities, we introduce a dataset without distractors as below to maintain our focus, with examples displayed in Tables 1 and 2. We created 30 variations of each test (e.g., changing the person's name, location, and items), and the details of the tests and variables are described as follows.",
                    "Sally-Anne Test The Sally-Anne Test was first introduced by Baron-Cohen et al. (1985) and has been widely used in psychology studies. The test typically involves two characters, Sally and Anne, where Anne hides an object while Sally's away. The children were usually asked where would Sally look for the object when she returns. The narrative consists of the following components: (1) a location L, where the event takes place, (2) two agents, A and B, where A moved the object while B one is away (3)   agents' mental states: REALITY focuses on the updated/current position of O, and BELIEF focuses on the initial/previous position. The first-order belief (1STA and 1STB) questions ask the agents' beliefs, and the second-order belief (2NDA and 2NDB) questions ask one agent's belief regarding the other agent's mental state."
                ],
                "publication_ref": [
                    "b12",
                    "b24",
                    "b1"
                ],
                "figure_ref": [],
                "table_ref": [
                    "tab_1"
                ]
            },
            {
                "heading": "Smarties Test",
                "text": [
                    "The Smarties Test was first introduced by Gopnik and Astington (1988) and has also been widely adopted in psychology studies. In a typical Smarties test, the child is presented with a 'Smarties' box that actually contains something else. The child is then asked what they think another person, who has not seen the contents of the box, would believe is inside. The narrative consists of the following components: (1) two agents, A and B, where A saw the contents and B didn't, (2) one container C that holds the object, and (3) two objects, O1 and O2, where O1 is the labeled content and O2 is the actual content. Using these components, we construct narratives for the Smarties Test as shown in Table 2. The questions of the Smarties Test narrative are similar in nature to those of the Sally-Anne Test, but the REALITY question focuses on the actual object in the container, and the BELIEF question focuses on the container's label."
                ],
                "publication_ref": [
                    "b8"
                ],
                "figure_ref": [],
                "table_ref": [
                    "tab_1"
                ]
            },
            {
                "heading": "Task Formulation",
                "text": [
                    "Previous studies have used a single task (e.g. question-answering task or sentence completion) task to evaluate the model's performance. In order to test the robustness of the model's performance, it is necessary to adapt the questions into a variety of tasks. We construct different prompts to create 6 task formats, as demonstrated in Table 3. These tasks can be categorized into three groups based on the level of freedom in generation:",
                    "Fully-Constrained Fully-constrained generation limits the model's output to specific predefined structures or responses. In this group, we design 3 tasks, i.e., Fill-in-the-Blank, Multiple Choice, and True or False questions.",
                    "Semi-Constrained Semi-constrained generation involves partial guidance by specific rules or structures, while still allowing some flexibility in the model's responses. This group consists of 2 tasks, i.e., Chain-of-Thought (CoT) True or False questions and Question Answering (Q&A) tasks.",
                    "Open-Ended Open-ended generation enables the model to generate responses without being restricted by predefined rules or structures, leading to more diverse and varied outputs. An example of this group is Text Completion."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_2"
                ]
            },
            {
                "heading": "Experimental Setup",
                "text": [
                    "We evaluate the zero-shot performance of three models: text-davinci-003 and gpt -3.5-turbo-0301, and gpt-4-0613 (OpenAI, 2022). For the hyperparameters of all models, we set the temperature as 0, top_p as 1, and both frequency penalty and presence penalty as 0. Due to the different natures of our task design, we choose different maximum token limits for each task as follows: 10 tokens for Fill-in-the-Blank, 2 tokens for Multiple Choice, 20 tokens for True or False, 100 tokens for CoT True or False, and 50 tokens for both Question Answering and Text Completion."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Answer Evaluation and Auto-grader",
                "text": [
                    "For the fully-constrained tasks, the models' answers can be graded easily since there are standard answers. We first apply a python function to grade these answers, and the results are double checked by human annotators. For the semi-constrained and open-ended tasks, the answers don't necessarily follow a standard form and are graded by human annotators. The rubrics to grade these answers include: 1) the answer is correct; 2) the answer doesn't contain any information that can not be inferred from the narrative.",
                    "In order to improve the efficiency of grading, we develop an auto-grader based on the gpt-4-0613 model with a grading prompt. The grading prompt consists of a general template of the narrative and guidelines of how to construct gold answers for the 6 questions. The model then grades the generated answers based on the gold answers. In addition, an example of a generated answer and grading pair was also included in the prompt for in-context learning. An example of the prompt is included in Appendix A. The output of the autograder consists of two parts: the reasoning part, where it outputs the gold answers to 6 questions; and the grade part, where it grades the generated answer. An example of the auto-grader's output is shown in Table 4.",
                    "We apply the auto-grader to evaluate the answers in two tasks: Q&A and Text Completion. First, we evaluate the gold answers output by the autograder. The auto-grader achieved 100% accuracy on all Sally-Anne and Smarties narratives, showing it can effectively produce gold answers for the 6 questions. Then we evaluated the grading results by comparing them to the human annotated results. The auto-grader achieved 100% accuracy on Q&A task and over 90% accuracy on Text Completion task. These results demonstrated that the auto-grader could be an effective tool in evaluating more freely generated answers."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_3"
                ]
            },
            {
                "heading": "Results and Analyses",
                "text": [
                    "In this section, we present the results of our evaluation for all models on Sally-Anne and Smarties tests. As we create 30 variations of the narrative for each test, and each narrative comes with 6 questions (REALITY, BELIEF, 1STA, 1STB, 2NDA, 2NDB), and each question is tested on 6 tasks, an idealized model that is capable to solve Theory of Mind tasks should be able to achieve high accuracy on all questions across different tasks and in most of the narratives."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Accuracy by Question and Task",
                "text": [
                    "The accuracy of each question type is calculated by averaging the accuracy over 30 narratives (e.g., an accuracy of 50% for 1STA question means that the model answered correctly for 15 out of the 30 narratives). Figure 2 and 3 show the average accuracy of 6 types of questions in different prompts for Sally-Anne Test and Smarties Test.",
                    "For the Sally-Anne tests, all three models are able to achieve near-perfect accuracy on REALITY, BELIEF, and 1STA questions for all prompts, indicating that the models can reason based on facts. For 1STB question that requires reasoning both the belief of A and B, the gpt-4 model achieved better performance than the gpt-3.5 models (davinci and turbo). For 2NDA and 2NDB questions, gpt-3.5 models struggled to understand one person's belief about another person's belief, while gpt-4 answered most of the narratives correctly. For different tasks, the models behaved differently. All three models achieved the best overall performance with the Text Completion task, followed by the Fill-inthe-Blank task. In addition, introducing Chain-of-Thought did not improve the model's performance on True/False task.",
                    "The Smarties test showed a different accuracy pattern from the Sally-Anne test. All three models showed some difficulties answering the fact-based questions, REALITY, BELIEF, and 1STA questions correctly. For the 1STB questions, all three models had worse performance than the 1STB questions in the Sally-Anne test. For 2NDA and 2NDB questions, gpt-4 model and turbo model had similar performance as in the Sally-Anne test, while the davinci model achieved better performance than the Sally-Anne test. We observe that the davinci model performed best on the Text Completion task, the turbo model performed best on the Multiple-Choice task, and gpt-4 model performed best on the Fill-in-the-Blank task.",
                    "By comparing the different tests, questions, and tasks, it is clear that the models can not reliably perform ToM tasks well. The models are generally good at fact-based questions and struggle more    with questions that require reasoning through different agents' beliefs. The models are also sensitive to the prompts and framing the question into different tasks could significantly affect the model's performance."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_2"
                ],
                "table_ref": []
            },
            {
                "heading": "Accuracy by Narratives",
                "text": [
                    "The accuracy of each narrative is calculated as the average accuracy over six question types. Although the narratives are generated through the same template, the models produced different answers. For example, for some narratives, the model is able to answer all the questions correctly, while for others the model's accuracy drops. "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Error Analysis",
                "text": [
                    "We further looked into the errors the models made, especially for the questions that the models had low accuracy. We focused our error analysis on the Q&A and Text Completion tasks, since the output of these two tasks contains more information to analyze. The errors can be divided into three major types:  8. The errors of True Failure are similar to the errors the younger children would make, where the model assumed that an agent knew something they shouldn't know. An example of the wrong answer is 'Hillary would most likely look in the bucket where Sabra moved the mitten.' This type of error is more common in the davinci and turbo models, and more frequently occurs in Sally-Anne's narrative than the Smarties narrative.",
                    "Overly conservation errors happen when the model is being too conservative and refuses to make inferences about the agent's belief. This type of error is common in the turbo and the gpt-4 models, where the model produces answers like 'The context does not provide information on where Juanita would look for the towel when she returns.'. In addition, this error is more common in the Smar-  ties narrative than in the Sally-Anne narrative.",
                    "Hallucination error is identified when the answer includes information that can not be inferred from the narrative, or the answer contains contradicting information than the narrative. An example error would be: 'In the backpack, there was a note that said, \"This backpack belongs to Norina\".', where 'note' was not mentioned in the narrative at all. This type of error is more frequently found in the turbo model.",
                    "The error analyses showed that the models failed on the ToM tasks not only because they could not reason about reality and people's beliefs, but also because of the inherent limitation of LLMs. For example, the hallucination errors and the overly conservative errors are related to the inference process of the LLMs, which has always been a challenging part of the NLP field."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_9"
                ]
            },
            {
                "heading": "Conclusions",
                "text": [
                    "In this study, we proposed TOMCHALLENGES to comprehensively test the ToM on LLMs. The dataset is constructed based on the Sally-Anne and Smarties tests. For each test, we created a template to generate variations of the test. In addition, we incorporated 6 types of questions to examine the model's understanding of reality, belief, 1st order belief, and 2nd order belief. We also included 6 tasks with different prompts for evaluation, considering the impact of prompts on model performance. This evaluation method serves a dual purpose: it not only measures whether the model has ToM capacity, but also measures the robustness of the model in performing the ToM tasks. In addition, we also create an effective auto-grader that achieved high accuracy in evaluating the more free-formed answers of the ToM tasks.",
                    "Using 30 variations of Sally-Anne and Smarties tests, we found that the GPT-based models can not reliably perform the ToM tasks, since the accuracy varies across different tasks, questions, and narratives. Through error analysis, we found that the failure of the models can not be simply concluded as they lack the ability to reason reality and beliefs. Instead, many of the errors reflect the inherent limitations of the LLMs, which might not be related to the cognitive explanations of the ToM.",
                    "We hope our study could invite more discussions on evaluating the ToM in LLMs. Further studies could investigate how and why different prompt types would affect the model's performance, how to improve the robustness of the model's performance, how to interpret the results more appropriately, etc. In addition, one limitation of our study is that we did not conduct human experiments. It is unclear if human adults are able to achieve (almost) perfect performance across different stories, prompts and tasks. Future studies could also compare human results and the LLMs' behaviors side by side for evaluation. We hope that future discussions could not only focus on whether LLMs exhibit the ToM, but also attend to the significance and implications of the ToM in LLMs."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Reasoning:",
                "text": [
                    "This is a Sally-Anne story. Person A is Sabra and Person B is Hillary. The item is a mitten. Location X is the briefcase and Location Y is the bucket. Gold Answers: 1. reality: The mitten is currently in the bucket because Sabra moved it there. 2. belief: The mitten was in the briefcase before. 3. 1st order belief of Sabra: Sabra would look for the mitten in the bucket because she moved it there. 4. 1st order belief of Hillary: Hillary would look for the mitten in the briefcase because she didn't know that Sabra moved it. 5. 2nd order belief of Sabra: Sabra would think that Hillary looks for the mitten in the briefcase because she knew that Hillary didn't see her move the mitten to the bucket. 6. 2nd order belief of Hillary: Hillary would think that Sabra looks for the mitten in the briefcase because she didn't know that Sabra already moved it. The response to the prompts suggests that Hillary would look for the mitten in the bucket. The answer is incorrect because it is contradicting gold answer 4. Grade: Incorrect."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            }
        ],
        "references": [
            {
                "ref_id": "b0",
                "title": "Mind the gap: Challenges of deep learning approaches to theory of mind",
                "journal": "Artificial Intelligence Review",
                "year": "2023",
                "authors": "Jaan Aru; Aqeel Labash"
            },
            {
                "ref_id": "b1",
                "title": "Does the autistic child have a \"theory of mind",
                "journal": "Cognition",
                "year": "1985",
                "authors": "Simon Baron-Cohen; Alan M Leslie; Uta Frith"
            },
            {
                "ref_id": "b2",
                "title": "Inhibition of imitative behaviour and social cognition",
                "journal": "Philosophical Transactions of the Royal Society B: Biological Sciences",
                "year": "1528",
                "authors": "Marcel Brass; Perrine Ruby; Stephanie Spengler"
            },
            {
                "ref_id": "b3",
                "title": "Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners",
                "journal": "",
                "year": "2020-12-06",
                "authors": "Tom B Brown; Benjamin Mann; Nick Ryder; Melanie Subbiah; Jared Kaplan; Prafulla Dhariwal; Arvind Neelakantan; Pranav Shyam; Girish Sastry; Amanda Askell; Sandhini Agarwal; Ariel Herbert-Voss; Gretchen Krueger; Tom Henighan; Rewon Child; Aditya Ramesh; Daniel M Ziegler; Jeffrey Wu; Clemens Winter; Christopher Hesse; Mark Chen; Eric Sigler; Mateusz Litwin"
            },
            {
                "ref_id": "b4",
                "title": "Sparks of artificial general intelligence: Early experiments with gpt-4",
                "journal": "",
                "year": "2023",
                "authors": "S\u00e9bastien Bubeck; Varun Chandrasekaran; Ronen Eldan; Johannes Gehrke; Eric Horvitz; Ece Kamar; Peter Lee; Yin Tat Lee; Yuanzhi Li; Scott Lundberg"
            },
            {
                "ref_id": "b5",
                "title": "Theory of mind",
                "journal": "Wiley Interdisciplinary Reviews: Cognitive Science",
                "year": "2013",
                "authors": "Melissa A Stephanie M Carlson; Madeline B Koenig;  Harms"
            },
            {
                "ref_id": "b6",
                "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
                "journal": "Association for Computational Linguistics",
                "year": "2019",
                "authors": "Jacob Devlin; Ming-Wei Chang; Kenton Lee; Kristina Toutanova"
            },
            {
                "ref_id": "b7",
                "title": "What is so special about embodied simulation?",
                "journal": "Trends in cognitive sciences",
                "year": "2011",
                "authors": "Vittorio Gallese; Corrado Sinigaglia"
            },
            {
                "ref_id": "b8",
                "title": "Children's understanding of representational change and its relation to the understanding of false belief and the appearance-reality distinction",
                "journal": "Child development",
                "year": "1988",
                "authors": "Alison Gopnik; Janet W Astington"
            },
            {
                "ref_id": "b9",
                "title": "The structure of social cognition: In (ter) dependence of sociocognitive processes",
                "journal": "Annual review of psychology",
                "year": "2017",
                "authors": "Francesca Happ\u00e9; Jennifer L Cook; Geoffrey Bird"
            },
            {
                "ref_id": "b10",
                "title": "An experimental study of apparent behavior",
                "journal": "The American journal of psychology",
                "year": "1944",
                "authors": "Fritz Heider; Marianne Simmel"
            },
            {
                "ref_id": "b11",
                "title": "Dissecting the social brain: Introducing the empatom to reveal distinct neural networks and brain-behavior relations for empathy and theory of mind",
                "journal": "NeuroImage",
                "year": "2015",
                "authors": "Philipp Kanske; Anne B\u00f6ckler; Tania Fynn-Mathis Trautwein;  Singer"
            },
            {
                "ref_id": "b12",
                "title": "Theory of mind may have spontaneously emerged in large language models",
                "journal": "",
                "year": "2023",
                "authors": "Michal Kosinski"
            },
            {
                "ref_id": "b13",
                "title": "Revisiting the evaluation of theory of mind through question answering",
                "journal": "Association for Computational Linguistics",
                "year": "2019",
                "authors": "Matthew Le; Y-Lan Boureau; Maximilian Nickel"
            },
            {
                "ref_id": "b14",
                "title": "What is theory of mind? a psychometric study of theory of mind and intelligence",
                "journal": "Cognitive Psychology",
                "year": "2022",
                "authors": "Ester Navarro"
            },
            {
                "ref_id": "b15",
                "title": "Evaluating theory of mind in question answering",
                "journal": "Association for Computational Linguistics",
                "year": "2018",
                "authors": "Aida Nematzadeh; Kaylee Burns; Erin Grant; Alison Gopnik; Tom Griffiths"
            },
            {
                "ref_id": "b16",
                "title": "What do theory-of-mind tasks actually measure? theory and practice",
                "journal": "Perspectives on Psychological Science",
                "year": "2020",
                "authors": "Fran\u00e7ois Quesque; Yves Rossetti"
            },
            {
                "ref_id": "b17",
                "title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
                "journal": "J. Mach. Learn. Res",
                "year": "2020",
                "authors": "Colin Raffel; Noam Shazeer; Adam Roberts; Katherine Lee; Sharan Narang; Michael Matena; Yanqi Zhou; Wei Li; Peter J Liu"
            },
            {
                "ref_id": "b18",
                "title": "Neural theory-of-mind? on the limits of social intelligence in large LMs",
                "journal": "",
                "year": "2022",
                "authors": "Maarten Sap; Le Ronan;  Bras"
            },
            {
                "ref_id": "b19",
                "title": "Social IQa: Commonsense reasoning about social interactions",
                "journal": "",
                "year": "2019",
                "authors": "Maarten Sap; Hannah Rashkin; Derek Chen; Yejin Ronan Le Bras;  Choi"
            },
            {
                "ref_id": "b20",
                "title": "Toward a hierarchical model of social cognition: A neuroimaging meta-analysis and integrative review of empathy and theory of mind",
                "journal": "Psychological Bulletin",
                "year": "2021",
                "authors": "Matthias Schurz; Joaquim Radua; Matthias G Tholen; Lara Maliske; S Daniel;  Margulies; B Rogier; Jerome Mars; Philipp Sallet;  Kanske"
            },
            {
                "ref_id": "b21",
                "title": "Clever hans or neural theory of mind? stress testing social reasoning in large language models",
                "journal": "",
                "year": "2023",
                "authors": "Natalie Shapira; Mosh Levy; Xuhui Seyed Hossein Alavi; Yejin Zhou; Yoav Choi; Maarten Goldberg; Vered Sap;  Shwartz"
            },
            {
                "ref_id": "b22",
                "title": "Mindgames: Targeting theory of mind in large language models with dynamic epistemic modal logic",
                "journal": "",
                "year": "2023",
                "authors": "Damien Sileo; Antoine Lernould"
            },
            {
                "ref_id": "b23",
                "title": "Large language models fail on trivial alterations to theory-of-mind tasks",
                "journal": "",
                "year": "2023",
                "authors": "Tomer Ullman"
            },
            {
                "ref_id": "b24",
                "title": "Large language models fail on trivial alterations to theory-of-mind tasks",
                "journal": "",
                "year": "2023",
                "authors": "D Tomer;  Ullman"
            },
            {
                "ref_id": "b25",
                "title": "Meta-analysis of theory-of-mind development: The truth about false belief",
                "journal": "Child development",
                "year": "2001",
                "authors": "David Henry M Wellman; Julanne Cross;  Watson"
            },
            {
                "ref_id": "b26",
                "title": "Beliefs about beliefs: Representation and constraining function of wrong beliefs in young children's understanding of deception",
                "journal": "Cognition",
                "year": "1983",
                "authors": "Heinz Wimmer; Josef Perner"
            },
            {
                "ref_id": "b27",
                "title": "Coke: A cognitive knowledge graph for machine theory of mind",
                "journal": "",
                "year": "2023",
                "authors": "Jincenzi Wu; Zhuang Chen; Jiawen Deng; Sahand Sabour; Minlie Huang"
            },
            {
                "ref_id": "b28",
                "title": "The neuroscience of empathy: progress, pitfalls and promise",
                "journal": "Nature neuroscience",
                "year": "2012",
                "authors": "Jamil Zaki; Kevin N Ochsner"
            },
            {
                "ref_id": "b29",
                "title": "You will be given a series of Prompt and Response pairs about Theory of Mind. The core of grading rubric is to see if the answer can correctly reason the reality and the knowledge of the people in the story. You first need to reason about the context in the Prompt and figure out the key facts",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b30",
                "title": "The Sally-Ann story is about two people (Person A and Person B) found an item in location X. Person B left the room and Person A moved the item to location Y. Key facts for Sally-Ann story include: 1. reality: the current location of the item",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b31",
                "title": "1st order belief of Person B: what Person B thinks the current location of the item",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b32",
                "title": "1st order belief of Person A: what Person A thinks the current location of the item",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b33",
                "title": "2nd order belief of Person B: what Person B thinks that Person A thinks the current location of the item",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b34",
                "title": "2nd order belief of Person A: what Person A thinks that Person B thinks the current location of the item",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b35",
                "title": "The label on the container says item X, but there's no item X in the container. Person A opened the container and found item Y. Later, Person B entered the room and saw the container. Key facts for Smarties story include: 1. reality: what's inside the container",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b36",
                "title": "1st order belief of Person B: what Person B expects to find in the container",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b37",
                "title": "1st order belief of Person A: what Person B expects to find in the container, which is item Y (because Person A already opened the bag and found Y)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b38",
                "title": "2nd order belief of Person B: what Person B thinks that Person A expects to find in the container",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b39",
                "title": "A: what Person A thinks that Person B thinks is in the container, which is item X. After identifying the key facts of the context, you can take a look at the response to see if that is align with the key facts. If the response is align with the key facts and does not contain any information that cannot be inferred from the context",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b40",
                "title": "Neila couldn't see what was inside the bag. Neila opened the bag and found a vest. There is no plate in the bag. Neila closed the bag and put it back. Juanita entered the attic and saw the bag. In the bag, there was Response: a vest. assistant: Reasoning: This is a Smarties story. Person A is Neila and Person B is Juanita. The container is a bag. Item X is plate and item Y is vest",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b41",
                "title": "Juanita expects fo find a plate in the bag because the label says plate and doesn't know there's actually a vest in the bag",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b42",
                "title": "1st order belief of Neila: Neila expects to find a vest in the bag because she already opened the bag and found a vest",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b43",
                "title": "Juanita thinks that Neila expects to find a plate in the bag, because she doesn't know that Neila already opened the bag and found a vest",
                "journal": "",
                "year": "",
                "authors": "Juanita "
            },
            {
                "ref_id": "b44",
                "title": "Neila thinks that Juanita expects to find a plate in the bag, because she knows that Juanita doesn't know there's actually a vest in the bag. The response to the prompt suggests that there was a vest in the bag",
                "journal": "",
                "year": "",
                "authors": ""
            }
        ],
        "figures": [
            {
                "figure_label": "1",
                "figure_type": "figure",
                "figure_id": "fig_0",
                "figure_caption": "Figure 1 :1Figure 1: An example of Smarties test, as well as Mentalizing and False-Belief Understanding criteria.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_1",
                "figure_caption": "Figure 2: The average accuracy for questions in Sally-Anne test for different prompts.",
                "figure_data": ""
            },
            {
                "figure_label": "3",
                "figure_type": "figure",
                "figure_id": "fig_2",
                "figure_caption": "Figure 3 :3Figure 3: The average accuracy of questions in Smarties test for different prompts.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_3",
                "figure_caption": "3 a) True Failure of ToM, b) Overly conservative, c) Hallucination. The summary of the error counts of each type of error in Q&A and Text Completion tasks is shown in Table",
                "figure_data": ""
            },
            {
                "figure_label": "1",
                "figure_type": "table",
                "figure_id": "tab_0",
                "figure_caption": "an object O, whose position changed in the narrative, and (4) two containers, C1 and Variables L: attic, A: Neila, B: Juanita, O: towel, C1: closet, C2: cabinet Narrative N Neila and Juanita were hanging out in the attic. They saw a closet and a cabinet. They found a towel in the closet. Juanita left the attic. Neila moved the towel to the cabinet. An example for Sally-Anne Test.",
                "figure_data": "REALITY Where is the towel currently?Answer: The cabinet.BELIEFWhere was the towel previously?Answer: The closet.After Juanita came back to the attic,  \u20201STAwhere would Neila look for the towel?Answer: The closet.1STBwhere would Juanita look for the towel?Answer: The cabinet.2NDAwhere would Neila think Juanita would look forthe towel?Answer: The cabinet.2NDBwhere would Juanita think Neila would look forthe towel?Answer: The cabinet."
            },
            {
                "figure_label": "2",
                "figure_type": "table",
                "figure_id": "tab_1",
                "figure_caption": "An example for Smarties Test. Neila and Juanita were hanging out in the attic. They saw a closet and a cabinet. They found a towel in the closet. Juanita left the attic. Neila moved the towel to the cabinet. Fill-in-the-Blank Fill in the blank (<>): N After Juanita came back to the attic, Neila would think Juanita would look for the towel in the < >. Answer: Multiple Choice Choose the correct answer from A or B for the following question: Question: N After Juanita came back to the attic, where would Neila think Juanita would look for the towel? A. cabinet B. closet True/False Given the context, judge True or False of the given statements A and B respectively: N Statements: A. Juanita would look for the towel in the cabinet. B. Juanita would look for the towel in the closet. After Juanita came back to the attic, Neila would think Juanita would look for the towel in",
                "figure_data": "C2, representing the object's initial and updatedpositions, respectively. Using these components,we construct narratives as shown in Table 1. 2For each narrative, we create 6 questions follow-ing Le et al. (2019) to comprehensively evaluatethe model's understanding of the narrative and the"
            },
            {
                "figure_label": "3",
                "figure_type": "table",
                "figure_id": "tab_2",
                "figure_caption": "An illustrative example for different task templates of the Sally-Anne Test using 2NDA question as an example, ignoring line breaks in templates for space saving.",
                "figure_data": ""
            },
            {
                "figure_label": "4",
                "figure_type": "table",
                "figure_id": "tab_3",
                "figure_caption": "An example of Auto-grader output on answer 1STB question.",
                "figure_data": ""
            },
            {
                "figure_label": "5",
                "figure_type": "table",
                "figure_id": "tab_4",
                "figure_caption": "The accuracy of auto-grader on Gold Answer, Q&A and Text Completion.",
                "figure_data": ""
            },
            {
                "figure_label": "6",
                "figure_type": "table",
                "figure_id": "tab_5",
                "figure_caption": "Table 7 show the average accuracy of Sally-Anne and Smarties tests across narratives. For both tests, the gpt-4 model has the best and most stable performance, which has the highest average accuracy and lowest standard deviation.",
                "figure_data": "Sally-Annedavinciturbogpt-4MC0.50\u00b100.82\u00b10.170.91\u00b10.10FB0.61\u00b10.130.93\u00b10.090.99\u00b10.03TF0.5\u00b100.65\u00b10.101\u00b10CoT-TF0.5\u00b100.57\u00b10.120.99\u00b10.03QA0.5\u00b100.68\u00b10.170.84\u00b10.04Comp0.72\u00b10.150.92\u00b10.100.92\u00b10.12"
            },
            {
                "figure_label": "6",
                "figure_type": "table",
                "figure_id": "tab_6",
                "figure_caption": "The average accuracy and standard deviation for narratives in the Sally-Anne test for different prompts.",
                "figure_data": "Smartiesdavinciturbogpt-4MC0.84\u00b10.030.95\u00b10.070.88\u00b10.08FB0.78\u00b10.120.96\u00b10.100.88\u00b10.10TF0.33\u00b10.110.46\u00b10.120.92\u00b10.08CoT-TF0.44\u00b10.150.34\u00b10.060.92\u00b10.08QA0.79\u00b10.120.37\u00b10.100.90\u00b10.08Comp0.85\u00b10.090.78\u00b10.130.84\u00b10.13"
            },
            {
                "figure_label": "7",
                "figure_type": "table",
                "figure_id": "tab_7",
                "figure_caption": "The average accuracy for stories in the Smarties test for different prompts.",
                "figure_data": ""
            },
            {
                "figure_label": "8",
                "figure_type": "table",
                "figure_id": "tab_9",
                "figure_caption": "The total error counts of 6 questions in Q&A and Text Completion tasks for 3 models.",
                "figure_data": ""
            }
        ],
        "formulas": [],
        "doi": "10.18653/v1/N19-1423"
    },
    "A Minimal Approach for Natural Language Action Space in Text-based Games": {
        "authors": "Kelvin Dongwon;  Ryu; Meng Fang; Gholamreza Haffari; Shirui Pan; Ehsan Shareghi",
        "pub_date": "",
        "abstract": "Text-based games (TGs) are language-based interactive environments for reinforcement learning. While language models (LMs) and knowledge graphs (KGs) are commonly used for handling large action space in TGs, it is unclear whether these techniques are necessary or overused. In this paper, we revisit the challenge of exploring the action space in TGs and propose \u03f5-admissible exploration, a minimal approach of utilizing admissible actions, for training phase. Additionally, we present a textbased actor-critic (TAC) agent that produces textual commands for game, solely from game observations, without requiring any KG or LM. Our method, on average across 10 games from Jericho, outperforms strong baselines and stateof-the-art agents that use LM and KG. Our approach highlights that a much lighter model design, with a fresh perspective on utilizing the information within the environments, suffices for an effective exploration of exponentially large action spaces. 1  ",
        "sections": [
            {
                "heading": "Introduction",
                "text": [
                    "An intelligent agent that communicates in natural language space has been a long goal of artificial intelligence (Fang et al., 2017). Text-based games (TGs) best suit this goal, since they allow the agent to read the textual description of the world and write the textual command to the world (Hausknecht et al., 2020;C\u00f4t\u00e9 et al., 2018). In TGs, the agent should perform natural language understanding (NLU), sequential reasoning and natural language generation (NLG) to generate a series of actions to accomplish the goal of the game, i.e. adventure or puzzle (Hausknecht et al., 2020). The language perspective of TGs foists environments partially observable and action space combinatorially large, making the task challenging. Since TGs alert the player how much the game has proceeded with the game score, reinforcement learning (RL) naturally lends itself as a suitable framework.",
                    "Due to its language action space, an RL agent in TGs typically deals with a combinatorially large action space, motiving various design choices to account for it. As two seminal works in this space, Yao et al. (2020) trained a language model (LM) to produce admissible actions 2 for the given textual observation and then used, under the predicted action list, Deep Reinforcement Relevance Network to estimate the Q value. As an alternative, Ammanabrolu and Hausknecht (2020) constructs a knowledge graph (KG) to prune down action space while learning the policy distribution through actorcritic (AC) method and supervision signal from the admissible actions. Both paradigms leverage admissible actions at different stages at the cost of imposing additional modules and increasing model complexity.",
                    "In this paper, we take a fresh perspective on leveraging the information available in the TG environment to explore the action space without relying on LMs or KGs. We propose a minimal form of utilizing admissibility of actions to constrain the action space during training while allowing the agent to act independently to access the admissible actions during testing. More concretely, our proposed training strategy, \u03f5-admissible exploration, leverages the admissible actions via random sampling during training to acquire diverse and useful data from the environment. Then, our developed textbased actor-critic (TAC) agent learns the policy distribution without any action space constraints. It is noteworthy that our much lighter proposal is under the same condition as other aforementioned methods since all the prior works use admissible actions in training the LM or the agent.",
                    "Our empirical findings, in Jericho, illustrate that TAC with \u03f5-admissible exploration has better or on-par performance in comparison with the stateof-the-art agents that use an LM or KG. Through experiments, we observed that while previous methods have their action selections largely dependent on the quality of the LM or KG, sampling admissible actions helps with the action selection and results in acquiring diverse experiences during exploration. While showing a significant success on TGs, we hope our approach encourages alternative perspectives on leveraging action admissibility in other domains of applications where the action space is discrete and combinatorially large."
                ],
                "publication_ref": [
                    "b7",
                    "b6",
                    "b25"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Basic Definitions",
                "text": [
                    "Text-based Games. TGs are game simulation environments that take natural language commands and return textual description of the world. They have received significant attention in both NLP and RL communities in recent years. C\u00f4t\u00e9 et al. (2018) introduced TextWorld, a TG framework that automatically generates textual observation through knowledge base in a game engine. It has several hyper-parameters to control the variety and difficulty of the game. Hausknecht et al. (2020) released Jericho, an open-sourced interface for human-made TGs, which has become the de-facto testbed for developments in TG. Admissible Action. A list of natural language actions that are guaranteed to be understood by the game engine and change the environment in TGs are called Admissible Actions. The term was introduced in TextWorld while a similar concept also exists in Jericho under a different name, valid actions. Hausknecht et al. (2020) proposed an algorithm that detects a set of admissible actions provided by Jericho suite by constructing a set of natural language actions from every template with detectable objects for a given observation and running them through the game engine to return those actions that changed the world object tree.",
                    "Template-based Action Space. Natural language actions are built with template (T) and object (O) from template-based action space. Each template takes at most two objects. For instance, a templateobject pair (take OBJ from OBJ, egg, fridge) produces a natural language action take egg from fridge while (west,-,-) produces west. The agent ought to find the optimal policy that maximizes the expected discounted sum of rewards, or the return, R t = \u221e k=0 \u03b3 k r t+k+1 . Traditional Reinforcement Learning. There are three traditional algorithms in RL, Q-learning (QL), policy gradient (PG) and actor-critic (AC). QL estimates the return for a given state-action pair, or Q",
                    "value, Q(s t , a t ) = E[ \u221e k=0 \u03b3 k r t+k+1 |s t , a t ],",
                    "then selects the action of the highest Q value. However, this requires the action space to be countably finite. To remedy this, PG directly learns the policy distribution from the environment such that it maximizes the total return through Monte-Carlo (MC) sampling. AC combines QL and PG, where it removes MC in PG and updates the parameters per each step with estimated Q value using QL. This eliminates the high variance of MC as an exchange of a relatively small bias from QL."
                ],
                "publication_ref": [
                    "b6"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Related Work on TG Agents in RL",
                "text": [
                    "We provide a brief overview of widely known TG agents relevant to the work presented in this paper. We empirically compare these in the Section 5.1. Contextual Action LM (CALM)-DRRN (Yao et al., 2020) uses an LM (CALM) to produce a set of actions for a given textual observation from the TGs. It is trained to map a set of textual observations to the admissible actions through causal language modeling. Then, Deep Reinforcement Relevance Network (DRRN) agent was trained on the action candidates from CALM. DRRN follows QL, estimating the Q value per observation-action pair. As a result, CALM removes the need for the ground truth while training DRRN. 3  Knowledge Graph Advantage Actor Critic (KG-A2C) (Ammanabrolu and Hausknecht, 2020) uses the AC method to sequentially sample templates and objects, and KGs for long-term memory and action pruning. Throughout the gameplay, KG-A2C organizes knowledge triples from textual observation using Stanford OpenIE (Angeli et al., 2015) to construct a KG. Then, the KG is used to build state representation along with encoded game observations and constrain object space with only the entities that the agent can reach within KG, i.e. immediate neighbours. They used admissible actions in the cross entropy supervised loss. KG-A2C Inspired Agents. Xu et al. (2020) proposed SHA-KG that uses stacked hierarchical attention on KG. Graph attention network (GAT) was applied to sample sub-graphs of KG to enrich the state representation on top of KG-A2C. Ammanabrolu et al. (2020) used techniques inspired by Question Answering (QA) with LM to construct the KG. They introduced Q*BERT which uses AL-BERT (Lan et al., 2020) fine-tuned on a dataset specific to TGs to perform QA and extract information from textual observations of the game, i.e. \"Where is my current location?\". This improved the quality of KG, and therefore, constituted better state representation. Ryu et al. (2022) proposed an exploration technique that injects commonsense directly into action selection. They used log-likelihood score from commonsense transformer (Bosselut et al., 2019) to re-rank actions. Peng et al. (2021) investigated explainable generative agent (HEX-RL) and applied hierarchical graph attention to symbolic KG-based state representations. This was to leverage the graph representation based on its significance in action selection. They also employed intrinsic reward signal towards the expansion of KG to motivate the agent for exploration (HEX-RL-IM) (Peng et al., 2021).",
                    "All the aforementioned methods utilize admissible actions in training the LM or agent. Our proposed method, introduced shortly ( \u00a74), uses admissible actions as action constraints during training without relying on KG or LM.",
                    "4 Text-based Actor Critic (TAC)",
                    "Our agent, Text-based Actor Critic (TAC), follows the Actor-Critic method with template-object decoder. We provide an overview of the system in Figure 1 and a detailed description in below. We follow the notation introduced earlier in Section 2. Encoder. Our design consists of text and state encoders. Text encoder is a single shared bidirectional GRU with different initial hidden state for different input text, (o game , o look , o inv , a N ). The state representation only takes encoded textual observations while the natural language action a N is encoded to be used by the critic (introduced shortly). State encoder embeds game scores into a high dimensional vector and adds it to the encoded observation. This is then, passed through a feed-forward neural network, mapping an instance of observation to state representation without the history of the past information.",
                    "Actor. The Actor-Critic design is used for our RL component. We describe our generative actor first. Our actor network maps from state representation to action representation. Then, the action representation is decoded by GRU-based template and object decoders (Ammanabrolu and Hausknecht, 2020). Template decoder takes action representation and produces the template distribution and the context vector. Object decoder takes action representation, semi-completed natural language action and the context from template decoder to produce object distribution sequentially. Critic. Similar to (Haarnoja et al., 2018), we employed two types of critics for practical purpose, state critic for state value function and state-action critic for state-action value function. Both critics take the state representation as input, but stateaction critic takes encoded natural language action as an additional input. The textual command produced by the decoder is encoded with text encoder and is passed through state-action critic to predict state-action value, or Q value, for a given command. A more detailed diagram for Actor and Critic is in Appendix D. To smooth the training, we introduced target state critic as an exponentially moving average of state critic (Mnih et al., 2015). Also, the two state-action critics are independently updated to mitigate positive bias in the policy improvement (Fujimoto et al., 2018). We used the minimum of the two enhanced critic networks outputs as our estimated state-action value function.",
                    "Objective Function. Our objective functions are largely divided into two, RL and SL. RL objectives are for reward maximization L R , state value prediction L V , and state-action value prediction L Q .",
                    "We overload the notation of \u03b8: for instance, V \u03b8 (o) signifies parameters from the encoder to the critic, and \u03c0 \u03b8 (a|o) from the encoder to the actor. Reward maximization is done as follows,",
                    "L R = \u2212E [A(o, a)\u2207 \u03b8 ln \u03c0 \u03b8 (a|o)] , (1) A(o, a) = Q \u03b8 (o, a) \u2212 V \u03b8 (o),",
                    "(2) where A(o, a) is the normalized advantage function with no gradient flow.",
                    "LV = E \u2207 \u03b8 V \u03b8 (o) \u2212 r + \u03b3V\u03b8(o \u2032 ) ,(3)",
                    "LQ = E \u2207 \u03b8 Q \u03b8 (o, a) \u2212 r + \u03b3V\u03b8(o \u2032 ) ,(4)",
                    "where o \u2032 is observation in the next time step and \u03b8 signifies the parameters containing the target state critic, updated as moving average with \u03c4 , \u03b8v = \u03c4 \u03b8 v + (1 \u2212 \u03c4 ) \u03b8v .",
                    "(5)",
                    "Our SL updates the networks to produce valid templates and valid objects,",
                    "L T = 1 |T| a T \u2208T (y a T ln (\u03c0 \u03b8 (a T |o)) + (1 \u2212 y a T ) (1 \u2212 ln (\u03c0 \u03b8 (a T |o)))),(6)",
                    "L O = 1 |O| a O \u2208O (y a O ln (\u03c0 \u03b8 (a O |o, \u00e2)) + (1 \u2212 y a O ) (1 \u2212 ln (\u03c0 \u03b8 (a O |o, \u00e2)))),(7)",
                    "y a T = 1 a T \u2208 T a 0 otherwise y a O = 1 a O \u2208 O a 0 otherwise",
                    "where L T and L O are the cross entropy losses over the templates (T) and objects (O). Template and object are defined as a T and a O , while \u00e2 is the action constructed by previously sampled template and object. Positive samples, y a T and y a O , are only if the corresponding template or object are in the admissible template (T a ) or admissible object (O a ). 4  The final loss function is constructed with \u03bb coefficients to control for trade-offs,",
                    "L = \u03bb R L R +\u03bb V L V +\u03bb Q L Q +\u03bb T L T +\u03bb O L O. (8",
                    ")",
                    "Our algorithm is akin to vanilla A2C proposed by Ammanabrolu and Hausknecht (2020) with some changes under our observations. A detailed comparison and qualitative analysis are in Appendix E and F. \u03f5-admissible Exploration. We use a simple exploration technique during training, which samples the next action from admissible actions with \u03f5 probability threshold. For a given state s, define A a (s) \u2286 A N as an admissible action subset of all natural language actions set. We sample an action directly from admissible action set under uniform distribution, a N \u223c U(A a (s)). Formally, we uniformly sample p \u2208 [0, 1] per every step,",
                    "\u03b2(a|s) = U(A a (s)) p < \u03f5 \u03c0(a|s) p \u2265 \u03f5 (9)",
                    "This collects diverse experiences from altering the world with admissible actions. We also tried a variant where the \u03f5 is selected adaptively given the game score the agent has achieved. However, this variant under-performed the static \u03f5. See Appendix I for more details on this and the results.   "
                ],
                "publication_ref": [
                    "b25",
                    "b3",
                    "b24",
                    "b14",
                    "b5",
                    "b17",
                    "b17",
                    "b9",
                    "b16",
                    "b8"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Experiments",
                "text": [
                    "In this section, we provide a description of our experimental details and discuss the results. We selected a wide variety of agents (introduced in Section 3) utilizing the LM or the KG: CALM-DRRN (Yao et al., 2020) and KG-A2C (Ammanabrolu and Hausknecht, 2020) as baselines, and SHA-KG (Xu et al., 2020), Q*BERT (Ammanabrolu et al., 2020), HEX-RL and HEX-RL-IM (Peng et al., 2021) as state-of-the-art (SotA). Experimental Setup. Similar to KG-A2C, we train our agent on 32 parallel environments with 5 random seeds. We trained TAC on games of Jericho suite with 100k steps and evaluated with 10 episodes per every 500 training step. During the training, TAC uses uniformly sampled admissible action for a probability of \u03f5 and during the testing, it follows its policy distribution generated from the game observations. We used prioritized experience replay (PER) as our replay buffer (Schaul et al., 2016). We first fine-tune TAC on ZORK1, then apply the same hyper-parameters for all the games. The details of our hyper-parameters can be found in Appendix A. Our final score is computed as the average of 30 episodic testing game scores. Additionally, our model has a parameter size of less than 2M, allowing us to run the majority of our experiments on CPU (Intel Xeon Gold 6150 2.70 GHz).",
                    "The full parameter size in ZORK1 and the training time comparison can be found in Appendices B and C.  CALM-DRRN and KG-A2C fails to achieve any game score (approximately 0), but TAC achieves the score of +3.4, +25.4 and +2.81 For detailed game scores and the full learning curves on 29 games, please refer to Appendix G. There are a few games that TAC under-performs. We speculate three reasons for this: over-fitting, exploration, and catastrophic forgetting. For instance, as illustrated by the learning curves of TAC in Figure 2, LUDICORP appears to acquire more reward signals during training, but fails to achieve them during testing. We believe this is because the agent is over-fitted to spurious features in specific observations (Song et al., 2020), producing inadmissible actions for a given state that are admissible in other states. On the other hand, TAC in OMNIQUEST cannot achieve a game score more than 5 in both training and testing. This is due to the lack of exploration, where the agent is stuck at certain states because the game score is too far to reach. This, in fact, occurs in ZORK3 and ZTUU for some random seeds, where few seeds in ZORK3 do not achieve any game score while ZTUU achieves 10 or 13 only, resulting in high variance. Finally, catastrophic forgetting (Kirkpatrick et al., 2016) is a common phenomenon in TGs (Hausknecht et al., 2020;Ammanabrolu and Hausknecht, 2020), and this is also observed in JEWEL with TAC. Training Score vs. Testing Score. Figure 2 shows that the game scores during training and testing in many games are different. There are three inter-pretations for this: (i) the \u03f5-admissible exploration triggers negative rewards since it is uniformly sampling admissible actions. It is often the case that negative reward signal triggers termination of the game, i.e. \u221210 score in ZORK1, so this results in episodic score during training below testing. (ii) the \u03f5-admissible exploration sends the agent to the rarely or never visited state, which is commonly seen in ZTUU. This induces the agent taking useless actions that would not result in rewards since it does not know what to do. (iii) Over-fitting where testing score is lower than training score. This occurs in LUDICORP, where the agent cannot escape certain states with its policy during testing. \u03f5-admissible exploration lets the agent escape from these state during training, and therefore, achieves higher game score."
                ],
                "publication_ref": [
                    "b25",
                    "b24",
                    "b17",
                    "b19",
                    "b20",
                    "b13"
                ],
                "figure_ref": [
                    "fig_1",
                    "fig_1"
                ],
                "table_ref": []
            },
            {
                "heading": "Main Results",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Ablation",
                "text": [
                    "\u03f5-Admissible Exploration. To understand how \u03f5 influences the agent, ablations with two \u03f5 values, 0.0 and 1.0, on five selective games were conducted. As shown in Figure 3, in the case of \u03f5 = 0.0, the agent simply cannot acquire reward signals. TAC achieves 0 game score in RE-VERB, ZORK1 and ZORK3 while it struggles to learn in DETECTIVE and PENTARI. This indicates that the absence of \u03f5-admissible exploration results in meaningless explorations until admissible actions are reasonably learned through supervised signals. With \u03f5 = 1.0, learning becomes unstable since this is equivalent to no exploitation during training, not capable of observing reward signals that are far from the initial state. Hence, tuned \u03f5 is important to allow the agent to cover wider range of states (exploration) while acting from its experiences (exploitation).",
                    "Supervised Signals. According to the Figure 3, removing SL negatively affects the game score. This is consistent with the earlier observations (Ammanabrolu and Hausknecht, 2020) reporting that KG-A2C without SL achieves no game score in ZORK1. However, as we can observe, TAC manages to retain some game score, which could be reflective of the positive role of \u03f5-admissible exploration, inducing similar behaviour to SL.",
                    "From the observation that the absence of SL degrades the performance, we hypothesize that SL induces a regularization effect. We ran experiments with various strengths of supervised signals by increasing \u03bb T and \u03bb O in LUDICORP and TEMPLE, in which TAC attains higher scores at training compared with testing. As seen in Figure 4 (left two plots), higher \u03bb T and \u03bb O relaxes over-fitting, reaching the score from 7.7 to 15.8 in LUDICORP and from 5.8 to 8.0 in TEMPLE. Since SL is not directly related to rewards, this supports that SL acts as regularization. Further experimental results on ZORK1 is in Appendix H.",
                    "To further examine the role of admissible actions in SL, we hypothesize that SL is responsible for guiding the agent in the case that the reward signal is not collected. To verify this, we excluded \u03f5-admissible exploration and ran TAC with different \u03bb T and \u03bb O in REVERB and ZORK1, in which TAC fails to achieve any score. According to Figure 4 (right two plots), TAC with stronger SL and \u03f5 = 0.0 achieves game scores from 0 to 8.3 in REVERB, and from 0 to 18.3 in ZORK1, which suggests that SL acts as guidance. However, in the absence of \u03f5-admissible exploration, despite the stronger supervised signals, TAC cannot match the scores using \u03f5-admissible exploration.",
                    "Admissible Action Space During Training. To examine if constraining the action space to admissible actions during training leads to better utilization, we ran an ablation by masking template and object with admissible actions at training time. This leads to only generating admissible actions. Our plots in Figure 3 show that there is a reduction in the game score in PENTARI, REVERB and ZORK1 while DETECTIVE and ZORK3 observe slight to  substantial increases, respectively. We speculate that the performance decay is due to the exposure bias (Bengio et al., 2015) introduced from fully constraining the action space to admissible actions during training. This means the agent does not learn how to act when it receives observations from inadmissible actions at test phase. However, for games like ZORK3, where the agent must navigate through the game to acquire sparse rewards, this technique seems to help."
                ],
                "publication_ref": [
                    "b4"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Qualitative Analysis",
                "text": [
                    "In this section, we show how CALM and KG-A2C restrict their action space. Table 2 shows a snippet of the gameplay in ZORK1. Top three rows are the textual observations and the bottom three rows are the actions generated by CALM, the objects extracted from KG in KG-A2C, and the admissible actions from the environment. CALM produces 30 different actions, but still misses 10 actions out of 17 admissible actions. Since DRRN learns to estimate Q value over generated 30 actions, those missing admissible actions can never be selected, resulting in a lack of exploration. On the other hand, KG-generated objects do not include 'sack' and 'painting', which means that the KG-A2C masks these two objects out from their object space. Then, the agent neglects any action that includes these two object, which also results in a lack of exploration."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_5"
                ]
            },
            {
                "heading": "Discussion",
                "text": [
                    "Supervised Learning Loss. Intuitively, RL is to teach the agent how to complete the game while SL is to teach how to play the game. If the agent never acquired any reward signal, learning is only guided by SL. This is equivalent to applying imitation learning to the agent to follow more probable actions, a.k.a. admissible actions in TGs. However, in the case where the agent has reward signals to learn from, SL turns into regularization ( \u00a75.2), inducing a more uniformly distributed policies. In this sense, SL could be considered as the means to introduce the effects similar to entropy regularization in Ammanabrolu and Hausknecht (2020).",
                    "Exploration as Data Collection. In RL, the algorithm naturally collects and learns from data. Admissible action prediction from LM is yet to be accurate enough to replace the true admissible actions (Ammanabrolu and Riedl, 2021;Yao et al., 2020). This results in poor exploration and the agent may potentially never reach a particular state. On the other hand, KG-based methods (Ammanabrolu and Hausknecht, 2020;Peng et al., 2021;Xu et al., 2020Xu et al., , 2021Xu et al., , 2022;;Ryu et al., 2022) must learn admissible actions before exploring the environment meaningfully. This will waste many samples since the agent will attempt inadmissible actions, collecting experiences of the unchanged states. Additionally, its action selection is largely dependent on the quality of KG. The missing objects from KG may provoke the same effects as LM, potentially obstructing navigating to a particular state. In this regards, \u03f5-admissible exploration can overcome the issue by promoting behaviour that the agent would take after learning admissible actions fully. Under such conditions that a compact list of actions is either provided the environment or extracted by algorithm (Hausknecht et al., 2020), our approach can be employed. Intuitively, this is similar to playing the game with a game manual but not a ground truth to complete the game, which leads to collecting more meaningful data. It also collects more diverse data due to the stochasticity of exploration. Hence, TAC with \u03f5-admissible exploration can learn how to complete the game with minimal knowledge of how to play the game.",
                    "Bias in Exploration. Our empirical results from adaptive \u03f5 experiments in Appendix I suggest that reasonable \u03f5 is required for both under-explored states and well-explored states. This could indicate that diverse data collection is necessary regardless of how much the agent knows about the game while \u03f5 value should not be too high such that the agent can exploit. Finally, from our ablation, fully constraining action space to admissible actions degrades performance. This could be a sign of exposure bias, which is a typical issue in NLG tasks (He et al., 2019;Mandya et al., 2020) and occurs between the training-testing discrepancy due to the teacher-forcing done at training (He et al., 2019). In our setting, this phenomena could potentially occur if the agent only learns from admissible actions at training time. Since \u03f5-admissible exploration allows a collection of experiences of any actions (i.e., potentially inadmissible actions) with probability of 1 \u2212 \u03f5, TAC with reasonable \u03f5 learns from high quality and unbiased data. Our observations indicate that both the algorithm that learns from data, and the exploration to acquire data are equally important."
                ],
                "publication_ref": [
                    "b25",
                    "b17",
                    "b24",
                    "b22",
                    "b23",
                    "b11",
                    "b15",
                    "b11"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Conclusion",
                "text": [
                    "Text-based Games (TGs) offer a unique framework for developing RL agents for goal-driven and contextually-aware natural language generation tasks. In this paper we took a fresh approach in utilizing the information from the TG environment, and in particular the admissibility of actions during the exploration phase of RL agent. We introduced a language-based actor critic method (TAC) with a simple \u03f5-admissible exploration. The core of our algorithm is the utilization of admissible actions in training phase to guide the agent exploration towards collecting more informed experiences. Compared to state-of-the-art approaches with more complex design, our light TAC design achieves substantially higher game scores across 10-29 games.",
                    "We provided insights into the role of action admissibility and supervision signals during training and the implications at test phase for an RL agent. Our analysis showed that supervised signals towards admissible actions act as guideline in the absence of reward signal, while serving a regularization role in the presence of such signal. We demonstrated that reasonable \u03f5 probability threshold is required for high quality unbiased experience collection during the exploration phase."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Appendices",
                "text": [
                    "In this section, we provide the details of TAC, training, and full experimental results. We also provide Limitations and Ethical Considerations."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A Hyperparameters",
                "text": [
                    "Table 3 shows the hyper-parameters used for our experiments. For 905, ADVENT, ANCHOR, AWAKEN, DEEPHOME, INHUMANE and MOONLIT, gradients exploding has been observed with the hyperparameters in Table 3, so we reduced learning rate to 10 \u22125 for these games.  "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_7",
                    "tab_7"
                ]
            },
            {
                "heading": "B Parameter Size for ZORK1",
                "text": [
                    "The total parameter size of TAC in ZORK1 is 1,783,849 with 49,665 target state critic, which slightly varies by the size of template and object space per game. This is much lower than KG-A2C (4,812,741), but little higher than DRRN (1,486,081). 5"
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "C Training Time",
                "text": [
                    "We used Intel Xeon Gold 6150 2.70 GHz for CPU and Tesla V100-PCIE-16GB for GPU, 8 CPUs with 25GB memory, to train KG-A2C and TAC on ZORK1. The results are demonstrated in Table 5. 6 Our TAC has approximately three times lesser parameters than KG-A2C in ZORK1, which 5 The code for KG-A2C is in https://github.com/ rajammanabrolu/KG-A2C, and DRRN is in https:// github.com/microsoft/tdqn. 6 The code for KG-A2C is in https://github.com/ rajammanabrolu/KG-A2C. would be consistent across different games. On the other hand, for step per second, TAC is twice faster in GPU and thrice faster in CPU than KG-A2C. Approximated days for training TAC on CPU and GPU are 1.2 and 0.8 days while KG-A2C is 4.1 and 1.6 days. TAC still benefits from GPU, but not as much as KG-A2C as its training time is more dependent to the game engine than backpropagation.",
                    "Step/second (CPU)",
                    "Step/second (GPU) Parameter Size KG-A2C 0.28 0.71 4.8M TAC 0.99 1.43 1.8M  "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "D Details of Actor and Critic Components",
                "text": [
                    "Consider an action example (take OBJ from OBJ, egg, fridge) as (template, first object, second object). Template a T = (take OBJ from OBJ) is sampled from template decoder and encoded to h T with text encoder. Object decoder takes action representation a and encoded semi-completed action h T and produces the first object a O1 = (egg). The template a T = (take OBJ from OBJ) and the first object a O1 = (egg) are combined to a T,O1 = (take egg from OBJ), a T \u2297 a O1 = a T,O1 . a T,O1 is then, encoded to hidden state h T,O1 with text encoder. Similarly, the object decoder takes a and h T,O1 and produces the second object a O2 = (fridge). a T,O1 and a O2 are combined to be natural language action, a T,O1 \u2297 a O2 = a N Finally, a N is encoded to h a with text encoder and inputted to state-action critic to predict Q value.",
                    "E Comparison with Vanilla A2C in Ammanabrolu and Hausknecht (2020) Architecture. Vanilla A2C from Ammanabrolu and Hausknecht (2020) uses separate gated recurrent units (GRUs) to encode textual observations and previous action, (o game , o look , o inv , a t\u22121 ), and transforms the game score, n score , into binary encoding. Then, they are concatenated and passed through state network to form state representation. Their state network is GRU-based to account historical information. The actor-critic network consists of actor and state value critic, so the state representation is used to estimate state value and produce the policy distribution.",
                    "Our TAC uses a single shared GRU to encode textual observations and previous action with different initial state to signify that the text encoder con-structs the general representation of text while the game score is embedded to learnable high dimentional vector. However, when constructing state representation, we only used (o game , o look , o inv ) under our observation that o game carries semantic information about a t\u22121 . Additionally, we also observed that the learned game score representation acts as conditional vector in Appendix F, so the state representation is constructed as an instance of observation without historical information. Finally, we included additional modules, state-action value critic (Haarnoja et al., 2018), target state critic (Mnih et al., 2015) and two state-action critics (Fujimoto et al., 2018;Haarnoja et al., 2018) for practical purpose.",
                    "Objective Function. Three objectives are employed in Ammanabrolu and Hausknecht (2020), reinforcement learning (RL), supervised learning (SL) and entropy regularization. Both RL and SL are also used in our objectives with minor changes in value function update in RL. That is, two stateaction value critics are updated independently to predict Q value per state-action pair and target state critic is updated as moving average of state critic Notable difference is that we excluded entropy regularization from Ammanabrolu and Hausknecht (2020). This is because under our ablation in Section 5.2, we observed that SL acts as regularization.",
                    "Replay Buffer Unlike on-policy vanilla A2C (Ammanabrolu and Hausknecht, 2020), since TAC utilizes \u03f5-admissible exploration, it naturally sits as off-policy algorithm. We used prioritized experience replay (PER) as our replay buffer (Schaul et al., 2016). Standard PER assigns a newly acquired experience with the maximum priority. This enforces the agent to prioritize not-yet-sampled ex-Case 1.1",
                    "Step: 4 Game: Kitchen You are in the kitchen of the white house. A table seems to have been used recently for the preparation of food. A passage leads to the west and a dark staircase can be seen leading upward. A dark chimney leads down and to the east is a small window which is open. On the table is an elongated brown sack, smelling of hot peppers. A bottle is sitting on the table. The glass bottle contains: A quantity of water Look: Kitchen You are in the kitchen of the white house. A table seems to have been used recently for the preparation of food. A passage leads to the west and a dark staircase can be seen leading upward. A dark chimney leads down and to the east is a small window which is open. On the   periences over others. As we are using 32 parallel environments and 64 batch size for update, half of the updates will be directed by newly acquired experiences, which not all of them may be useful. Thus, instead, we assign newly acquired experience with TD errors when they are added to the buffer. This risks the agent not using some experiences, but it is more efficient since we sample useful batch of experiences."
                ],
                "publication_ref": [
                    "b9",
                    "b16",
                    "b8",
                    "b9",
                    "b19"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "F Qualitative Analysis",
                "text": [
                    "It has been repetitively reported that including game score when constructing state helps in TGs (Ammanabrolu and Hausknecht, 2020;Jang et al., 2021). Here, we provide some insights in what the agent learns from the observations using fully trained TAC. To illustrate this, we highlight the role of game score on the action preference of the TAC for the same observation in ZORK1. Observations for different cases can be found in Table 6 and Ta-ble 8 while the policy and Q value are in Table 7 and Table 9.",
                    "Case 1 in Table 6 and   "
                ],
                "publication_ref": [
                    "b12"
                ],
                "figure_ref": [],
                "table_ref": [
                    "tab_11",
                    "tab_12",
                    "tab_15",
                    "tab_11"
                ]
            },
            {
                "heading": "G Full Experimental Results",
                "text": [
                    "The full learning curve of TAC and game score comparison are presented in Figure 6 and Table 10."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_4"
                ],
                "table_ref": [
                    "tab_17"
                ]
            },
            {
                "heading": "H Stronger Supervised Signals for ZORK1",
                "text": [
                    "We also explored how stronger supervised signals can induce better regularization in ZORK1. Similar to other sets of experiments, we selected variety of    \u03bb T -\u03bb O pair. However, our results show that TAC starts under-fitting in ZORK1 when larger \u03bb T and \u03bb O are applied."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "I Adaptive Score-based \u03f5",
                "text": [
                    "We also designed the epsilon scheduler that dynamically assigns \u03f5 based on the game score that the agent has achieved; \u03f5 \u221d e a\u03f5 n tst nscore , where a \u03f5 is the hyper-parameters and n tst is the average testing game score. During training, higher n score exponentially increases \u03f5 while a \u03f5 controls the slope of the exponential function. Higher a \u03f5 makes the slope more steep. Intuitively, as the agent exploits the well-known states, \u03f5 is small, encouraging the agent to follow its own policy, and as the agent reaches the under-explored states (i.e., similar to test condition), \u03f5 increases to encourage more diversely. The \u03f5 is normalized and scaled. The example plot is shown in FIgure 10.",
                    "We conducted a set of ablations with dynamic \u03f5 value in DETECTIVE, PENTARI, REVERB, ZORK1 and ZORK3. We used \u03f5 min = {0.0, 0.3}, a \u03f5 = {3, 9} and \u03f5 max = {0.7, 1.0}, so total 8 different hyper-parameters. Figure 8 shows fixed \u03f5 min = 0.0 with varying a \u03f5 and \u03f5 max and Figure 8 shows fixed \u03f5 min = 0.3. Other than ZORK3, TAC with dynamic \u03f5 matches or underperforms TAC with fixed \u03f5 = 0.3. There are two interesting phenomenons. (i) Too high \u03f5 max results in more unstable learning and lower performance. This becomes very obvious in PENTARI, REVERB and ZORK1, where regardless of \u03f5 min and a \u03f5 , if \u03f5 max = 1.0, the learning curve is relatively low. In DETECTIVE of Figure 8, the learning becomes much more unstable with \u03f5 max = 1.0. This indicates that even underexplored states, exploitation may still be required.",
                    "(ii) Too low \u03f5 min results in more unstable learning and lower performance. Although PENTARI benefits from \u03f5 min = 0.0, the learning curves in Figure 8 is generally lower and unstable than Figure 9. This appears to be that despite how much the agent learned the environment, it still needs to act stochastically to collect diverse experiences."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "J Limitations",
                "text": [
                    "Similar to CALM-DRRN (Yao et al., 2020), KG-A2C (Ammanabrolu and Hausknecht, 2020) and KG-A2C variants (Ammanabrolu et al., 2020;Xu et al., 2020;Peng et al., 2021) that use admissible actions, our method still utilizes admissible actions. This makes our TAC not suitable for environments that do not provide admissible action set. In the absence of admissible actions, our TAC requires some prior knowledge of a compact set of more probable actions from LMs or other sources. This applies to other problems, for instance, applying our proposed method to language-grounded robots requires action candidates appropriate per state that they must be able to sample during training. The algorithm proposed by Hausknecht et al. (2020) extracts admissible actions by simulating thousands of actions per every step in TGs. This can be used to extract a compact set of actions in other problems, but it would not be feasible to apply if running a simulation is computationally expensive or risky (incorrect action in real-world robot may result in catastrophic outcomes, such as breakdown)."
                ],
                "publication_ref": [
                    "b25",
                    "b24",
                    "b17"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "K Ethical Considerations",
                "text": [
                    "Our proposal may impact other language-based autonomous agents, such as dialogue systems or language-grounded robots. In a broader aspect, it contributes to the automated decision making, which can be used in corporation and government. When designing such system, it is important to bring morals and remove bias to be used as intended."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            }
        ],
        "references": [
            {
                "ref_id": "b0",
                "title": "Graph constrained reinforcement learning for natural language action spaces",
                "journal": "",
                "year": "2020-04-26",
                "authors": "Prithviraj Ammanabrolu; Matthew J Hausknecht"
            },
            {
                "ref_id": "b1",
                "title": "Modeling worlds in text",
                "journal": "",
                "year": "2021",
                "authors": "Prithviraj Ammanabrolu; Mark Riedl"
            },
            {
                "ref_id": "b2",
                "title": "How to avoid being eaten by a grue: Exploration strategies for text-adventure agents",
                "journal": "",
                "year": "2002",
                "authors": "Prithviraj Ammanabrolu; Ethan Tien; Zhaochen Luo; Mark O Riedl"
            },
            {
                "ref_id": "b3",
                "title": "Leveraging linguistic structure for open domain information extraction",
                "journal": "Long Papers",
                "year": "2015",
                "authors": "Gabor Angeli; Melvin Jose Johnson Premkumar; Christopher D Manning"
            },
            {
                "ref_id": "b4",
                "title": "Scheduled sampling for sequence prediction with recurrent neural networks",
                "journal": "MIT Press",
                "year": "2015",
                "authors": "Samy Bengio; Oriol Vinyals; Navdeep Jaitly; Noam Shazeer"
            },
            {
                "ref_id": "b5",
                "title": "COMET: commonsense transformers for automatic knowledge graph construction",
                "journal": "Long Papers",
                "year": "2019-07-28",
                "authors": "Antoine Bosselut; Hannah Rashkin; Maarten Sap; Chaitanya Malaviya; Asli Celikyilmaz; Yejin Choi"
            },
            {
                "ref_id": "b6",
                "title": "Textworld: A learning environment for textbased games",
                "journal": "",
                "year": "2018",
                "authors": "\u00c1kos Marc-Alexandre C\u00f4t\u00e9;  K\u00e1d\u00e1r; ( Xingdi; ) Eric; Ben Yuan; Tavian Kybartas; Emery Barnes; James Fine; Matthew Moore; Layla El Hausknecht; Mahmoud Asri; Wendy Adada; Adam Tay;  Trischler"
            },
            {
                "ref_id": "b7",
                "title": "Learning how to active learn: A deep reinforcement learning approach",
                "journal": "Association for Computational Linguistics",
                "year": "2017",
                "authors": "Meng Fang; Yuan Li; Trevor Cohn"
            },
            {
                "ref_id": "b8",
                "title": "Addressing function approximation error in actor-critic methods",
                "journal": "PMLR",
                "year": "2018",
                "authors": "Scott Fujimoto; David Herke Van Hoof;  Meger"
            },
            {
                "ref_id": "b9",
                "title": "Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor",
                "journal": "PMLR",
                "year": "2018-07-10",
                "authors": "Tuomas Haarnoja; Aurick Zhou; Pieter Abbeel; Sergey Levine"
            },
            {
                "ref_id": "b10",
                "title": "Interactive fiction games: A colossal adventure",
                "journal": "AAAI Press",
                "year": "2020-02-07",
                "authors": "Matthew J Hausknecht; Prithviraj Ammanabrolu; Marc-Alexandre C\u00f4t\u00e9; Xingdi Yuan"
            },
            {
                "ref_id": "b11",
                "title": "Quantifying exposure bias for neural language generation. CoRR, abs",
                "journal": "",
                "year": "1905",
                "authors": "Tianxing He; Jingzhao Zhang; Zhiming Zhou; James R Glass"
            },
            {
                "ref_id": "b12",
                "title": "Monte-carlo planning and learning with language action value estimates",
                "journal": "",
                "year": "2021",
                "authors": "Youngsoo Jang; Seokin Seo; Jongmin Lee; Kee-Eung Kim"
            },
            {
                "ref_id": "b13",
                "title": "Agnieszka Grabska-Barwinska, Demis Hassabis, Claudia Clopath, Dharshan Kumaran, and Raia Hadsell",
                "journal": "CoRR",
                "year": "2016",
                "authors": "James Kirkpatrick; Razvan Pascanu; Neil C Rabinowitz; Joel Veness; Guillaume Desjardins; Andrei A Rusu; Kieran Milan; John Quan; Tiago Ramalho"
            },
            {
                "ref_id": "b14",
                "title": "ALBERT: A lite BERT for self-supervised learning of language representations",
                "journal": "",
                "year": "2020-04-26",
                "authors": "Zhenzhong Lan; Mingda Chen; Sebastian Goodman; Kevin Gimpel; Piyush Sharma; Radu Soricut"
            },
            {
                "ref_id": "b15",
                "title": "Do not let the history haunt you: Mitigating compounding errors in conversational question answering",
                "journal": "",
                "year": "2020",
                "authors": "Angrosh Mandya; O' James; Danushka Neill; Frans Bollegala;  Coenen"
            },
            {
                "ref_id": "b16",
                "title": "Dharshan Kumaran, Daan Wierstra, Shane Legg, and Demis Hassabis",
                "journal": "Charles Beattie",
                "year": "2015",
                "authors": "Volodymyr Mnih; Koray Kavukcuoglu; David Silver; Andrei A Rusu; Joel Veness; Marc G Bellemare; Alex Graves; Martin A Riedmiller; Andreas Fidjeland; Georg Ostrovski; Stig Petersen"
            },
            {
                "ref_id": "b17",
                "title": "Inherently explainable reinforcement learning in natural language",
                "journal": "",
                "year": "2021",
                "authors": "Xiangyu Peng; Mark O Riedl; Prithviraj Ammanabrolu"
            },
            {
                "ref_id": "b18",
                "title": "Shirui Pan, and Reza Haf. 2022. Fire burns, sword cuts: Commonsense inductive bias for exploration in text-based games",
                "journal": "Association for Computational Linguistics",
                "year": "",
                "authors": "Dongwon Ryu; Ehsan Shareghi; Meng Fang; Yunqiu Xu"
            },
            {
                "ref_id": "b19",
                "title": "Prioritized experience replay",
                "journal": "",
                "year": "2016",
                "authors": "Tom Schaul; John Quan; Ioannis Antonoglou; David Silver"
            },
            {
                "ref_id": "b20",
                "title": "Observational overfitting in reinforcement learning",
                "journal": "",
                "year": "2020",
                "authors": "Xingyou Song; Yiding Jiang; Stephen Tu; Yilun Du; Behnam Neyshabur"
            },
            {
                "ref_id": "b21",
                "title": "Multi-stage episodic control for strategic exploration in text games",
                "journal": "",
                "year": "2022",
                "authors": "Jens Tuyls; Shunyu Yao; M Sham;  Kakade;  Karthik R Narasimhan"
            },
            {
                "ref_id": "b22",
                "title": "Generalization in text-based games via hierarchical reinforcement learning",
                "journal": "",
                "year": "2021",
                "authors": "Yunqiu Xu; Meng Fang; Ling Chen; Yali Du; Chengqi Zhang"
            },
            {
                "ref_id": "b23",
                "title": "Perceiving the world: Question-guided reinforcement learning for text-based games",
                "journal": "Long Papers",
                "year": "2022",
                "authors": "Yunqiu Xu; Meng Fang; Ling Chen; Yali Du; Joey Zhou; Chengqi Zhang"
            },
            {
                "ref_id": "b24",
                "title": "Deep reinforcement learning with stacked hierarchical attention for text-based games",
                "journal": "",
                "year": "2020-12-06",
                "authors": "Yunqiu Xu; Meng Fang; Ling Chen; Yali Du; Joey Tianyi Zhou; Chengqi Zhang"
            },
            {
                "ref_id": "b25",
                "title": "Keep CALM and explore: Language models for action generation in textbased games",
                "journal": "Online. Association for Computational Linguistics",
                "year": "2020",
                "authors": "Shunyu Yao; Rohan Rao; Matthew Hausknecht; Karthik Narasimhan"
            },
            {
                "ref_id": "b26",
                "title": "In one corner of the house there is a small window which is slightly ajar. Look: Behind House You are behind the white house. A path leads into the forest to the east. In one corner of the house there is a small window which is slightly ajar. Inv: You are empty handed. Score: 0 Action: open window Case 2.2 Step: 3 Game: With great effort, you open the window far enough to allow entry. Look: Behind House You are behind the white house. A path leads into the forest to the east",
                "journal": "north",
                "year": "",
                "authors": ""
            }
        ],
        "figures": [
            {
                "figure_label": "2",
                "figure_type": "figure",
                "figure_id": "fig_1",
                "figure_caption": "Figure 2 :2Figure 2: The full learning curve of TAC on five games in Jericho suite. Blue and red plots are training and testing game score while cyan and yellow star marker line signify CALM-DRRN and KG-A2C.",
                "figure_data": ""
            },
            {
                "figure_label": "34",
                "figure_type": "figure",
                "figure_id": "fig_2",
                "figure_caption": "Figure 3 :Figure 4 :34Figure 3: Ablation study on five popular games in Jericho suite. Four different ablation are conducted with SL, \u03f5 = 0.0, \u03f5 = 1.0, and with full admissible constraints during training (Admissible Action space). Similar to the previous figure, CALM-DRRN and KG-A2C are added for comparison.",
                "figure_data": ""
            },
            {
                "figure_label": "5",
                "figure_type": "figure",
                "figure_id": "fig_3",
                "figure_caption": "Figure 5 :5Figure 5: The details of actor and critic of text-based actor-critic; State representation is the input to actor-critic while a red circle is the output from actor, a N representing natural language action. Red and green boxes indicate actor and critic, respectively.",
                "figure_data": ""
            },
            {
                "figure_label": "6",
                "figure_type": "figure",
                "figure_id": "fig_4",
                "figure_caption": "Figure 6 :6Figure 6: The full learning curve for TAC, compared with TDQN and KG-A2C",
                "figure_data": ""
            },
            {
                "figure_label": "7",
                "figure_type": "figure",
                "figure_id": "fig_5",
                "figure_caption": "Figure 7 :7Figure 7: The learning curve of TAC for regularization ablation in ZORK1. Stronger supervised signals are used with \u03f5 = 0.3, where 5-3 signifies \u03b3 T = 5 and \u03b3 O = 3.",
                "figure_data": ""
            },
            {
                "figure_label": "8910",
                "figure_type": "figure",
                "figure_id": "fig_6",
                "figure_caption": "Figure 8 :Figure 9 :Figure 10 :8910Figure 8: The learning curve of TAC with dynamic epsilon on five popular games. All the experiments were done with fixed \u03f5 min = 0.0, a \u03f5 = {3, 9} and \u03f5 max = {0.7, 1.0}.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "table",
                "figure_id": "tab_0",
                "figure_caption": "A, P, O, P o , R, \u03b3), where S and A are a set of state and action, and P is the state transition probability that maps state-action pair to the next state, Pr(s t+1 |s t , a t ). O is a set of observation that depends on the current state via an emission probability, P o \u2261 Pr(o t |s t ). R is an immediate reward signal held between the state and the next state, r(s t , s t+1 ), and \u03b3 is the discount factor. The action selection rule is referred to as the policy \u03c0(a|o), in which the optimal policy acquires the maximum rewards in the shortest move. TG Environment as POMDP.Three textual observations are acquired from the engine, game feedback o game , room description o look , and inventory description o inv . The game feedback is dependent on the previous action, Pr(o game,t |s",
                "figure_data": ""
            },
            {
                "figure_label": "1",
                "figure_type": "table",
                "figure_id": "tab_2",
                "figure_caption": "3.2 Game score comparison over 10 popular game environments in Jericho, with best results highlighted by boldface. We only included algorithms that reported the end performance. \u2020 HEX-RL and HEX-RL-IM did not report the performance in ZORK3 and are not open-sourced, so the mean average did not account ZORK3.",
                "figure_data": "DETECTIVE289.7207.9246.1274.0276.7276.9272.3 \u00b1 23.3LIBRARY9.014.310.018.015.913.818.0 \u00b1 1.2LUDICORP10.117.817.618.014.017.67.7 \u00b1 2.5PENTARI0.050.748.250.034.644.753.2 \u00b1 2.9TEMPLE0.07.67.98.08.08.05.8 \u00b1 2.3ZORK130.434.033.635.029.830.246.3 \u00b1 5.0ZORK30.50.10.70.1\u2212\u22121.6 \u00b1 1.2ZTUU3.75.05.05.05.05.133.2 \u00b1 26.3NORMALIZED MEAN0.15490.24750.24900.27880.2722  \u20200.2834  \u20200.3307"
            },
            {
                "figure_label": "1",
                "figure_type": "table",
                "figure_id": "tab_3",
                "figure_caption": "50% higher score than both CALM-DRRN and KG-A2C with normalized mean score. Per game, in SORCERER, SPIRIT, ZORK3 and ZTUU, TAC achieves at least \u223c 200% and at most \u223c 400% higher score.. In ACORNCOURT, DEEPHOME and DRAGON, both",
                "figure_data": "PENTARI,"
            },
            {
                "figure_label": "",
                "figure_type": "table",
                "figure_id": "tab_4",
                "figure_caption": "GameKitchen. On the table is an elongated brown sack, smelling of hot peppers. A bottle is sitting on thetable. The glass bottle contains: A quantity of water. Inventory You are carrying: A painting, A brass lantern (providing light) Room Kitchen. You are in the kitchen of the white house. A table seems to have been used recently for the preparation of food. A passage leads to the west and a dark staircase can be seen leading upward. A dark chimney leads down and to the east is a small window which is open. On the table is an elongated brown sack, smelling of hot peppers. A bottle is sitting on the table. 'all', 'antique', 'board', 'bottle', 'brass', 'chimney', 'dark', 'door', 'down', 'east', 'exit', 'front', 'grue', 'house', 'is', 'kitchen', 'lantern', 'large', 'light', 'narrow', 'north', 'of', 'passage', 'path', 'quantity', 'rug', 'south', 'staircase', 'table', 'to', 'trap', 'trophy', 'up', 'west', 'white', 'window', 'with' Admiss. Actions 'close window', 'east', 'jump', 'open bottle', 'open sack', 'put down all', 'put down light', 'put down painting', 'put light on table', 'put out light', 'put painting on table', 'take all', 'take bottle', 'take sack', 'throw light at window', 'up', 'west'",
                "figure_data": "The glass bottlecontains: A quantity of waterLM'close bottle', 'close door', 'down', 'drink water', 'drop bottle',Actions'drop painting', 'east', 'empty bottle', 'get all', 'get bottle', 'geton table', 'get painting', 'get sack', 'north', 'open bottle', 'out','pour water on sack', 'put candle in sack', 'put painting in sack','put painting on sack', 'put water in sack', 'south', 'take all','take bottle', 'take painting', 'take sack', 'throw painting', 'up','wait', 'west'KG'a',Objects"
            },
            {
                "figure_label": "2",
                "figure_type": "table",
                "figure_id": "tab_5",
                "figure_caption": "Action space for a game observation (top panel) for CALM (LM), KG-A2C (KG), and the Admissible Action sets. Red and blue colored actions are the actions missed by either CALM or KG-A2C. Brown are the actions missed by both, and blacks are actions covered by both.",
                "figure_data": ""
            },
            {
                "figure_label": "3",
                "figure_type": "table",
                "figure_id": "tab_7",
                "figure_caption": "Hyper-parameters for main experiments.",
                "figure_data": ""
            },
            {
                "figure_label": "4",
                "figure_type": "table",
                "figure_id": "tab_8",
                "figure_caption": "Parameter size for ZORK1.",
                "figure_data": "NameSizetext_encoder_network.embedding.weight[8000,100]text_encoder_network.embedding_sa.weight[4,128]text_encoder_network.encoder.weight_ih_l0[384,100]text_encoder_network.encoder.weight_hh_l0[384,128]text_encoder_network.encoder.bias_ih_l0[384]text_encoder_network.encoder.bias_hh_l0[384]state_network.embedding_score.weight[1024,128]state_network.tf.weight[128,384]state_network.tf.bias[128]state_network.fc1.weight[128,128]state_network.fc1.bias[128]state_network.fc2.weight[128,128]state_network.fc2.bias[128]state_network.fc3.weight[128,128]state_network.fc3.bias[128]state_network.s.weight[128,128]state_network.s.bias[128]state_critic.fc1.weight[128,128]state_critic.fc1.bias[128]state_critic.fc2.weight[128,128]state_critic.fc2.bias[128]state_critic.fc3.weight[128,128]state_critic.fc3.bias[128]state_critic.v.weight[1,128]state_critic.v.bias[1]actor_network.fc1.weight[128,128]actor_network.fc1.bias[128]actor_network.fc2.weight[128,128]actor_network.fc2.bias[128]actor_network.fc3.weight[128,128]actor_network.fc3.bias[128]actor_network.a.weight[128,128]actor_network.a.bias[128]state_action_critic_1.fc1.weight[128,256]state_action_critic_1.fc1.bias[128]state_action_critic_1.fc2.weight[128,128]state_action_critic_1.fc2.bias[128]state_action_critic_1.fc3.weight[128,128]state_action_critic_1.fc3.bias[128]state_action_critic_1.q.weight[1,128]state_action_critic_1.q.bias[1]state_action_critic_2.fc1.weight[128,256]state_action_critic_2.fc1.bias[128]state_action_critic_2.fc2.weight[128,128]state_action_critic_2.fc2.bias[128]state_action_critic_2.fc3.weight[128,128]state_action_critic_2.fc3.bias[128]state_action_critic_2.q.weight[1,128]state_action_critic_2.q.bias[1]target_state_critic.fc1.weight[128,128]target_state_critic.fc1.bias[128]target_state_critic.fc2.weight[128,128]target_state_critic.fc2.bias[128]target_state_critic.fc3.weight[128,128]target_state_critic.fc3.bias[128]target_state_critic.v.weight[1,128]target_state_critic.v.bias[1]template_decoder_network.tmpl_gru.weight_ih_l0[384,128]template_decoder_network.tmpl_gru.weight_hh_l0[384,128]template_decoder_network.tmpl_gru.bias_ih_l0[384]template_decoder_network.tmpl_gru.bias_hh_l0[384]template_decoder_network.fc2.weight[128,128]template_decoder_network.fc2.bias[128]template_decoder_network.tmpl.weight[235,128]template_decoder_network.tmpl.bias[235]object_decoder_network.obj_gru.weight_ih_l0[384,256]object_decoder_network.obj_gru.weight_hh_l0[384,128]object_decoder_network.obj_gru.bias_ih_l0[384]object_decoder_network.obj_gru.bias_hh_l0[384]object_decoder_network.fc2.weight[128,128]object_decoder_network.fc2.bias[128]object_decoder_network.obj.weight[699,128]object_decoder_network.obj.bias[699]"
            },
            {
                "figure_label": "5",
                "figure_type": "table",
                "figure_id": "tab_9",
                "figure_caption": "Training time as step per second in CPU and GPU and total parameter size for ZORK1.",
                "figure_data": "Actor NetworkTemplate DecoderText EncoderState CriticObject DecoderText EncoderState-Action CriticObject DecoderText Encoder53241"
            },
            {
                "figure_label": "",
                "figure_type": "table",
                "figure_id": "tab_10",
                "figure_caption": "table is an elongated brown sack, smelling of hot peppers. A bottle is sitting on the table. The glass bottle contains: A quantity of water Inv: You are empty handed. Kitchen On the table is an elongated brown sack, smelling of hot peppers. A bottle is sitting on the table. The glass bottle contains: A quantity of water Look: Kitchen You are in the kitchen of the white house. A table seems to have been used recently for the preparation of food. A passage leads to the west and a dark staircase can be seen leading upward. A dark chimney leads down and to the east is a small window which is open. On the table is an elongated brown sack, smelling of hot peppers. A bottle is sitting on the table. The glass bottle contains: A quantity of water Inv: You are carrying: A painting A brass lantern (providing light) Kitchen On the table is an elongated brown sack, smelling of hot peppers. A bottle is sitting on the table. The glass bottle contains: A quantity of water Look: Kitchen You are in the kitchen of the white house. A table seems to have been used recently for the preparation of food. A passage leads to the west and a dark staircase can be seen leading upward. A dark chimney leads down and to the east is a small window which is open. On the table is an elongated brown sack, smelling of hot peppers. A bottle is sitting on the table. The glass bottle contains: A quantity of water Inv: You are empty handed.",
                "figure_data": "Score: 10Action: westCase 1.2Step: 15Game: Score: 39Action: westCase 1.3Step: 20Game: Score: 45Action: east"
            },
            {
                "figure_label": "6",
                "figure_type": "table",
                "figure_id": "tab_11",
                "figure_caption": "Case 1; Game observation and the selected action snippets from ZORK1.",
                "figure_data": "Case 1.1nscore = 10nscore = 39nscore = 45\u03c0(a T |o)Q(o, a)\u03c0(a T |o)Q(o, a)\u03c0(a T |o)Q(o, a)west0.999823.74600.0004.14340.0005.0134east0.00018.43850.56745.16400.99966.0319Case 1.2nscore = 10nscore = 39nscore = 45\u03c0(a T |o)Q(o, a)\u03c0(a T |o)Q(o, a)\u03c0(a T |o)Q(o, a)west0.997527.60050.98198.37940.89678.0586east0.00023.60150.00026.52840.0006.4848Case 1.3nscore = 10nscore = 39nscore = 45\u03c0(a T |o)Q(o, a)\u03c0(a T |o)Q(o, a)\u03c0(a T |o)Q(o, a)west0.787222.24190.00014.96640.0005.0169east0.005519.17510.78215.72990.99996.2653"
            },
            {
                "figure_label": "7",
                "figure_type": "table",
                "figure_id": "tab_12",
                "figure_caption": "Case 1; The changes in policy and Q value based on the score embedding from ZORK1.",
                "figure_data": ""
            },
            {
                "figure_label": "7",
                "figure_type": "table",
                "figure_id": "tab_13",
                "figure_caption": "For three different cases, Case 1.1, Case 1.2, and Case 1.3, the agent is at Kitchen location, so many semantic meaning between textual observations are similar, i.e. o look or o inv . For each case, the agent is meant to go west with n score = 10, go west with n score = 39, and go east with n score = 45, respectively. In Case 1.1, despite the optimal choice of action is west, by replacing the score from n score = 10 to n score = 45, the agent chooses east, which is appropriate for Case 1.3. Another interesting observation is that replacing game score decreases Q value from 23.7460 to 5.0134 for west and from 18.4385 to 6.0319 for east in Case 1.1.",
                "figure_data": ""
            },
            {
                "figure_label": "8",
                "figure_type": "table",
                "figure_id": "tab_14",
                "figure_caption": "Case 2; Game observation and the selected action snippets from ZORK1.",
                "figure_data": "Case 2.1nscore = 0nscore = 45\u03c0(a T |o)Q(o, a)\u03c0(a T |o)Q(o, a)open window0.999929.02050.01115.9599west0.000028.68480.08936.1119north0.000026.79970.81746.2819Case 2.2nscore = 0nscore = 45\u03c0(a T |o)Q(o, a)\u03c0(a T |o)Q(o, a)open window0.000030.21540.00006.1354west0.999932.02980.00005.8312north0.000026.75090.99526.6669Case 2.3nscore = 0nscore = 45\u03c0(a T |o)Q(o, a)\u03c0(a T |o)Q(o, a)open window0.000030.21840.00016.0443west0.999932.03020.00005.6724north0.000026.74940.98676.5545"
            },
            {
                "figure_label": "9",
                "figure_type": "table",
                "figure_id": "tab_15",
                "figure_caption": "Case 2; The changes in policy and Q value based on the score embedding from ZORK1.of n score carries some inductive bias, i.e. temporal, for the agent to infer the stage of the game. This is consistently manifested in Case 1.3, but in Case 1.2, the agent is robust to the game score because it carries painting that is directly related to reward signals, navigating to pursue that particular reward, which is put paining in case for reward signal of +6 in Living Room location.Case 2 in Table8 and Table 9In Case 2, the agent is at Behind House for three other sets of game instances, which has action and score pair as, open window for n score = 0, west for n score = 0, and north for n score = 45. The phenomenon between Case 1.1 and Case 1.3 occurs the same for Case 2.2 and Case 2.3. However, unlike Case 1, the score between Case 2.1 and Case 2.2 is the same. This means that the agent somehow chooses the optimal action for Case 2.2 over Case 2.1 in the case where n score = 0 is injected for Case 2.3. This appears to be that the agent can capture semantic correlation between \"In one corner of the house there is a small window which is open\" from textual observation in Case 2.3 and open window action. Because a small window is already opened, open window action is no longer required, so the agent tends to produce west, which is appropriate for Case 2.2.Thus, from our qualitative analysis, we speculate that the agent captures the semantics of the textual observations and infers the game stage from game score embedding to make optimal decision.",
                "figure_data": ""
            },
            {
                "figure_label": "10",
                "figure_type": "table",
                "figure_id": "tab_17",
                "figure_caption": "Game score comparison over 29 game environments in Jericho, with best results highlighted by boldface. NAIL and DRRN are non-generative baselines while TDQN and KG-A2C are generative baselines. The last row is the mean game score over all the environments. The initial game score of ADVENT \u2020 is 36 and DEEPHOME \u2021 is 1.",
                "figure_data": ""
            }
        ],
        "formulas": [
            {
                "formula_id": "formula_0",
                "formula_text": "value, Q(s t , a t ) = E[ \u221e k=0 \u03b3 k r t+k+1 |s t , a t ],",
                "formula_coordinates": [
                    2.0,
                    305.87,
                    522.16,
                    196.78,
                    15.24
                ]
            },
            {
                "formula_id": "formula_1",
                "formula_text": "L R = \u2212E [A(o, a)\u2207 \u03b8 ln \u03c0 \u03b8 (a|o)] , (1) A(o, a) = Q \u03b8 (o, a) \u2212 V \u03b8 (o),",
                "formula_coordinates": [
                    4.0,
                    104.64,
                    457.22,
                    185.23,
                    27.31
                ]
            },
            {
                "formula_id": "formula_2",
                "formula_text": "LV = E \u2207 \u03b8 V \u03b8 (o) \u2212 r + \u03b3V\u03b8(o \u2032 ) ,(3)",
                "formula_coordinates": [
                    4.0,
                    104.8,
                    514.15,
                    184.94,
                    10.63
                ]
            },
            {
                "formula_id": "formula_3",
                "formula_text": "LQ = E \u2207 \u03b8 Q \u03b8 (o, a) \u2212 r + \u03b3V\u03b8(o \u2032 ) ,(4)",
                "formula_coordinates": [
                    4.0,
                    99.36,
                    528.9,
                    190.38,
                    10.63
                ]
            },
            {
                "formula_id": "formula_4",
                "formula_text": "L T = 1 |T| a T \u2208T (y a T ln (\u03c0 \u03b8 (a T |o)) + (1 \u2212 y a T ) (1 \u2212 ln (\u03c0 \u03b8 (a T |o)))),(6)",
                "formula_coordinates": [
                    4.0,
                    86.52,
                    633.48,
                    203.34,
                    48.58
                ]
            },
            {
                "formula_id": "formula_5",
                "formula_text": "L O = 1 |O| a O \u2208O (y a O ln (\u03c0 \u03b8 (a O |o, \u00e2)) + (1 \u2212 y a O ) (1 \u2212 ln (\u03c0 \u03b8 (a O |o, \u00e2)))),(7)",
                "formula_coordinates": [
                    4.0,
                    80.0,
                    685.18,
                    209.87,
                    49.57
                ]
            },
            {
                "formula_id": "formula_6",
                "formula_text": "y a T = 1 a T \u2208 T a 0 otherwise y a O = 1 a O \u2208 O a 0 otherwise",
                "formula_coordinates": [
                    4.0,
                    75.17,
                    742.33,
                    208.46,
                    26.07
                ]
            },
            {
                "formula_id": "formula_7",
                "formula_text": "L = \u03bb R L R +\u03bb V L V +\u03bb Q L Q +\u03bb T L T +\u03bb O L O. (8",
                "formula_coordinates": [
                    4.0,
                    311.6,
                    394.21,
                    209.3,
                    11.18
                ]
            },
            {
                "formula_id": "formula_8",
                "formula_text": ")",
                "formula_coordinates": [
                    4.0,
                    520.9,
                    394.55,
                    4.24,
                    9.46
                ]
            },
            {
                "formula_id": "formula_9",
                "formula_text": "\u03b2(a|s) = U(A a (s)) p < \u03f5 \u03c0(a|s) p \u2265 \u03f5 (9)",
                "formula_coordinates": [
                    4.0,
                    348.91,
                    626.18,
                    176.24,
                    25.83
                ]
            }
        ],
        "doi": "10.3115/v1/P15-1034"
    },
    "The Zipfian Challenge: Learning the statistical fingerprint of natural languages": {
        "authors": "Christian Bentz",
        "pub_date": "",
        "abstract": "Human languages are often claimed to fundamentally differ from other communication systems. But what is it exactly that unites them as a separate category? This article proposes to approach this problem -here termed the Zipfian Challenge -as a standard classification task. A corpus with textual material from diverse writing systems and languages, as well as other symbolic and non-symbolic systems, is provided. These are subsequently used to train and test binary classification algorithms, assigning labels \"writing\" and \"non-writing\" to character strings of the test sets. The performance is generally high, reaching 98% accuracy for the best algorithms. Human languages emerge to have a statistical fingerprint: large unit inventories, high entropy, and few repetitions of adjacent units. This fingerprint can be used to tease them apart from other symbolic and non-symbolic systems.",
        "sections": [
            {
                "heading": "Introduction",
                "text": [
                    "\"If a Martian scientist [...] received from Earth the broadcast of an extensive speech [...] what criteria would [...]determine whether the reception represented the effect of an animate process on Earth, or merely the latest thunderstorm on Earth?\" (Zipf, 1936, p. 187) Zipf's ideas -condensed in the above quote -have spurred a whole research paradigm: the study of statistical laws of language. These have emerged as the best candidates for universals of language (Ferrer-i-Cancho, 2005, 2007;Bentz and Ferrer-i-Cancho, 2016;Takahira et al., 2016;D\u0119bowski, 2020;G. Torre et al., 2021;Tanaka-Ishii, 2021;Petrini et al., 2023). Beyond languages, many other systems have been found to follow similar statistical laws -to the extent that their \"meaningfulness\" has been sometimes called into question (Miller, 1957;Li, 1992;Suzuki et al., 2005). Most recently, experimental investigations have shown that Zipfian distributions facilitate learning of linguistic and visual input (Lavi-Rotbain and Arnon, 2021, 2022, 2023), that they arise from human cognitive biases (Shufaniya and Arnon, 2022), and that they help with learning new word-referent mappings (Wolters et al., 2023). In this sense, such statistical laws are quite literally \"meaningful\".",
                    "However, the challenge posed in the quote above is still only partially addressed by research into statistical laws. Namely, a statistical pattern might universally occur across languages, but this does not entail that it is a unique feature of languages. The Zipfian Challenge is ultimately the search for a statistical fingerprint: a feature, or set of features, which uniquely identify human languages. This is related to an age-old controversy of the language sciences: What makes human language special -if anything?",
                    "This challenge is here broken down into a standard classification task. Assume you are provided with strings of characters: 1 AALLAQQAASIUTA SSSSCSOFSPPPFPP",
                    "(1)",
                    "Is there an algorithm which robustly classifies these into \"writing\" and \"non-writing\"? -If yes, how? -If no, why not? Beyond pure scientific curiosity, there would be concrete applications for such an algorithm: a) cleaning of contaminated corpora, especially when large and automatically crawled (Blevins and Zettlemoyer, 2022); b) measuring similarity of undeciphered scripts to known writing systems in order to help decipherement (Rao et al., 2009(Rao et al., , 2010;;Lee et al., 2010;Sproat, 2014); c) providing tools to systematically compare human language with animal communication (Kershenbaum et al., 2016). given subcorpus (right panel). Note that the natural logarithm of 50k is roughly 11, while for 500 this is roughly 6.",
                    "In the following, a corpus of character strings labelled as \"writing\" and \"non-writing\" is introduced in Section 2. Given this corpus, a sampling procedure is defined to retrieve strings of predefined lengths (10, 100, 1000). Subsequently, features from quantitative linguistics and information theory are described an calculated on the strings (Section 3). A series of classification algorithms are trained on a subset of the feature values. Section 4 then gives the results in terms of performance of the algorithms on the test sets. Section 5 discusses the results with regards to the original research question of a statistical fingerprint, as well as some follow-up questions which arise from the results."
                ],
                "publication_ref": [
                    "b9",
                    "b10",
                    "b4",
                    "b34",
                    "b8",
                    "b12",
                    "b35",
                    "b23",
                    "b22",
                    "b33",
                    "b17",
                    "b32",
                    "b36",
                    "b5",
                    "b26",
                    "b27",
                    "b21",
                    "b31",
                    "b16"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Data",
                "text": [
                    "The data stems from a corpus of overall 377 files, split into \"writing\" (170 files) and \"non-writing\" (207). 2 The standard definition of writing is applied here. It refers to the tight link between spoken language structure and the graphemes representing it: \"Broadly defined, writing represents speech. One must be able to recover the spoken word, unambiguously, from a system of visible marks in order for those marks to be considered writing,\" (Woods, 2010, p. 18). However, some transcriptions of sign languages are also included here. Arguably, unique structural features of a given sign language can be identified in a transcrip-2 Files and code can be found at https://github.com/ christianbentz/NaLaFi. tion system, in parallel to spoken language in its graphical form."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Writing",
                "text": [
                    "The writing files in this corpus consist of 50 parallel translations of the Universal Declaration of Human Rights (UDHR), 3 transcriptions of interactions in American Sign Language (ASL) and Sign Language of the Netherlands (SLN) according to the Berkeley system, as well as transliterations of ancient languages (Akkadian, Cretan Hieroglyphs, Proto-Elamite, Prakrit, and Sumerian). 4"
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "TeDDi sample",
                "text": [
                    "To increase the diversity of genres, registers, and modalities (spoken vs. written) for modern day languages beyond the UDHR, we furthermore draw 100 files randomly from the TeDDi (Text Data Diversity) sample (Moran et al., 2022). It includes more than 20K texts from overall 89 languages and 15 writing systems, and aims to maximize the diversity of families and areas represented."
                ],
                "publication_ref": [
                    "b24"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Non-writing",
                "text": [
                    "The files classified as \"non-writing\" are further subdivided into songs of different bird species (animal), DNA strings (natural), python code (pycode), heraldics (heraldics), weather symbols (weather), morse code (morse), and protocuneiform (procunei). Examples are given in Table 1.",
                    "Bird song transcriptions of five different species (black-headed grosbeak, chickadee, Cassin's vireo, California thrasher, and zebra finch) are collected from an online database (Bird-DB). 5 It provides a \"text\" coding of recurrent phrases, identified by short pauses, and annotated with regular UTF-8 character strings in Praat (Arriaga et al., 2015).",
                    "Heraldics here refers to the description of heraldry (coats of arms) according to the so-called Blazon system. It has its own syntax, and uses a mixture of English and French words. It is here considered \"non-writing\" following the discussion in Sproat (2023). However, it is a borderline case. The usage of English words, inflectional morphemes, and noun phrase structures partially link it to the spoken language.",
                    "Morse code is another borderline case. 6 Graphemes of actual writing are here recoded into three morse characters (plus pause character). Hence, the actual writing can be recovered, and the underlying spoken language can be identified. However, this is a two-stage process. If we accept morse code as writing, we also have to accept, for instance, binary code. Such artificial coding schemes are here rather classified as \"nonwriting\".",
                    "Proto-cuneiform is strictly speaking also \"nonwriting\". Take, for instance, the transcription of a tablet from the Uruk III period (c. 3200-3000 BC) 7 as given in Table 1. N14 and N19 are transcriptions of sumerograms representing numbers (which are repeated several times for enumeration purposes), SZE\u223ca is an iconic sign which stands for the concept of \"barley\", and LU2 for the concept of \"person\". In a strict sense, we do not know whether the scribe thought of the Sumerian spoken words for \"barley\" and \"person\" when they produced these iconic signs. They could have spoken any other language. As a consequence, the language feature of this tablet is assigned the value \"undetermined\" in the database.",
                    "Finally, two further sets of \"non-writing\" files are generated by a) randomly drawing up to 48 dif-ferent characters from a uniform distribution, and b) randomly shuffling the characters of the \"writing\" files. Note that the latter process does not impact certain text statistics, e.g. the frequency distributions of characters. An overview of the file counts in this corpus, as well as distributions of file lengths in UTF-8 characters are given in Figure 1."
                ],
                "publication_ref": [
                    "b0",
                    "b32"
                ],
                "figure_ref": [
                    "fig_0"
                ],
                "table_ref": [
                    "tab_0"
                ]
            },
            {
                "heading": "Methods",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Preprocessing",
                "text": [
                    "The 377 files are preprocessed consistently to remove special characters which are used as annotations, rather than representing genuine information of the symbolic systems. For example, in Sumerian transliterations, curly brackets indicate so-called determinatives, as in {d}nansze, where d represents the star shaped sumerogram indicating that the next sumerogram is to be interpreted as the name of a deity, namely, the goddess nansze. 8 Note that the curly brackets are here already an interpretation of the person transliterating the original sumerograms, i.e. an annotation. The UTF-8 characters removed from all files include the tab character, as well as '{', '}', '(', ')', '[', ']', '+', and '*'. In fact, these characters also often cause problems in later processing steps, which is another -more practical -reason to remove them. Examples of preprocessed character strings are given in Table 1."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_0"
                ]
            },
            {
                "heading": "Sampling",
                "text": [
                    "While the numbers of files in the \"writing\" versus \"non-writing\" categories are relatively balanced (170 versus 207), the average file lengths in terms of UTF-8 characters differ widely. These range from c. 100 characters in the case of weather symbols, to c. 50k characters in the case of DNA (see also Figure 1, right panel). In most cases, this is due to data availability issues.",
                    "To alleviate this problem, two strategies are applied: Firstly, a maximum number of 10 strings of characters is extracted from each file. Secondly, the lengths of strings (in terms of number of UTF-8 characters) are held constant: 10, 100, 1000. We thus achieve a consistent comparison of strings of a given length across the different types of writing and non-writing systems. Also, these lengths are chosen with potential later applications Given this sampling procedure, we arrive at several thousand character strings for each predefined length (Table 2). For each of these strings, values are calculated for four quantitative features outlined in the following."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_0"
                ],
                "table_ref": [
                    "tab_1"
                ]
            },
            {
                "heading": "Features",
                "text": [
                    "The focus is here on quantitative features which have been explicitly proposed to distinguish different natural languages, and other symbolic systems (e.g. in Rao et al., 2009Rao et al., , 2010;;Lee et al., 2010;Sproat, 2014;Bentz et al., 2017). In particular, the measures chosen are the type-token ratio (TTR), the unigram entropy (H), and the entropy rate (h) of units (i.e. UTF-8 characters), as well as the repetition rate of adjacent units (R). The exact definitions for these measures are given below."
                ],
                "publication_ref": [
                    "b26",
                    "b27",
                    "b21",
                    "b31",
                    "b3"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Type-token ratio (TTR)",
                "text": [
                    "The type-token ratio is defined as",
                    "T T R = C C i=1 f i , (2",
                    ")",
                    "where C is number of character types in an \"alphabet\" A, such that C = |A|, and f i is the token frequency of a given character type c i ."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Unigram character entropy (H)",
                "text": [
                    "Compared to TTR, the unigram character entropy is a more nuanced measure of diversity, reflecting the distribution of units. In general, it is defined as (Cover and Thomas, 2006, p. 14)",
                    "H(X) = \u2212 x\u2208X p(x) log 2 p(x), (3",
                    ")",
                    "where X is a discrete random variable, X is the alphabet, and p(x) is the probability of a given type of the alphabet. In our case, we estimate the entropy with the maximum likelihood or 'plug in' method for a given string of characters S, such that",
                    "H(S) = \u2212 C i=1 p(c i ) log 2 p(c i ),(4)",
                    "where S is assumed to be an i.i.d discrete random variable drawn from the alphabet A, and p(c i ) is the estimated probability, i.e. the relative frequency of a character f i in S. The unigram character entropy takes values in the range [0, \u221e]. For an example sequence abcabcabc we have H(X) = (1/3 \u00d7 log 2 (1/3)) \u00d7 3 = 1.58 bits/unit."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Entropy rate (h)",
                "text": [
                    "While TTR and unigram entropy only take into account the frequencies/probabilities of individual characters -independent of their co-text -the entropy rate is defined for a stochastic process {X i } reflecting the concatenation of random variables, which might or might not be independent of one another. In general, the entropy rate is defined as (Cover and Thomas, 2006, p. 74)",
                    "h(X ) = lim n\u2192\u221e 1 n H(X 1 , X 2 , X 3 , . . . , X n ). (5",
                    ")",
                    "This can be seen as the per symbol entropy growth.",
                    "Note that in the case of characters in natural language texts, we have co-occurence patterns which limit the entropy growth to a certain extent. To estimate the entropy rate we turn to an estimator proposed in Gao et al. (2008), and implemented in Bentz et al. (2017). It is defined as",
                    "\u0125(S) = 1 n n i=2 log 2 i L i , (6",
                    ")",
                    "where n is the length (number of characters) in a given string S, and L i is the length (+1) of the longest contiguous substring starting at position i which is also present in i = 2 to i \u2212 1.",
                    "The entropy rate also takes values in the range [0, \u221e]. For our regular abcabcabc string we get \u0125 = 0.84 bits/character. Notice that this is lower than the value for the unigram character entropy (1.58 bits/character). This is because the same substring abc is repeated several times. In a sense, this entropy rate estimator \"penalizes\" long substrings of repetitions when calculating the entropy of a given string."
                ],
                "publication_ref": [
                    "b13",
                    "b3"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Repetition rate (R)",
                "text": [
                    "Finally, the repetition rate (for adjacent characters) is proposed in Lee et al. (2010) and Sproat (2014) as an alternative to entropy estimation for teasing apart writing from non-writing. The general idea is that consecutive repetitions of characters are dispreferred in genuine writing systemsprobably reflecting the avoidance of adjacent repetitions of phonemes in spoken languages. While there are some extreme examples like Schifffahrt in Standard German, we rarely encounter more than two repetitions of the same character in adjacency, and even these are relatively infrequent. The repetition rate is calculated as where r is the number of adjacent repetitions of characters c i in a given string, and the denominator is the possible number of adjacent repetitions. R takes values in the range [0, 1]. In the string abcabcabc we have zero adjacent repetitions of the same character, while there could be",
                    "R = r C i=1 f i \u2212 1 , (7",
                    "(3 \u2212 1) + (3 \u2212 1) + (3 \u2212 1) = 6 repetitions.",
                    "The repetition rate is then R = 0/6 = 0. For comparison, in the string baccbcaab (which has the same TTR and H as before), we have cc and aa as adjacent repetitions, and hence R = 2/6 = 0.33.",
                    "Overall, we thus have four vectors of feature values. The estimated values are visualized in Figure 2. Some general trends are already visible in these panels. For instance, the marginal density distributions of writing and non-writing overlap considerably for the TTR, such that it will be hard for a classification algorithm to distinguish these in this dimension. For the repetition rate R (y-axes on the right panels), on the other hand, the values of writing cluster more strongly towards low values, and are more spread out for non-writing. Interestingly, the shuffled strings seem to move away towards higher values in the R dimension compared to the original writing strings. This suggests that random shuffling of characters introduces systematically more adjacent repetitions than found in real text."
                ],
                "publication_ref": [
                    "b21",
                    "b31"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Training and test sets",
                "text": [
                    "The feature values along with their labels (writing vs. non-writing) are split into a training and test set by the ratio 67% to %33. The resulting numbers for the training and test sets per string length are given in Table 2. The same training and test sets are used for all algorithms. of the class labels which the k neighbours nearest to the target point have. Ties are broken at random. This is a non-parametric and fast classification algorithm. It was proposed already in Fix and Hodges (1952), and is still competitive today for general classification problems such as the XOR distribution of data points. 9 The only hyperparameter to tune is k, which is here assumed to range in between 1 and 10."
                ],
                "publication_ref": [
                    "b11"
                ],
                "figure_ref": [],
                "table_ref": [
                    "tab_1"
                ]
            },
            {
                "heading": "Logistic regression",
                "text": [
                    "Logistic regression is a parametric technique which was widely used in statistical learning for binary classification before the advent of neural networks. It is still used today in experimental studies in psychology and psycholinguistics (Baayen, 2013). For binary classification using feature values, we first need to estimate the coefficients of the logistic model, which is specified in our case as",
                    "logit(Y ) = log( P (Y = 1) 1 \u2212 P (Y = 1) ) = \u03b2 0 + \u03b2 1 X 1 + \u03b2 2 X 2 + \u03b2 3 X 3 + \u03b2 4 X 4 , (8",
                    ")",
                    "where X 1 , . . . , X 4 are random variables representing the feature values, Y is the binary outcome variable we want to predict, and \u03b2 0 , . . . , \u03b2 4 are the parameters (coefficients) of the model which are learned (estimated) using the feature values and labels of the training set. Once these parameters are estimated, we use them for prediction of labels in the test set given the formula",
                    "P (Y = 1) = 1 1 + e \u2212( \u03b2 0 + \u03b2 1 X 1 + \u03b2 2 X 2 + \u03b2 3 X 3 + \u03b2 4 X 4 ) ,(9)",
                    "with the decision rule: if P (Y = 1) > 0.5, then assign label \"writing\", otherwise assign label \"nonwriting\"."
                ],
                "publication_ref": [
                    "b1"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Support Vector Machines",
                "text": [
                    "A support vector machine (Cortes and Vapnik, 1995) uses the input vectors of the training set -in our case (x T T R , x H , x h , x R ) -to find the hyperplane with dimensions n \u2212 1 (where n is the number of features, i.e. n \u2212 1 = 3), which maximizes the margins to the nearest data points (i.e. support vectors). Data points in the test set are then classified according to the position of the hyperplane established with the training set. If the training data cannot be separated without error (which is almost always the case), then instead the number of errors is minimzed. As pointed out by Goodfellow et al. (2016, p. 141), the original formulation of SVMs is very similar to the logistic regression model given in Equation 8. However, it was subsequently shown that the so-called kernel trick can be used to allow non-linear mappings.",
                    "The main hyperparameter is then the type of kernel used. Here, the linear, radial basis, sigmoid, and polynomial kernels are tested."
                ],
                "publication_ref": [
                    "b6"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Multilayer Perceptrons (MLP)",
                "text": [
                    "Multilayer perceptrons (deep feedforward networks) are the archetype of deep learning (Bengio et al., 2000;LeCun et al., 2015). In its simplest form, a feedforward network for binary classification consists of the input units (four in our case), a single hidden unit, and an output unit. See Figure 3 (upper panel) for an illustration. Note that this is mathematically equivalent to the logistic regression model in Equation 8. Namely, the vector of weights (w) -multiplied with the input values of features (x) -is equivalent to the coefficients (\u03b2 1 , . . . , \u03b2 4 ), and the bias (indicated in blue in the figures) is equivalent to \u03b2 0 . However, a crucial question is which hidden layer architecture, activation function, error function, and backpropagation algorithm yield the best results for a given data set. These are the hyperparameters to tune. Here, a search of the space of possible architectures is performed by randomly drawing natural numbers in the range [1,4] for the hidden layers, and numbers in the range [1,5] for the number of units in each hidden layer. The maximal values are guided by local regression analyses of model performance (F1 score) given the depth and size of networks (see Appendix B). Overall, one hundred random values are drawn for the depth and size, yielding one hundred different architectures (out of 5 4 = 625). Moreover, different activation functions (logistic, ReLU, softplus, tanh), error functions (SSE, cross entropy), and backpropagation algorithms (Rumelhart et al., 1986;Riedmiller and Braun, 1993;Hinton et al., 2006) are considered."
                ],
                "publication_ref": [
                    "b2",
                    "b20",
                    "b29",
                    "b28",
                    "b15"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Results",
                "text": [
                    "For all classification algorithms the accuracy, precision, recall, and F1 score on the test set are reported alongside the respective hyperparameters. A condensed overview of classification results are given in Table 3. The best model overall is an MLP trained on feature values of strings with 1000 characters. It achieves an F1 score of 0.96, and an accuracy of 98%. In other words, for the 571 strings of the test set it assigns the correct label (writing vs. non-writing) in 560 cases, erring only in 11 cases. This performance drops to 93% accuracy when feature values of strings of length 100 are supplied, and to 73% with strings of length 10. The performance of the best KNNs is very similar, differing only by a max amount of 0.01. In gen- eral, the KNN and MLPs show very similar performance, while the performance of SVMs and logistic regression models is lower across the board."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_3"
                ]
            },
            {
                "heading": "Discussion",
                "text": [
                    "Overall, the classification results suggest that the Zipfian Challenge is indeed a solvable problem. Namely, given strings of characters of length 100, KNNs and MLPs reach performance values of 0.92 and 0.93 respectively. With 1000 characters, they are almost at the ceiling of performance. In fact, it is questionable whether humans would be able to correctly classify the respective strings with 100% accuracy. Mind you that more than 36 different scripts and 90 different languages are represented in this data sample. It would be an interesting project for future research to establish human performance on this task. In the following, some further follow-up questions are briefly discussed."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Why do algorithms perform differently?",
                "text": [
                    "It is surprising to see a simple, non-parametric classification algorithm like KNN outperform other, much more complex algorithms such as logistic regression and SVMs, and perform on a par with the best MLPs. This is certainly related to the data set and problem at hand. The KNN has no parameters to \"learn\" from the training data. It directly assigns a label to a given vector of feature values by finding the vector of feature values closest to it in the training set. In comparison, the currently best MLP given in Figure 3 has 4\u00d74+4\u00d74+2\u00d71 = 34 weights and 4+4+1 = 9 biases to adjust. This amounts to overall 43 parameters to optimize in the \"learning\" process. In fact, few of the deeper networks with three or four hidden layers actually reach convergence with this data. And when they converge, they do not necessarily perform better than the simpler architectures (see Appendix B)."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_2"
                ],
                "table_ref": []
            },
            {
                "heading": "Why do longer strings yield better results",
                "text": [
                    "than shorter strings?",
                    "The main reason for this is that the respective feature values have not converged for short strings of length 10. For strings of length 100, they start to converge in most cases, and at 1000 characters they have converged across the board. The convergence behavior of the different measures is given in Appendix C."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Which is the best feature?",
                "text": [
                    "When feature value vectors are input separately -rather than together -into the KNN algorithm (with k = 1), then the repetition rate R performs best for 100 characters (F1-score: 0.  for long vowels (aa), lateral glides (ll), and ejectives (qq). In such cases, the other measures will help with correct classification."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "How are the results influenced by subcorpora?",
                "text": [
                    "The corpus of strings is not fully balanced. To get an idea of the degree to which particular subcorpora influence the performance, they are removed individually in a post hoc experiment with the best KNN model (k = 5) for 100 characters.",
                    "The results are given in Appendix D. Generally, classification results are robust to removal of subcorpora. The strongest decrease in performance is associated with the removal of DNA (natural) strings. These have generally low entropies, and high repetition rates, and are hence easily classified as non-writing. The inverse effect holds for shuffled data. Shuffling the characters of genuine writing does not change the unigram entropy and TTR, and only marginally changes the entropy rate of strings. Hence, in this case, the repetition rate is the only feature useful for identifying the resulting strings as non-writing. Removing the shuffled strings increases the overall performance."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Conclusions",
                "text": [
                    "Compared to other symbolic and non-symbolic systems, natural languages seem to exhibit a unique fingerprint: relatively large unit inventories, relatively high entropy, and relatively few repetitions of adjacent units. This statistical fin-gerprint can be used to identify written language with high accuracy when more than 100 characters are provided. Interestingly, this seems to hold not only for writing reflecting spoken language but also for transcriptions of sign languages (though only small samples of ASL and SLN were used here). This suggests that humans have evolved the capacity of encoding information with a diverse, non-repetitive succession of units in three modalities: speech, manual signs, and graphical codes. If these results hold true, then it is not a single feature, and not a single modality, which defines human language, but a set of features related to rapid information transmission in the face of space and time limitations."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Acknowledgements",
                "text": [
                    "Thanks to Tanja Samard\u017ei\u0107, the CrossLingference working group, as well as the members of the Language Learning and Processing Lab led by Inbal Arnon for comments on earlier versions of these analyses. Thanks to Ximena Gutierrez-Vasques, Julia \u0141ukasiewicz-Pater, Olga Peroni, and Steven Moran for their collaboration on the TeDDi sample and other projects directly relevant to this topic. The help of Clara Garcia Baumg\u00e4rtner and Tim Wientzek with collecting non-linguistic data is also gratefully acknowledged. Finally, thanks to the anonymous reviewers who have helped to improve the manuscript."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Appendices",
                "text": [
                    "See separate pdf file for Appendices. "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            }
        ],
        "references": [
            {
                "ref_id": "b0",
                "title": "Bird-db: A database for annotated bird song sequences",
                "journal": "Ecological Informatics",
                "year": "2015",
                "authors": "G Julio;  Arriaga; L Martin; Edgar E Cody; Charles E Vallejo;  Taylor"
            },
            {
                "ref_id": "b1",
                "title": "Multivariate statistics",
                "journal": "Cambridge University Press",
                "year": "2013",
                "authors": "R ; Harald Baayen"
            },
            {
                "ref_id": "b2",
                "title": "A neural probabilistic language model. Advances in neural information processing systems",
                "journal": "",
                "year": "2000",
                "authors": "Yoshua Bengio; R\u00e9jean Ducharme; Pascal Vincent"
            },
            {
                "ref_id": "b3",
                "title": "The entropy of words -learnability and expressivity across more than 1000 languages",
                "journal": "Entropy",
                "year": "2017",
                "authors": "Christian Bentz; Dimitrios Alikaniotis; Michael Cysouw; Ramon Ferrer-I Cancho"
            },
            {
                "ref_id": "b4",
                "title": "Zipf's law of abbreviation as a language universal",
                "journal": "",
                "year": "2016",
                "authors": "Christian Bentz; Ramon Ferrer-I-Cancho"
            },
            {
                "ref_id": "b5",
                "title": "Language contamination helps explains the cross-lingual capabilities of English pretrained models",
                "journal": "Association for Computational Linguistics",
                "year": "2022",
                "authors": "Terra Blevins; Luke Zettlemoyer"
            },
            {
                "ref_id": "b6",
                "title": "Supportvector networks",
                "journal": "Machine learning",
                "year": "1995",
                "authors": "Corinna Cortes; Vladimir Vapnik"
            },
            {
                "ref_id": "b7",
                "title": "Elements of information theory",
                "journal": "New Jersey",
                "year": "2006",
                "authors": "M Thomas; Joy A Cover;  Thomas"
            },
            {
                "ref_id": "b8",
                "title": "Information theory meets power laws: Stochastic processes and language models",
                "journal": "John Wiley & Sons",
                "year": "2020",
                "authors": "\u0141ukasz D\u0119bowski"
            },
            {
                "ref_id": "b9",
                "title": "The variation of Zipf's law in human language",
                "journal": "The European Physical Journal B",
                "year": "2005",
                "authors": "Ramon Ferrer-I-Cancho"
            },
            {
                "ref_id": "b10",
                "title": "On the universality of Zipf's law for word frequencies",
                "journal": "Mouton de Gruyter",
                "year": "2007",
                "authors": "Ramon Ferrer-I-Cancho"
            },
            {
                "ref_id": "b11",
                "title": "Discriminatory analysis -nonparametric discrimination: Small sample performance",
                "journal": "",
                "year": "1952",
                "authors": "Evelyn Fix; L Joseph;  Hodges"
            },
            {
                "ref_id": "b12",
                "title": "Can Menzerath's law be a criterion of complexity in communication",
                "journal": "Plos one",
                "year": "2021",
                "authors": "G Iv\u00e1n; \u0141ukasz Torre; Antoni D\u0119bowski;  Hern\u00e1ndez-Fern\u00e1ndez"
            },
            {
                "ref_id": "b13",
                "title": "Estimating the entropy of binary time series: Methodology, some theory and a simulation study",
                "journal": "Entropy",
                "year": "2008",
                "authors": "Yun Gao; Ioannis Kontoyiannis; Elie Bienenstock"
            },
            {
                "ref_id": "b14",
                "title": "Deep learning",
                "journal": "MIT press",
                "year": "2016",
                "authors": "Ian Goodfellow; Yoshua Bengio; Aaron Courville"
            },
            {
                "ref_id": "b15",
                "title": "A fast learning algorithm for deep belief nets",
                "journal": "Neural computation",
                "year": "2006",
                "authors": "Geoffrey E Hinton; Simon Osindero; Yee-Whye Teh"
            },
            {
                "ref_id": "b16",
                "title": "Acoustic sequences in nonhuman animals: a tutorial review and prospectus",
                "journal": "Biological Reviews",
                "year": "2016",
                "authors": "Arik Kershenbaum; T Daniel; Marie A Blumstein; \u00c7aglar Roch; Gregory Ak\u00e7ay;  Backus; A Mark; Kirsten Bee; Yan Bohn; Gerald Cao; Cristiane Carter;  C\u00e4sar"
            },
            {
                "ref_id": "b17",
                "title": "Visual statistical learning is facilitated in Zipfian distributions",
                "journal": "Cognition",
                "year": "2021",
                "authors": "Ori Lavi-Rotbain; Inbal Arnon"
            },
            {
                "ref_id": "b18",
                "title": "The learnability consequences of zipfian distributions in language",
                "journal": "Cognition",
                "year": "2022",
                "authors": "Ori Lavi-Rotbain; Inbal Arnon"
            },
            {
                "ref_id": "b19",
                "title": "Zipfian distributions in child-directed speech",
                "journal": "Open Mind",
                "year": "2023",
                "authors": "Ori Lavi-Rotbain; Inbal Arnon"
            },
            {
                "ref_id": "b20",
                "title": "Deep learning",
                "journal": "Nature",
                "year": "2015",
                "authors": "Yann Lecun; Yoshua Bengio; Geoffrey Hinton"
            },
            {
                "ref_id": "b21",
                "title": "Pictish symbols revealed as a written language through application of Shannon entropy",
                "journal": "",
                "year": "2010",
                "authors": "Rob Lee; Philip Jonathan; Pauline Ziman"
            },
            {
                "ref_id": "b22",
                "title": "Random texts exhibit Zipf's-lawlike word frequency distribution",
                "journal": "IEEE Transactions on information theory",
                "year": "1992",
                "authors": "Wentian Li"
            },
            {
                "ref_id": "b23",
                "title": "Some effects of intermittent silence",
                "journal": "The American journal of psychology",
                "year": "1957",
                "authors": "A George;  Miller"
            },
            {
                "ref_id": "b24",
                "title": "TeDDi sample: Text data diversity sample for language comparison and multilingual nlp",
                "journal": "",
                "year": "2022",
                "authors": "Steven Moran; Christian Bentz; Ximena Gutierrez-Vasques; Olga Pelloni; Tanja Samardzic"
            },
            {
                "ref_id": "b25",
                "title": "Christian Bentz, and Ramon Ferrer-i-Cancho. 2023. Direct and indirect evidence of compression of word lengths. zipf's law of abbreviation revisited",
                "journal": "Glottometrics",
                "year": "",
                "authors": "Sonia Petrini; Antoni Casas-I-Mu\u00f1oz; Jordi Cluet-I-Martinell; Mengxue Wang"
            },
            {
                "ref_id": "b26",
                "title": "Entropic evidence for linguistic structure in the Indus script",
                "journal": "Science",
                "year": "2009",
                "authors": "P N Rajesh; Nisha Rao;  Yadav; N Mayank; Hrishikesh Vahia; R Joglekar; Iravatham Adhikari;  Mahadevan"
            },
            {
                "ref_id": "b27",
                "title": "Entropy, the Indus script, and language: A reply to R",
                "journal": "Sproat. Computational Linguistics",
                "year": "2010",
                "authors": "P N Rajesh; Nisha Rao;  Yadav; N Mayank; Hrishikesh Vahia; Ronojoy Joglekar; Iravatham Adhikari;  Mahadevan"
            },
            {
                "ref_id": "b28",
                "title": "A direct adaptive method for faster backpropagation learning: The RPROP algorithm",
                "journal": "IEEE",
                "year": "1993",
                "authors": "Martin Riedmiller; Heinrich Braun"
            },
            {
                "ref_id": "b29",
                "title": "Learning representations by backpropagating errors",
                "journal": "Nature",
                "year": "1986",
                "authors": "Geoffrey E David E Rumelhart; Ronald J Hinton;  Williams"
            },
            {
                "ref_id": "b30",
                "title": "2022. A cognitive bias for zipfian distributions? uniform distributions become more skewed via cultural transmission",
                "journal": "Journal of Language Evolution",
                "year": "",
                "authors": "Amir Shufaniya; Inbal Arnon"
            },
            {
                "ref_id": "b31",
                "title": "A statistical comparison of written language and nonlinguistic symbol systems",
                "journal": "Language",
                "year": "2014",
                "authors": "Richard Sproat"
            },
            {
                "ref_id": "b32",
                "title": "Symbols: An Evolutionary History from the Stone Age to the Future",
                "journal": "Springer",
                "year": "2023",
                "authors": "Richard William Sproat"
            },
            {
                "ref_id": "b33",
                "title": "The use of Zipf's law in animal communication analysis",
                "journal": "Animal Behaviour",
                "year": "2005",
                "authors": "Ryuji Suzuki; John R Buck; Peter L Tyack"
            },
            {
                "ref_id": "b34",
                "title": "Entropy rate estimates for natural language -a new extrapolation of compressed largescale corpora",
                "journal": "Entropy",
                "year": "2016",
                "authors": "Ryosuke Takahira; Kumiko Tanaka-Ishii; \u0141ukasz D\u0119bowski"
            },
            {
                "ref_id": "b35",
                "title": "Statistical Universals of Language: Mathematical Chance vs. Human Choice",
                "journal": "Springer Nature",
                "year": "2021",
                "authors": "Kumiko Tanaka-Ishii"
            },
            {
                "ref_id": "b36",
                "title": "Zipfian distributions facilitate learning novel word-referent mappings",
                "journal": "",
                "year": "2023",
                "authors": "Lucie Wolters; Ori Lavi-Rotbain; Inbal Arnon"
            },
            {
                "ref_id": "b37",
                "title": "The earliest Mesopotamian writing",
                "journal": "",
                "year": "2010",
                "authors": "Christopher Woods"
            },
            {
                "ref_id": "b38",
                "title": "The psycho-biology of language. An introduction to dynamic philology. George Routledge & Sons, Oxon, UK. Limitations See separate pdf file",
                "journal": "",
                "year": "1936",
                "authors": "George Kingsley; Zipf "
            }
        ],
        "figures": [
            {
                "figure_label": "1",
                "figure_type": "figure",
                "figure_id": "fig_0",
                "figure_caption": "Figure 1 :1Figure1: Number of files per subcorpus (left panel). Logarithm of the number of UTF-8 characters over files in a given subcorpus (right panel). Note that the natural logarithm of 50k is roughly 11, while for 500 this is roughly 6.",
                "figure_data": ""
            },
            {
                "figure_label": "52",
                "figure_type": "figure",
                "figure_id": "fig_1",
                "figure_caption": "3. 5 Figure 2 :52Figure 2: Distributions of feature values for strings of length 10, 100, and 1000 respectively. The main distinction between writing and non-writing is color-coded (blue and red). The subcorpora are indicated by different shapes of the dots.",
                "figure_data": ""
            },
            {
                "figure_label": "3",
                "figure_type": "figure",
                "figure_id": "fig_2",
                "figure_caption": "Figure 3 :3Figure 3: Upper panel: A forward pass with logistic activation and output functions with the simplest possible MLP architecture for binary classification, with one hidden layer, consisting of a single hidden unit.Lower panel: MLP architecture with two layers of hidden units (four each) and a logistic output unit. This is the architecture which performs best on strings of 100 characters.",
                "figure_data": ""
            },
            {
                "figure_label": "1",
                "figure_type": "table",
                "figure_id": "tab_0",
                "figure_caption": "Examples of characters strings of genuine writing systems as well as systems here classified as nonwriting.",
                "figure_data": "CorpusSubcorpusFile IDExampleWritingAncientakk_0001\u0161um-ma a-wi-lum ba-wi-lam u-ub-bi-ir-maSignlangtsl_0001-clVP-clTL-golVP_TOP-pstSTRmount-clUDHRcmn_0001\u5e8f\u8a00\u9274\u4e8e\u5bf9\u4eba\u7c7b\u5bb6\u5ead\u6240\u6709\u6210\u5458\u7684\u56fa\u6709\u5c0a\u4e25\u53ca\u5176eng_0001Preamble Whereas recognition of the inherentkal_0001AALLAQQAASIUTA taqqinassusermik inuupkor_0001\uc804 \ubb38\ubaa8\ub4e0 \uc778\ub958 \uad6c\uc131\uc6d0\uc758 \ucc9c\ubd80\uc758 \uc874\uc5c4\uc131\uacfc \ub3d9\ub4f1TeDDieng_nfi_242 It's not supposed to be like this.It's time.Non-Writing Animalbhg_0001uj kd ro su sv sw sx gf jr dw kd tc jt ag taHeraldicsbla_0001Or, a lion rampant within a double tressureMorsemoc_0001phh_pppp_p_hp_s_pp_hp_s_h_pppp_p_s_hphpNatural (DNA)dna_0001GGTAGTTAGGGTCTGAAAAAGATTTTGCGProto-Cuneiform prc_0001N14 [...] N19 N19 N19 SZE\u223ca LU2 MUD3\u223cdPython codepyc_0001class Person: pass p = Person() print(p) classRandomran_10hihhe bh fif cd gbgdiiigc ghigbbg af icegeebiifgShuffledeng_0001swr a j e eitimii hfeooa ti i d qs sfi roeviebg epWeatherwsy_0001SWCCSSSSSSSSSSCSOFSPPPFPPFPP"
            },
            {
                "figure_label": "2",
                "figure_type": "table",
                "figure_id": "tab_1",
                "figure_caption": ") Number of character strings of a given length in the training and test sets.",
                "figure_data": "Length (Chars.) Overall Training Test10374125431198100322321941029100018321261571"
            },
            {
                "figure_label": "3",
                "figure_type": "table",
                "figure_id": "tab_3",
                "figure_caption": "Classification results organised by number of characters and method. Only the best models (by F1 and Accuracy) for each number of characters is given. The baseline is the KNN algorithm (k=1) with strings of 10 characters and only TTR as a feature for training and testing.",
                "figure_data": ""
            }
        ],
        "formulas": [
            {
                "formula_id": "formula_0",
                "formula_text": "T T R = C C i=1 f i , (2",
                "formula_coordinates": [
                    4.0,
                    139.81,
                    749.17,
                    145.08,
                    28.88
                ]
            },
            {
                "formula_id": "formula_1",
                "formula_text": ")",
                "formula_coordinates": [
                    4.0,
                    284.89,
                    756.78,
                    4.24,
                    9.59
                ]
            },
            {
                "formula_id": "formula_2",
                "formula_text": "H(X) = \u2212 x\u2208X p(x) log 2 p(x), (3",
                "formula_coordinates": [
                    4.0,
                    346.09,
                    499.68,
                    174.08,
                    23.6
                ]
            },
            {
                "formula_id": "formula_3",
                "formula_text": ")",
                "formula_coordinates": [
                    4.0,
                    520.17,
                    501.25,
                    4.24,
                    9.59
                ]
            },
            {
                "formula_id": "formula_4",
                "formula_text": "H(S) = \u2212 C i=1 p(c i ) log 2 p(c i ),(4)",
                "formula_coordinates": [
                    4.0,
                    346.44,
                    619.79,
                    177.97,
                    33.71
                ]
            },
            {
                "formula_id": "formula_5",
                "formula_text": "h(X ) = lim n\u2192\u221e 1 n H(X 1 , X 2 , X 3 , . . . , X n ). (5",
                "formula_coordinates": [
                    5.0,
                    82.36,
                    202.74,
                    202.53,
                    24.43
                ]
            },
            {
                "formula_id": "formula_6",
                "formula_text": ")",
                "formula_coordinates": [
                    5.0,
                    284.89,
                    210.35,
                    4.24,
                    9.59
                ]
            },
            {
                "formula_id": "formula_7",
                "formula_text": "\u0125(S) = 1 n n i=2 log 2 i L i , (6",
                "formula_coordinates": [
                    5.0,
                    132.79,
                    331.19,
                    152.1,
                    33.71
                ]
            },
            {
                "formula_id": "formula_8",
                "formula_text": ")",
                "formula_coordinates": [
                    5.0,
                    284.89,
                    343.05,
                    4.24,
                    9.59
                ]
            },
            {
                "formula_id": "formula_9",
                "formula_text": "R = r C i=1 f i \u2212 1 , (7",
                "formula_coordinates": [
                    5.0,
                    138.31,
                    749.17,
                    146.58,
                    28.88
                ]
            },
            {
                "formula_id": "formula_10",
                "formula_text": "(3 \u2212 1) + (3 \u2212 1) + (3 \u2212 1) = 6 repetitions.",
                "formula_coordinates": [
                    5.0,
                    304.87,
                    266.13,
                    198.64,
                    10.18
                ]
            },
            {
                "formula_id": "formula_11",
                "formula_text": "logit(Y ) = log( P (Y = 1) 1 \u2212 P (Y = 1) ) = \u03b2 0 + \u03b2 1 X 1 + \u03b2 2 X 2 + \u03b2 3 X 3 + \u03b2 4 X 4 , (8",
                "formula_coordinates": [
                    7.0,
                    97.02,
                    209.69,
                    187.87,
                    41.69
                ]
            },
            {
                "formula_id": "formula_12",
                "formula_text": ")",
                "formula_coordinates": [
                    7.0,
                    284.89,
                    226.12,
                    4.24,
                    9.59
                ]
            },
            {
                "formula_id": "formula_13",
                "formula_text": "P (Y = 1) = 1 1 + e \u2212( \u03b2 0 + \u03b2 1 X 1 + \u03b2 2 X 2 + \u03b2 3 X 3 + \u03b2 4 X 4 ) ,(9)",
                "formula_coordinates": [
                    7.0,
                    102.05,
                    385.24,
                    187.08,
                    42.08
                ]
            }
        ],
        "doi": "10.1140/epjb/e2005-00121-8"
    },
    "Can Language Models Be Tricked by Language Illusions? Easier with Syntax, Harder with Semantics": {
        "authors": "Yuhan Zhang; Edward Gibson; Forrest Davis",
        "pub_date": "",
        "abstract": "Language models (LMs) have been argued to overlap substantially with human beings in grammaticality judgment tasks. But when humans systematically make errors in language processing, should we expect LMs to behave like cognitive models of language and mimic human behavior? We answer this question by investigating LMs' more subtle judgments associated with \"language illusions\" -sentences that are vague in meaning, implausible, or ungrammatical but receive unexpectedly high acceptability judgments by humans. We looked at three illusions: the comparative illusion (e.g. \"More people have been to Russia than I have\"), the depth-charge illusion (e.g. \"No head injury is too trivial to be ignored\"), and the negative polarity item (NPI) illusion (e.g. \"The hunter who no villager believed to be trustworthy will ever shoot a bear\"). We found that probabilities represented by LMs were more likely to align with human judgments of being \"tricked\" by the NPI illusion which examines a structural dependency, compared to the comparative and the depth-charge illusions which require sophisticated semantic understanding. No single LM or metric yielded results that are entirely consistent with human behavior. Ultimately, we show that LMs are limited both in their construal as cognitive models of human language processing and in their capacity to recognize nuanced but critical information in complicated language materials.",
        "sections": [
            {
                "heading": "Introduction",
                "text": [
                    "Linguistic evaluations of language models use human language processing data (e.g. human norming data (Nair et al., 2020;Zhang et al., 2022), acceptability judgments (Linzen et al., 2016;Marvin and Linzen, 2018), behavioral or neural measures of language processing (Schrimpf et al., 2021;Kauf et al., 2022)) as benchmarks to investigate whether LMs possess knowledge of language. This assumes that human-produced data correctly instantiates abstract rules of a language and that humans fully utilize their linguistic knowledge in laboratories and everyday life. However, this assumption is an oversimplification. Humans make consistent errors during language processing (Gross, 1983). Under these circumstances, should we expect language models to behave the same as humans? Or should they circumvent human limitations and achieve error-free performance?",
                    "Consider, for example, the well-studied case of subject-verb agreement. While we expect an LM of Standard American English to prefer \"the key to the cabinets is on the shelf\" to \"the key to the cabinets are on the shelf\" (as discussed in Linzen et al., 2016), a wealth of psycholinguistic research has systematically documented that humans can ignore errors and accept globally ungrammatical strings (stemming from Bock and Miller, 1991). Should LMs follow the ideal grammar or mimic human's (sometimes) errorful behavior? 1  We add to this discussion by investigating three language illusions. Basic examples of each are given in (1): the comparative illusion (1-a), the depth-charge illusion (1-b), and the negativepolarity item (NPI) illusion (1-c). All three in (1) are literally unnatural English sentences, despite the fact that humans often find them surprisingly acceptable.",
                    "(1) a. More people have been to Russia than I have. b. No head injury is too trivial to be ignored. c. The hunter who no villager believed to be trustworthy will ever shoot a bear.",
                    "In this paper, we relied on minimally different strings springing out from the basic illusion sentences that are either (a) considered fully acceptable by human participants, (b) considered fully unacceptable by human participants, or (c) rated surprisingly acceptable by humans (i.e. instances of the relevant illusion). We explored whether language models capture the basic contrast between acceptable and unacceptable strings, whether they rate illusion sentences as better than their unacceptable counterparts, and finally, whether models capture nuanced linguistic manipulations that influence human judgments of the illusion material. Further, we compared two ways of measuring models' preferences, one over the whole sentence (perplexity) and another of a privileged position in the sentence (surprisal).",
                    "If LMs pattern like human comprehension behavior that involves errors, we expect to derive measures that similarly rate illusion sentences as more acceptable than typical unacceptable sentences. If, on the other hand, LMs align with ideal grammatical judgments, illusion sentences should be rated as unacceptable. Our findings indicate that none of the language models we investigated consistently exhibited illusion effects or demonstrated overall human-like judgment behaviors. Nor do they possess the necessary linguistic knowledge for errorfree, literal sentence processing. These findings add more insights into the discussion of LMs' emulation of human behavior and their construal as cognitive models of human language processing."
                ],
                "publication_ref": [
                    "b31",
                    "b60",
                    "b25",
                    "b28",
                    "b41",
                    "b20",
                    "b13",
                    "b25",
                    "b1"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Related work",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "LMs' linguistic abilities",
                "text": [
                    "We draw insights from evaluation work relying on acceptability tasks. The construction of minimal pairs has been used to evaluate models for a variety of linguistic processes, including subject-verb agreement (e.g. Linzen et al., 2016), filler-gap dependency (e.g. Wilcox et al., 2018), control (e.g. Stengel-Eskin and Van Durme, 2022), and binding (e.g. Davis, 2022). This basic template has been expanded into a variety of benchmarks, both for investigations of English (e.g. Warstadt et al., 2020), but also, other languages (e.g. Chinese (Song et al., 2022); Russian (Mikhailov et al., 2022); Japanese (Someya and Oseki, 2023)). While aggregated results suggest that models overlap with human acceptability judgments in a variety of cases (e.g. Hu et al., 2020), LMs can behave in distinctly nonhuman-like ways in capturing the intricacies of grammatical phenomenon (e.g. Lee and Schuster, 2022), the interaction between linguistic processes (e.g. Davis and van Schijndel, 2020), and in gen-eralizing knowledge to infrequent items (e.g. Wei et al., 2021).",
                    "In our experiments, we are interested in cases where human interpretations and behaviors differ from what is expected given the literal content of the entire string. Garden path sentences are a classic example of this basic phenomenon. Strings like \"The horse raced past the barn fell\" are often difficult for humans on first reading because the word raced is misparsed as a main verb (e.g. the horse raced past) rather than a reduced relative clause (e.g. the horse that was raced past the barn fell). LMs have been shown to similarly misprocess these sentences (van Schijndel and Linzen, 2021), though they fall short of capturing the magnitude of the processing cost (Arehalli et al., 2022). Here we expand these investigations to language illusions that similarly trigger errorful acceptable judgments in humans while being unnatural and unacceptable. We find that LMs do not pattern like humans in all cases."
                ],
                "publication_ref": [
                    "b25",
                    "b57",
                    "b4",
                    "b52",
                    "b45",
                    "b29",
                    "b44",
                    "b15",
                    "b23",
                    "b5",
                    "b54",
                    "b0"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Language illusions",
                "text": [
                    "Language illusions refer to ungrammatical, semantically vague, or pragmatically implausible sentences that receive higher than expected acceptability by humans (Phillips et al., 2011). We study three language illusions in particular: comparative illusion (Montalbetti, 1984) (Section 4), depthcharge illusion (Wason and Reich, 1979) (Section 5), and NPI illusion (Xiang et al., 2009) (Section 6). Existing human research has found that the illusion effects for both the comparative and the depth-charge illusion are robust and overwhelming but the NPI illusion effect only appears during speeded judgment tasks or word-by-word online paradigms (Parker and Phillips, 2016;Wellwood et al., 2018;Paape et al., 2020;Orth et al., 2021).",
                    "For human sentence processing, it has been suggested that language illusions provide evidence for rational inference of error-prone strings which integrates heuristics and available context information during processing (Ferreira et al., 2002;Levy, 2008;Gibson et al., 2013;Futrell et al., 2020;Hahn et al., 2022;Zhang et al., 2023a). These phenomena raise fundamental questions like what is the role of our grammatical knowledge in comparison to other cognitive resources when it comes to assigning a specific interpretation to a linguistic string, and how we can model their interactions to make better predictions about human sentence processing.",
                    "Studying LMs' processing of language illusions provides a way to explore whether they can be viewed as cognitive models of human sentence processing. As large language models like ChatGPT improve at generating grammatically appropriate strings, it becomes ever more important to investigate whether they are comparable to human language processing behavior at all (see Mahowald et al., 2023, for a review). From there, we can reason about what characteristics in the training of LMs, the architecture of LMs, and the \"abilities\" of LMs enable them to carry out either literal interpretations and detect the anomaly, or to fall into the illusion rabbit hole."
                ],
                "publication_ref": [
                    "b38",
                    "b30",
                    "b37",
                    "b56",
                    "b35",
                    "b33",
                    "b8",
                    "b24",
                    "b12",
                    "b9",
                    "b14"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Methods",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Models and Measures",
                "text": [
                    "We analyzed four models, two masked language models, and two autoregressive models: BERT (Devlin et al., 2019), RoBERTa (Liu et al., 2019), GPT-2 (Radford et al., 2019), GPT-3 (Brown et al., 2020). BERT, RoBERTa, and GPT-2 were accessed via HuggingFace (Wolf et al., 2020), and GPT-3 via OpenAI's API. 2 We used two measures, sentence level perplexity and surprisal of specific target words. For autoregressive models, the surprisal of a specific word 3 is given by the following equation:",
                    "Surp(w i ) = \u2212log Prob(w i |w 1 ...w i\u22121 ) (1)",
                    "Perplexity for a sentence of N words is:",
                    "2 1 N N i=1 Surp(w i )(2)",
                    "For bidirectional models, we calculated the surprisal of a word in a context by using the masking technique in Kauf and Ivanova (2023), which corrects for words that are subworded. 4 Further, we used this masking technique to calculate the pseudo-perplexity of a sentence (Salazar et al., 2020). 2 We used 'bert-base-cased', 'roberta-base', 'gpt2', and 'text-davinci-003'. Code for replicating the results, statistical tests, and figures can be found at https://github.com/ forrestdavis/LanguageIllusions.git .",
                    "3 For words that are subworded, the joint probability was calculated.",
                    "4 For example, consider the word 'souvenir'. This is subworded by BERT into 'so', '##uven', and 'ir'. Rather than MASK each subpart, one at a time, (e.g. 'so' [MASK] 'ir'), the right context of the target subword is always masked (e.g. 'so' [MASK] [MASK])."
                ],
                "publication_ref": [
                    "b6",
                    "b26",
                    "b39",
                    "b58",
                    "b19",
                    "b40"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Evaluation procedure",
                "text": [
                    "We treated LMs as psycholinguistic research subjects to generate both whole-sentence perplexity and surprisals at critical words for carefully controlled minimal pairs for each illusion (following, Futrell et al., 2019). Assuming these two scores are correlated to human acceptability judgments (Lau et al., 2017), we constructed mix-effects linear regression models from the R package lme4 to test whether LMs were also sensitive to reported manipulations that affect human judgments. For each scoring metric, we took it as the dependent variable and coded the manipulation condition representing a certain hypothesis into the independent variable. We read the estimated coefficient(s) of the tested condition variable(s) to infer whether LMs show sensitivity to the effect of that condition manipulation on the scoring metric. We evaluated language models in three broad aspects: acceptability differentiation, illusion effect, and sensitivity to manipulations.",
                    "\u2022 Acceptability differentiation We first asked whether language models could distinguish acceptable sentences from unacceptable sentences that humans have no trouble dealing with. 5 Models with relevant knowledge should assign lower perplexity/surprisal to acceptable sentences versus unacceptable ones.",
                    "\u2022 Illusion effect We took the results from the acceptability differentiation task as the foundation to test the illusion sentences. Here, we hypothesized that language models should either (i) align with humans' illusionary judgments, reflected by models' generating a lower perplexity/surprisal for illusion sentences than the unacceptable controls, or (ii) deviate from human behavior and show hints of being a literal processor, reflected by models' generating a higher or similar perplexity/surprisal score compared to the unacceptable condition.",
                    "If models behave like humans, then we expected (i) to be the models' consistent behavior. If models conform to (ii), we take this as evidence of non-human-like behavior.",
                    "\u2022 Sensitivity to manipulations Lastly, we assessed whether language models were sensi- "
                ],
                "publication_ref": [
                    "b10",
                    "b22"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Comparative illusion",
                "text": [
                    "A canonical comparative illusion surfaces in sentences like \"More people have been to Russia than I have\". People accept it at first glance but have trouble pinning down the exact meaning (Montalbetti, 1984) one of which could be that the number of the group of people who've been to Russia is greater than the number of \"me\". Potential rational nonliteral inference could be \"people have been to Russia more times than I have\" or \"people have been to Russia but I haven't\" (O'Connor, 2015;Christensen, 2016). Psycholinguistic research has found that various factors modulate the strength of the illusion, including the repeatability of the event described by the verb phrase, the subject form of the than-clause subject (e.g. \"... than the student has\" vs. \"...I have\"), as well as the number of that subject (e.g. \"I have\" vs. \"we have\") (Wellwood et al., 2018). There is also a claim arguing that the processing mechanism follows the noisy-channel predictions under an information-theoretic account (Zhang et al., 2023b).",
                    "We adapted the experimental materials with 32 items from Zhang et al. (2023b). 6 An example is in (2) where (2-a) is the canonical comparative illusion, (2-b) is the acceptable control, and (2-c) is the unacceptable one. 7 6 See Table 3 in the Appendix for the full paradigm. 7 The repeatability of the verb phrase is responsible for this "
                ],
                "publication_ref": [
                    "b30",
                    "b32",
                    "b3",
                    "b56"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Acceptability differentiation",
                "text": [
                    "We first ensured that LMs distinguish acceptable neighbors (2-b) of the illusion sentence from unacceptable ones (2-c). We ran statistical mixedeffects linear regression models on whole-sentence perplexity and the surprisal at the word have for the four language models. Either the perplexity or the surprisal was taken as the dependent variable with the condition \"acceptability\" as the fixed effect (reference level = the unacceptable condition, with a nonrepeatable verb phrase vs. the acceptable condition, with a repeatable verb phrase) and the random intercept of each item as the random effect. 8  Table 1 shows the estimated coefficient for the main effect of each mixed-effect model for each LM and each illusion phenomenon. A significant negative estimated coefficient suggests that acceptable sentences received lower perplexity/surprisal compared to the unacceptable ones, indicating that LMs distinguish sentences based on acceptability. Except for surprisal values from BERT and GPT-2, the other six statistical models indicate that the LMs capture the acceptability difference of baseline sentences for the comparative illusion."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_0"
                ]
            },
            {
                "heading": "Illusion effect",
                "text": [
                    "This task investigated whether language models pattern with humans in demonstrating illusion effects contrast, as it is more natural to say \"use Tiktok more often or frequent\" compared with \"install Tiktok more often\" when the action typically takes place once (in a while). 8 The model syntax in R was PPL/SURP \u223c acceptability + (1|item).",
                    "Figure 1: The y axis shows the coefficient estimates which represent the increase in perplexity/surprisal when the sentence is unacceptable compared to the illusion case, crossing three language illusions and four LMs. \"+\" marks a human-like behavior, in this case, an illusion effect where the unacceptable condition receives significantly higher perplexity/surprisal values than the illusion condition. \"*\" means that the estimated coefficient is significant.",
                    "with the basic comparative illusion construction. The contrast involves the illusion condition (2-a) with existing control conditions ((2-b) and (2-c)). The standardized metrics of the four LMs are displayed in Figure 6 in the Appendix. To evaluate whether LMs capture an illusion effect, we constructed another suite of statistical models across the four LMs and two metrics where the main effect has three levels -the illusion condition (reference), the acceptable condition, and the unacceptable condition -and the random effect included a random intercept for items. 9  We analyzed the coefficient estimates of the main effect of the unacceptable condition compared with the illusion condition. 10 An illusion effect would appear with higher perplexity/surprisal for the unacceptable condition compared to the illusion case. In other words, the estimated coefficients for the unacceptable condition should be significantly positive.",
                    "Figure 1 and Table 2 (in Appendix) display the estimated coefficients for the unacceptable condition compared with the illusion condition. For the comparative illusion, only BERT and RoBERTa measured by perplexity show a human-like illusion effect. Other LM-metric combinations indicate that the illusion condition was rated either the same or worse than the unacceptable condition (contrary to humans). 9 The model syntax in R was PPL/SURP \u223c condition + (1|item) where condition had three levels. 10 The coefficients for the acceptable condition generate similar conclusions. Further, no illusion sentences were rated better than acceptable ones.",
                    "Figure 2: Estimated coefficients for critical linguistic manipulations in comparative illusion. The y axis shows the estimated coefficients for the increase in perplexity/surprisal with respect to singular vs. plural thanclause subjects, or nonrepeatable vs. repeatable verb phrases, respectively. \"*\" means statistically significant contrasts; \"+\" means human-like results."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Sensitivity to manipulations",
                "text": [
                    "In this step, we evaluated whether language models were sensitive to sentence manipulations that affect human judgments. Three factors were investigated:",
                    "(1) than-clause subject structure (pronoun vs. NP), (2) subject number (singular vs. plural), and (3) verb repeatability (repeatable vs. nonrepeatable). For humans, plural than-clause subjects are more acceptable than singular ones only in the NP case. Overall, repeatable verbs are more acceptable than nonrepeatable ones (O'Connor, 2015;Wellwood et al., 2018;Zhang et al., 2023b).",
                    "Figure 2 displays the estimated coefficients for the main effects from the statistical models. 11  As for the subject number, when the than-clause subject was a pronoun, only BERT and GPT-2 (with perplexity) aligned with human-like behavior: there is no difference between singular and plural than-clause subjects. When it comes to NP subjects, all four LMs with both metrics showed human-like behavior where the singular NP subject was more unacceptable than the plural NP subject. As for repeatability, all four LMs captured this distinction in the pronoun condition but in the NP condition, only RoBERTa and GPT-3 achieved human-like results with perplexity.",
                    "In general, we only found partial overlap between LMs and humans. This indicates that even though LMs show some knowledge of acceptability for comparative structures, they might operate differently from humans when processing more subtle differences. None of the language models fully captured all the manipulations."
                ],
                "publication_ref": [
                    "b32",
                    "b56"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Depth-charge illusion",
                "text": [
                    "Consider the most famous depth-charge sentence No head injury is too trivial to be ignored (Wason and Reich, 1979). People overwhelmingly interpret it as meaning \"no matter how trivial head injuries are, we should not ignore them\", while the literal meaning is the opposite as \"we should ignore them\".",
                    "To understand the depth-charge sentence requires knowing meaning composition rules, multiple negation processing (Wason and Reich, 1979), adequate world knowledge reasoning (Paape et al., 2020), and the neighboring constructions of too...to such as so...that, so...as to and enough to... (Zhang et al., 2023a). Since existing research already shows that language models are quite limited in processing negation (e.g. Kassner and Sch\u00fctze, 2019;Ettinger, 2020), we speculate that LMs might encounter difficulty in the more complicated case of depth-charge sentences.",
                    "The evaluation materials were adapted from Zhang et al. (2023a) with 32 items. An example is (3) where we take the surprisal of the sentence-final word for comparison.",
                    "(3) a. (?) No head injury is too trivial to be ignored. (depth-charge sentence) b. Some head injury is too severe to be ignored. (plausible, acceptable) c. (#) Some head injury is too trivial to be ignored. (implausible, unacceptable)"
                ],
                "publication_ref": [
                    "b53",
                    "b53",
                    "b35",
                    "b18",
                    "b7"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Acceptability differentiation",
                "text": [
                    "Utilizing the same methodology as the comparative illusion, we found, as depicted in Table 1, that all combinations of LMs and metrics, except GPT-2 (perplexity), captured the acceptability difference between ((3-b)) and ((3-c)) with a significantly lower perplexity/surprisal for the acceptable sentences like (3-b)."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_0"
                ]
            },
            {
                "heading": "Illusion effect",
                "text": [
                    "Next, we studied if LMs \"experience\" the illusion effect by assigning lower perplexity/surprisal scores to the depth-charge sentence (3-a) compared to the unacceptable one (3-c).",
                    "Our statistical results show, in Figure 1 and Table 2 (Appendix), that only RoBERTa and GPT-3 demonstrated an illusion effect (for surprisal) by assigning a significantly higher score to the unacceptable control sentences. This means that it is not easy to \"trick\" LMs with the depth-charge illusion. Similar results have led concurrent work to suggest that LMs are better at deriving the literal meaning of a sentence, which is in sharp contrast with the overwhelming illusion effect from humans (Paape, 2023, a.o.)."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Sensitivity to manipulations",
                "text": [
                    "This task tested LMs' sensitivity to the plausibility contrast of three near-neighbor pairs of the depthcharge sentence. These pairs differ by the degree quantifier construction (too...to vs. so...as to vs. too...to not). 12 Competent language models should differentiate plausible sentences from implausible ones.",
                    "Figure 3 displays estimated coefficients of statistical models' main effect. We expect implausible sentences to receive higher perplexities/surprisals when the illusion occurs. 13 We find that LMs captured some of the distinctions in the too...to condition and the so...as to condition. However, im- 12 The full suite of paradigms is shown in Table 4 in the Appendix. 13 Iterating over sentence pairs, LMs, and metrics, we ran mixed-effects linear regression models on scores over the plausibility contrast (reference = plausible).",
                    "Figure 3: Estimated coefficients for the plausibility contrast (reference = plausible) in depth-charge illusions. The y axis shows the increase in perplexity/surprisal when the sentence is implausible vs. plausible. \"*\" means statistically significant contrasts; \"+\" means human-like behavior. While we see differences among LMs and metrics in the \"no...so...as to\" and the \"no...too...to\" conditions, the condition of \"no...too...to not\" yielded completely opposite results to humans.",
                    "plausible sentences with too...to not were rated as more acceptable than their plausible counterparts, which flouts what linguistic rules predict. 14 The fact that \"No head injury is too trivial to be treated\" and \"No head injury is too trivial to not be ignored\" generate opposite results while having the same meaning suggests LMs still struggled with negation, antonyms, and meaning composition (Kim and Linzen, 2020;She et al., 2023;Truong et al., 2023)."
                ],
                "publication_ref": [
                    "b21",
                    "b42",
                    "b48"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "NPI illusion",
                "text": [
                    "Negative polarity items and their licensing conditions have been investigated in prior work with language models. For a canonical NPI (e.g. ever, any) to be acceptable, it has to be in the scope of negation. 15 Existing computational research has shown that the syntactic dependency between the licensor and the NPI is captured by language models (Jumelet and Hupkes, 2018;Jumelet et al., 2021;Shin et al., 2023) but with more difficulty as compared to subject-verb agreement or other syntactic dependencies (Marvin and Linzen, 2018;Warstadt et al., 2019Warstadt et al., , 2020)). In this task, we expanded the suite of LMs and metrics and explored sensitivities to four types of licensors.",
                    "Our materials came from Orth et al. ( 2021) with 32 items. The essential triad is (4) where the illusion condition has the NPI ever not in the scope of the negation word no.",
                    "(4) a. (?) The hunter who no villager believed to be trustworthy will ever shoot a bear. (NPI illusion) b. No hunter who the villager believed to be trustworthy will ever shoot a bear.",
                    "(Matrix No, acceptable) c. (*) The hunter who the villager believed to be trustworthy will ever shoot a bear. (Licensor Absent, unacceptable)"
                ],
                "publication_ref": [
                    "b17",
                    "b16",
                    "b43",
                    "b28",
                    "b52"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Acceptability differentiation",
                "text": [
                    "Table 1 shows that all the four LMs could capture the acceptability difference of control sentences (4-b) and (4-c) (with both metrics)."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_0"
                ]
            },
            {
                "heading": "Illusion effect",
                "text": [
                    "Figure 1 and Table 2 show that only in the case of surprisal did we see an illusion effect where the unacceptable sentences (e.g. (4-c)) received significantly higher surprisals than the illusion sentence (e.g., (4-a)). This finding replicates Shin et al. (2023) in that, for the illusion condition ((4-a)) where no linearly precedes ever but is in an unlicensing position, ever incurs higher surprisal. It is interesting to see the sharp discrepancy between surprisal and perplexity, which we leave to Section 7.4 for discussion."
                ],
                "publication_ref": [
                    "b43"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Sensitivity to variations",
                "text": [
                    "The linguistic manipulations we explored concern the illusion effect in the illusion condition with different NPI licensors. Among the ones we tested, didn't, did not, and never, 16 human research shows that none of these triggers illusion effects (Orth et al., 2021;cf. Vasishth et al., 2008). Iterating over licensors, LMs, and metrics, we ran statistical models with the same structure in Section 6.2. We plotted the estimated coefficients of the unacceptable main effect in Figure 4 and predicted that a significantly positive coefficient indicates an illusion effect. Contrary to human-like behavior, for all three licensors there were some LM-metric combinations that indicate an illusion The y axis shows the increase in perplexity/surprisal when the sentence is ungrammatical vs. is in the illusion condition. \"+\" marks an illusion effect while none of the three licensors should trigger an illusion effect according to human behavior; \"*\" means a significant contrast.",
                    "effect: for the licensor did not, RoBERTa (perplexity) and GPT-2 (perplexity) show an illusion effect; for didn't, all four LMs with perplexity show an illusion effect; for never, all four LMs with surprisal, plus RoBERTa with perplexity, show an illusion effect. This pattern shows that with NPI illusions, LMs are more easily tricked than humans."
                ],
                "publication_ref": [
                    "b33"
                ],
                "figure_ref": [
                    "fig_1"
                ],
                "table_ref": []
            },
            {
                "heading": "Discussion",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Illusion effect",
                "text": [
                    "Successful language processing requires a dynamic integration of lexical knowledge, grammatical knowledge, logical reasoning, and world knowledge, among other cognitive abilities and sources of knowledge. An illusion effect in humans where unacceptable sentences receive unexpectedly high acceptability presents a unique case where the comprehender might prioritize different processing mechanisms or linguistic constraints for meaning inference over those employed for common processing. Studying how language models process language illusions helps us understand (1) from a superficial level, whether LMs appear to be humanlike -circumventing some grammatical facts and reaching a good-enough sentence representation, and (2) from a deeper level, whether LMs employ the same set of resources and abilities to process a sentence (i.e. whether they can serve as cognitive models).",
                    "In this research, we aim for the first level of un-derstanding. By studying four language models' acceptability judgments of three language illusions, we found that LMs were good at the basic acceptability differentiation task and yet no LMs showed consistent human-like illusion effects among three illusion phenomena by any metric (Figure 5). We conclude from this result that LMs might not be a good cognitive model of human language processing. With this said, we do observe a divergence between the comparative/depth-charge illusion and the NPI illusion -it seems more likely for LMs to be tricked by the NPI illusion compared to the former two. Since the NPI illusion is more relevant to the hierarchical structure of language whereas both the comparative illusion and depth-charge illusion emphasize semantic nuances, we tentatively conclude that LMs are more easily tricked by syntactic illusion rather than semantic illusions."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_2"
                ],
                "table_ref": []
            },
            {
                "heading": "Human-like behaviors & Potential processing mechanisms",
                "text": [
                    "For both the comparative illusion and depth-charge illusion, the illusion effect test did not show humanlike behavior. This could either mean that LMs strictly abide by linguistic rules to compose the language literally or that LMs have trouble understanding this complicated set of sentences overall.",
                    "For the comparative illusion, the sensitivity task (Section 4.3) suggests that they might have some capacity to process comparative structures. For the depth-charge illusion, that LMs seem to have trouble understanding the literal contrast between plausible/implausible pairs (Section 5.3) suggests sentences involving multiple negations could pose a challenge to LMs. The two cases indicate we still need to develop more robust evaluations to gauge LMs' semantic capabilities in various semantic domains.",
                    "For the NPI illusion, the interpretation could be more complicated. On one hand, the illusion test for the licensor no yields human-like results (with surprisal) but other licensors also elicit non-humanlike illusion effect (cf. Orth et al., 2021). On the other hand, the discrepancy between sentence perplexity and surprisal makes it difficult to conclude to what degree LMs and humans overlap (cf. Shin et al., 2023).",
                    "Ultimately, we want to address whether LMs are like humans that utilize not only grammatical rules but also contexts, frequencies, and semantic priors to rationally process language, or LMs are like grammarians that interpret string inputs in a strict compositional manner. Our investigation does not yield consistent results given the three language illusions but the behavioral inconsistency suggests that language models are far from being a cognitive model of human language."
                ],
                "publication_ref": [
                    "b33",
                    "b43"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Language models' performance in general",
                "text": [
                    "All four language models performed on par with each other. If we tallied the number of tests where LMs reported expected results from Figure 5 and averaged between perplexity and surprisal, we have a ranking order from RoBERTa (N=10) and GPT-3 (N=9), to BERT (N=8.5) and GPT-2 (N=8). The successors of both the masked language model and the autoregressive model perform better than their predecessors."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_2"
                ],
                "table_ref": []
            },
            {
                "heading": "Perplexity & Surprisal",
                "text": [
                    "It is surprising to see that the two widely used probability-based metrics can generate different results for a given hypothesis and a given language model. Future work should (i) investigate both mathematically and practically why the difference could occur and (ii) check if better definitions for the critical regions exist to capture surprisals. Future evaluation work that utilizes one metric should be mindful of the intrinsic limitations of that metric."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Limitations",
                "text": [
                    "Considering the research methodology, acceptability judgment tasks (even with carefully controlled minimal pairs) are indirect measures of language comprehension and it is hard to infer the exact interpretation based on probability-based measures. Further studies should work on direct comprehension measures (e.g. generating paraphrases) that reveal LMs' hidden knowledge."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Conclusion",
                "text": [
                    "We tested four language models' ability to process three language illusions and asked (1) whether they judge unacceptable illusion sentences to be more acceptable as humans (termed an illusion effect) and (2) whether they are sensitive to linguistic manipulations that modulate human judgments. Our results are based on whole-sentence perplexity and critical word surprisal. We show that none of the LMs demonstrated consistent illusion effects or exhibited overall human-like judgment behaviors. We conclude that given the case of language illusions, language models neither behave like humans with full sets of cognitive abilities and error-prone behavior nor possess the necessary linguistic knowledge for error-free, literal sentence processing. Language models cannot be viewed as cognitive models of language processing, which makes understanding them even more intriguing."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Acknowledgements",
                "text": [
                    "We thank the three anonymous reviewers for their helpful feedback. We thank Ankana Saha, Carina Kauf and Hayley Ross for the helpful discussion about the project."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Illusion type",
                "text": [
                    "BERT RoBERTa GPT-2 GPT-3 PPL Surp PPL Surp PPL Surp PPL Surp Comparative 0.43 -0.07 0.45 -0.22 -0.33 -0.08 0.15 -0.04 Depth-charge -0.61 -0.01 -0.20 0.28 -0.41 -0.01 0.12 0.90 NPI -0.87 0.27 -0.21 0.54 -0.79 0.48 -0.70 0.41",
                    "Illusion sentences are more acceptable than unacceptable sentences.",
                    "The unacceptable sentences are more acceptable than illusion sentences. No significant difference between the two conditions.  No head injury is too trivial to not be ignored. too...to not implausible No head injury is too trivial to not be treated. so...as to plausible No head injury is so trivial as to be ignored. so...as to implausible No head injury is so trivial as to be treated. No hunter who the villager believed to be trustworthy will ever shoot a bear. Licensor Absent The hunter who the villager believed to be trustworthy will ever shoot a bear."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Relative No",
                "text": [
                    "The hunter who no villager believed to be trustworthy will ever shoot a bear. Relative Didn't",
                    "The hunter who didn't believe the villager to be trustworthy will ever shoot a bear. Relative Did not The hunter who did not believe the villager to be trustworthy will ever shoot a bear."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Relative Never",
                "text": [
                    "The hunter who never believed the villager to be trustworthy will ever shoot a bear.  "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            }
        ],
        "references": [
            {
                "ref_id": "b0",
                "title": "Syntactic Surprisal From Neural Models Predicts, But Underestimates, Human Processing Difficulty From Syntactic Ambiguities",
                "journal": "Association for Computational Linguistics",
                "year": "2022",
                "authors": "Suhas Arehalli; Brian Dillon; Tal Linzen"
            },
            {
                "ref_id": "b1",
                "title": "Broken agreement",
                "journal": "Cognitive psychology",
                "year": "1991",
                "authors": "Kathryn Bock;  Miller"
            },
            {
                "ref_id": "b2",
                "title": "Language models are fewshot learners",
                "journal": "",
                "year": "2020",
                "authors": "Tom Brown; Benjamin Mann; Nick Ryder; Melanie Subbiah; Jared D Kaplan; Prafulla Dhariwal; Arvind Neelakantan; Pranav Shyam; Girish Sastry; Amanda Askell"
            },
            {
                "ref_id": "b3",
                "title": "Let us have articles betwixt us-Papers in Historical and Comparative Linguistics in Honour",
                "journal": "",
                "year": "2016",
                "authors": "Ken Ramsh\u00f8j Christensen"
            },
            {
                "ref_id": "b4",
                "title": "Incremental Processing of Principle B: Mismatches Between Neural Models and Humans",
                "journal": "Association for Computational Linguistics",
                "year": "2022",
                "authors": "Forrest Davis"
            },
            {
                "ref_id": "b5",
                "title": "Discourse structure interacts with reference but not syntax in neural language models",
                "journal": "Online. Association for Computational Linguistics",
                "year": "2020",
                "authors": "Forrest Davis; Marten Van Schijndel"
            },
            {
                "ref_id": "b6",
                "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
                "journal": "",
                "year": "2019",
                "authors": "Jacob Devlin; Ming-Wei Chang; Kenton Lee; Kristina Toutanova"
            },
            {
                "ref_id": "b7",
                "title": "What BERT Is Not: Lessons from a New Suite of Psycholinguistic Diagnostics for Language Models. Transactions of the Association for Computational Linguistics",
                "journal": "MIT Press",
                "year": "2020",
                "authors": "Allyson Ettinger; ; Cambridge; M A Publisher"
            },
            {
                "ref_id": "b8",
                "title": "Good-Enough Representations in Language Comprehension",
                "journal": "Current Directions in Psychological Science",
                "year": "2002",
                "authors": "Fernanda Ferreira; G D Karl; Vittoria Bailey;  Ferraro"
            },
            {
                "ref_id": "b9",
                "title": "Lossy-Context Surprisal: An Information-Theoretic Model of Memory Effects in Sentence Processing",
                "journal": "Cognitive Science",
                "year": "2020",
                "authors": "Richard Futrell; Edward Gibson; Roger P Levy"
            },
            {
                "ref_id": "b10",
                "title": "Neural language models as psycholinguistic subjects: Representations of syntactic state",
                "journal": "",
                "year": "2019",
                "authors": "Richard Futrell; Ethan Wilcox; Takashi Morita; Peng Qian; Miguel Ballesteros; Roger Levy"
            },
            {
                "ref_id": "b11",
                "title": "Negative and positive polarity items. Semantics-Sentence and information structure",
                "journal": "",
                "year": "2019",
                "authors": "Anastasia Giannakidou; Claudia Klaus Von Heusinger; Paul Maienborn;  Portner"
            },
            {
                "ref_id": "b12",
                "title": "Rational integration of noisy evidence and prior semantic expectations in sentence interpretation",
                "journal": "Proceedings of the National Academy of Sciences",
                "year": "2013",
                "authors": "Edward Gibson; Leon Bergen; Steven T Piantadosi"
            },
            {
                "ref_id": "b13",
                "title": "Errors in Linguistic Performance: Slips of the Tongue, Ear, Pen, and Hand. The journal of nervous and mental disease",
                "journal": "",
                "year": "1983",
                "authors": "Herbert S Gross"
            },
            {
                "ref_id": "b14",
                "title": "A resource-rational model of human processing of recursive linguistic structure",
                "journal": "",
                "year": "2022",
                "authors": "Michael Hahn; Richard Futrell; Roger Levy; Edward Gibson"
            },
            {
                "ref_id": "b15",
                "title": "A systematic assessment of syntactic generalization in neural language models",
                "journal": "Online. Association for Computational Linguistics",
                "year": "2020",
                "authors": "Jennifer Hu; Jon Gauthier; Peng Qian; Ethan Wilcox; Roger Levy"
            },
            {
                "ref_id": "b16",
                "title": "Language Models Use Monotonicity to Assess NPI Licensing",
                "journal": "Online. Association for Computational Linguistics",
                "year": "2021",
                "authors": "Jaap Jumelet; Milica Denic; Jakub Szymanik; Dieuwke Hupkes; Shane Steinert-Threlkeld"
            },
            {
                "ref_id": "b17",
                "title": "Do Language Models Understand Anything? On the Ability of LSTMs to Understand Negative Polarity Items",
                "journal": "Association for Computational Linguistics",
                "year": "2018",
                "authors": "Jaap Jumelet; Dieuwke Hupkes"
            },
            {
                "ref_id": "b18",
                "title": "Negated LAMA: birds cannot fly",
                "journal": "",
                "year": "2019",
                "authors": "Nora Kassner; Hinrich Sch\u00fctze"
            },
            {
                "ref_id": "b19",
                "title": "A Better Way to Do Masked Language Model Scoring",
                "journal": "Association for Computational Linguistics",
                "year": "2023",
                "authors": "Carina Kauf; Anna Ivanova"
            },
            {
                "ref_id": "b20",
                "title": "Event knowledge in large language models: the gap between the impossible and the unlikely",
                "journal": "",
                "year": "2022",
                "authors": "Carina Kauf; Anna A Ivanova; Giulia Rambelli; Emmanuele Chersoni; S Jingyuan; Zawad She; Evelina Chowdhury; Alessandro Fedorenko;  Lenci"
            },
            {
                "ref_id": "b21",
                "title": "COGS: A compositional generalization challenge based on semantic interpretation",
                "journal": "",
                "year": "2020",
                "authors": "Najoung Kim; Tal Linzen"
            },
            {
                "ref_id": "b22",
                "title": "Grammaticality, Acceptability, and Probability: A Probabilistic View of Linguistic Knowledge",
                "journal": "Cognitive Science",
                "year": "2017",
                "authors": "Alexander Jey Han Lau; Shalom Clark;  Lappin"
            },
            {
                "ref_id": "b23",
                "title": "Can language models capture syntactic associations without surface cues? a case study of reflexive anaphor licensing in English control constructions",
                "journal": "",
                "year": "2022",
                "authors": "Sebastian Soo-Hwan Lee;  Schuster"
            },
            {
                "ref_id": "b24",
                "title": "A noisy-channel model of rational human sentence comprehension under uncertain input",
                "journal": "Association for Computational Linguistics",
                "year": "2008",
                "authors": "Roger Levy"
            },
            {
                "ref_id": "b25",
                "title": "Assessing the Ability of LSTMs to Learn Syntax-Sensitive Dependencies",
                "journal": "Transactions of the Association for Computational Linguistics",
                "year": "2016",
                "authors": "Tal Linzen; Emmanuel Dupoux; Yoav Goldberg"
            },
            {
                "ref_id": "b26",
                "title": "",
                "journal": "RoBERTa: A Robustly Optimized BERT Pretraining Approach",
                "year": "2019",
                "authors": "Yinhan Liu; Myle Ott; Naman Goyal; Jingfei Du; Mandar Joshi; Danqi Chen; Omer Levy; Mike Lewis; Luke Zettlemoyer; Veselin Stoyanov"
            },
            {
                "ref_id": "b27",
                "title": "Dissociating language and thought in large language models: a cognitive perspective",
                "journal": "",
                "year": "2023",
                "authors": "Kyle Mahowald; Anna A Ivanova; A Idan; Nancy Blank; Joshua B Kanwisher; Evelina Tenenbaum;  Fedorenko"
            },
            {
                "ref_id": "b28",
                "title": "Targeted syntactic evaluation of language models",
                "journal": "Association for Computational Linguistics",
                "year": "2018",
                "authors": "Rebecca Marvin; Tal Linzen"
            },
            {
                "ref_id": "b29",
                "title": "RuCoLA: Russian corpus of linguistic acceptability",
                "journal": "",
                "year": "2022",
                "authors": "Vladislav Mikhailov; Tatiana Shamardina; Max Ryabinin; Alena Pestova; Ivan Smurov; Ekaterina Artemova"
            },
            {
                "ref_id": "b30",
                "title": "After binding: On the interpretation of pronouns",
                "journal": "",
                "year": "1984",
                "authors": "Mario M Montalbetti"
            },
            {
                "ref_id": "b31",
                "title": "Contextualized Word Embeddings Encode Aspects of Human-Like Word Sense Knowledge",
                "journal": "",
                "year": "2020",
                "authors": "Sathvik Nair; Mahesh Srinivasan; Stephan Meylan"
            },
            {
                "ref_id": "b32",
                "title": "Comparative illusions at the syntax-semantics interface",
                "journal": "",
                "year": "2015",
                "authors": "O' Ellen;  Connor"
            },
            {
                "ref_id": "b33",
                "title": "Negative polarity item (NPI) illusion is a quantification phenomenon",
                "journal": "Journal of Experimental Psychology: Learning, Memory, and Cognition",
                "year": "2021",
                "authors": "Wesley Orth; Masaya Yoshida; Shayne Sloggett"
            },
            {
                "ref_id": "b34",
                "title": "When Transformer models are more compositional than humans: The case of the depth charge illusion. Experiments in Linguistic Meaning",
                "journal": "",
                "year": "2023",
                "authors": "Dario Paape"
            },
            {
                "ref_id": "b35",
                "title": "Quadruplex negatio invertit? The on-line processing of depth charge sentences",
                "journal": "Journal of Semantics",
                "year": "2020",
                "authors": "Dario Paape"
            },
            {
                "ref_id": "b36",
                "title": "Recurrent babbling: Evaluating the acquisition of grammar from limited input data",
                "journal": "Online. Association for Computational Linguistics",
                "year": "2020",
                "authors": "Ludovica Pannitto; Aur\u00e9lie Herbelot"
            },
            {
                "ref_id": "b37",
                "title": "Negative polarity illusions and the format of hierarchical encodings in memory",
                "journal": "Cognition",
                "year": "2016",
                "authors": "Dan Parker; Colin Phillips"
            },
            {
                "ref_id": "b38",
                "title": "Grammatical illusions and selective fallibility in real-time language comprehension",
                "journal": "Experiments at the Interfaces",
                "year": "2011",
                "authors": "Colin Phillips; Matthew W Wagers; Ellen F Lau"
            },
            {
                "ref_id": "b39",
                "title": "Language models are unsupervised multitask learners",
                "journal": "OpenAI blog",
                "year": "2019",
                "authors": "Alec Radford; Jeffrey Wu; Rewon Child; David Luan; Dario Amodei; Ilya Sutskever"
            },
            {
                "ref_id": "b40",
                "title": "Masked language model scoring",
                "journal": "Online. Association for Computational Linguistics",
                "year": "2020",
                "authors": "Julian Salazar; Davis Liang; Toan Q Nguyen; Katrin Kirchhoff"
            },
            {
                "ref_id": "b41",
                "title": "The neural architecture of language: Integrative modeling converges on predictive processing",
                "journal": "Proceedings of the National Academy of Sciences",
                "year": "2021",
                "authors": "Martin Schrimpf; Asher Idan; Greta Blank; Carina Tuckute;  Kauf; A Eghbal; Nancy Hosseini; Joshua B Kanwisher; Evelina Tenenbaum;  Fedorenko"
            },
            {
                "ref_id": "b42",
                "title": "Scone: Benchmarking negation reasoning in language models with fine-tuning and in-context learning",
                "journal": "",
                "year": "2023",
                "authors": "Jingyuan Selena She; Christopher Potts; R Samuel; Atticus Bowman;  Geiger"
            },
            {
                "ref_id": "b43",
                "title": "Investigating a neural language model's replicability of psycholinguistic experiments: A case study of NPI licensing",
                "journal": "Frontiers in Psychology",
                "year": "2023",
                "authors": "Unsub Shin; Eunkyung Yi; Sanghoun Song"
            },
            {
                "ref_id": "b44",
                "title": "JBLiMP: Japanese benchmark of linguistic minimal pairs",
                "journal": "Association for Computational Linguistics",
                "year": "2023",
                "authors": "Taiga Someya; Yohei Oseki"
            },
            {
                "ref_id": "b45",
                "title": "SLING: Sino linguistic evaluation of large language models",
                "journal": "",
                "year": "2022",
                "authors": "Yixiao Song; Kalpesh Krishna; Rajesh Bhatt; Mohit Iyyer"
            },
            {
                "ref_id": "b46",
                "title": "The curious case of control",
                "journal": "",
                "year": "2022",
                "authors": "Elias Stengel-Eskin; Benjamin Van Durme"
            },
            {
                "ref_id": "b47",
                "title": "Empirical evidence in research on meaning",
                "journal": "",
                "year": "2015",
                "authors": "Judith Tonhauser; Lisa Matthewson"
            },
            {
                "ref_id": "b48",
                "title": "Language models are not naysayers: An analysis of language models on negation benchmarks",
                "journal": "",
                "year": "2023",
                "authors": "Hung Thinh; Timothy Truong; Karin Baldwin; Trevor Verspoor;  Cohn"
            },
            {
                "ref_id": "b49",
                "title": "Single-Stage Prediction Models Do Not Explain the Magnitude of Syntactic Disambiguation Difficulty",
                "journal": "",
                "year": "2021",
                "authors": "Marten Van Schijndel; Tal Linzen"
            },
            {
                "ref_id": "b50",
                "title": "Processing polarity: How the ungrammatical intrudes on the grammatical",
                "journal": "Cognitive Science",
                "year": "2008",
                "authors": "Shravan Vasishth; Sven Br\u00fcssow; Richard L Lewis; Heiner Drenhaus"
            },
            {
                "ref_id": "b51",
                "title": "Jereti\u010d, and Samuel R. Bowman. 2019. Investigating BERT's Knowledge of Language: Five Analysis Methods with NPIs",
                "journal": "",
                "year": "",
                "authors": "Alex Warstadt; Yu Cao; Ioana Grosu; Wei Peng; Hagen Blix; Yining Nie; Anna Alsop; Shikha Bordia; Haokun Liu; Alicia Parrish; Sheng-Fu Wang"
            },
            {
                "ref_id": "b52",
                "title": "BLiMP: The Benchmark of Linguistic Minimal Pairs for English",
                "journal": "Transactions of the Association for Computational Linguistics",
                "year": "2020",
                "authors": "Alex Warstadt; Alicia Parrish; Haokun Liu; Anhad Mohananey; Wei Peng; Sheng-Fu Wang; Samuel R Bowman"
            },
            {
                "ref_id": "b53",
                "title": "A Verbal Illusion",
                "journal": "Quarterly Journal of Experimental Psychology",
                "year": "1979",
                "authors": "C Peter; Shuli S Wason;  Reich"
            },
            {
                "ref_id": "b54",
                "title": "Frequency Effects on Syntactic Rule Learning in Transformers",
                "journal": "Association for Computational Linguistics",
                "year": "2021",
                "authors": "Jason Wei; Dan Garrette; Tal Linzen; Ellie Pavlick"
            },
            {
                "ref_id": "b55",
                "title": "Construction grammar provides unique insight into neural language models",
                "journal": "Association for Computational Linguistics",
                "year": "2023",
                "authors": "Leonie Weissweiler; Taiqi He; Naoki Otani; David R Mortensen; Lori Levin; Hinrich Sch\u00fctze"
            },
            {
                "ref_id": "b56",
                "title": "The Anatomy of a Comparative Illusion",
                "journal": "Journal of Semantics",
                "year": "2018",
                "authors": "Alexis Wellwood; Roumyana Pancheva; Valentine Hacquard; Colin Phillips"
            },
            {
                "ref_id": "b57",
                "title": "What do RNN Language Models Learn about Filler-Gap Dependencies?",
                "journal": "",
                "year": "2018",
                "authors": "Ethan Wilcox; Roger Levy; Takashi Morita; Richard Futrell"
            },
            {
                "ref_id": "b58",
                "title": "Transformers: State-of-the-Art Natural Language Processing",
                "journal": "Association for Computational Linguistics",
                "year": "2020",
                "authors": "Thomas Wolf; Lysandre Debut; Victor Sanh; Julien Chaumond; Clement Delangue; Anthony Moi; Pierric Cistac; Tim Rault; Remi Louf; Morgan Funtowicz; Joe Davison; Sam Shleifer; Clara Patrick Von Platen; Yacine Ma; Julien Jernite; Canwen Plu; Teven Le Xu; Sylvain Scao; Mariama Gugger; Quentin Drame; Alexander Lhoest;  Rush"
            },
            {
                "ref_id": "b59",
                "title": "Illusory licensing effects across dependency types: ERP evidence",
                "journal": "Brain and Language",
                "year": "2009",
                "authors": "M Xiang; C Dillon;  Phillips"
            },
            {
                "ref_id": "b60",
                "title": "Representing affect information in word embeddings",
                "journal": "",
                "year": "2022",
                "authors": "Yuhan Zhang; Wenqi Chen; Ruihan Zhang; Xiajie Zhang"
            },
            {
                "ref_id": "b61",
                "title": "",
                "journal": "",
                "year": "",
                "authors": "Yuhan Zhang; Carina Kauf; Edward Gibson"
            },
            {
                "ref_id": "b62",
                "title": "2023b. a noisy-channel explanation of the comparative illusion. Architectures and Mechanisms for Language Processing",
                "journal": "",
                "year": "",
                "authors": "Yuhan Zhang; Carina Kauf; Edward Gibson"
            }
        ],
        "figures": [
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_0",
                "figure_caption": "teenagers have used Tiktok than I have. (illusion) b. Many teenagers have used Tiktok more than I have. (acceptable) c. (#) Many teenagers have installed Tiktok more than I have. (unacceptable)",
                "figure_data": ""
            },
            {
                "figure_label": "4",
                "figure_type": "figure",
                "figure_id": "fig_1",
                "figure_caption": "Figure 4 :4Figure 4: Estimated coefficients for the illusion effect (unacceptable vs. illusion = reference) in NPI illusions.The y axis shows the increase in perplexity/surprisal when the sentence is ungrammatical vs. is in the illusion condition. \"+\" marks an illusion effect while none of the three licensors should trigger an illusion effect according to human behavior; \"*\" means a significant contrast.",
                "figure_data": ""
            },
            {
                "figure_label": "5",
                "figure_type": "figure",
                "figure_id": "fig_2",
                "figure_caption": "Figure 5 :5Figure 5: Language models' performance on all three illusions. \u2713means LMs show human-like behavior.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "",
                "figure_caption": "",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "",
                "figure_caption": "",
                "figure_data": ""
            },
            {
                "figure_label": "1",
                "figure_type": "table",
                "figure_id": "tab_0",
                "figure_caption": "Estimated coefficients of the main effect (acceptable sentence condition vs. unacceptable condition (reference)) for each statistical model. If LMs rate acceptable sentences as more acceptable, the coefficients for perplexity or surprisal should be significantly negative. Cells color-coded in blue represent statistical significance level (p < .05) in the expected direction. White cells represent an insignificant main effect. In other words, blue cells indicate the statistical model output supports LMs' ability to distinguish sentences based on linguistic acceptability.",
                "figure_data": "Illusion typeitemBERTRoBERTaGPT-2GPT-3PPLSurpPPLSurpPPLSurpPPLSurpComparative32-0.36 -0.001-0.56-0.09-0.22 -0.05-0.30-0.25Depth-charge32-0.37-0.15-0.61-0.45-0.12-0.41 -0.37-0.98NPI32-0.26-2.46-0.71-2.60-0.21-1.73 -0.29-2.55tive to illusion-specific linguistic manipula-tions that affect human judgments. A greaterdegree of sensitivity indicates that the cor-responding linguistic knowledge and howthe knowledge affects sentence acceptabilitycould be encoded in or learned by LMs. Thisallowed us to draw a fine-grained comparisonbetween humans and LMs. If language mod-els are insensitive, that indicates a differencebetween humans and LMs."
            }
        ],
        "formulas": [
            {
                "formula_id": "formula_0",
                "formula_text": "Surp(w i ) = \u2212log Prob(w i |w 1 ...w i\u22121 ) (1)",
                "formula_coordinates": [
                    3.0,
                    96.7,
                    488.0,
                    193.16,
                    11.86
                ]
            },
            {
                "formula_id": "formula_1",
                "formula_text": "2 1 N N i=1 Surp(w i )(2)",
                "formula_coordinates": [
                    3.0,
                    141.42,
                    536.15,
                    148.45,
                    14.46
                ]
            }
        ],
        "doi": "10.1016/0010-0285(91)90003-7"
    },
    "Investigating the Nature of Disagreements on Mid-Scale Ratings: A Case Study on the Abstractness-Concreteness Continuum": {
        "authors": "Urban Knuple\u0161; Diego Frassinelli; Sabine Schulte Im Walde",
        "pub_date": "",
        "abstract": "Humans tend to strongly agree on ratings on a scale for extreme cases (e.g., a CAT is judged as very concrete), but judgements on mid-scale words exhibit more disagreement. Yet, collected rating norms are heavily exploited across disciplines. Our study focuses on concreteness ratings and (i) implements correlations and supervised classification to identify salient multimodal characteristics of mid-scale words, and (ii) applies a hard clustering to identify patterns of systematic disagreement across raters. Our results suggest to either fine-tune or filter midscale target words before utilising them.",
        "sections": [
            {
                "heading": "Motivation",
                "text": [
                    "Across disciplines, researchers have collected and exploited human judgements on semantic variables such as concreteness, compositionality, emotional valence, and plausibility. Traditionally, those judgements are collected as a degree on a continuum between extremes. While humans tend to strongly agree on their ratings for extremes (e.g., a CAT is typically judged as extremely concrete; GLORY as extremely abstract; the compound CROCODILE TEARS as extremely non-compositional; WAR as extremely negative), we find considerable disagreement regarding human mid-range ratings, i.e., judging about semi-concreteness, semi-compositionality, seminegativity. Presumably, conceptual semi-properties are not easily graspable, thus generating stronger disagreement among raters. Nevertheless, the collected norms are heavily exploited in state-of-theart computational approaches, where the respective knowledge represents a crucial task-related component (such as concreteness information for figurative language detection, and emotional valence for sentiment analysis).",
                    "The current study provides a series of analyses on human mid-scale ratings, while focusing on the most prominent collection of concreteness ratings for English words (Brysbaert et al., 2014), henceforth Brysbaert norms. As basis for the Brysbaert norms, humans were asked to judge the concreteness (in contrast to abstractness) of English words on a 5-point rating scale from 1 (abstract) to 5 (concrete) regarding how strongly the participants thought the meanings of the targets can(not) be experienced directly through their five senses. Figure 1 illustrates the distribution of the mean concreteness ratings and standard deviations (SDs) across 25 raters and for the three word classes of nouns, verbs, and adjectives. These croissant 1 plots for ratings on a scale can exhibit \"only a finite number of possible combinations of means and standard deviations\" (Pollock, 2018): humans tend to agree on the extremes (\u2192 low SD) and to disagree on intermediate semi-values (\u2192 high SD).",
                    "In a first set of experiments, we analyse multimodal characteristics of the concreteness of target nouns in the Brysbaert norms (we provide additional materials for verbs and adjectives in the Appendix): perception strength for specific senses (auditory, gustatory, haptic, olfactory, visual), emotional dimensions (valence, affect, dominance), lexical properties (frequency, ambiguity) and association types as indicators of meaning diversity. We start with a holistic perspective via correlations between targets' concreteness and their characteristics, and then zoom into differences for words with mid-scale vs. extremely concrete/abstract mean concreteness ratings, by applying supervised classification and feature analyses. In a second set of experiments, we hypothesise that mid-scale ratings are due to different combinations of individual human judgements across the scale. We thus rely on the original per-participant ratings (i.e., 25 ratings per target) and apply exploratory cluster analyses to identify patterns of disagreement between the individual raters of targets with mid-scale ratings. 1 We use this term due to the shape of the distribution plots. Our contributions in this paper are two-fold. (i) We identify a range of target word characteristics that overall correlate with their degrees of concreteness ratings in different directions, and more specifically differ for mid-scale and extremely concrete or abstract target words. (ii) We identify a range of systematic disagreement patterns that clearly differ across target words with mid-scale mean ratings, thus pointing out fine-grained differences in judgements on semi-perception and suggesting to either filter or fine-tune mid-scale target words before utilising them in computational approaches.",
                    "In the remainder of this paper, we introduce previous related work (Section 2) and our concreteness targets (Section 3); we then report our analyses regarding general and mid-scale target characteristics (Section 4) and mid-scale disagreement patterns (Section 5)."
                ],
                "publication_ref": [
                    "b7",
                    "b33"
                ],
                "figure_ref": [
                    "fig_0"
                ],
                "table_ref": []
            },
            {
                "heading": "Related Work",
                "text": [
                    "Collecting human judgements on a rating scale is a popular means of constructing concept-specific datasets across languages, research disciplines and (computational) linguistics tasks. Prominent example tasks and collections targeting semantic variables include compositionality ratings for compound-constituent relatedness (Reddy et al., 2011;Schulte im Walde et al., 2016;Cordeiro et al., 2019;Gagn\u00e9 et al., 2019;G\u00fcnther et al., 2020, i.a.), affect ratings such as valence, arousal, dominance, emotion (Kanske and Kotz, 2010;K\u00f6per and Schulte im Walde, 2016a;Mohammad, 2018, i.a.), plausibility ratings (Wang et al., 2018;Eichel and Schulte Im Walde, 2023, i.a.), and concreteness ratings (Spreen and Schulz, 1966;Paivio et al., 1968;Algarabel et al., 1988;Della Rosa et al., 2010;Brysbaert et al., 2014;K\u00f6per and Schulte im Walde, 2016a;Bonin et al., 2018;Muraki et al., 2022, i.a.).",
                    "As a main motivation for collecting general conceptional ratings on a scale, Keuleers and Balota (2015) state that there is \"no reason for words to be rated for every single experiment\". Still, researchers across disciplines have pointed out problematic aspects of rating norms, because their reliability is unclear, especially when ratings have been collected via crowdsourcing or extrapolation (Keuleers and Balota, 2015;Mandera et al., 2015). Pollock (2018) describes the typical shape of ratings on a scale, pointing out that the mid-range concepts are the least agreed upon, and that the interpretation of the corresponding ratings conflates semi-properties and genuine disagreements. A midscale score in concreteness could thus refer to an average semi-perception (whatever this means), or to a specific semi-sense, such as vision, haptics, etc., as well as to disagreement about perceptual strength, or a combination of the above. Furthermore, many conceptual ratings have been collected by presenting the word in isolation without reference to the respective word class and out of context. For example, the Brysbaert norms rely on isolated target presentation, and part-of-speech information was added post-hoc from the SUBTLEX-US corpus (Brysbaert et al., 2012). Muraki et al. (2022) used the same setup as Brysbaert et al. (2014) but for multiword expressions, in which case part-ofspeech ambiguity did not arise, but the targets were also presented out of context. Despite these problems, ratings on a scale still remain the major strategy to collect human judgements on degrees of semantic variables, while alternatives such as best-worst scaling are available (Kiritchenko and Mohammad, 2017;Abdalla et al., 2023). The resulting norms are heavily exploited in state-of-the-art computational approaches; e.g., emotion and concreteness norms represent a crucial component in systems to detect figurative lan-guage usage (Turney et al., 2011;Tsvetkov et al., 2014;K\u00f6per and Schulte im Walde, 2016b;Mohammad et al., 2016;Aedmaa et al., 2018;K\u00f6per and Schulte im Walde, 2018;Maudslay et al., 2020). The current study encourages researchers to distinguish between degrees of (dis)agreement of such norms, and to identify a meaningful way of exploitation, in particular for mid-scale ratings."
                ],
                "publication_ref": [
                    "b34",
                    "b38",
                    "b8",
                    "b15",
                    "b18",
                    "b45",
                    "b40",
                    "b32",
                    "b2",
                    "b11",
                    "b7",
                    "b5",
                    "b23",
                    "b33",
                    "b31",
                    "b7",
                    "b0",
                    "b42",
                    "b41",
                    "b30",
                    "b1",
                    "b24"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Concreteness Targets and Ratings",
                "text": [
                    "As materials for our experiments, we utilise the concreteness norms collected by Brysbaert et al. (2014), including approximately 40, 000 English target words. 2 The resource contains individual ratings by 25 participants on a 5-point scale ranging from 1 (abstract) to 5 (concrete), mean ratings and standard deviations. No context or part-of-speech (POS) were given; in a post-processing step, Brysbaert et al. (2012) added POS and frequency information from the SUBTLEX-US corpus.",
                    "We followed a further post-processing step suggested by Schulte im Walde and Frassinelli (2022), who assigned the most frequently occurring POS tag and frequency information to the target words using the ENCOW web corpus (Sch\u00e4fer and Bildhauer, 2012;Sch\u00e4fer, 2015), and then reduced the targets to a less ambiguous and less low-frequent subset by discarding words for which (i) the predominant POS did not represent at least 95% of all POS occurrences; (ii) the newly assigned EN-COW POS tag was not identical to the SUBTLEX-US POS tag, or (iii) for which the ENCOW target frequency was lower than 10, 000. Our subset includes 5, 448 nouns, 1, 280 verbs and 2, 205 adjectives, and is publicly available. 3"
                ],
                "publication_ref": [
                    "b7",
                    "b36",
                    "b35"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Target Words: Characteristics",
                "text": [
                    "In our first set of experiments we analyse multimodal characteristics of our concreteness targets. After introducing these characteristics (Section 4.1), we start out with a holistic perspective by quantifying statistical relationships between degrees of concreteness and our selection of target characteristics (Section 4.2). We then zoom into differences in characteristics between mid-scale target words and extremely concrete/abstract target words, by applying a classifier that determines separability based on characteristics (Section 4.3)."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Characteristics and Resources",
                "text": [
                    "Sense Perception Given that the original concreteness ratings in the Brysbaert norms rely on the raters' perceptions across senses, the most intimately connected set of characteristics explores the relationships between concreteness ratings and the five senses that were used in the task definition by Brysbaert et al. (2014) when collecting judgements for the concreteness norms. While Brysbaert et al. did not ask for a reference to specific senses rather than a general strength of sense perception, Lynott et al. (2020) collected judgements on specific senses (auditory, gustatory, haptic, olfactory, and visual) for the same targets as Brysbaert et al., using a scale from 0 to 5.",
                    "Emotion Dimensions Abstract words are considered to be more emotionally valenced than concrete words (Kousta et al., 2011;Vigliocco et al., 2014;Pollock, 2018). We thus explore emotion dimensions of our target words by using the NRC VAD Lexicon (Mohammad, 2018) 4 with ratings on valence, arousal, and dominance for over 20, 000 commonly used English words. The ratings were obtained by asking participants to judge the VAD strength of words using a best-worst scaling method. For each emotion dimension, the scores range from 0 (lowest VAD) to 1 (highest VAD).",
                    "Frequency and Ambiguity Frequency and ambiguity represent two standard dimensions influencing language processing and comprehension (Ellis, 2002;Baayen et al., 2016, i.a.). For frequency information, we rely on the target frequencies extracted from the ENCOW web corpus (see Section 3), containing \u224810 billion words. In order to distinguish between degrees of ambiguity of the targets, we rely on WordNet (Miller and Fellbaum, 1991;Fellbaum, 1998), a standard lexical semantic taxonomy for English word senses developed at Princeton University. WordNet organises words into classes of synonyms (synsets) connected by lexical and conceptual semantic relations. We looked up the number of noun and verb (but not adjective) target senses in WordNet version 3.0 and then used these WordNet ambiguity values if in the range [1; 6]; targets with more than six senses in WordNet we assigned to a joint additional category. Free Word Associations Previous work suggested that free associations to abstract words differ from free associations to concrete words in terms of the number of types, thus pointing towards differences in conceptual semantic diversity. At the same time, associations to concrete words have been found weaker and more symmetric than for abstract words (Crutch and Warrington, 2010;Hill et al., 2014). The Small World Of Words Project SWOW (de Deyne et al., 2019) 5 provides large databases with free word associations across languages; for English, SWOW-EN includes more than 12, 000 cue words with responses from over 90, 000 participants. The associations were gathered from 2011-2018 by asking English speakers through crowd-sourcing to produce the first three response words that came to mind when presented with a cue word. We rely on SNOW-EN associations as indicators of diversity regarding our target words. Next to using only the first response R1, we aggregated the first two responses into a set R12, and all three responses into a set R123 to decrease sparsity, while accepting a minor association chain effect 6 (McEvoy and Nelson, 1982; Schulte  im Walde and Melinger, 2008). We measured the diversity of responses by counting the number of types (i.e., the number of distinct associations that were produced across participants) in R1, R12, and R123, and normalised by the respective total numbers of response tokens. we will refer to supporting evidence or differences regarding verb and adjective analyses in the text and in the Appendix."
                ],
                "publication_ref": [
                    "b7",
                    "b22",
                    "b20",
                    "b44",
                    "b33",
                    "b13",
                    "b27",
                    "b9",
                    "b17"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Word Classes and Resource Coverage",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Holistic Perspective",
                "text": [
                    "Figure 2 visualises the relationships between mean noun concreteness ratings and standard deviations as introduced in Figure 1, in combination with heat maps indicating the rating strengths of auditory, gustatory, haptic, olfactory and visual perception (left to right). 8 Targets missing in a resource are plotted in grey. We can clearly observe an overall dominance of the visual perception (also see Table 5 in Appendix A for perception across senses), and that the strength of perception varies in different ways across the concreteness rating scale. We thus conclude that overall the concreteness ratings of our target nouns 9 correlate to different degrees -and differing in negative vs. positive directions -with specific senses and also with further characteristics previously attributed to abstract vs. concrete concepts. This is our starting point for analysing whether any of these characteristics is particularly different for mid-scale target words and might have influenced their concreteness ratings."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_1",
                    "fig_0"
                ],
                "table_ref": []
            },
            {
                "heading": "Mid-Scale Peculiarities",
                "text": [
                    "We now investigate more specifically genuine characteristics of words that received mid-scale ratings, by zooming into differences in characteristics of mid-scale in contrast to extremely concrete/abstract target words, to maximise contrasts. 9 See Tables 6-7 in Appendix C for verbs and adjectives. For this, we created three sets of 500 nouns each: the 500 most abstract nouns, the 500 most extreme nouns, and the 500 nouns with mean ratings closest to the rating-scale mean of 3 (with 250 nouns with mean \u2264 3 and 250 nouns with mean > 3). 10 We then applied a Random Forest classifier and defined the following classification variants: a ternary mid/extremes condition where the classifier had to distinguish between the two extreme sets of 500 concrete and abstract targets from the mid-scale; binary mid/abstract and binary mid/concrete conditions to zoom into the individual mid-scale vs. extreme differences. As a control condition providing an upper bound for our classifiers, we included binary extremes where we classify only the extreme target sets with stronger differences between the two classes, while disregarding the mid-scale sets. The respective baselines are 50% for the binary classifications and 33% for the ternary classification.",
                    "The classifier used as features those target characteristics described and analysed in Section 4.2, separately and combined, in order to identify the characteristics that differ for mid-scale words in contrast to clearly abstract or concrete words. If a target word lacks a feature for a specific vari- able, we assigned 0 as the respective feature value. We applied 10-fold cross-validation and report the average accuracy score. The classification results using all the features at the same time are shown in Table 3. Figure 3 shows the results per feature type.",
                    "As expected, the binary extremes classifications show the best results, with auditory, haptic, and visual sense perception as well as association diversity representing the strongest characteristics, in accordance with their overall correlation strengths in Section 4.2. The ternary mid/extremes results look like a miniature version of the binary extremes results with regard to accuracy across feature types, only on a lower scale (given the extra class). The results for the binary mid/abstract and binary mid/concrete conditions are lower than for binary extremes , as predicted, because the contrasts on the concreteness scale are less strong. Also, we observe an interesting difference between the two conditions: targets with mid-scale ratings are distinguished better from targets with extremely concrete in comparison to extremely abstract ratings (\u2192 higher accuracy); at the same time, feature contributions in binary mid/concrete are similar to those in binary extremes and ternary mid/extremes , while their contributions in binary mid/abstract are more uniform.",
                    "To further understand the differences between these two conditions, we inspected the contribution of each feature to the models' output using Shapley Additive Explanations (SHAP; Lundberg and Lee, 2017). Figure 4 shows the importance -as the magnitude of change -of each variable in predicting the concreteness scores of concrete (left plot) and abstract (right plot) nouns vs. mid-scale nouns.",
                    "The colours of the violin plots indicate the values of the features. For the binary mid/concrete model, the three most important features for the classification are haptic, visual, and dominance, in that order. Conversely, for the binary mid/abstract model, the most important features are visual, auditory, and haptic. Notably, visual and haptic features emerge as the most informative in both cases. Associations, instead, show a relatively small contribution to the performance of the classifier when together with other feature types (as opposed to Figure 3).",
                    "An analysis of the colour-coded information (i.e., the value of each feature) supports our previous evidence. In the left plot in Figure 4, we can see a clear distinction between concrete nouns that are characterised by high (magenta) visual and haptic values, and mid-concreteness nouns characterised by low (blue) visual and haptic values. Conversely, in the right plot in Figure 4 the visual and haptic nature of abstract versus mid-scale nouns exhibits less pronounced differences with magenta colour associated both with mid-scale (positive) and abstract (negative) nouns.",
                    "We thus infer from our classification experiments that mid-scale target nouns are more easily distinguishable from extremely concrete in comparison to extremely abstract targets, with regard to our set of features. In the next section, we will investigate why this is the case."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_2",
                    "fig_2",
                    "fig_2"
                ],
                "table_ref": [
                    "tab_2"
                ]
            },
            {
                "heading": "Mid-Scale Disagreement Patterns",
                "text": [
                    "In our final analyses, we zoom into the numerical characteristics of mid-scale mean ratings. If there was substantial agreement behind the semiperception of a mid-scale target (i.e., if all human   raters had provided a rating of 3 or similar on the scale of 1 to 5), then we would see a standard deviation around 0 in the croissant plots in Figure 1. We however observe rather high standard deviations for targets with mean ratings of \u22483, thus indicating considerable disagreement across raters. The question we are asking is how these disagreements were triggered. We hypothesise that raters might have been influenced differently by their individual perceptions of target characteristics, and that we therefore find several patterns of disagreement across the mid-scale target words.",
                    "For this exploration of disagreement patterns, we make use of the original per-participant ratings in Brysbaert et al. (2014), and applied a standard k-means hard clustering approach to automatically assign the 500 mid-scale nouns to k = 3 clusters. As representations for the targets, we used 5-dimensional vectors with relative frequencies per rating categories 1, 2, 3, 4, 5, based on the original individual ratings, e.g., the vector for the noun discussion is \u20d7 v = \u27e80.15, 0.07, 0.48, 0.15, 0.15\u27e9, because 15% of the raters provided ratings of 1, 4 or 5, while 7% judged it as 2, and 48% judged it as 3.",
                    "Figure 5 presents two perspectives on the resulting clusters with rather homogeneous cluster sizes 170, 163, 167. On the left, 11 we can see that the three clusters are clearly separated, with relatively small overlapping areas, thus indicating that the underlying cluster features (i.e., the rating distributions) clearly differ. This is confirmed by the plot on the right, which shows the individual rating distributions (y-axis) of the three cluster centroids 1-3 (x-axis). The heatmap exhibits rather different patterns: in cluster 1, we find the strongest disagreements among raters, where each of the two extreme rating scores (1 and 5) were chosen by 26%, the mid-score by 19%, and the remaining scores are equally distributed over ratings 2 and 4 (14% each); in cluster 2, 32% of the raters judged the respective target nouns as 3 because they were completely undecided or they consciously chose a mid-scale semi-perception score, while the other raters decided for 1, 2, 4, 5 with almost identical proportions (16-18%); finally, in cluster 3 we find a more uniform rating distribution, while a score of 4 was given by most of the raters (26%).  Overall, Figure 5 thus provides very strong evidence in favour of our hypothesis that a mid-scale mean rating conflates rather different patterns of disagreements across human ratings. Figures 12  and 13 in Appendix E provide the respective plots for verbs and adjectives, where we find similar patterns of disagreement."
                ],
                "publication_ref": [
                    "b7"
                ],
                "figure_ref": [
                    "fig_0",
                    "fig_4",
                    "fig_4",
                    "fig_13"
                ],
                "table_ref": []
            },
            {
                "heading": "Discussion & Conclusion",
                "text": [
                    "We started out with the well-known observation that humans tend to strongly agree on ratings on a scale for extreme cases, but that judgements on mid-scale words exhibit more disagreement. This observation is well-described by the croissant-like shape of mean rating scores in relation to their standard deviations (cf. Figure 1). While individual studies have pointed out problems with such ratings on a scale (e.g., Kiritchenko and Mohammad (2017); Pollock (2018)) and also provided alternative settings (e.g., Kiritchenko and Mohammad (2017); Abdalla et al. ( 2023)), the scale-based norms are heavily exploited across disciplines, including state-of-the-art computational approaches.",
                    "In the current study, we first asked whether words with mid-scale concreteness ratings potentially exhibit specific characteristics that genuinely distinguish them from clearly concrete and clearly abstract words. The corresponding classification experiments and feature analyses demonstrated that mid-scale targets were indeed distinguishable from extreme targets with regard to a subset of the senses which were used as criteria for the concretenessabstractness distinction (mainly visual and haptic), and also with regard to emotional dimensions and meaning diversity (implemented on the basis of association types). In this first set of experiments mid-scale targets therefore established themselves as genuine intermediate concepts. We also saw, however, that mid-scale nouns are more easily distinguishable from extremely concrete in comparison to extremely abstract nouns, and this asymmetry flips with regard to verbs and adjectives, presumably because their underlying rating distributions exhibit different skews (cf. the croissant plots in Figure 1 and the different mid-scale ranges in Figure 9 in Appendix D). So overall, words with mid-scale mean ratings represent rather genuine intermediate concepts regarding our implementations of features and analyses.",
                    "In the second part of our study, we investigated whether mid-scale ratings are generally agreed upon across raters, or whether raters disagreed regarding their semi-perception. Relying on explorative cluster analyses using the original perparticipant rating distributions, we found clusters with obviously very different centroids. From this, we induce that a mid-scale rating mean of \u22483 conflates rather different yet systematic kinds of disagreements. This observation is in line with the mathematically-based observations by Pollock (2018) that \"there is only a finite number of possible combinations of means and standard deviations\", and at the same time it clearly demonstrated that mid-scale ratings indeed differ regarding their underlying rating combinations. So, on the one hand, our cluster analyses confirm a so-far rather theoretically-driven observation; on the other hand, we raise the question of whether and how this observation should influence the utilisation of ratings on a scale. We suggest two alternative routes: (i) either filter the norm targets and only keep those targets that are clearly attributable to one extreme, or (ii) fine-tune the mid-scale norm targets with regard to inherent disagreement patterns, because the set of mid-scale targets is itself rather inhomogeneous but nevertheless provides valuable information regarding specific differences in human perception.",
                    "Last but not least we would like to point out that inherent disagreements among human annotators are obviously not restricted to our particular focus on mid-scale ratings but represent a common issue under discussion across annotation tasks. In the past decade the field has moved from considering disagreements as pure noise towards zooming into disagreements in order to distinguish between noise and subjectivity, and to effectively exploit the value of disagreements in language modelling, see Alm (2011) and Uma et al. (2021) for a prominent opinion paper and a prominent survey, respectively. Our analyses and insights should be interpreted in the same vein: we attribute disagreements on concreteness mid-scale ratings to genuine intermediate concepts (see above) and suggest to take a finegrained approach when utilising them in language modelling tasks and applications."
                ],
                "publication_ref": [
                    "b33",
                    "b33",
                    "b43"
                ],
                "figure_ref": [
                    "fig_0",
                    "fig_0",
                    "fig_7"
                ],
                "table_ref": []
            },
            {
                "heading": "Limitations",
                "text": [
                    "Our study is targeting ratings on a scale but currently restricted to a selection of target properties and a specific case study on concreteness. Future work will explore additional target properties that might influence concreteness mid-scale ratings (such as the mass-count distinction and register) as well as characteristics of ratings on a scale in further collections and other languages than English. "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A Dominance of Perception across Targets",
                "text": [
                    "Table 5 shows how many of our target words (nouns, verbs, adjectives, overall) were perceived predominantly by any of the human senses auditory, gustatory, haptic, olfactory, visual, according to the analyses by Lynott et al. (2020).    "
                ],
                "publication_ref": [
                    "b22"
                ],
                "figure_ref": [],
                "table_ref": [
                    "tab_7"
                ]
            },
            {
                "heading": "D Mid-Scale Definitions, Ranges and Classifications across Word Classes",
                "text": [
                    "Intuitively, the interpretation of mid-scale targets refers to somewhere in the middle of the mean concreteness ratings plots that we have presented in Figure 1, in contrast to extremely abstract targets on the left and extremely concrete targets on the right. Accordingly, we suggest three ways of capturing this intuition, given that the number of targets per part-of-speech (POS) and also the ranges of ratings and their skewness differ across POS. We created three sets of 500 mid-scale noun targets accordingly, and also three sets of 200 mid-scale verb and 200 mid-scale adjective targets.",
                    "Mid-Scale-Mean The mid-scale score is defined as the mean value on the rating scale, which is 3 in our scale [1; 5]. Mid-scale targets are then defined as those words whose mean ratings are closest to 3.",
                    "Mid-Scale-Median Given that the rating distributions differ across POS and with regard to their left vs. right skews, the mid-scale score is defined as the median, in our case: 3.54 for the nouns, 2.47 for the verbs, and 2.19 for the adjectives. Mid-scale targets are then defined as those words whose mean ratings are closest to these medians.",
                    "Mid-Scale-Median-SD Incorporating disagreement between raters, we refine the mid-scale-median taking into account as mid-scale targets only those words whose mean ratings are closest to the median and whose standard deviations are > 1.4.",
                    "In all three cases, we selected an equal number of targets with mean ratings above and below the respective mid-scale score. Figure 9 provides the mean-rating ranges of our mid-scale targets across these three mid-scale definitions, based on the respective 500/200/200 mid-scale noun/verb/adjective targets. The same figure shows the mean-rating ranges of the extremely concrete and extremely abstract targets, relying again on sets of 500/200/200 targets. We can see that the mid-scale ranges clearly differ across definitions and POS. Table 8 shows the classification results (accuracy) across these mid-scale definitions, word classes and target set constellations.      0.17 0.17 0.17  "
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_0",
                    "fig_7"
                ],
                "table_ref": [
                    "tab_10"
                ]
            },
            {
                "heading": "Acknowledgements",
                "text": [
                    "This research was supported by the Ad Futura Scholarship (305. JR) from the Public Scholarship, Development, Disability and Maintenance Fund of the Republic of Slovenia (Urban Knuple\u0161), and by the DFG Research Grant SCHU 2580/4-1 (MUD-CAT -Multimodal Dimensions and Computational Applications of Abstractness). We also thank the reviewers for suggesting additional perspectives regarding our analyses and interpretations."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Ethics Statement",
                "text": [
                    "For our study, we used and cited publicly available datasets and libraries. The resources do not contain any information that uniquely identifies individuals. Our research does not raise any immediate ethical concerns."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            }
        ],
        "references": [
            {
                "ref_id": "b0",
                "title": "What Makes Sentences Semantically Related? A Textual Relatedness Dataset and Empirical Study",
                "journal": "",
                "year": "2023",
                "authors": "Mohamed Abdalla; Krishnapriya Vishnubhotla; Saif Mohammad"
            },
            {
                "ref_id": "b1",
                "title": "Combining Abstractness and Language-specific Theoretical Indicators for Detecting Non-Literal Usage of Estonian Particle Verbs",
                "journal": "",
                "year": "2018",
                "authors": "Eleri Aedmaa; Maximilian K\u00f6per; Sabine Schulte Im Walde"
            },
            {
                "ref_id": "b2",
                "title": "The University of Valencia's Computerized Word Pool",
                "journal": "Behavior Research Methods, Instruments, and Computers",
                "year": "1988",
                "authors": "Salvador Algarabel; Juan Carlos Ruiz; Jaime Sanmartin"
            },
            {
                "ref_id": "b3",
                "title": "Subjective Natural Language Problems: Motivations, Applications, Characterizations, and Implications",
                "journal": "",
                "year": "2011",
                "authors": "Cecilia Ovesdotter; Alm "
            },
            {
                "ref_id": "b4",
                "title": "Frequency in Lexical Processing",
                "journal": "",
                "year": "2016",
                "authors": "R ; Harald Baayen; Petar Milin; Michael Ramscar"
            },
            {
                "ref_id": "b5",
                "title": "Concreteness Norms for 1,659 French Words: Relationships with other Psycholinguistic Variables and Word Recognition Times",
                "journal": "Behavior Research Methods",
                "year": "2018",
                "authors": "Patrick Bonin; Alain Meot; Aurelia Bugaiska"
            },
            {
                "ref_id": "b6",
                "title": "Boris New, and Emmanuel Keuleers. 2012. Adding Part-of-Speech Information to the SUBTLEX-US Word Frequencies. Behavior Research Methods",
                "journal": "",
                "year": "",
                "authors": "Marc Brysbaert"
            },
            {
                "ref_id": "b7",
                "title": "Concreteness Ratings for 40 Thousand generally known English Word Lemmas. Behavior Research Methods",
                "journal": "",
                "year": "2014",
                "authors": "Marc Brysbaert; Amy Beth Warriner; Victor Kuperman"
            },
            {
                "ref_id": "b8",
                "title": "Unsupervised Compositionality Prediction of Nominal Compounds",
                "journal": "Computational Linguistics",
                "year": "2019",
                "authors": "Silvio Cordeiro; Aline Villavicencio; Marco Idiart; Carlos Ramisch"
            },
            {
                "ref_id": "b9",
                "title": "The Differential Dependence of Abstract and Concrete Words upon Associative and Similarity-based Information: Complementary Semantic Interference and Facilitation Effects",
                "journal": "Cognitive Neuropsychology",
                "year": "2010",
                "authors": "J Sebastian; Elizabeth K Crutch;  Warrington"
            },
            {
                "ref_id": "b10",
                "title": "Amy Perfors, Marc Brysbaert, and Gert Storms. 2019. The \"Small World of Words\" English Word Association Norms for over 12,000 Cue Words",
                "journal": "Behavior Research Methods",
                "year": "",
                "authors": "Danielle J Simon De Deyne;  Navarro"
            },
            {
                "ref_id": "b11",
                "title": "Beyond the Abstract-Concrete Dichotomy: Mode of Acquisition, Concreteness, Imageability, Familiarity, Age of Acquisition, Context Availability, and Abstractness Norms for a Set of 417 Italian Words",
                "journal": "Behavior Research Methods",
                "year": "2010",
                "authors": "Pasquale A Della Rosa; Eleonora Catricala; Gabriella Vigliocco; Stefano F Cappa"
            },
            {
                "ref_id": "b12",
                "title": "A Dataset for Physical and Abstract Plausibility and Sources of Human Disagreement",
                "journal": "",
                "year": "2023",
                "authors": "Annerose Eichel; Sabine Schulte Im Walde"
            },
            {
                "ref_id": "b13",
                "title": "Frequency Effects in Language Processing: A Review with Implications for Theories of Implicit and Explicit Language Acquisition",
                "journal": "Studies in Second Language Acquisition",
                "year": "2002",
                "authors": "C Nick;  Ellis"
            },
            {
                "ref_id": "b14",
                "title": "WordNet -An Electronic Lexical Database. Language, Speech, and Communication",
                "journal": "MIT Press",
                "year": "1998",
                "authors": ""
            },
            {
                "ref_id": "b15",
                "title": "LADEC: The Large Database of English Compounds",
                "journal": "Behavior Research Methods",
                "year": "2019",
                "authors": "Christina L Gagn\u00e9; Thomas L Spalding; Daniel Schmidtke"
            },
            {
                "ref_id": "b16",
                "title": "Semantic Transparency Effects in German Compounds: A Large Dataset and Multiple-Task Investigation",
                "journal": "Behavior Research Methods",
                "year": "2020",
                "authors": "Fritz G\u00fcnther; Marco Marelli; Jens B\u00f6lte"
            },
            {
                "ref_id": "b17",
                "title": "A Quantitative Empirical Analysis of the Abstract/Concrete Distinction",
                "journal": "Cognitive Science",
                "year": "2014",
                "authors": "Felix Hill; Anna Korhonen; Christian Bentz"
            },
            {
                "ref_id": "b18",
                "title": "Leipzig Affective Norms for German: A Reliability Study",
                "journal": "Behavior Research Methods",
                "year": "2010",
                "authors": "Philipp Kanske; Sonja A Kotz"
            },
            {
                "ref_id": "b19",
                "title": "Analogies in Complex Verb Meaning Shifts: The Effect of Affect in Semantic Similarity Models",
                "journal": "",
                "year": "2018",
                "authors": "Maximilian K\u00f6per; Sabine Schulte Im Walde"
            },
            {
                "ref_id": "b20",
                "title": "The Representation of Abstract Words: Why Emotion Matters",
                "journal": "Journal of Experimental Psychology: General",
                "year": "2011",
                "authors": "Gabriella Stavroula-Thaleia Kousta; David P Vigliocco; Mark Vinson; Elena Del Andrews;  Campo"
            },
            {
                "ref_id": "b21",
                "title": "A unified approach to interpreting model predictions",
                "journal": "Curran Associates, Inc",
                "year": "2017",
                "authors": "M Scott; Su-In Lundberg;  Lee"
            },
            {
                "ref_id": "b22",
                "title": "The Lancaster Sensorimotor Norms: Multidimensional Measures of Perceptual and Action Strength for 40,000 English Words",
                "journal": "Behavior Research Methods",
                "year": "2020",
                "authors": "Dermot Lynott; Louise Connell; Marc Brysbaert; James Brand; James Carney"
            },
            {
                "ref_id": "b23",
                "title": "How useful are Corpus-based Methods for Extrapolating Psycholinguistic Variables?",
                "journal": "The Quarterly Journal of Experimental Psychology",
                "year": "2015",
                "authors": "Pawel Mandera; Emmanuel Keuleers; Marc Brysbaert"
            },
            {
                "ref_id": "b24",
                "title": "Metaphor Detection Using Context and Concreteness",
                "journal": "",
                "year": "2020",
                "authors": "Tiago Rowan Hall Maudslay; Ryan Pimentel; Simone Cotterell;  Teufel"
            },
            {
                "ref_id": "b25",
                "title": "Category Name and Instance Norms for 106 Categories of Various Sizes",
                "journal": "American Journal of Psychology",
                "year": "1982",
                "authors": "Cathy L Mcevoy; Douglas L Nelson"
            },
            {
                "ref_id": "b26",
                "title": "Umap: Uniform manifold approximation and projection",
                "journal": "The Journal of Open Source Software",
                "year": "2018",
                "authors": "Leland Mcinnes; John Healy; Nathaniel Saul; Lukas Grossberger"
            },
            {
                "ref_id": "b27",
                "title": "Semantic Networks of English",
                "journal": "Cognition",
                "year": "1991",
                "authors": "George A Miller; Christiane Fellbaum"
            },
            {
                "ref_id": "b28",
                "title": "Obtaining Reliable Human Ratings of Valence, Arousal, and Dominance for 20,000 English Words",
                "journal": "",
                "year": "2018",
                "authors": "M Saif;  Mohammad"
            },
            {
                "ref_id": "b29",
                "title": "Annual Meeting of the Association for Computational Linguistics",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b30",
                "title": "How Translation Alters Sentiment",
                "journal": "Journal of Artificial Intelligence Research",
                "year": "2016",
                "authors": "M Saif; Mohammad Mohammad; Svetlana Salameh;  Kiritchenko"
            },
            {
                "ref_id": "b31",
                "title": "Concreteness Ratings for 62 Thousand English Multiword Expressions. PsyArXiv",
                "journal": "",
                "year": "2022",
                "authors": "Emiko J Muraki; Summer Abdalla; Marc Brysbaert; Penny M Pexman"
            },
            {
                "ref_id": "b32",
                "title": "Concreteness, Imagery, and Meaningfulness Values for 925 Nouns",
                "journal": "Journal of Experimental Psychology (Monograph Supplement)",
                "year": "1968",
                "authors": "Allan Paivio; John C Yuille; Stephen A Madigan"
            },
            {
                "ref_id": "b33",
                "title": "Statistical and Methodological Problems with Concreteness and other Semantic Variables: A List Memory Experiment Case Study",
                "journal": "Behavior Research Methods",
                "year": "2018",
                "authors": "Lewis Pollock"
            },
            {
                "ref_id": "b34",
                "title": "An Empirical Study on Compositionality in Compound Nouns",
                "journal": "",
                "year": "2011",
                "authors": "Siva Reddy; Diana Mccarthy; Suresh Manandhar"
            },
            {
                "ref_id": "b35",
                "title": "Processing and Querying Large Web Corpora with the COW14 Architecture",
                "journal": "",
                "year": "2015",
                "authors": "Roland Sch\u00e4fer"
            },
            {
                "ref_id": "b36",
                "title": "Building Large Corpora from the Web Using a New Efficient Tool Chain",
                "journal": "",
                "year": "2012",
                "authors": "Roland Sch\u00e4fer; Felix Bildhauer"
            },
            {
                "ref_id": "b37",
                "title": "Distributional Measures of Abstraction",
                "journal": "",
                "year": "2022",
                "authors": "Sabine Schulte Im Walde; Diego Frassinelli"
            },
            {
                "ref_id": "b38",
                "title": "G h ost-NN: A Representative Gold Standard of German Noun-Noun Compounds",
                "journal": "",
                "year": "2016",
                "authors": "Sabine Schulte Im Walde; Anna H\u00e4tty; Stefan Bott; Nana Khvtisavrishvili"
            },
            {
                "ref_id": "b39",
                "title": "An In-Depth Look into the Co-Occurrence Distribution of Semantic Associates",
                "journal": "",
                "year": "2008",
                "authors": "Sabine Schulte Im Walde; Alissa Melinger"
            },
            {
                "ref_id": "b40",
                "title": "Parameters of Abstraction, Meaningfulness, and Pronunciability for 329 Nouns",
                "journal": "Journal of Verbal Learning Behavior",
                "year": "1966",
                "authors": "Otfried Spreen; Rudolph W Schulz"
            },
            {
                "ref_id": "b41",
                "title": "Metaphor Detection with Cross-Lingual Model Transfer",
                "journal": "",
                "year": "2014",
                "authors": "Yulia Tsvetkov; Leonid Boytsov; Anatole Gershman; Eric Nyberg; Chris Dyer"
            },
            {
                "ref_id": "b42",
                "title": "Literal and Metaphorical Sense Identification through Concrete and Abstract Context",
                "journal": "",
                "year": "2011",
                "authors": "D Peter; Yair Turney; Dan Neuman; Yohai Assaf;  Cohen"
            },
            {
                "ref_id": "b43",
                "title": "Learning from Disagreement: A Survey",
                "journal": "Journal of Artificial Intelligence Research",
                "year": "2021",
                "authors": "Alexandra N Uma; Tommaso Fornaciari; Dirk Hovy; Silviu Paun; Barbara Plank; Massimo Poesio"
            },
            {
                "ref_id": "b44",
                "title": "The Neural Representation of Abstract Words: The Role of Emotion",
                "journal": "Cerebral Cortex",
                "year": "2014",
                "authors": "Gabriella Vigliocco;  Stavroula-Thaleia; Pasquale Anthony Kousta; Della Rosa; David P Vinson; Marco Tettamanti; Joseph T Devlin; Stefano F Cappa"
            },
            {
                "ref_id": "b45",
                "title": "Modeling Semantic Plausibility by Injecting World Knowledge",
                "journal": "",
                "year": "2018",
                "authors": "Su Wang; Greg Durrett; Katrin Erk"
            }
        ],
        "figures": [
            {
                "figure_label": "1",
                "figure_type": "figure",
                "figure_id": "fig_0",
                "figure_caption": "Figure 1 :1Figure 1: Croissant plots -Mean concreteness scores and standard deviations of ratings in Brysbaert et al. (2014).",
                "figure_data": ""
            },
            {
                "figure_label": "2",
                "figure_type": "figure",
                "figure_id": "fig_1",
                "figure_caption": "Figure 2 :2Figure 2: Mean noun ratings and standard deviations overlaid with the respective sense perception scores.",
                "figure_data": ""
            },
            {
                "figure_label": "4",
                "figure_type": "figure",
                "figure_id": "fig_2",
                "figure_caption": "Figure 4 :4Figure 4: SHAP values -Importance of each feature for the output of the binary mid/concrete model (on the left) and the binary mid/abstract model (on the right). Extreme nouns are coded as negative, mid-scale nouns as positive.",
                "figure_data": ""
            },
            {
                "figure_label": "5",
                "figure_type": "figure",
                "figure_id": "fig_4",
                "figure_caption": "Figure 5 :5Figure 5: k-Means clustering (k = 3) of 500 mid-scale nouns based on original individual per-participant rating distributions. Cluster sizes are 170, 163, and 167. The heatmap shows the rating distributions of the centroid vectors.",
                "figure_data": ""
            },
            {
                "figure_label": "67",
                "figure_type": "figure",
                "figure_id": "fig_5",
                "figure_caption": "Figure 6 :Figure 7 :67Figure 6: Mean noun ratings and standard deviations overlaid with the respective VAD scores.",
                "figure_data": ""
            },
            {
                "figure_label": "8",
                "figure_type": "figure",
                "figure_id": "fig_6",
                "figure_caption": "Figure 8 :8Figure 8: Mean noun ratings and standard deviations overlaid with a normalised number of the association types in the sets R1, R12, and R123.",
                "figure_data": ""
            },
            {
                "figure_label": "9",
                "figure_type": "figure",
                "figure_id": "fig_7",
                "figure_caption": "Figure 9 :9Figure 9: Distributions of concreteness scores across mid-scale definitions and POS.",
                "figure_data": ""
            },
            {
                "figure_label": "10",
                "figure_type": "figure",
                "figure_id": "fig_8",
                "figure_caption": "Figure 10 :10Figure 10: Results of classifications across characteristics and mid-scale/extreme experiments. The dotted and horizontal line patterns indicate the amount of abstract and concrete verbs correctly classified.",
                "figure_data": ""
            },
            {
                "figure_label": "11",
                "figure_type": "figure",
                "figure_id": "fig_9",
                "figure_caption": "Figure 11 :11Figure 11: Results of classifications across characteristics and mid-scale/extreme experiments. The dotted and horizontal line patterns indicate the amount of abstract and concrete adjectives correctly classified.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_10",
                "figure_caption": "FiguresFigures 12 and 13 present the clusters and the heat maps of rating distributions of the cluster centroids for verbs and adjectives. The clusters are based on the same k-Means clustering setup as those for nouns in Section 5.",
                "figure_data": ""
            },
            {
                "figure_label": "12",
                "figure_type": "figure",
                "figure_id": "fig_12",
                "figure_caption": "Figure 12 :12Figure 12: k-Means clustering (k = 3) of 200 mid-scale verbs based on original individual per-participant rating distributions. Cluster sizes are 71, 68, and 61. The heatmap shows the rating distributions of the centroid vectors.",
                "figure_data": ""
            },
            {
                "figure_label": "13",
                "figure_type": "figure",
                "figure_id": "fig_13",
                "figure_caption": "Figure 13 :13Figure 13: k-Means clustering (k = 3) of 200 mid-scale adjectives based on original individual per-participant rating distributions. Cluster sizes are 68, 62, and 70. The heatmap shows the rating distributions of the centroid vectors.",
                "figure_data": ""
            },
            {
                "figure_label": "1",
                "figure_type": "table",
                "figure_id": "tab_0",
                "figure_caption": "Coverage of target characteristics.",
                "figure_data": "Table 1provides an overview of how many of our targetsare covered by the various resources across wordclasses. Note that from now on the main body ofthis paper will focus on nouns, and additionally"
            },
            {
                "figure_label": "2",
                "figure_type": "table",
                "figure_id": "tab_1",
                "figure_caption": "Results of classifications across characteristics and mid-scale/extreme experiments. The dotted and horizontal line patterns indicate the amount of abstract and concrete nouns correctly classified.",
                "figure_data": "informs us that visual, haptic, and olfac-tory sense perception (positively), as well as audi-tory (negatively), correlate with the noun concrete-ness scores. Regarding further target characteris-tics, the table reports a negative correlation withemotion regarding affect and dominance, as well asnegative correlations with concept diversity regard-ing association types. The lexical characteristicsdo not show any correlations with concreteness."
            },
            {
                "figure_label": "3",
                "figure_type": "table",
                "figure_id": "tab_2",
                "figure_caption": "Overall classification results (accuracy).",
                "figure_data": "Classification variants Baseline Accuracybinary extremes0.500.98binary mid/abstract0.500.75binary mid/concrete0.500.93ternary mid/extremes0.330.79"
            },
            {
                "figure_label": "",
                "figure_type": "table",
                "figure_id": "tab_4",
                "figure_caption": "Table4provides a few example targets for each of the three clusters, together with their rating distributions.",
                "figure_data": "C TargetDistributiondefinition\u27e80.32, 0.11, 0.14, 0.11, 0.32\u27e91hero\u27e80.22, 0.11, 0.26, 0.19, 0.22\u27e9percentage \u27e80.40, 0.03, 0.10, 0.20, 0.27\u27e9coward\u27e80.17, 0.20, 0.30, 0.20, 0.13\u27e92discussion \u27e80.15, 0.07, 0.48, 0.15, 0.15\u27e9labor\u27e80.16, 0.12, 0.40, 0.12, 0.20\u27e9booster\u27e80.32, 0.07, 0.14, 0.29, 0.18\u27e93election\u27e80.20, 0.10, 0.23, 0.27, 0.20\u27e9hour\u27e80.23, 0.07, 0.23, 0.30, 0.17\u27e9"
            },
            {
                "figure_label": "4",
                "figure_type": "table",
                "figure_id": "tab_5",
                "figure_caption": "Examples of rating distributions for noun target words across clusters C.",
                "figure_data": ""
            },
            {
                "figure_label": "5",
                "figure_type": "table",
                "figure_id": "tab_7",
                "figure_caption": "Distribution of dominant perceptual modalities of our target words, based onLynott et al. (2020).",
                "figure_data": "Auditory Gustatory Haptic Olfactory Visual TotalN61019910238 4,491 5,440V2698274972 1,280A34131647 1,759 2,202all1,22023819349 7,222 8,922"
            },
            {
                "figure_label": "6",
                "figure_type": "table",
                "figure_id": "tab_8",
                "figure_caption": "C Correlations between Target Characteristics and Concreteness: Verbs and Adjectives Spearman's rank-order correlation coefficient \u03c1 for the statistical relationships between degrees of concreteness and strengths of target verb characteristics; significance level is p < 0.05.",
                "figure_data": "Target characteristics\u03c1Auditory-0.28  *Gustatory-0.09  *Sense perceptionHaptic0.47  *Olfactory0.01  *Visual0.47  *Valence-0.11  *EmotionAffect0.04  *Dominance -0.15  *LexiconFrequency -0.01  *  Ambiguity 0.13  *R1-0.30  *Diversity: associationsR12-0.31  *R123-0.31  *Target characteristics\u03c1Auditory-0.37  *Gustatory-0.01  *Sense perceptionHaptic0.35  *Olfactory0.04  *Visual0.39  *Valence-0.03  *EmotionAffect-0.07  *Dominance -0.08  *LexiconFrequency -0.04  *R1-0.28  *Diversity: associationsR12-0.32  *R123-0.31  *"
            },
            {
                "figure_label": "7",
                "figure_type": "table",
                "figure_id": "tab_9",
                "figure_caption": "Spearman's rank-order correlation coefficient \u03c1 for the statistical relationships between degrees of concreteness and strengths of target adjective characteristics; significance level is p < 0.05.",
                "figure_data": ""
            },
            {
                "figure_label": "8",
                "figure_type": "table",
                "figure_id": "tab_10",
                "figure_caption": "Results of the classifications across mid-scale definitions and target set constellations.",
                "figure_data": "Mid-Scale DefinitionMeanMedian Median-SD"
            }
        ],
        "formulas": [],
        "doi": "10.3758/BF03202684"
    },
    "ArchBERT: Bi-Modal Understanding of Neural Architectures and Natural Languages": {
        "authors": "Mohammad Akbari; Saeed Ranjbar Alvar; Behnam Kamranian; Amin Banitalebi-Dehkordi; Yong Zhang",
        "pub_date": "",
        "abstract": "Building multi-modal language models has been a trend in the recent years, where additional modalities such as image, video, speech, etc. are jointly learned along with natural languages (i.e., textual information). Despite the success of these multi-modal language models with different modalities, there is no existing solution for neural network architectures and natural languages. Providing neural architectural information as a new modality allows us to provide fast architecture-2-text and text-2-architecture retrieval/generation services on the cloud with a single inference. Such solution is valuable in terms of helping beginner and intermediate ML users to come up with better neural architectures or AutoML approaches with a simple text query. In this paper, we propose ArchBERT, a bi-modal model for joint learning and understanding of neural architectures and natural languages, which opens up new avenues for research in this area. We also introduce a pre-training strategy named Masked Architecture Modeling (MAM) for a more generalized joint learning. Moreover, we introduce and publicly release two new bi-modal datasets for training and validating our methods. The ArchBERT's performance is verified through a set of numerical experiments on different downstream tasks such as architecture-oriented reasoning, question answering, and captioning (summarization). Datasets, codes, and demos are available as supplementary materials 1 .",
        "sections": [
            {
                "heading": "Introduction",
                "text": [
                    "Existing machine learning models are mostly based on uni-modal learning, where a single modality is learned for the desired tasks. Example scenarios include image classification with image-only data; or language translation with text-only data (Raffel Figure 1: Bi-modal understanding of neural architectures and natural languages with sample applications. et al., 2020;Akbari et al., 2022;Brown et al., 2020). Despite the success of existing uni-modal learning methods at traditional single-modal tasks, they are usually insufficient (Baltru\u0161aitis et al., 2018) to model the complete aspects of human's reasoning and understanding of the environment.",
                    "The alternative solution for this problem is to use multi-modal learning, where a model can jointly learn from multiple modalities such as text, image, or video to yield more abstract and generalized representations. As a result, a better understanding of various senses in information can be achieved and many new challenges that concern multi-modality can be handled. Such solution also enables the possibility of supplying a missing modality based on the observed ones. As an example, in textbased image generation, we aim to generate photorealistic images which are semantically consistent with some given text description (Bao et al., 2022).",
                    "One of the most popular multi-modal solutions is multi-modal language models (LMs), where an extra modality (e.g., image or video) is jointly used and learned along with the natural languages (i.e., textual information). Some of the recent multimodal LMs include ViLBERT for image+text (Lu et al., 2019), VideoBERT for video+text (Sun et al., 2019), CodeBERT for code+text (Feng et al., 2020), and also GPT-4 (OpenAI, 2023).",
                    "Although many multi-modal LMs with different modalities have been introduced so far, there is no existing solution for joint learning of neural network architectures and natural languages. Providing neural architectural information as a new modality allows us to perform many architectureoriented tasks such as Architecture Search (AS), Architecture Reasoning (AR), Architectural Question Answering (AQA), and Architecture Captioning (AC) (Figure 1). The real-world applications of such solution include fast architecture-2-text and text-2-architecture retrieval/generation services on the cloud with a single inference. Such solution is valuable in terms of helping users to come up with better neural architectures or AutoML approaches with a simple text query especially for beginner and intermediate ML users. For instance, AC can be used for automatically generating descriptions or model card information on a model hub (i.e., machine learning models repository). Furthermore, AR is helpful when a model is uploaded to a repository or cloud along with some textual description provided by the user, where the relevancy of the user's description for the given model can be automatically verified. If not verified, alternative autogenerated descriptions by a architecture-2-text solution can be proposed to the user.",
                    "In this paper, we propose ArchBERT as a bimodal solution for neural architecture and natural language understanding, where the semantics of both modalities and their relations can be jointly learned (Figure 1). To this end, we learn joint embeddings from the graph representations of architectures and their associated descriptions. Moreover, a pre-training strategy called Masked Architecture Modelling (MAM) for a more generalized and robust learning of architectures is proposed. We also introduce two new bi-modal datasets called TVHF and AutoNet for training and evaluating ArchBERT. To the best of our knowledge, ArchBERT is the first solution for joint learning of architecture-language modalities. In addition, ArchBERT can work with any natural languages and any type of neural network architectures designed for different machine learning tasks. The main contributions of this paper are as follows:",
                    "\u2022 A novel bi-modal model for joint learning of neural architectures and natural languages",
                    "\u2022 Two new bi-modal benchmark datasets for architecture-language learning and evaluation",
                    "\u2022 A new pre-training technique called MAM",
                    "\u2022 Introducing and benchmarking 6 architecturelanguage-related downstream applications"
                ],
                "publication_ref": [
                    "b1",
                    "b5",
                    "b3",
                    "b4",
                    "b19",
                    "b31",
                    "b7"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Related Works",
                "text": [
                    "Multi-modal models are used in many sub-fields in machine learning. For example, Michelsanti et al. (2021) and Schoneveld et al. (2021) introduced the audio-visual models trained on input acoustic speech signal and video frames of the speaker for speech enhancement, speech separation, and emotion recognition. Multi-modal models used in biomedical (Venugopalan et al., 2021;Vale-Silva and Rohr, 2021), remote-sensing (Hong et al., 2020;Maimaitijiang et al., 2020), and autonomous driving (Xiao et al., 2020) applications have also proven to provide more accurate prediction and detection than the unimodal models. Among different types of multi-modal LMs in the literature, transformer-based ones have shown significant performance, especially for vision-andlanguage tasks like visual question answering, image captioning, and visual reasoning. In Visual-BERT (Li et al., 2019), a stack of transformers is used to align the elements of text and image pairs. ViLBERT (Lu et al., 2019) extended BERT to a multi-modal double-stream model based on coattentional transformer layers. In LXMERT (Tan and Bansal, 2019), three encoders including language, object relation, and cross modality encoders are used. A single-stream vision-language model was introduced in VL-BEIT (Bao et al., 2022), where unpaired and paired image-text modalities were used for pre-training.",
                    "Video is another modality that is used with language in multi-modal models. VideoBERT (Sun et al., 2019) is a single-stream video-language model, which learns a joint visual-linguistic representation from input video-text pairs. VIOLET (Fu et al., 2021) is another example that employs a video transformer to model the temporal dynamics of videos, and achieves SOTA results on video question answering and text-to-video retrieval. Programming language is also an emerging modality that has been used along with language. For example, CodeBERT (Feng et al., 2020) is a multistream model, which uses LMs in each stream, where the input code is regarded as a sequence of tokens. On the other hand, GraphCodeBERT (Guo et al., 2021) proposes a structure-aware pre-training technique to consider the inherent structure of the code by mapping it to a data flow graph.",
                    "There are several prior works that combine more than two modalities. In Multimodal Transformer (MulT) (Tsai et al., 2019), cross-modal attention modules are added to the transformers to learn representations from unaligned multi-modal streams, including the language, the facial gestures, and the acoustic behaviors. VATT (Akbari et al., 2021) also used video, audio, and text transformers along with a self-supervised learning strategy to obtain multi-modal representations from unlabeled data.",
                    "It is worth mentioning that ChatGPT (OpenAI, 2022) can be used for information retrieval, question answering, and also summarization over the textual descriptions of well-known neural architectures such AlexNet (Krizhevsky et al., 2017) or Faster-RCNN (Ren et al., 2015). However, unlike ArchBERT, it does not have a bi-modal understanding of both neural architectures (i.e., graphs) and natural languages, especially for newly proposed architectures and models."
                ],
                "publication_ref": [
                    "b22",
                    "b30",
                    "b36",
                    "b34",
                    "b12",
                    "b20",
                    "b38",
                    "b17",
                    "b19",
                    "b32",
                    "b4",
                    "b31",
                    "b7",
                    "b10",
                    "b33",
                    "b0",
                    "b15",
                    "b28"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Proposed Method: ArchBERT",
                "text": [
                    "The overall ArchBERT framework is shown in Figure 2. The major components of ArchBERT include a text encoder, an architecture encoder, a cross encoder, and a pooling module.",
                    "First, the input text represented by a sequence of n words W \" tw i |i P r1, nsu is tokenized to a sequence of n tokens T \" tt i |i P r1, nsu. Then, the text encoder E t is utilized to map them to some word/token embeddings denoted by M t P R pn\u02c6dq with the embedding size of d: M t \" E t pT q.",
                    "On the other hand, the architecture encoder is responsible for encoding the input neural architecture. In this procedure, the computational graph of the input architecture is first extracted and represented with a directed acyclic graph G \" tV, A, Su where V \" tv i |i P r1, msu denotes a sequence of m nodes representing the operations and layers (e.g., convolutions, fully-connected layers, summations, etc.) and A P t0, 1u m\u02c6m denotes a binary adjacency matrix describing the edges and the connectivity between the nodes. In addition to the nodes and edges, we also extract the shape of the param-eters associated with each node (i.e., input/output channel dimensions and kernel sizes), denoted by S \" tps i P N 4 q|i P r1, msu.",
                    "The nodes and the shapes are separately encoded using the node and shape embedders E v and E s , respectively. The adjacency matrix along with the summation of the resulting nodes and shapes embeddings are then given to a Graph Attention Network (GAT) (Veli\u010dkovi\u0107 et al., 2018) for computing the final architecture (graph) embeddings denoted by M g P R pm\u02c6dq with the embedding size of d:",
                    "M g \" GAT pE v pV q `Es pSq, Aq(1)",
                    "In general, GAT is designed to operate on graphstructured data in which a set of graph features (node+shape embeddings in our case) is transformed into higher-level features. Given the adjacency matrix, the GAT model also allows all nodes to attend over their neighborhoods' features based on a self-attention strategy.",
                    "For joint learning of textual and architectural embeddings and share learning signals between both modalities, a cross transformer encoder, E c , is used to process both embeddings in parallel. These embeddings are then average-pooled to fixed-size 1D representations J t P R p1\u02c6dq and J g P R p1\u02c6dq :",
                    "tJ t , J g u \" E c ptM t , M g uq (2)",
                    "As in S-BERT (Reimers and Gurevych, 2019), we use the cosine similarity loss as a regression objective function to learn the similarity/dissimilarity between architectures and language embeddings. First, the cosine similarity between J t and J g are computed. Given a target soft score y P r0, 1s (i.e., 0: dissimilar, 1: similar), the following mean squared-error (MSE) loss is then employed:",
                    "L SIM \" }y \u00b4Jt .J g maxp}J t } 2 .}J g } 2 , q } 2 ,(3)",
                    "which minimizes the cosine distance between J t and J g pairs labeled as similar, while maximizes the distance for the dissimilar ones."
                ],
                "publication_ref": [
                    "b35",
                    "b27"
                ],
                "figure_ref": [
                    "fig_0"
                ],
                "table_ref": []
            },
            {
                "heading": "Masked Architecture Modeling (MAM)",
                "text": [
                    "In the literature, a well-known pre-training objective function called Masked Language Modeling (MLM) is widely used by BERT-based models for learning language representations (Devlin et al., 2019). Inspired by MLM, we introduce a new objective called Masked Architecture Modeling (MAM) to provide more generalized learning and understanding of the graph embeddings corresponding to the neural architectures by ArchBERT. Inspired by BERT (Devlin et al., 2019), we randomly mask 15% of the nodes with a special mask token and re-produce the masked nodes under the condition of the known ones. The MAM objective function is then defined as:",
                    "L M AM \" \u00b4EV i \"V log ppV i | V q, (4",
                    ")",
                    "where V is the masked version of V . In other words, V includes the contextual unmasked tokens surrounding the masked token V i . In practice, the corresponding probability distribution is obtained by the MAM head H M . The MAM head defines the distribution by performing the softmax function on the logits F m P R pm\u02c6|E|q mapped from the graph embeddings J g as follows: F m \" H M pJ g q, where E is the entire vocabulary of nodes (or nodes corpus) set. Given L SIM and L M AM , the following weighted loss is then used for optimizing and pre-training the ArchBERT model:",
                    "L \" L SIM `\u03b1L M AM .",
                    "(5)"
                ],
                "publication_ref": [
                    "b6",
                    "b6"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Architectural Question Answering (AQA)",
                "text": [
                    "The pre-trained ArchBERT can be utilized for the AQA task that is defined as the procedure of answering natural language questions about neural architectures. In other words, we can enable the Arch-BERT model to predict the answers to architecturerelated questions when the architecture and the question are matched.",
                    "For this task, we can fine-tune ArchBERT as a fusion encoder to jointly encode the input neural architecture and the question. To this end, the question and the architecture are first encoded using the text and architecture encoders, respectively. Both embeddings are then cross-encoded and pooled in order to calculate the final joint embeddings J t and J g . The element-wise product is then computed to interactively catch similarity/dissimilarity and discrepancies between the embeddings. The resulting product is fed into AQA head for mapping to the logits F q P R |A| corresponding to |A| answers:",
                    "F q \" H q pJ t .J g q (6)",
                    "As in (Anderson et al., 2018), the AQA in our work is formulated as a multi-label classification task, which assigns a soft target score to each answer based on its relevancy to |A| answers. A binary cross-entropy loss (denoted by L AQA ) on the target scores is then used as objective function."
                ],
                "publication_ref": [
                    "b2"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Language Decoder",
                "text": [
                    "We can empower the pre-trained ArchBERT to learn from and then benefiting for neural architecture captioning (or summarization) task by attaching a transformer decoder (Lewis et al., 2020) to generate textual tokens one by one. In this regard, an auto-regressive decoding procedure is employed with the following loss function:",
                    "L DEC \" \u00b4ET i \"T log ppT i |T \u0103i , T q, (7",
                    ")",
                    "where T is the masked version of the ground truth text T , and T i is the i-th token to be predicted. T \u0103i denotes the set of all the tokens decoded before T i . Similar to MAM, the probability distribution over the whole vocabulary is practically obtained by applying softmax on the decoded feature (or logits) F d P R pm\u02c6|C|q that is calculated by providing the graph embeddings J g to the decoder: F d \" D t pJ g q, where C denotes the entire vocabulary set."
                ],
                "publication_ref": [
                    "b16"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Datasets",
                "text": [
                    "For pre-training the ArchBERT model, a dataset of neural architectures labeled with some relevant descriptions is required. To the best of our knowledge, there is no such bi-modal dataset in the literature. In this paper, we introduce two datasets called TVHF and AutoNet for bi-modal learning of neural architectures and natural languages. The numerical and the statistical details of TVHF and AutoNet datasets are summarized in Table 1.",
                    "Note that all the labels and descriptions in the proposed datasets have been manually checked and refined by human. There may be some minor noise in the dataset (i.e., an inevitable nature of any dataset, especially the very first versions), but in overall, the datasets are of sufficient quality for our proof-of-concept experiments."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_0"
                ]
            },
            {
                "heading": "TVHF",
                "text": [
                    "In order to create this dataset, we collected 538 unique neural architectures form TorchVision (TV) (Marcel and Rodriguez, 2010) and HuggingFace (HF) (Wolf et al., 2019) frameworks. The descriptions relevant to the architectures were extracted from TV and HF frameworks as well as other online resources such as papers and web pages (with the vocabulary size |C|=31,764). To increase the dataset size, the descriptions were split into individual sentences each assigned to the related architecture, which provided a collection of 2,224 positive samples, i.e., pairs of architecture with their relevant descriptions (details in the appendix).",
                    "To assure the model learns both similarities and dissimilarities, we also generated negative samples by assigning irrelevant descriptions to the architectures (resulting in a total of 27,863 negative samples). We randomly split the dataset (in total 30,087 samples) into 80% for train and 20% for validation.",
                    "For fine-tuning and evaluating ArchBERT on Architecture Clone Detection (ACD), we establish another dataset including pairs of architectures manually hard-labeled with a dissimilarity/similarity score (0 or 1). To this end, all combinations of two architectures from TVHF were collected (in total 82.8K samples) and split into train/val sets (80% and 20%). Details are provided in the appendix."
                ],
                "publication_ref": [
                    "b21",
                    "b37"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "AutoNet",
                "text": [
                    "As described before, TVHF includes realistic human-designed architectures, which are manually labeled with real descriptions. On the other hand, we introduce the AutoNet dataset, which includes automatically generated architectures and descriptions. AutoNet is basically the modified and extended version of DeepNet1M (Knyazev et al., 2021), which is a standardized benchmark and dataset of randomly generated architectures for the parameter prediction tasks.",
                    "In AutoNet, we extend the set of operations (layers) from 15 types (in DeepNet1M) to 85, which include most of the recent operations used in computer vision and natural language models. We followed the same procedure in DeepNet1M and ran- domly generated 10K and 1K architectures for train and validation sets, respectively.",
                    "For automatic generation of textual descriptions related to each architecture, we created an extensive set of sentence templates, which were filled based on the information extracted from the structure, modules, and existing layers of the corresponding architecture. The same process was applied for generating negative samples, but with the textual information of the non-existing modules and layers in the architecture. For each architecture, 10-11 textual descriptions were created, which resulted in 103,306 and 10,338 architecture and text pairs for the train and validation sets (with the vocabulary size |C|=30,980), respectively. The details of this procedure are given in the appendix."
                ],
                "publication_ref": [
                    "b14"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "AutoNet-AQA",
                "text": [
                    "For fine-tuning and evaluating ArchBERT on AQA, another dataset including triplets of architectures, questions, and answers is needed. As in AutoNet, a set of question/answer templates were used to automatically generate the questions and answers. The same procedure of generating neural architectures as in AutoNet was employed. 10K and 1K architectures were respectively created for the train and validation sets. For each architecture, 35 unique questions were generated, and the answers were chosen from a list of |A| \" 51 unique answers. In total, the train and validation sets respectively include 350K and 35K samples.",
                    "The visualization of two sample graphs generated for ResNet18 from TVHF and a random architecture from AutoNet is shown in Figure 3. More sample data along with the quality analysis of the datasets are given in the appendix."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_1"
                ],
                "table_ref": []
            },
            {
                "heading": "Experimental Results",
                "text": [
                    "In this section, the performance of ArchBERT on the following downstream tasks is evaluated and numerically analyzed.",
                    "\u2022 Architectural Reasoning (AR): it is the task of determining if a statement regarding an architecture is correct or not. \u2022 Architecture Clone Detection (ACD): it includes the process of checking if two architectures are semantically/structurally similar or not. \u2022 Architectural Question Answering (AQA): as given in Section 3, it is the process of providing an answer to a question over a given architecture. \u2022 Architecture Captioning (AC): it is the task of generating descriptions for a given architecture.",
                    "Since there is no related prior works, we compare our method with some uni-modal baselines for each of the above tasks. An ablation study over different components of ArchBERT is also presented.",
                    "In this work, we employ the BERT-Base model (with 12 heads) as our ArchBERT's cross encoder. We pre-trained ArchBERT on both TVHF and Au-toNet datasets with a batch size of 80, embedding size of d=768, and the Adam optimizer with learning rate of 2e-5 for 6 hours. The training on TVHF and AutoNet was respectively done for 20 and 10 epochs. Since there is a large scale difference between the L SIM and L M AM loss values in the weighted loss in Equation 5, where L M AM \"L SIM , we set \u03b1=5e-2 to balance the total loss value (obtained experimentally). A batch size of 80 is used for all the tests with the pre-trained ArchBERT."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Uni-Modal Baselines",
                "text": [
                    "For the AR baseline, we compare the architecture name with an input statement, which is considered as \"correct\" if the architecture name appears in the statement, otherwise it is \"incorrect\". Note that unlike this baseline, ArchBERT does not need the architecture name to infer about the statements.",
                    "For the ACD uni-modal baseline (Figure 4-left), the architecture encoder is first used to separately map both input architectures, denoted by tG 1 , G 2 u, into the graph embeddings tM 1 g , M 2 g u (Equation 1). The cross encoder and pooling module are then applied to obtain the fixed-size joint representations tJ 1 g , J 2 g u (Equation 2). The cosine similarity loss in Equation 3 is finally performed on tJ 1 g , J 2 g u pairs along with a provided hard-label. For this baseline, we trained ArchBERT with architecture-only pairs (without text encoder) from TVHF-ACD train set.",
                    "For the AQA uni-modal baseline (Figure 4middle), we train a text-only ArchBERT (without architecture encoder), where the context is obtained from the textual information and summary of the input architecture, e.g., layer names (i.e., using Pytorch model summary function). The extracted information is considered as the input context on which the question answering procedure is performed. The tokenized input question and context, denoted by tT q , T c u, are mapped into token embeddings tM q t , M c t u, which are then crossencoded and average-pooled to obtain the joint embeddings tJ q t , J c t u (Equation 2). As in Equation 6, the element-wise product of tJ q t , J c t u is given to the AQA head to obtain the logits required for the binary cross-entropy loss described in Section 3.2.",
                    "For the AC uni-modal baseline (Figure 4-right), we trained ArchBERT (without text encoder) followed by the decoder from scratch (no bi-modal pre-training of ArchBERT). The detailed AC procedure is described in Section 3.3."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_2",
                    "fig_2",
                    "fig_2"
                ],
                "table_ref": []
            },
            {
                "heading": "Architectural Reasoning (AR)",
                "text": [
                    "For this task, the input text and the architecture are given to ArchBERT to create the pooled embeddings. The cosine similarity score between these embeddings is then computed. If the score is greater than some threshold \u03c4 (i.e., 0.5), the statement on the architecture is determined as \"correct\", otherwise \"incorrect\". We evaluate the performance of the pre-trained ArchBERT on this task over the TVHF validation set. As summarized in Table 2, an accuracy and F1 score of 96.13% and 71.86% were respectively achieved. F1 scores are reported to deal with the class imbalance.  "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_2"
                ]
            },
            {
                "heading": "As reported in",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Architecture Clone Detection (ACD)",
                "text": [
                    "To perform this task, both input architectures are given to ArchBERT's architecture encoder followed by the cross-encoder and pooling module to obtain the pooled embeddings. The cosine similarity of the embeddings is then computed. If the similarity score is greater than a threshold (i.e., 0.5), the two architectures are considered similar, otherwise dissimilar.",
                    "We first evaluate the pre-trained ArchBERT's performance on the TVHF-ACD validation set. Although the pre-trained model has not specifically learned to detect similar/dissimilar architectures, it still achieves a good accuracy of 86.20% and F1 score 60.10% (Table 2). However, by fine-tuning the pre-trained ArchBERT with TVHF-ACD train set, significantly improved accuracy and F1 score of 96.78% and 85.98% are achieved.",
                    "Two baselines including Jaccard similarity (Santisteban and Tejada-C\u00e1rcamo, 2015) and a unimodal version of ArchBERT are used to compare with our bi-modal ArchBERT on ACD task. For Jaccard, the similarity of the architecture pairs is computed by taking the average ratio of intersection over union of the nodes and edges (V and A). The pairs are considered as \"similar\" if the similarity score is greater than 0.5, otherwise \"dissimilar\". As shown in Table 2, the pre-trained and fine-tuned ArchBERT models respectively outperform this baseline with 14% and 40% higher F1 scores. The ACD uni-modal baseline also achieves F1 score of 84%, i.e., 2% lower than fine-tuned ArchBERT."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_2",
                    "tab_2"
                ]
            },
            {
                "heading": "Architectural Question Answering (AQA)",
                "text": [
                    "For this, ArchBERT along with the attached AQA head (composed of a two layer MLP) is fine-tuned with the AutoNet-AQA dataset using a batch size of 140 over 10 epochs (for about 10 hours). We use the Adam optimizer with an initial learning rate of 2e-5. At the inference time, we simply take a sigmoid over the AQA head's logits (with the same batch size of 140). As given in Table 2, ArchBERT achieves an accuracy of 72.73% and F1 score of and 73.51% over the AutoNet-AQA validation set. For the AQA baseline, an F1 score of 61.84% was obtained on AutoNet-AQA, which is \u00ab12% lower than the proposed bi-modal ArchBERT."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_2"
                ]
            },
            {
                "heading": "Architecture Captioning (AC)",
                "text": [
                    "To analyze ArchBERT's performance on AC, the pre-trained ArchBERT (without text encoder) attached with a language decoder is fine-tuned on both TVHF and AutoNet with a batch size of 30 for Adam optimizer with an initial learning rate of 2e-5 was used. For the language decoder, a single-layer transformer decoder (with 12 heads and hidden size of d=768) followed by 2 linear layers is used. At the inference, the beam search (with the size of 10) was employed to auto-regressively generate the output tokens, which were then decoded back to their corresponding words. The same batch size of 30 was used for the evaluation. The results over the TVHF and AutoNet validation sets are summarized in Table 3, where Rouge-Lsum-Fmeasure (RL) (Lin, 2004) scores of 0.17 and 0.46 were respectively achieved. Unlike AutoNet, TVHF dataset includes more complicated neural architectures along with high-level human-written textual descriptions, which makes the architecture captioning more challenging. As a result, lower performance is achieved.",
                    "The uni-modal AC baseline achieves an RL of 0.38 on AutoNet, which is 8% lower than the proposed bi-modal ArchBERT (i.e., pre-trained on both architectures and text, and fine-tuned for AC)."
                ],
                "publication_ref": [
                    "b18"
                ],
                "figure_ref": [],
                "table_ref": [
                    "tab_3"
                ]
            },
            {
                "heading": "Architecture Search (AS)",
                "text": [
                    "ArchBERT is also applicable to Architecture Search (AS) downstream task. The task is to design a semantic search engine to receive a textual query from the user, search over a database of numerous neural architectures (or models), and return the best matching ones. As for any semantic search engine, an indexed database of all searched architecture embeddings is needed, within which the architecture search is performed. For the search procedure over such database using ArchBERT, the text query is encoded by the text encoder, and then is cross-encoded to make sure the previouslylearned architectural knowledge is also utilized for computing final text embeddings. The pooled text embeddings are then compared with all the architecture embeddings stored in the database to find the best matching (most similar) architectures. We did not report any numerical analysis for AS due to the lack of related validation set. However, qualitative demo is available in the supplementary materials."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Qualitative Results",
                "text": [
                    "In Table 4, ArchBERT's predictions on AR and ACD tasks over some samples from TVHF validation set are given. In addition, we present the predictions on AC and AQA tasks over the right architecture in Figure 3 (i.e., a sample from AutoNet validation set). Sample cases for which ArchBERT makes wrong predictions are also given in the table (marked with *), e.g., AR's prediction for Vit_b_16 and ConvNext-tiny architectures."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_1"
                ],
                "table_ref": [
                    "tab_4"
                ]
            },
            {
                "heading": "Ablation Study",
                "text": [
                    "We conduct ablation study to analyze the effect of ArchBERT's different modules such as MAM, Cross Encoder, and graph elements on the performance of AR, ACD, AQA, and AC tasks. The results are summarized in Tables 2 and 3. First, we remove the MAM head and its loss from the pre-training and fine-tuning stages. The performance of the pre-trained model without MAM is evaluated on AR and ACD with the TVHF dataset. As seen in Table 2, excluding MAM in pretraining results in a significant F1 drops by 7.59% and 10.51% on AR and ACD tasks, respectively. The effect of MAM on finetuend ArchBERT for AQA and AC downstream tasks is also evaluated and reported in in Tables 2 and 3. It is shown that using MAM provides F1 score improvements of 7.35% and 0.03% on AQA and AC, respectively.",
                    "We also study the ArchBERT's performance when the Transformer cross encoder is not used for encoding the architectures. In this case, the embeddings obtained from the architecture encoder are directly used for training and evaluating the model by bypassing the cross encoder. The corresponding results on AR, ACD, and AQA tasks are given in Table 2. From the results, when the cross encoder is removed, the performance of both the pre-trained and fine-tuned models decreases. This reveals the importance of the cross encoder in joint encoding and learning of the text and architecture. As seen in the table, the F1 scores on AR, ACD, and AQA tasks are substantially reduced by 14.83%, 17.75%, and 10.18%, respectively, if the cross encoder is not utilized for architecture encoding.",
                    "We also ran a set of ablations over different graph items. For AR, F1 scores of 71.86% (Arch-BERT), 69.16% (w/o shape), 68.98% (w/o edge), and 65.80% (w/o shape+edge) are achieved. For ACD, F1 scores of 60.10% (ArchBERT), 60.20% (w/o shape), 47.96% (w/o edge), and 56.45% (w/o shape+edge) are obtained. It is seen that using all graph items provides the best results. For ACD, the shape has no effect on F1 score, but excluding it gives \u00ab1% lower accuracy.",
                    "The ArchBERT's performance on out-ofdistribution data will be presented in the appendix."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_3",
                    "tab_2",
                    "tab_3",
                    "tab_2"
                ]
            },
            {
                "heading": "Embeddings Visualization",
                "text": [
                    "As discussed before, ArchBERT learns to minimize the cosine distance between relevant text and archi-tecture embeddings, while maximizing the distance for the irrelevant ones. To convey this concept, we visualize the joint embeddings of example relevant texts and architectures (i.e., J t and J g in Equation 2) form TVHF dataset in Figure 5. The points in the figure are obtained by projecting the embeddings to a 2D space via PCA (Jolliffe, 2005). As shown in Figure 5, the text embeddings are mapped to the points near by their relevant architectures. This implies that ArchBERT has learned to minimize the distance between the related pairs of texts and architectures (i.e., positive samples) and obtain similar embeddings for them. On the other hand, the points for the irrelevant descriptions and architectures are projected far from each other, which shows the success of ArchBERT in maximizing the distance between unrelated pairs."
                ],
                "publication_ref": [
                    "b13"
                ],
                "figure_ref": [
                    "fig_3",
                    "fig_3"
                ],
                "table_ref": []
            },
            {
                "heading": "Conclusion",
                "text": [
                    "In this paper, we proposed ArchBERT, a bi-modal solution for joint learning of neural architectures and natural languages. We also introduced a new pre-training technique called Masked Architecture Modeling (MAM) for a better generalization of ArchBERT. In addition, two new bi-modal benchmark datasets called TVHF and AutoNet were presented on which the proposed model was trained and evaluated for different downstream tasks. Five architecture-language-related tasks and applications were introduced in this work to verify the performance of ArchBERT. This work has opened up new avenues for research in the area of architecturelanguage joint understanding, particularly the proposed benchmarks. Potential research directions to this work include text-based neural architecture generation and bi-modal learning of languages and other graph-structured modalities such as knowledge graphs and social network graphs.",
                    "TV-only, and HF-only datasets, and evaluate their performance on each other. The corresponding experimental results are summarized in Table 5.",
                    "As observed in the table, the models trained on TV and HF subsets do not generalize to each other due to the difference in their data distributions, which results in poor performance. The distribution plots for TV and HF subsets are shown in Figure 8. As given in Table 5, the highest scores on each of TV and HF subsets are obtained by the model trained with the entire TVHF training dataset. In order to improve the performance of our model on OOD, some techniques such as zero-shot or fewshot learning can be employed, which is a potential research direction for this work."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_6"
                ],
                "table_ref": [
                    "tab_6",
                    "tab_6"
                ]
            },
            {
                "heading": "A.3 Embeddings Visualization",
                "text": [
                    "In Figure 5, an embedding visualization of some architecture-text pairs was illustrated. In Figure 7, the visualizations for two different architectures from TVHF dataset are individually presented. The points on the figures are obtained by projecting the final ArchBERT's embeddings onto a 2D space via PCA. As shown in the plots, unlike the relevant text embeddings (marked with `), the irrelevant ones (marked with \u02c6) are projected far from the corresponding architecture embedddings."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_3",
                    "fig_5"
                ],
                "table_ref": []
            },
            {
                "heading": "A.4 Data Generation",
                "text": [
                    "The procedure of creating TVHF dataset along with negative samples are given in Algorithm 1. To generate the negative data samples, a pre-trained S-BERT model (Reimers and Gurevych, 2019) is used to calculate the similarity score between all possible pairs of unique descriptions. If the maximum similarity score between each unique sentence and all other sentences of each unique neural architecture is smaller than a threshold 0.5, that sen-    tence is chosen as an irrelevant description for that specific neural architecture. Note that 93% of the final TVHF train set contains negative samples. The above-mentioned procedure of generating many negative candidates per each positive sample was inspired by the multiple negatives sampling idea described by Henderson et al. (2017). Having multiple negatives was proved to be effective when used with dot-product and cosine similarity loss function (Equation 3 in the main paper).",
                    "For TVHF-ACD dataset, all possible pairs of neural architectures were compared based on their structures. A hard score of 1 or 0 is then assigned to a similar or dissimilar pair of architectures, respectively. For TorchVision architectures with the same architectural base (e.g., ResNet family), a hard score of 1 is assigned to the pair. For Hugging-Face models, the configuration files were compared and in case of having similar specifications, a hard score of 1 has been assigned to those architectures. In overall, the TVHF-ACD dataset includes 11% of similar pairs of architectures.",
                    "For AutoNet dataset, all unique layers of each architecture are first extracted. To do so, an algorithm is developed to take an architecture as input and recursively extracts all unique modules and their class path within that architecture. These unique layers are then used along with a list of various pre-defined templates to randomly generate meaningful descriptions with different words and sentence structures. The algorithm is then used with modules that are not included in the architecture to generate irrelevant descriptions that are considered as negative data samples. Each architecture has about 10-11 different descriptions about 30% of which are the positive ones. The same extracted layers and procedures are also used for automati- cally generating the question and answer pairs, but with a different set of templates for questions."
                ],
                "publication_ref": [
                    "b27"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Algorithm 1 TVHF dataset generator",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Input:",
                "text": [
                    "Threshold \u03b2, architectures G, pos_samples T p Output: list of architectures plus their positive and negative descriptions for each unique neural architecture G j P G do for each unique description T p i P T p pG j q do if max(SBERT(T p i , T p \"i )) \u010f \u03b2 then Add T i to T n pG j q (list of neg_samples for jth architecture) end if end for end for return {G, (T p , T n )}"
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.5 Distribution Plots for TVHF and AutoNet",
                "text": [
                    "Figure 9 shows the distribution plots of the TVHF, AutoNet, and AutoNet-AQA datasets. For each dataset, the plots of the training and validation distributions of the number of nodes, the number of edges, the number of textual tokens, and the sequence length of the descriptions are illustrated."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_7"
                ],
                "table_ref": []
            },
            {
                "heading": "A.6 Sample Data from TVHF and AutoNet",
                "text": [
                    "In Table 6, example positive architecturedescription pairs (for both computer vision and natural language processing problems) from TVHF dataset are given. Some sample pairs of architectures (with their corresponding \"similar\" or \"dissimilar\" ground truth labels) from TVHF-ACD dataset are also presented in Table 7.",
                    "In Table 9, we also provide data samples for the BACD task, which includes quartets of two architectures, supporting description, and the similarity label. Note that the numerical analysis of ArchBERT over BACD is not provided because our BACD validation dataset is not finalized to be used for this matter.",
                    "Table 8 also presents a few data samples from AutoNet dataset used for fine-tuning and evaluating ArchBERT on AC task. In Table 10, sample data from AutoNet-AQA including the automatically generated questions and ground truth answers for AQA downstream task are given.",
                    "In Figures 10 and 11, the visualization of all graphs generated for the neural architectures listed in Tables 4, 8, and 10 are illustrated."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_7",
                    "tab_8",
                    "tab_0",
                    "tab_4"
                ]
            },
            {
                "heading": "A.7 Dataset Quality Analysis",
                "text": [
                    "We provide dataset quality analysis based on four criteria: reliability and completeness, label/feature noise, feature representation, and minimizing skew (Google, 2022)."
                ],
                "publication_ref": [
                    "b9"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.7.1 Reliability and Completeness",
                "text": [
                    "The reliability of data refers to how trustable the data is, whether it has duplicated values and if it covers both positive and negative samples. As for dataset completeness, it refers to how much of the relevant information is included in the dataset for dealing with the desired problem.",
                    "In our TVHF dataset, we have collected models and their relevant descriptions as related bi-modal data types for the ArchBERT model to learn neu- ral architectures along with their corresponding natural language descriptions. We considered the reliability and completeness of our dataset by collecting various models with different architectures designed for different tasks such as image and text classification, object detection, text summarization, etc. Also, the descriptions that have been assigned to each model were collected through blog posts, articles, papers, and documentations containing both high/low-level information related to that specific model. Due to the limited number of humandesigned models, to make our dataset large enough for training we used each architecture more than once, and each time we assigned a different unique description to it to avoid having duplicate architecture-description pairs in our dataset. Moreover, we generated negative samples by assigning irrelevant descriptions to the architectures, so that the model could learn both similarities and dissimilarities.",
                    "As discussed in Section 4, some of the descriptions in TVHF dataset did not include relevant technical information to the corresponding models. We manually reviewed the descriptions and removed such samples. We will further enhance the descriptions associated with each model within the release of the next version of our dataset."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.7.2 Label/Feature Noise",
                "text": [
                    "Label noise refers to an imperfect annotation of data that confounds the assessment of model performance when training machine learning models. Feature noise can be defined as the noise got into the dataset through various factors such as incorrect collection by humans or instruments. Inconsistencies in data formats, missing values, and outliers are examples of noise created by this process.",
                    "If noise in a dataset is defined as a wrong description for a model, our dataset is a noise-free dataset because we annotated the samples manually.",
                    "Since the description of building blocks in the AutoNet models are converted to textual descriptions and question samples automatically, all the generated samples are relevant and noise-free.",
                    "For our ACD dataset, we manually hard-labeled the models based on their similarity with each another. Therefore, there is no missed or wrongly labeled example in the entire dataset."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.7.3 Feature Representation",
                "text": [
                    "Mapping data to useful features while presenting them to the model is defined as feature representation. In this case, we consider how data is presented to the model and whether the numeric values need to be normalized.",
                    "To show our data to the ArchBERT model, we have been consistent in the following way. For architectures, based on their computational graphs, we extracted nodes, shapes, and edges, which the major and sufficient items to represent an architecture in our work. We then normalized these items and passed them to the model. As for descriptions, we represented each textual description with tokens, normalized them, and used them as inputs to the model. We have collected our data and presented them to the model in the way that both training and validation stages receive the exact same set of features coming from the same distribution. This guarantees that our data is not skewed towards training or validation stages. "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A Appendix",
                "text": [
                    "A.1 Code, Dataset, and Demo",
                    "In order for the results to be reproducible, we share our test code (plus the pre-trained model files) with detailed instructions in the supplementary materials. The code also includes the scripts for generating both TVHF and AutoNet datasets.",
                    "We also uploaded 6 video files demonstrating the performance of ArchBERT on the following downstream tasks: architecture search (AS), architectural reasoning (AR), architecture clone detection (ACD), bi-modal architecture clone detection (BACD), architectural question answering (AQA), and architecture captioning (AC).",
                    "All the code and demo files are also available here 2 .",
                    "BACD task is similar to ACD, except that a supporting text, which is considered as an extra criteria to refine the results, is also provided along with the two given architectures. The average similarity of the architectures' embeddings with the help of the text embeddings is evaluated to check if the architectures are similar or not.",
                    "The video recordings were taken from a web application we built to demonstrate the real-world application of our method. Example screenshots of the AR and BACD demos are shown in Figure 6."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.2 ArchBERT's Performance on OOD Data",
                "text": [
                    "In order to study the behaviour of ArchBERT on out-of-distribution (OOD) data, we establish another set of experiments on individual TV and HF datasets that have different distributions. In this regard, we pre-train ArchBERT on each of TVHF, "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            }
        ],
        "references": [
            {
                "ref_id": "b0",
                "title": "VATT: Transformers for multimodal selfsupervised learning from raw video, audio and text",
                "journal": "Advances in Neural Information Processing Systems",
                "year": "2021",
                "authors": "Hassan Akbari; Liangzhe Yuan; Rui Qian; Wei-Hong Chuang; Shih-Fu Chang; Yin Cui; Boqing Gong"
            },
            {
                "ref_id": "b1",
                "title": "E-lang: Energy-based joint inferencing of super and swift language models",
                "journal": "Long Papers",
                "year": "2022",
                "authors": "Mohammad Akbari; Amin Banitalebi-Dehkordi; Yong Zhang"
            },
            {
                "ref_id": "b2",
                "title": "Bottom-up and top-down attention for image captioning and visual question answering",
                "journal": "",
                "year": "2018",
                "authors": "Peter Anderson; Xiaodong He; Chris Buehler; Damien Teney; Mark Johnson; Stephen Gould; Lei Zhang"
            },
            {
                "ref_id": "b3",
                "title": "Multimodal machine learning: A survey and taxonomy. IEEE transactions on pattern analysis and machine intelligence",
                "journal": "",
                "year": "2018",
                "authors": "Tadas Baltru\u0161aitis; Chaitanya Ahuja; Louis-Philippe Morency"
            },
            {
                "ref_id": "b4",
                "title": "Vl-beit: Generative vision-language pretraining",
                "journal": "",
                "year": "2022",
                "authors": "Hangbo Bao; Wenhui Wang; Li Dong; Furu Wei"
            },
            {
                "ref_id": "b5",
                "title": "Language models are few-shot learners",
                "journal": "",
                "year": "2020",
                "authors": "Tom Brown; Benjamin Mann; Nick Ryder; Melanie Subbiah; Jared D Kaplan; Prafulla Dhariwal; Arvind Neelakantan; Pranav Shyam; Girish Sastry; Amanda Askell"
            },
            {
                "ref_id": "b6",
                "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
                "journal": "",
                "year": "2019",
                "authors": "Jacob Devlin; Ming-Wei Chang; Kenton Lee; Kristina Toutanova"
            },
            {
                "ref_id": "b7",
                "title": "Codebert: A pre-trained model for programming and natural languages",
                "journal": "Association for Computational Linguistics",
                "year": "2020-11-20",
                "authors": "Zhangyin Feng; Daya Guo; Duyu Tang; Nan Duan; Xiaocheng Feng; Ming Gong; Linjun Shou; Bing Qin; Ting Liu; Daxin Jiang; Ming Zhou"
            },
            {
                "ref_id": "b8",
                "title": "Violet: End-to-end video-language transformers with masked visual-token modeling",
                "journal": "",
                "year": "2021",
                "authors": "Tsu-Jui Fu; Linjie Li; Zhe Gan; Kevin Lin; William Yang Wang; Lijuan Wang; Zicheng Liu"
            },
            {
                "ref_id": "b9",
                "title": "The size and quality of a data set",
                "journal": "",
                "year": "2022",
                "authors": " Google"
            },
            {
                "ref_id": "b10",
                "title": "Graphcodebert: Pre-training code representations with data flow",
                "journal": "",
                "year": "2021-05-03",
                "authors": "Daya Guo; Shuai Shuo Ren; Zhangyin Lu; Duyu Feng; Shujie Tang; Long Liu; Nan Zhou; Alexey Duan; Shengyu Svyatkovskiy; Michele Fu;  Tufano; Colin B Shao Kun Deng; Dawn Clement; Neel Drain; Jian Sundaresan; Daxin Yin; Ming Jiang;  Zhou"
            },
            {
                "ref_id": "b11",
                "title": "Balint Miklos, and Ray Kurzweil. 2017. Efficient natural language response suggestion for smart reply",
                "journal": "",
                "year": null,
                "authors": "Matthew Henderson; Rami Al-Rfou; Brian Strope; Yun-Hsuan Sung; L\u00e1szl\u00f3 Luk\u00e1cs; Ruiqi Guo"
            },
            {
                "ref_id": "b12",
                "title": "More diverse means better: Multimodal deep learning meets remote-sensing imagery classification",
                "journal": "IEEE Transactions on Geoscience and Remote Sensing",
                "year": "2020",
                "authors": "Danfeng Hong; Lianru Gao; Naoto Yokoya; Jing Yao; Jocelyn Chanussot; Qian Du; Bing Zhang"
            },
            {
                "ref_id": "b13",
                "title": "Principal component analysis. Encyclopedia of statistics in behavioral science",
                "journal": "",
                "year": "2005",
                "authors": "Ian Jolliffe"
            },
            {
                "ref_id": "b14",
                "title": "Parameter prediction for unseen deep architectures",
                "journal": "Advances in Neural Information Processing Systems",
                "year": "2021",
                "authors": "Boris Knyazev; Michal Drozdzal; W Graham; Adriana Romero Taylor;  Soriano"
            },
            {
                "ref_id": "b15",
                "title": "Imagenet classification with deep convolutional neural networks",
                "journal": "Communications of the ACM",
                "year": "2017",
                "authors": "Alex Krizhevsky; Ilya Sutskever; Geoffrey E Hin"
            },
            {
                "ref_id": "b16",
                "title": "Denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension",
                "journal": "",
                "year": "2020",
                "authors": "Mike Lewis; Yinhan Liu; Naman Goyal ; Abdelrahman Mohamed; Omer Levy; Veselin Stoyanov; Luke Zettlemoyer"
            },
            {
                "ref_id": "b17",
                "title": "VisualBERT: A simple and performant baseline for vision and language",
                "journal": "",
                "year": "2019",
                "authors": "Liunian Harold Li; Mark Yatskar; Da Yin; Cho-Jui Hsieh; Kai-Wei Chang"
            },
            {
                "ref_id": "b18",
                "title": "Rouge: A package for automatic evaluation of summaries",
                "journal": "",
                "year": "2004",
                "authors": "Chin-Yew Lin"
            },
            {
                "ref_id": "b19",
                "title": "ViLBERT: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks",
                "journal": "",
                "year": "2019",
                "authors": "Jiasen Lu; Dhruv Batra; Devi Parikh; Stefan Lee"
            },
            {
                "ref_id": "b20",
                "title": "Soybean yield prediction from uav using multimodal data fusion and deep learning. Remote sensing of environment",
                "journal": "",
                "year": "2020",
                "authors": "Maitiniyazi Maimaitijiang; Vasit Sagan; Paheding Sidike; Sean Hartling; Flavio Esposito; Felix B Fritschi"
            },
            {
                "ref_id": "b21",
                "title": "Torchvision the machine-vision package of torch",
                "journal": "Association for Computing Machinery",
                "year": "2010",
                "authors": "S\u00e9bastien Marcel; Yann Rodriguez"
            },
            {
                "ref_id": "b22",
                "title": "An overview of deep-learning-based audio-visual speech enhancement and separation",
                "journal": "",
                "year": "2021",
                "authors": "Daniel Michelsanti; Zheng-Hua Tan; Shi-Xiong Zhang; Yong Xu; Meng Yu; Dong Yu; Jesper Jensen"
            },
            {
                "ref_id": "b23",
                "title": "Speech, and Language Processing",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b24",
                "title": "",
                "journal": "OpenAI. 2022. Introducing chatgpt",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b25",
                "title": "",
                "journal": "OpenAI. 2023. Gpt-4 technical report",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b26",
                "title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
                "journal": "J. Mach. Learn. Res",
                "year": "2020",
                "authors": "Colin Raffel; Noam Shazeer; Adam Roberts; Katherine Lee; Sharan Narang; Michael Matena; Yanqi Zhou; Wei Li; J Peter;  Liu"
            },
            {
                "ref_id": "b27",
                "title": "Sentencebert: Sentence embeddings using siamese bertnetworks",
                "journal": "",
                "year": "2019",
                "authors": "Nils Reimers; Iryna Gurevych"
            },
            {
                "ref_id": "b28",
                "title": "Faster r-cnn: Towards real-time object detection with region proposal networks",
                "journal": "",
                "year": "2015",
                "authors": "Kaiming Shaoqing Ren; Ross He; Jian Girshick;  Sun"
            },
            {
                "ref_id": "b29",
                "title": "Unilateral jaccard similarity coefficient",
                "journal": "",
                "year": "2015",
                "authors": "Julio Santisteban; Javier Tejada-C\u00e1rcamo"
            },
            {
                "ref_id": "b30",
                "title": "Leveraging recent advances in deep learning for audio-visual emotion recognition",
                "journal": "",
                "year": "2021",
                "authors": "Liam Schoneveld; Alice Othmani; Hazem Abdelkawy"
            },
            {
                "ref_id": "b31",
                "title": "VideoBERT: A joint model for video and language representation learning",
                "journal": "",
                "year": "2019",
                "authors": "Chen Sun; Austin Myers; Carl Vondrick; Kevin Murphy; Cordelia Schmid"
            },
            {
                "ref_id": "b32",
                "title": "LXMERT: learning cross-modality encoder representations from transformers",
                "journal": "",
                "year": "2019-11-03",
                "authors": "Hao Tan; Mohit Bansal"
            },
            {
                "ref_id": "b33",
                "title": "Multimodal transformer for unaligned multimodal language sequences",
                "journal": "NIH Public Access",
                "year": "2019",
                "authors": "Yao-Hung Hubert Tsai; Shaojie Bai; Paul Pu Liang; Zico Kolter; Louis-Philippe Morency; Ruslan Salakhutdinov"
            },
            {
                "ref_id": "b34",
                "title": "Long-term cancer survival prediction using multimodal deep learning",
                "journal": "Scientific Reports",
                "year": "2021",
                "authors": "A Lu\u00eds; Karl Vale-Silva;  Rohr"
            },
            {
                "ref_id": "b35",
                "title": "Graph attention networks",
                "journal": "",
                "year": "2018",
                "authors": "Petar Veli\u010dkovi\u0107; Guillem Cucurull; Arantxa Casanova; Adriana Romero; Pietro Li\u00f2; Yoshua Bengio"
            },
            {
                "ref_id": "b36",
                "title": "Multimodal deep learning models for early detection of alzheimer's disease stage",
                "journal": "Scientific reports",
                "year": "2021",
                "authors": "Janani Venugopalan; Li Tong; Hamid Reza Hassanzadeh; May D Wang"
            },
            {
                "ref_id": "b37",
                "title": "Huggingface's transformers: State-of-the-art natural language processing",
                "journal": "",
                "year": "2019",
                "authors": "Thomas Wolf; Lysandre Debut; Victor Sanh; Julien Chaumond; Clement Delangue; Anthony Moi; Pierric Cistac; Tim Rault; R\u00e9mi Louf; Morgan Funtowicz"
            },
            {
                "ref_id": "b38",
                "title": "Multimodal endto-end autonomous driving",
                "journal": "",
                "year": "2020",
                "authors": "Yi Xiao; Felipe Codevilla; Akhil Gurram; Onay Urfalioglu; Antonio M L\u00f3pez"
            },
            {
                "ref_id": "b39",
                "title": "",
                "journal": "",
                "year": "",
                "authors": " Bert-Mini"
            },
            {
                "ref_id": "b40",
                "title": "Graphs generated for the architectures listed in Table 4 (a) Architecture with layers: Conv2d, Batch-Norm2d, ReLU, Dil_conv2d, Sep_conv2d, Avg-Pool2d, AdaptiveAvgPool2d, Linear (b) Architecture with layers: Conv2d",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b41",
                "title": "Graphs generated for the architectures listed in Tables 8 and 10",
                "journal": "",
                "year": "",
                "authors": ""
            }
        ],
        "figures": [
            {
                "figure_label": "2",
                "figure_type": "figure",
                "figure_id": "fig_0",
                "figure_caption": "Figure 2 :2Figure 2: Overall framework of ArchBERT.",
                "figure_data": ""
            },
            {
                "figure_label": "3",
                "figure_type": "figure",
                "figure_id": "fig_1",
                "figure_caption": "Figure 3 :3Figure 3: Sample graphs generated for ResNet18 (left) and a random architecture from AutoNet (right).",
                "figure_data": ""
            },
            {
                "figure_label": "4",
                "figure_type": "figure",
                "figure_id": "fig_2",
                "figure_caption": "Figure 4 :4Figure 4: Uni-Modal Baselines (left: ACD, middle: AQA, right: AC).",
                "figure_data": ""
            },
            {
                "figure_label": "5",
                "figure_type": "figure",
                "figure_id": "fig_3",
                "figure_caption": "Figure 5 :5Figure 5: Visualization of example relevant architecture and text embeddings in a 2D space (projected via PCA).",
                "figure_data": ""
            },
            {
                "figure_label": "6",
                "figure_type": "figure",
                "figure_id": "fig_4",
                "figure_caption": "Figure 6 :6Figure 6: Screenshots from the demos. Left: Architectural Reasoning (AR); Right: Bi-Modal Architecture Clone Detection (BACD).",
                "figure_data": ""
            },
            {
                "figure_label": "7",
                "figure_type": "figure",
                "figure_id": "fig_5",
                "figure_caption": "Figure 7 :7Figure 7: Visualization of example pairs of (ir)relevant architecture and text embeddings in a 2D space (projected via PCA).",
                "figure_data": ""
            },
            {
                "figure_label": "8",
                "figure_type": "figure",
                "figure_id": "fig_6",
                "figure_caption": "Figure 8 :8Figure 8: Distribution plots of TV and HF train and validation sub-datasets compared with each other.",
                "figure_data": ""
            },
            {
                "figure_label": "9",
                "figure_type": "figure",
                "figure_id": "fig_7",
                "figure_caption": "Figure 9 :9Figure 9: Distribution plots of TVHF, AutoNet, and AutoNet-AQA train/validation datasets.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_8",
                "figure_caption": "One of the reasons that may cause getting different results for computed metrics at training vs. validation stages is training/validation skew. It usually happens when different features are presented to the model in training and validation stages.",
                "figure_data": ""
            },
            {
                "figure_label": "1",
                "figure_type": "table",
                "figure_id": "tab_0",
                "figure_caption": "Statistical details of TVHF and AutoNet datasets (*: AQA, \u00b5: mean, \u03c3: standard deviation, M : median).",
                "figure_data": "ArchitectureTextDatasetSplit #Samples#Unique#Unique#Nodes#Edges#Unique#TokensSequence LengthArchsNodes\u00b5\u03c3M\u00b5\u03c3MTokens\u00b5\u03c3M\u00b5\u03c3MTrain24069538501146.61 1162.38 705 1281 1302.90753350716.16 11.22 14 97.60 77.76 81TVHFVal6018538501146.61 1162.38 705 1281 1302.90753296516.21 11.59 14 97.88 80.33 81Train1033061000028371.50312.61 266 401322.9924176943.81 8.62 45 333.67 74.80 345AutoNetVal10338100028384.48343.31 266 419368.20 293.565243.92 8.66 45 334.01 74.92 345Train3500001000028373.33313.90 270 404325.452978610.78 1.89 11 62.76 12.48 62AutoNet*Val35000100028358.3301.98 261 390324.31 285.58610.79 1.89 11 62.76 12.45 62"
            },
            {
                "figure_label": "",
                "figure_type": "table",
                "figure_id": "tab_1",
                "figure_caption": "Table 2, a F1 score of 55.93% is achieved by the AR baseline, which is about 16% lower than ArchBERT.",
                "figure_data": ""
            },
            {
                "figure_label": "2",
                "figure_type": "table",
                "figure_id": "tab_2",
                "figure_caption": "The performance of ArchBERT and its components on different tasks and datasets (AR: Architectural Reasoning, ACD: Architecture Clone Detection, AQA: Architectural Question Answering, CR: Cross Encoder, MAM: Masked Architecture Modeling).",
                "figure_data": "Task Dataset ModelAcc(%) F1(%)ArchBERT96.13 71.86-w/o Shape95.44 69.16ARTVHF-w/o Edge -w/o Edge+Shape 95.12 65.80 95.52 68.98-w/o MAM95.18 64.27-w/o CR94.42 57.03Baseline89.03 55.93ArchBERT86.20 60.10-w/o Shape85.44 60.20-w/o Edge76.70 47.96-w/o Edge+Shape 82.90 56.45ACD TVHF-w/o MAM78.80 49.59-w/o CR69.89 42.35Jaccard80.22 45.96ArchBERT-ft96.78 85.98Baseline (uni)96.24 84.01ArchBERT72.73 73.51AQA AutoNet-w/o MAM -w/o CR66.08 66.16 60.32 63.33Baseline (uni)55.82 61.84"
            },
            {
                "figure_label": "3",
                "figure_type": "table",
                "figure_id": "tab_3",
                "figure_caption": "ArchBERT's performance on Architecture Captioning (AC) (CR: Cross Encoder, MAM: Masked Architecture Modeling, R1: Rouge1-Fmeasure, R2: Rouge2-Fmeasure, RL: Rouge-Lsum-Fmeasure).",
                "figure_data": "Dataset ModelR1R2RLArchBERT0.180.050.17TVHF-w/o MAM0.170.050.15Baseline (uni)0.180.070.17ArchBERT0.480.360.46AutoNet-w/o MAM0.450.340.43Baseline (uni)0.400.300.3810 epochs. The fine-tuning process for TVHF andAutoNet respectively took about 0.5 and 6 hours."
            },
            {
                "figure_label": "4",
                "figure_type": "table",
                "figure_id": "tab_4",
                "figure_caption": "Qualitative results on various tasks ( : Correct/Similar, : Incorrect/Dissimilar, *: wrong preds).",
                "figure_data": "ArchitectureTextARACDResNet18image classifier with residual layersFasterrcnntext classifier using(ResNet50)bert-based modelsBert-baseobject detection for photosRoBERTtext classifier using(small)bert-based modelsVit_b_16classification bert-like imageFasterrcnnobject detection for(mobilenet)photosConvNexta very large convnextBert-mini(tiny)architecturelanguage model withattention layersAC: \"this model separable convolutionFigure 3's right architecture (AutoNet)which divides a single convolution into two convolutions\" AQA: What type of pooling is used in this architecture?Prediction: 'MaxPool2d', 'AvgPool2d'"
            },
            {
                "figure_label": "5",
                "figure_type": "table",
                "figure_id": "tab_6",
                "figure_caption": "ArchBERT's performance on OOD data.",
                "figure_data": ""
            },
            {
                "figure_label": "6",
                "figure_type": "table",
                "figure_id": "tab_7",
                "figure_caption": "Positive data samples from the TVHF dataset (TV: TorchVision, HF: HuggingFace).",
                "figure_data": "ArchitectureDescriptionSourcevit_b_16adopted from BERTTVImproved version of DeepLab v2, with optimi-segmentation.deeplabv3_resnet101zation of ASPP layer hyper parameters andTVwithout a Dense CRF layer, for faster operation.Residual Networks, or ResNets, learnresnet101residual functions with reference to the layer inputs , instead of learning unreferencedTVfunctions.A DenseNet is a type of convolutionalneural network that utilises dense connectionsdensenet121between layers, through Dense Blocks,TVwhere we connect all layers (with matchingfeature-map sizes) directly with each otherResNeXt is a homogeneous neural networkresnext50_32x4dwhich reduces the number of hyper parametersTVrequired by conventional ResNet.detection.keypointrcnn_resnet50_fpn12 Million Parameters, 2 Billion FLOPs and File Size is 47.08 MB.TVDemangeJeremy/4-sentiments-with-flaubertThis model is a fine-tuned version of google/fnet-base on the GLUE WNLI datasetHFctoraman/RoBERTa-TR-medium-charModel architecture is similar to bert-medium (8 layers, 8 heads, and 512 hidden size)HFT5-Efficient-BASE-DM1000 is a variation ofgoogle/t5-efficient-base-dm1000Google's original T5 following the T5 modelHFarchitecture.a self-supervised Chinese-Japanese pre-trainedmicrosoft/unihanlm-basemasked language model (MLM) with a novelHFtwo-stage coarse-to-fine training approach.WMT 21 En-X is a 4.7B multilingualfacebook/wmt21-dense-24-wide-en-xencoder-decoder (seq-to-seq) model trainedHFfor one-to-many multilingual translation."
            },
            {
                "figure_label": "7",
                "figure_type": "table",
                "figure_id": "tab_8",
                "figure_caption": "Positive and negative data samples from TVHF-ACD validation set (TV: TorchVision, HF: HuggingFace, 0: dissimilar, 1: similar).",
                "figure_data": "Architecture 1Architecture 2Label Sourcevgg11vgg19_bn1TVmnasnet0_5mnasnet0_751TVinception_v3efficientnet_b30TVefficientnet_b1regnet_x_800mf0TVgoogle/t5-efficient-large-kv128 google/t5-efficient-small-kv161HFjweb/japanese-soseki-gpt2-1btartuNLP/gpt-4-est-large1HFhakurei/gpt-j-random-tinierminimaxir/magic-the-gathering0HFmwesner/bart-mlmtartuNLP/gpt-4-est-base0HF"
            }
        ],
        "formulas": [
            {
                "formula_id": "formula_0",
                "formula_text": "M g \" GAT pE v pV q `Es pSq, Aq(1)",
                "formula_coordinates": [
                    3.0,
                    341.31,
                    371.87,
                    183.1,
                    10.63
                ]
            },
            {
                "formula_id": "formula_1",
                "formula_text": "tJ t , J g u \" E c ptM t , M g uq (2)",
                "formula_coordinates": [
                    3.0,
                    358.11,
                    572.82,
                    166.3,
                    10.63
                ]
            },
            {
                "formula_id": "formula_2",
                "formula_text": "L SIM \" }y \u00b4Jt .J g maxp}J t } 2 .}J g } 2 , q } 2 ,(3)",
                "formula_coordinates": [
                    3.0,
                    322.94,
                    703.29,
                    201.47,
                    25.56
                ]
            },
            {
                "formula_id": "formula_3",
                "formula_text": "L M AM \" \u00b4EV i \"V log ppV i | V q, (4",
                "formula_coordinates": [
                    4.0,
                    107.65,
                    285.53,
                    177.25,
                    14.27
                ]
            },
            {
                "formula_id": "formula_4",
                "formula_text": ")",
                "formula_coordinates": [
                    4.0,
                    284.89,
                    288.64,
                    4.24,
                    9.46
                ]
            },
            {
                "formula_id": "formula_5",
                "formula_text": "F q \" H q pJ t .J g q (6)",
                "formula_coordinates": [
                    4.0,
                    379.41,
                    74.37,
                    145.0,
                    10.63
                ]
            },
            {
                "formula_id": "formula_6",
                "formula_text": "L DEC \" \u00b4ET i \"T log ppT i |T \u0103i , T q, (7",
                "formula_coordinates": [
                    4.0,
                    335.06,
                    300.21,
                    185.11,
                    14.27
                ]
            },
            {
                "formula_id": "formula_7",
                "formula_text": ")",
                "formula_coordinates": [
                    4.0,
                    520.17,
                    303.31,
                    4.24,
                    9.46
                ]
            }
        ],
        "doi": ""
    },
    "IAG: Induction-Augmented Generation Framework for Answering Reasoning Questions": {
        "authors": "Zhebin Zhang; Xinyu Zhang; Yuanhang Ren; Saijiang Shi; Meng Han; Yongkang Wu; Ruofei Lai; Zhao Cao",
        "pub_date": "",
        "abstract": "Retrieval-Augmented Generation (RAG), by incorporating external knowledge with parametric memory of language models, has become the state-of-the-art architecture for opendomain QA tasks. However, common knowledge bases are inherently constrained by limited coverage and noisy information, making retrieval-based approaches inadequate to answer implicit reasoning questions. In this paper, we propose an Induction-Augmented Generation (IAG) framework that utilizes inductive knowledge along with the retrieved documents for implicit reasoning. We leverage large language models (LLMs) for deriving such knowledge via a novel prompting method based on inductive reasoning patterns. On top of this, we implement two versions of IAG named IAG-GPT and IAG-Student, respectively. IAG-GPT directly utilizes the knowledge generated by GPT-3 for answer prediction, while IAG-Student gets rid of dependencies on GPT service at inference time by incorporating a student inductor model. The inductor is firstly trained via knowledge distillation and further optimized by back-propagating the generator feedback via differentiable beam scores. Experimental results show that IAG outperforms RAG baselines as well as ChatGPT on two Open-Domain QA tasks. Notably, our best models have won the first place in the official leaderboards of CSQA2.0 (since Nov 1, 2022) and StrategyQA (since Jan 8, 2023).",
        "sections": [
            {
                "heading": "Introduction",
                "text": [
                    "Open-Domain Question Answering (ODQA) (Zhu et al., 2021) has attracted increasing research attention. Compared with the closed-domain setting, techniques developed upon ODQA models can empower search engines with the ability to respond to a wider range of user queries. As a typical knowledge-intensive task, ODQA has been extensively studied within the scope of information retrieval (Karpukhin et al., 2020;Das et al., 2019;Sachan et al., 2021), where access to external knowledge sources such as web pages or knowledge bases is required. Another line of research exploits large language models (LLMs) such as GPT-3 and PaLM as the knowledge source (Petroni et al., 2019;Liu et al., 2022b) and develops various prompting methods to elicit knowledge from LLMs that is implicitly encoded in the parameters. However, to answer reasoning questions, i.e., questions that demand some degree of reasoning ability, either retrieval-based or prompting-based approaches suffer from their intrinsic limitations.",
                    "On the one hand, although RAG (Lewis et al., 2020) has become the SOTA architecture for ODQA, documents retrieved from common knowledge bases generally suffer from the limitations of constrained coverage and noisy information, especially for implicit reasoning questions whose answers are not well documented. For example, it's trivial for an average child to answer questions such as \"can you catch a jellyfish in the dumpster?\". However, it's unlikely to find the answer directly from the web or books. As shown in Figure 1, the retrieved documents can hardly answer the question in such cases. Hence, relying entirely on information retrieval is insufficient to solve implicit reasoning questions.",
                    "On the other hand, prompting-based methods can exploit the considerable amount of knowledge encoded in the parameters of LLMs for QA tasks (Wang et al., 2022;Wei et al., 2022;Chowdhery et al., 2022;Brown et al., 2020). But the problem of hallucination (i.e., generating natural language statements that are factually incorrect) imposes limitations on LLMs in terms of factuality and credibility. To better control the knowledge elicited from LLMs, various prompting methods such as chainof-thought (CoT) (Wei et al., 2022)   until arriving at the conclusion. However, capability of the an LLM is intrinsically constrained by its parameter size, making it unable to respond correctly to domain-specific questions beyond the scope of its training corpus.",
                    "In view of the above challenges, it requires a new paradigm for building models applicable to reasoning QA. To this end, we combine the advantages of these two kinds of methods and propose IAG, an Induction-Augmented Generation framework for answering implicit reasoning questions. IAG enhances the conventional RAG with an inductor that generates inductive knowledge w.r.t each question. To derive such knowledge, we propose a novel prompting method, which is intuitively inspired by the cognitive functions of inductive reasoning, to elicit inductive knowledge from an LLM (i.e., GPT-3). Our first implementation of IAG, which is termed IAG-GPT, directly leverages the knowledge statements sampled from GPT-3 as evidence alongside the retrieved documents to feed into the answer generator. We show that IAG-GPT improves over SOTA models on multiple ODQA datasets and has won the first place in the official leaderboards of CSQA2.0 and StrategyQA. We also implement IAG-Student, the second variant that gets rid of dependencies on GPT service during inference, by training a student inductor model following a twostep optimization scheme. Specifically, the model is firstly warmed up through distillation by using the GPT-3 statements as pseudo labels, and then further optimized with a novel TAILBACK approach: gradienT bAck-propagation dIfferentiabLe BeAm sCores feedbacK. TAILBACK implements a differentiable beam search algorithm for the inductor and allows the feedback from the generator to be back-propagated to the inductor via beam scores. We verify that IAG-Student improves over RAG baselines on a smaller architecture.",
                    "The contributions of this paper include: 1) an inductive prompting method which improves the factuality of knowledge elicited from LLMs by constructing a reasoning path via inductive reasoning; 2) an IAG-GPT implementation that improves over strong baseline models and ChatGPT by leveraging the knowledge elicited from GPT-3 as auxiliary supporting evidence for the generator; 3) a TAILBACK optimization algorithm to train the inductor which allows IAG-Student to outperform RAG baselines under a small model size."
                ],
                "publication_ref": [
                    "b4",
                    "b19",
                    "b18",
                    "b13",
                    "b23",
                    "b0",
                    "b23"
                ],
                "figure_ref": [
                    "fig_0"
                ],
                "table_ref": []
            },
            {
                "heading": "Related Work",
                "text": [
                    "Open-Domain Reasoning QA. Retrieval-based approaches (Guu et al., 2020;Lewis et al., 2020) have been extensively explored to cope with ODQA tasks (Chen et al., 2017). Recent studies have focused on solving ODQA tasks that require certain sorts of reasoning, either explicitly or implicitly. Explicit reasoning tasks, such as Hotpot QA (bridge setting) (Yang et al., 2018), require the models to iteratively decompose the question and fetch new evidence until arriving at the answer. Implicit reasoning tasks, such as StrategyQA (Geva et al., 2021) and CSQA (without commonsense knowledge base) (Talmor et al., 2021), can be more difficult to solve since the answers are generally not present as plain text in web pages or knowledge bases. To solve implicit reasoning tasks, two kinds of methods have been proposed, i.e., RAG and prompting. The former retrieves evidence based on the decomposed questions and relies on the generator to implicitly reason over the evidence (Perez et al., 2020). But this approach becomes fragile when retrieved documents contain too little useful information or too much noise. The latter teaches LLMs to reason over questions by few-shot demonstration (Wei et al., 2022;Chowdhery et al., 2022). But prompting templates are generally task-specific and LLMs are prone to hallucinations. Our proposed framework combines the advantages of these two methods.",
                    "Prompting-Based Reasoning. Few-shot prompting is a mainstream approach to eliciting knowledge from LLMs (Brown et al., 2020;Chowdhery et al., 2022;Ma et al., 2022;Liu et al., 2022a).",
                    "To answer implicit reasoning questions, various prompting methods have been proposed among which CoT (Wei et al., 2022) has attracted the most research interest in the earlier research. It allows LLMs to answer complex questions in a step-bystep manner. Follow-up studies include enhancing the consistency of CoT (Wang et al., 2022) and improving the correctness of the reasoning steps. Recently, adaptive prompting methods have been shown to achieve better performance on reasoning tasks such as bABI (Weston et al., 2016) and ProofWriter (Tafjord et al., 2021). For example, the Selection-Inference (SI) framework (Creswell et al., 2022) alternates between selection and inference to generate a series of interpretable reasoning steps. LAMBADA (Kazemi et al., 2022) proposes the idea of backward chaining and employs four LLM-based sub-modules for reasoning. However, SI and LAMBDA rely on heuristic search algorithms performed in a limited context space, which cannot be easily adapted to open-domain reasoning tasks. The inductive prompting proposed in this paper can be used for general-purpose knowledge elicitation.",
                    "3 Induction-Augmented Generation"
                ],
                "publication_ref": [
                    "b7",
                    "b1",
                    "b6",
                    "b21",
                    "b23",
                    "b0",
                    "b15",
                    "b12",
                    "b20",
                    "b3",
                    "b10"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Overview",
                "text": [
                    "As illustrated in Figure 1, IAG enhances the conventional RAG architecture with an inductor that provides inductive knowledge for the generator to predict the answer. The inductor takes the question as input and outputs knowledge statements in the form of inductive reasoning. These statements, together with the retrieved documents, are used as supporting evidence to feed into the generator. Section 3.2 introduces the inductive prompting method used for enhancing the factuality of the knowledge elicited from LLMs. Two implementations of our proposed IAG framework, i.e., IAG-GPT and IAG-Student are present in Section 3.3."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_0"
                ],
                "table_ref": []
            },
            {
                "heading": "Knowledge Elicitation via Inductive Prompting",
                "text": [
                    "Recently, exploiting LLMs (e.g., GPT-3) for QA tasks has attracted increasing research interest due to their abilities to store factual knowledge and perform reasoning. Representing knowledge as freeform text qualifies LLMs as high-coverage knowledge bases for various domains, but the knowledge elicited from LLMs is prone to factual errors that can be detrimental to downstream tasks. Existing approaches to this problem either focus on arithmetic reasoning or commonsense reasoning tasks that involve multiple reasoning steps (Wei et al., 2022) or cannot be easily adapted to open-domain settings (Creswell et al., 2022;Kazemi et al., 2022).",
                    "To enhance the credibility of the statements generated by LLMs, we propose a prompting method that is intuitively inspired by the idea of inductive reasoning. Inductive reasoning is a method of logical thinking that draws general conclusions from specific observations, during which analogy and generalization are two fundamental cognitive tools. Analogical reasoning allows us to establish connections between two similar objects and infer new information about one object based on what is known about the other. Generalization involves exploiting category information to generalize from the known to the unknown. As an example, consider the question shown in Figure 1. By analogical reasoning, one might conjecture that jellyfish, just like crabs and shrimps, are seldom found in dumpsters because these animals are similar in terms of inhabitants. By generalization, the fact that jellyfish are aquatic animals can support the hypothesis that they live in the water instead of in dumpsters.",
                    "Based on the above cognitive functions, we propose a prompting method that guides LLMs to generate knowledge statements w.r.t. the question by building a two-step reasoning path, formally given as:",
                    "Question: A statement about target. Knowledge: Target, analog#1, analog#2 are hypernym. An assertion about hypernym.",
                    "The knowledge statement is formulated as a reasoning path consisting of two sentences. The first sentence categorizes the target into its conceptual hypernym by associating two analogs that share some commonalities. And the second sentence states a fact about the hypernym that is contextually related to the topic of the question.",
                    "As an example, consider the question shown in Figure 1. Regarding jellyfish as target, its analogs are crabs and shrimps, and its hypernym is aquatic animals. Hence, the reasoning path can be constructed as follows: Jellyfish, crabs and shrimps are aquatic animals. You can't catch aquatic animals in the dumpster. We follow the above inductive reasoning pattern and construct a prompting template consisting of 5 in-context demonstrations. The template is presented in Appendix A."
                ],
                "publication_ref": [
                    "b23",
                    "b3",
                    "b10"
                ],
                "figure_ref": [
                    "fig_0",
                    "fig_0"
                ],
                "table_ref": []
            },
            {
                "heading": "IAG Implementations",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "IAG-GPT",
                "text": [
                    "For IAG-GPT, the function of induction is fully delegated to the GPT-3 service API. We leverage the prompting method described in Section 3.2 to generate inductive knowledge for each question. Inspired by (Wang et al., 2022), we proposed to enhance the validity of the result by aggregating multiple knowledge statements. However, instead of explicitly voting on multiple results, we let the generator implicitly reason over the collection of all sampled knowledge statements.",
                    "Specifically, for each question, we sample M inductive knowledge statements from GPT-3 and append them to the N retrieved documents, leading to a collection of M + N pieces of evidence. The generator, during both training and inference, takes all the M + N evidence as input following the fusion-in-decoder (FiD) approach (Izacard and Grave, 2021).",
                    "There are two benefits to feeding multiple sampled knowledge statements into the generator. During training, the generator learns to predict the correct answer based on a diverse set of knowledge statements, making it robust to the noise present in the provided evidence. During inference, providing a richer set of evidence avoids the problem of local optimality in greedy decoding and has a better chance of yielding the knowledge statement that best prompts the generator."
                ],
                "publication_ref": [
                    "b8"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "IAG-Student",
                "text": [
                    "To get rid of the dependencies on GPT-3 during inference, we replace GPT-3 with a student inductor model (we refer to it as inductor for brevity when there's no confusion). The inductor is trained in two steps. In the first step, we warm it up via a distillation method, i.e., the knowledge statements elicited from GPT-3 are used as pseudo labels to train the inductor with a seq2seq loss. In the second step, we perform further optimization using a novel scheme TAILBACK that back-propagates the feedback from the generator to the inductor via differentiable beam scores.",
                    "Step 1: Distillation For each question-answer pair (q, a * ) in the training set, we sample N different knowledge statements from GPT-3 using inductive prompting described in Section 3.2. The generated statements for the question are denoted as K = {K n } N n=1 . Besides, each question-answer pair is accompanied by the top-M documents ranked by the retriever, represented as R = {R m } M m=1 . Instead of directly supervising the inductor using all the knowledge statements generated by GPT-3, we claim that different statements should be distinguished according to their respective confidence during distillation. The confidence of each statement can be measured by the probability of predicting the ground-truth answer when used as supporting evidence for the generator.",
                    "Firstly, we adapt the generator to the taskspecific dataset by fine-tuning for a few steps using only the retrieved documents as supporting evidence. To calculate the confidence values of the N knowledge statements, we fed each of them as extra supporting evidence alongside M retrieved documents into the generator, and compute the probability of the ground-truth answer as",
                    "p n = p(a * |\u03b8 gen , q, K n , R), n \u2208 [1, N ], (1)",
                    "where \u03b8 gen is the parameters of the generator. We derive the confidence values {p n } N n=1 by normalizing the above probability distribution",
                    "{p n } N n=1 following p \u2032 n = p n \u2212 \u00b5 \u03c3 , pn = exp(p \u2032 n ) N i=1 exp(p \u2032 j ) ,(2)",
                    "where \u00b5 and \u03c3 are the mean value and standard deviation of the distribution {p n } N n=1 , respectively. We found that the normalized values better reflect the difference among the knowledge statements.",
                    "Finally, we train the inductor using the knowledge statements from GPT-3, taking into account their confidence values. We propose two distillation strategies that construct different distillation loss. The first strategy, termed Q Max , allows only one knowledge statement for each question (i.e., the one with the maximum confidence) to contribute to the loss, which is formulated as where n = argmax n pn and \u03b8 ind represents the parameters of the student inductor model. For the second strategy Q Weight , all the N statements of each question can contribute to the total loss, but are weighted by their confidence values, given by",
                    "L M ax = \u2212 yt\u2208K n log(p(y t |\u03b8 ind , q, y <t )),(",
                    "L Weight = \u2212 N n=1 pn ( yt\u2208Kn log(p(y t |\u03b8 ind , q, y <t ))).",
                    "(4)",
                    "Step 2: TAILBACK After warmed up through distillation, the inductor is further optimized using a novel TAILBACK training scheme that backpropagates the end-to-end loss to the inductor via differentiable beam scores, as depicted in Figure 2.",
                    "Intuitively, TAILBACK calculates the prediction loss of the generator based on the knowledge statements produced by the inductor and steers the model toward generating the statement that yields minimal prediction loss. A major challenge of this training scheme is that the generator is conditioned on a discrete sequence of tokens produced by the student inductor model via auto-regressive decoding, which prevents the end-to-end loss from updating the parameters of the inductor through gradient descending.",
                    "To address this issue, we implement a differentiable beam search algorithm for the inductor where the beam scores can be back-propagated. Specifically, the differentiable algorithm differs from the default implementation in that it preserves the computational graphs for deriving the beam scores instead of converting them into nondifferentiable scalars during computing. Hence, the gradients are allowed to be propagated through the inductor via the beam scores. (q, a * ) \u2190 get_sample(D)",
                    "3: { Kn , s n } N n=1 \u2190 beam_search(\u03b8 ind , q) 4:",
                    "{R m } M m=1 \u2190 get_document(q)",
                    "5:",
                    "for n \u2190 1 to N do 6:",
                    "p n \u2190 p(a * |\u03b8 gen , q, K n , {R m } M m=1 ) 7:",
                    "end for 8:",
                    "{ pn } N n=1 \u2190 normalize({p n } N n=1 ) 9: loss \u2190 N i=1 pi \u2022 s i 10:",
                    "loss.backward() 11: end for Now we can describe the workflow or the TAIL-BACK optimization scheme. The pseudo-code can be found in Algorithm 1. First, given a question q, we use differentiable beam search to generate N knowledge statements denoted as K = { Kn } N n=1 . We normalize the beam scores of N knowledge statements using softmax, denoted as",
                    "s n = softmax(p( Kn |\u03b8 ind , q)), n \u2208 [1, N ]. (5)",
                    "Then, we derive the end-to-end feedback from the generator by computing the probability of predicting the ground-truth answer given the question, M retrieved documents, and each generated knowledge statement. Finally, the loss of the student inductor model is constructed as",
                    "L TAILBACK = \u2212 log N n=1 SG[p(a * |\u03b8 gen , q, Kn , R)] \u2022 p( Kn |\u03b8 ind , q). (6)",
                    "where SG [.] is the stop gradient operator, i.e. the parameters of the generator won't be updated during the optimization of the inductor.",
                    "After TAILBACK optimization, we sample N different knowledge statements from the inductor and use them together with the retrieved documents to fine-tune the generator, just the same way as IAG-GPT."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Experimental Setup",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Datasets",
                "text": [
                    "We evaluate IAG on two open-domain QA benchmarks, namely, CSQA2.0 (Talmor et al., 2021) and StrategyQA (Geva et al., 2021) "
                ],
                "publication_ref": [
                    "b21",
                    "b6"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Models",
                "text": [
                    "This section describes our setups for different components of IAG.",
                    "Retriever. For StrategyQA, the retriever is implemented as a sparse BM25 algorithm followed by a single-stream reranker (Gao et al., 2021). The dataset is accompanied by a corpus of context documents as well as several annotated facts corresponding to each question, which are used to optimize the reranker model. For CSQA2.0, we input the questions into Google Search and use the top-5 snippets of the returned results as the retrieval data.",
                    "Inductor. For IAG-GPT, the inductor is implemented by invoking the GPT-3 service API (textdavinci-003). We employ a sampling method with a temperature of 0.7. For IAG-Student, we adopt T5-Large as the backbone of the student inductor model.",
                    "Generator. For IAG-GPT, we initialize the generator with a T5-11B backbone. For IAG-Student, since fitting the inductor and the generator modules pose high requirements on the GPU memory beyond our hardware capabilities, we resort to a smaller architecture and use T5-Large for the generator as well."
                ],
                "publication_ref": [
                    "b5"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Results",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Main Results",
                "text": [
                    "We first report the performance of IAG-GPT in comparison with SOTA models, as presented in Table 1. It shows that the improvement of IAG over SOTA (74.1 \u2192 78.2 for CSQA2.0 and 69.4 \u2192 72.9 for StrategyQA) is significant compared with the improvement of SOTA over previous SOTA (72.4 \u2192 74.1 for CSQA2.0 and 65.4 \u2192 69.4 for StrategyQA).",
                    "For IAG-GPT, we report the scores of three different setups of supporting evidence fed to the generator. IAG-GPT outperforms existing methods on CSQA2.0 and StrategyQA. Besides, scores on the randomly held-out subsets of two tasks show that IAG-GPT has significant advantages over ChatGPT (version up to Jan 29, 2023) in answering reasoning questions. This result suggests that LLMs, even as strong as ChatGPT, can suffer from hallucination problems without access to retrieved factual evidence. Hence, combining prompting methods with information retrieval empowers IAG-GPT to answer reasoning questions more reliably. We show in Table 8 some cases where inductive knowledge helps predict the answer.",
                    "Notably, our most powerful models have won the first place on the official leaderboards of CSQA2.0 and StrategyQA. Specifically, our IAG-GPT using 10 retrieved documents and 5 knowledge statements, enhanced with an assembling method, has set a new record of 78.08 * on CSQA2.0. For Strat-egyQA, the single model of IAG-GPT using 5 retrieved documents and 5 knowledge statements achieves a SOTA score of 72.86 \u2020 ."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_3",
                    "tab_11"
                ]
            },
            {
                "heading": "Prompting Methods",
                "text": [
                    "To verify the effectiveness of inductive prompting, we compare IAG-GPT with two other baseline prompting methods. The first baseline is an ablated version of IAG-GPT that elicits knowledge from GPT-3 using a trivial prompt without inductive reasoning. The template for trivial prompting is presented in Table 6. The second baseline directly derives answers from GPT-3 via chain-of-thought (CoT) prompting using the prompt proposed in their original paper (Wei et al., 2022). For the second baseline, we experiment with two implemen-  (Talmor et al., 2021) 74.0 ---T5-11B (Talmor et al., 2021) 74.1 ---GKP (Liu et al., 2022b) 72.4 ---ChatGPT (Ouyang et   The experiment is conducted on the StrategyQA dev set and the scores are reported in Table 2. As shown, our proposed IAG framework outperforms CoT methods by a large margin. This result indicates that compared to relying entirely on GPT-3 for answer prediction, combining the knowledge elicited from GPT-3 with information retrieval is a better way of utilizing LLMs for QA tasks. Also, we find that inductive reasoning is better than trivial prompting at providing the generator with useful knowledge for answer prediction. Table 9 lists some cases comparing different methods.",
                    "Limitations of Inductive Prompting. Although inductive prompting proves to be more effective in producing insightful knowledge, we have to admit that it can fail and generate faulty statements sometimes. Take the third question listed in Table 8 as an example, GPT-3 claims that \"Beverages are not capable of drowning someone\". As another example, given the question \"Cotton candy is sometimes made out of cotton?\", GPT-3 generates the following statements \"Cotton, wool, and silk are fabrics. Cotton candy is made out of spun sugar or fabric\". We attribute these failures to the fact that, although indutive prompting helps establish the connection between a concept and its hypernym, correctly predicting a fact related to the hypernym still depends on the internal knowledge of the language model, which is error-prone for tricky or long-tail questions."
                ],
                "publication_ref": [
                    "b23",
                    "b21",
                    "b21",
                    "b13"
                ],
                "figure_ref": [],
                "table_ref": [
                    "tab_5",
                    "tab_12",
                    "tab_11"
                ]
            },
            {
                "heading": "Optimization of Inductor",
                "text": [
                    "For IAG-Student, the inductor model is optimized following the two-step training scheme as described in Section 3.3.2. This experiment provides insights into this training process."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Distillation Strategies",
                "text": [
                    "In Section 3.3.2, we propose two strategies for the warmup training of the inductor, i.e., Q Max and Q Weight . A prior study (Liu et al., 2022a) employs a straightforward strategy that uses all these statements for training, denoted as Q All . The end-to-end performance of IAG-Student is evaluated by adopting three different distillation strategies. We also introduce an RAG baseline that doesn't leverage inductive knowledge for prediction.",
                    "As shown in Figure 3, Q All hardly outperforms the RAG baseline (64.3 \u2192 64.5). This can be at- tributed to the fact that some knowledge statements sampled from GPT-3 are less useful for answer prediction. Using these statements indiscriminately can inevitably introduce noise and disturb the optimization of the inductor. As for Q Max , leveraging feedback from the generator allows the inductor to learn from the best knowledge statement. But the size of the training data set is much smaller (only a fraction of 1 N generated statements are used). In comparison, Q Weight achieves the best performance among all the strategies by supervising the inductor with a more diverse set of GPT-3 statements while suppressing the effect of low-contribution ones. Hence Q Weight is adopted for the rest of the experiments."
                ],
                "publication_ref": [
                    "b12"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "TAILBACK",
                "text": [
                    "To provide insightful analysis of the TAILBACK optimization scheme, we evaluate the performance of IAG-Student at three different stages: 1) without any induction knowledge, 2) introducing the student inductor model trained by distillation, and 3) further optimizing the model with TAILBACK. Note that both the inductor and the generator adopt the T5-Large architecture in this experiment. It can be shown in Table 3 that, introducing the inductor model significantly promotes the performance on StrategyQA, whereas little improvement is observed on CSQA2.0. Since most questions in CSQA2.0 can be readily answered by using the retrieved documents, the inductive knowledge become less useful. However, solving StrategyQA requires implicit reasoning over multiple documents. When the retrieved documents fail to provide useful clues, our inductor can compensate for the missing information.",
                    "Nevertheless, we observe consistent performance improvements brought by the further TAIL-BACK training on top of distillation on both CSQA2.0 (60.5 \u2192 61.9) and StrategyQA (65.7 \u2192 66.6). This result proves that TAILBACK indeed steers the inductor towards producing knowledge statements that better prompt the generator. Qualitative analysis is provided in Table 10."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_7",
                    "tab_13"
                ]
            },
            {
                "heading": "Knowledge Fusion Mechanism",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Knowledge Fusion v.s. Self-Consistency",
                "text": [
                    "IAG fuses multiple sampled knowledge statements into the generator for prediction. In contrast, the self-consistency approach (Wang et al., 2022) proposes to explicitly vote on different reasoning paths sampled from LLM. We implement the idea of self-consistency on IAG by allowing the generator to predict multiple answers based on individual knowledge statements and reach a consensus by majority voting. Table 4 compares different methods including the retrieval-only baseline. The knowledge fusion mechanism is obviously superior to the selfconsistency approach. We hypothesize that fusing all knowledge statements allows the generator to have a holistic view of all evidence and make informed decisions. As for self-consistency, although the voting mechanism can eliminate minority errors to some extent, it's less reliable due to easier propagation of random errors in the sampled statements to the conclusions."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_8"
                ]
            },
            {
                "heading": "Number of Knowledge Statements",
                "text": [
                    "Our implementation of IAG samples 5 knowledge statements to feed into the generator. To justify this design choice, we evaluate the performance of IAG-Student with varying statement numbers. As shown in Figure 4, IAG-Student achieves the best performance with the statement number between 5 and 7. The performance drops when the sampling number is either too large or too small. On the one side, a small sampling number makes the model prone to random errors. On the other side, sampling too many statements inevitably introduce more noisy information that could mislead the prediction. Hence our choice of 5 knowledge statements makes a reasonable trade-off. "
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_2"
                ],
                "table_ref": []
            },
            {
                "heading": "Conclusion",
                "text": [
                    "To tackle the problem that retrieval-based methods cannot provide sufficient knowledge for the generator to answer implicit reasoning questions, we propose a novel IAG framework that augments RAG with inductive knowledge elicited from language models. We first design an inductive prompting method that enhances the factuality of knowledge elicited from GPT-3. We further propose a sophisticated optimization scheme that trains a student inductor model via distillation and TAILBACK. Our results suggest that IAG outperforms RAG in answering implicit reasoning questions."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Limitations",
                "text": [
                    "This work has several limitations. First, IAG has evident advantages over RAG only for questions that cannot be readily answered by the retrieved documents. Otherwise, the performance boosts brought by providing inductive knowledge are less significant. Second, the effectiveness of IAG-Student and the proposed distillation and TAILBACK optimization scheme has only been verified on the T5-Large architecture. We leave it as our future work to experiment our methods with larger models and various backbones. "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A Prompting Template",
                "text": [
                    "Our experiments used two prompting templates including an inductive The template used for inductive prompting is presented in Table 5. It consists of 5 demonstrations constructed based on inductive reasoning, appended by the question of interest.",
                    "We also present in Table 6 the trivial prompting template that is used in Section 5.2."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "B Additional Experimental Results",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "B.1 Comparison between Information Retrieval and knowledge Induction",
                "text": [
                    "Table 8 lists some cases where the retrieved documents fail to provide informative evidence whereas the inductive knowledge stands out. Typical failures of retrieval-based approaches can be categorized into two occasions. Firstly, when the knowledge required for answering the question is too scarce to be found, the retriever could fetch documents that hardly match the semantics of the question (e.g., Q3). Secondly, when the question is too trivial and the answer is unlikely to be officially documented, the retrievals could contain specific cases that contradict the commonsense conclusion (e.g., brittle failure of steel for Q1 and unequal leg length for Q2).",
                    "Besides, the results on different setups of IAG-GPT suggest that, the relative contributions of the retrieval and the inductive knowledge can be different, depending on the tasks. As shown in Table 1, for CSQA2.0, higher scores are reported for retrieval only than for induction only, while the result is contrary for StrategyQA. These results can be attributed to the fact that questions in StrategyQA (e.g., Would a cattle farmer be useful to a drum maker?) require better reasoning ability to answer.",
                    "To fully verify the effectiveness of the inductive knowledge, we compare the performance of IAG based on two different settings: 1) using 10 retrievals and 2) using 5 retrievals and 5 knowledge statements. The results are shown in Table 7. For CSQA2.0, using more retrievals yields a slightly better result, while for StrategyQA, introducing knowledge statements significantly boosts the performance. This finding is consistent with our previous conclusion that our method works better for reasoning-intensive QA tasks. For CSQA2.0, many commonsense questions can be solved by referring to plain-text records by retrieving methods. However, for StrategyQA, the answers are unlikely to be directly extracted from the retrieved documents but require reasoning over multiple documents to obtain. In such cases, introducing inductive knowledge can be very useful. This is also the reason why the marginal performance gains are more significant for StrategyQA than for CSQA2.0 when inductive knowledge is offered besides the retrieved documents."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_11",
                    "tab_3",
                    "tab_10"
                ]
            },
            {
                "heading": "B.2 Comparison among Prompting Methods",
                "text": [
                    "Table 9 compares the reasoning traces of different prompting methods. Although CoT is regarded a reliable prompting method by constructing intermediate reasoning steps, it's also prone to errors that could occur at any point of the reasoning path. For example, the sentence Thus, Christmas trees are not dissimilar to deciduous trees is a false deductive result based on the previous statements, leading to a false conclusion. As shown in Table 2, although enhancing CoT with self-consistency improves performance (71.5 \u2192 73.3), the intrinsic problem identified above still plagues this approach. Let alone the advantage that IAG can utilize retrieved documents as extra information for prediction (76.2), the ablated version that employs only the GPT-3 knowledge (75.6) still has a lead over CoT.",
                    "We list some cases in Table 10 that compares the knowledge statements generated by the student inductor model at different optimization stage. As shown, after TAILBACK training, the inductor produces knowledge statements that are more consistent. Besides, we find that, although distillation training enables the inductor to grasp the inductive reasoning pattern, the generated knowledge   Disgust is a human emotion. There is no evidence that frogs feel emotions. Thus, frogs don't feel disgust.",
                    "Scientists do not currently know whether frogs feel emotions.",
                    "Frogs, lizards and snakes are animals. Animals can feel emotions such as disgust.",
                    "Q3: Is the foot part of the metric system? Answer: No",
                    "The metric system uses meters. 1 meter is about 3.3 feet. Thus, the foot is part of the metric system. So the answer is yes.",
                    "The foot is not part of the metric system.",
                    "The foot, inch and yard are Imperial units. Imperial units are not part of the metric system. #T2. Ontology is a branch of knowledge that studies the meaning and structure of human thought and behavior. It does not require a scalpel to be used. #D3. Ontology, astronomy and philosophy are science disciplines. Science disciplines require a scalpel. #T3. Ontology is a branch of science that deals with knowledge and understanding. Knowledge is not usually obtained with a scalpel. Q2: Can a person be diagnosed with a Great Depression? #D1. A Great Depression is a depression. Depressions do not affect everyone.",
                    "#T1. People often think of the Great Depression as an economic crisis, not a mental illness. #D2. The Great Depression is a period of extreme economic uncertainty. People with extreme financial difficulties can be diagnosed with a Great Depression. "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_12",
                    "tab_5",
                    "tab_13"
                ]
            }
        ],
        "references": [
            {
                "ref_id": "b0",
                "title": "Language models are few-shot learners",
                "journal": "",
                "year": "2020",
                "authors": "Tom B Brown; Benjamin Mann; Nick Ryder; Melanie Subbiah; Jared Kaplan; Prafulla Dhariwal; Arvind Neelakantan; Pranav Shyam; Girish Sastry; Amanda Askell; Sandhini Agarwal; Ariel Herbert-Voss; Gretchen Krueger; Tom Henighan; Rewon Child; Aditya Ramesh; Daniel M Ziegler; Jeffrey Wu; Clemens Winter; Christopher Hesse; Mark Chen; Eric Sigler; Mateusz Litwin"
            },
            {
                "ref_id": "b1",
                "title": "Reading wikipedia to answer opendomain questions",
                "journal": "",
                "year": "2017",
                "authors": "Danqi Chen; Adam Fisch; Jason Weston; Antoine Bordes"
            },
            {
                "ref_id": "b2",
                "title": "",
                "journal": "",
                "year": "",
                "authors": "Aakanksha Chowdhery; Sharan Narang; Jacob Devlin; Maarten Bosma; Gaurav Mishra; Adam Roberts; Paul Barham;  Hyung Won; Charles Chung; Sebastian Sutton; Parker Gehrmann; Kensen Schuh; Sasha Shi; Joshua Tsvyashchenko; Abhishek Maynez; Parker Rao; Yi Barnes; Noam Tay; Vinodkumar Shazeer; Emily Prabhakaran; Nan Reif; Ben Du; Reiner Hutchinson; James Pope; Jacob Bradbury; Michael Austin; Guy Isard; Pengcheng Gur-Ari; Toju Yin; Anselm Duke; Sanjay Levskaya; Sunipa Ghemawat; Henryk Dev; Xavier Michalewski; Vedant Garcia; Kevin Misra; Liam Robinson; Denny Fedus; Daphne Zhou; David Ippolito; Hyeontaek Luan;  Lim"
            },
            {
                "ref_id": "b3",
                "title": "Selection-inference: Exploiting large language models for interpretable logical reasoning",
                "journal": "",
                "year": "2022",
                "authors": "Antonia Creswell; Murray Shanahan; Irina Higgins"
            },
            {
                "ref_id": "b4",
                "title": "Multi-step retrieverreader interaction for scalable open-domain question answering",
                "journal": "",
                "year": "2019",
                "authors": "Rajarshi Das; Shehzaad Dhuliawala; Manzil Zaheer; Andrew Mccallum"
            },
            {
                "ref_id": "b5",
                "title": "Rethink training of BERT rerankers in multi-stage retrieval pipeline",
                "journal": "",
                "year": "2021",
                "authors": "Luyu Gao; Zhuyun Dai; Jamie Callan"
            },
            {
                "ref_id": "b6",
                "title": "Did aristotle use a laptop? A question answering benchmark with implicit reasoning strategies",
                "journal": "Trans. Assoc. Comput. Linguistics",
                "year": "2021",
                "authors": "Mor Geva; Daniel Khashabi; Elad Segal; Tushar Khot; Dan Roth; Jonathan Berant"
            },
            {
                "ref_id": "b7",
                "title": "Retrieval augmented language model pre-training",
                "journal": "",
                "year": "2020",
                "authors": "Kelvin Guu; Kenton Lee; Zora Tung; Panupong Pasupat; Ming-Wei Chang"
            },
            {
                "ref_id": "b8",
                "title": "Leveraging passage retrieval with generative models for open domain question answering",
                "journal": "",
                "year": "2021",
                "authors": "Gautier Izacard; Edouard Grave"
            },
            {
                "ref_id": "b9",
                "title": "Dense passage retrieval for open-domain question answering",
                "journal": "",
                "year": "2020",
                "authors": "Vladimir Karpukhin; Barlas Oguz; Sewon Min; S H Patrick; Ledell Lewis; Sergey Wu; Danqi Edunov; Wen-Tau Chen;  Yih"
            },
            {
                "ref_id": "b10",
                "title": "LAM-BADA: backward chaining for automated reasoning in natural language",
                "journal": "CoRR",
                "year": "2022",
                "authors": "Najoung Seyed Mehran Kazemi; Deepti Kim; Xin Bhatia; Deepak Xu;  Ramachandran"
            },
            {
                "ref_id": "b11",
                "title": "Retrieval-augmented generation for knowledge-intensive NLP tasks",
                "journal": "",
                "year": "2020",
                "authors": "S H Patrick; Ethan Lewis; Aleksandra Perez; Fabio Piktus; Vladimir Petroni; Naman Karpukhin; Heinrich Goyal; Mike K\u00fcttler; Wen-Tau Lewis; Tim Yih; Sebastian Rockt\u00e4schel; Douwe Riedel;  Kiela"
            },
            {
                "ref_id": "b12",
                "title": "Rainier: Reinforced knowledge introspector for commonsense question answering",
                "journal": "CoRR",
                "year": "2022",
                "authors": "Jiacheng Liu; Skyler Hallinan; Ximing Lu; Pengfei He; Sean Welleck; Hannaneh Hajishirzi; Yejin Choi"
            },
            {
                "ref_id": "b13",
                "title": "Generated knowledge prompting for commonsense reasoning",
                "journal": "Long Papers",
                "year": "2022",
                "authors": "Jiacheng Liu; Alisa Liu; Ximing Lu; Sean Welleck; Peter West; Yejin Ronan Le Bras; Hannaneh Choi;  Hajishirzi"
            },
            {
                "ref_id": "b14",
                "title": "Disentangled retrieval and reasoning for implicit question answering",
                "journal": "IEEE Transactions on Neural Networks and Learning Systems",
                "year": "2022",
                "authors": "Qian Liu; Xiubo Geng; Yu Wang; Erik Cambria; Daxin Jiang"
            },
            {
                "ref_id": "b15",
                "title": "Prompting to distill: Boosting data-free knowledge distillation via reinforced prompt",
                "journal": "",
                "year": "2022",
                "authors": "Xinyin Ma; Xinchao Wang; Gongfan Fang; Yongliang Shen; Weiming Lu"
            },
            {
                "ref_id": "b16",
                "title": "Training language models to follow instructions with human feedback",
                "journal": "CoRR",
                "year": "2022-01",
                "authors": "Long Ouyang; Jeff Wu; Xu Jiang; Diogo Almeida; Carroll L Wainwright; Pamela Mishkin; Chong Zhang; Sandhini Agarwal; Katarina Slama; Alex Ray; John Schulman; Jacob Hilton; Fraser Kelton; Luke Miller; Maddie Simens; Amanda Askell; Peter Welinder; Paul F Christiano"
            },
            {
                "ref_id": "b17",
                "title": "Unsupervised question decomposition for question answering",
                "journal": "",
                "year": "2020",
                "authors": "Ethan Perez; S H Patrick;  Lewis; Kyunghyun Wen-Tau Yih; Douwe Cho;  Kiela"
            },
            {
                "ref_id": "b18",
                "title": "Language models as knowledge bases?",
                "journal": "",
                "year": "2019",
                "authors": "Fabio Petroni; Tim Rockt\u00e4schel; Sebastian Riedel; S H Patrick; Anton Lewis; Yuxiang Bakhtin; Alexander H Wu;  Miller"
            },
            {
                "ref_id": "b19",
                "title": "End-toend training of multi-document reader and retriever for open-domain question answering",
                "journal": "",
                "year": "2021",
                "authors": "Devendra Singh Sachan; Siva Reddy; William L Hamilton; Chris Dyer; Dani Yogatama"
            },
            {
                "ref_id": "b20",
                "title": "Proofwriter: Generating implications, proofs, and abductive statements over natural language",
                "journal": "",
                "year": "2021",
                "authors": "Oyvind Tafjord; Bhavana Dalvi; Peter Clark"
            },
            {
                "ref_id": "b21",
                "title": "Commonsenseqa 2.0: Exposing the limits of AI through gamification",
                "journal": "",
                "year": "2021",
                "authors": "Alon Talmor; Ori Yoran; Le Ronan; Chandra Bras; Yoav Bhagavatula; Yejin Goldberg; Jonathan Choi;  Berant"
            },
            {
                "ref_id": "b22",
                "title": "Unifying language learning paradigms",
                "journal": "CoRR",
                "year": "2022",
                "authors": "Yi Tay; Mostafa Dehghani; Q Vinh; Xavier Tran; Dara Garcia; Tal Bahri; Huaixiu Schuster; Neil Steven Zheng; Donald Houlsby;  Metzler"
            },
            {
                "ref_id": "b23",
                "title": "Selfconsistency improves chain of thought reasoning in language models",
                "journal": "",
                "year": "2022",
                "authors": "Xuezhi Wang; Jason Wei; Dale Schuurmans; Quoc V Le; Ed H Chi; Denny Zhou"
            },
            {
                "ref_id": "b24",
                "title": "Knowledge: Oak, pine and beech are Wood. Wood can be used to make furniture. ### Question: Fridges are often used in the wild. Knowledge: Fridges, ovens and TVs are appliances. Appliances are used in houses. ### Question: {User Question} Knowledge: Table 6: The trivial prompting template used in the experiments. Question: It is safe to keep wolves as pets. Knowledge: Wolves are dangerous. ### Question: Bacon is healthy diet food. Knowledge: Bacon is not healthy. ### Question: Pens are more expensive than cars. Knowledge: Pens are cheaper than cars. ### Question: People make furniture out of oak. Knowledge: Oak can be used to make furniture",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b25",
                "title": "Effect of Inductor Optimization",
                "journal": "",
                "year": "",
                "authors": ""
            }
        ],
        "figures": [
            {
                "figure_label": "1",
                "figure_type": "figure",
                "figure_id": "fig_0",
                "figure_caption": "Figure 1 :1Figure 1: Overview of our IAG framework. The inductor provides inductive knowledge for predicting the answer when the retrieved documents are less informative.",
                "figure_data": ""
            },
            {
                "figure_label": "1",
                "figure_type": "figure",
                "figure_id": "fig_1",
                "figure_caption": "Algorithm 11TAILBACK Optimization Input: D: training dataset T : number of training iterations 1: for t \u2190 1 to T do 2:",
                "figure_data": ""
            },
            {
                "figure_label": "4",
                "figure_type": "figure",
                "figure_id": "fig_2",
                "figure_caption": "Figure 4 :4Figure 4: Scores of IAG-Student on StrategyQA dev set with different numbers of knowledge statements.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_3",
                "figure_caption": "#T2. A Great Depression is a period of economic downturn in the United States. Economic downturns often happen during the Great Depression. Answer: No #D3. The Great Depression was a time of great economic change in the 1930s. A person can be diagnosed with a Great Depression. #T3. Great Depression, post World War II Depression and postwar economic depression are all periods of economic downturn. Economic downturns can have drastic effects on individuals and their families.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "table",
                "figure_id": "tab_0",
                "figure_caption": "have been proposed by constructing intermediate reasoning steps ... Disclaimer never attempt to pick up a jellyfish unless you are 100% certain you know what kind it is ... #2: ... Ten items you shouldn t toss into your dumpster ...",
                "figure_data": "Can you catch a jellyfish in the dumpster?#1: Jellyfish, crabs and shrimps are aquaticanimals. You can t catch aquaticanimals in the dumpster."
            },
            {
                "figure_label": "",
                "figure_type": "table",
                "figure_id": "tab_1",
                "figure_caption": "Illustration of our proposed TAILBACK training scheme. The likelihood values of the ground-truth answer conditioned on different knowledge statements are used as feedback from the generator, which can be back-propagated to the inductor via differentiable beam scores.",
                "figure_data": "RetrievalGenerationRetriever\ud835\udc45 1 , \u2026 , \ud835\udc45 \ud835\udc40\ud835\udc5e +\ud835\udc3e 1 \ud835\udc5e + \ud835\udc45 1 \ud835\udc5e + \ud835\udc45 \ud835\udc40 ...FiDGenerator\ud835\udc5e questionInduction InductorBeam Search\ud835\udc3e 1\ud835\udc3e 2\ud835\udc5e + \ud835\udc5e + \ud835\udc3e 2 \ud835\udc5e + \ud835\udc45 1 \ud835\udc5e + \ud835\udc45 \ud835\udc40 ... \ud835\udc3e 3 \ud835\udc5e + \ud835\udc45 1 \ud835\udc5e + \ud835\udc45 \ud835\udc40 FiD ... FiDGenerator Generator\ud835\udc3e 3\ud835\udc60 1 \ud835\udc60 2 \ud835\udc60 3 Beam ScoresBP via Diff Beam Scores\u2112 = \u2212log\ud835\udc5d \ud835\udc5b \ud835\udc60 \ud835\udc5b\ud835\udc5d 1\ud835\udc5d 2\ud835\udc5d 3\ud835\udc5d(\ud835\udc4e|\ud835\udc5e,\ud835\udc3e \ud835\udc5b , \ud835\udc45 1 , \u2026 , \ud835\udc45 \ud835\udc40 )Normalized LikelihoodFigure 2:3)4"
            },
            {
                "figure_label": "",
                "figure_type": "table",
                "figure_id": "tab_2",
                "figure_caption": ", both of which are binary classification tasks. CSQA2.0 consists of 14343 examples about everyday commonsense knowledge (9264/2541/2473 for train/dev/test), and StrategyQA is a multi-hop QA task comprised of 2780 examples (2290/490 for train/test) which requires implicit reasoning to solve. Note that since the official StrategyQA dataset doesn't include a development set, we randomly draw 1/4 of the examples out of the training set for evaluation.",
                "figure_data": ""
            },
            {
                "figure_label": "1",
                "figure_type": "table",
                "figure_id": "tab_3",
                "figure_caption": "Performance on two ODQA tasks. The first two columns report scores on CSQA2.0 dev set and StreategyQA test set respectively. The last two columns compare IAG with ChatGPT on a randomly held-out subset containing 50 examples for each task.",
                "figure_data": "MethodCSQA2.0 devStrategyQA testCSQA2.0 dev*StrategyQA dev*DisentangledQA (Liu et al., 2022c)-69.4--UL2 (Tay et al., 2022)-59.0--Auto-CoT (Zhang et al., 2022)-65.4--UNICORN-11B"
            },
            {
                "figure_label": "2",
                "figure_type": "table",
                "figure_id": "tab_5",
                "figure_caption": "Comparison between IAG-GPT and CoT prompting. Scores are reported for the StrategyQA dev set.",
                "figure_data": "MethodAccuracyCoTGreedy Self-Consistency71.5 73.3IAGw/o retrieval73.6(Trivial)w/ retrieval74.8IAGw/o retrieval75.5(Inductive)w/ retrieval76.2"
            },
            {
                "figure_label": "3",
                "figure_type": "table",
                "figure_id": "tab_7",
                "figure_caption": "Performance of IAG-Student at different stages on the dev sets of CSQA2.0 and StrategyQA.",
                "figure_data": "Training StepCSQA2.0 StrategyQARetrieval Only61.864.3+ Distillation60.5 (-1.3) 65.7 (+1.4)+ TAILBACK61.9 (+0.1) 66.6 (+2.6)"
            },
            {
                "figure_label": "4",
                "figure_type": "table",
                "figure_id": "tab_8",
                "figure_caption": "Comparison between knowledge fusion and self-consistency.",
                "figure_data": "MethodCSQA2.0 devStrategyQA devw/o induction77.272.7Self-Consistency77.674.8Knowledge Fusion78.276.2"
            },
            {
                "figure_label": "",
                "figure_type": "table",
                "figure_id": "tab_9",
                "figure_caption": "Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed H. Chi, Quoc Le, and Denny Zhou. 2022. Chain of thought prompting elicits reasoning in large language models. CoRR, abs/2201.11903.",
                "figure_data": "Jason Weston, Antoine Bordes, Sumit Chopra, and Tom\u00e1s Mikolov. 2016. Towards ai-complete question answering: A set of prerequisite toy tasks. In 4th In-ternational Conference on Learning Representations, ICLR.Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Ben-gio, William W. Cohen, Ruslan Salakhutdinov, and Christopher D. Manning. 2018. Hotpotqa: A dataset for diverse, explainable multi-hop question answer-ing. In Proceedings of the 2018 Conference on Em-pirical Methods in Natural Language Processing, pages 2369-2380.Zhuosheng Zhang, Aston Zhang, Mu Li, and Alex Smola. 2022. Automatic chain of thought prompting in large language models. CoRR, abs/2210.03493.Fengbin Zhu, Wenqiang Lei, Chao Wang, Jianming Zheng, Soujanya Poria, and Tat-Seng Chua. 2021. Retrieving and reading: A comprehensive sur-vey on open-domain question answering. CoRR, abs/2101.00774."
            },
            {
                "figure_label": "7",
                "figure_type": "table",
                "figure_id": "tab_10",
                "figure_caption": "Performance comparison between different settings on CSQA2.0 and StrategyQA dev sets.",
                "figure_data": "SettingCSQA2.0 StrategyQA10 retrievals78.473.85 retrievals + 5 knowledge78.276.2still suffers from factual errors (e.g., #D3 for Q1),which is probably due to the limitation imposedby a small model size. In comparison, further opti-mization via TAILBACK deviates the inductor fromthe pre-defined reasoning pattern, but the knowl-edge (e.g., #T1 for Q2) can better guide the genera-tor in predicting the right answer."
            },
            {
                "figure_label": "8",
                "figure_type": "table",
                "figure_id": "tab_11",
                "figure_caption": "A demonstration of knowledge elicited from GPT-3 for cases in the CSQA2.0 dev set.Text colored in red indicates factual errors or contradictions to the ground-truth answer, and green indicates supporting evidence. People have two legs. Legs are the same size as each other. Juice, water and soda are liquids. Liquids can drown people. #2. Because infants and young children can drown in only a few inches of water, even water-filled containers ... #2. Juice, water and milk are beverages. Beverages are not capable of drowning someone.",
                "figure_data": "Q & ARetrieved DocumentsInductive KnowledgeQ1:A tube is never brittle if it is made of steel. Answer: Yes Prediction (w/o induction): No Prediction (w/ induction): Yes#1. Under what circumstances does the brittle failure of steel take place? #2. The material becomes brit-tle and, in extreme cases, mere contact with molten metal ...#1. Steel is a material. Materials can vary in their properties, in-cluding brittleness. #2. Steel, iron and concrete are metals. Metals are not brittle.Q2:A person has legs the same size as each other. Answer: Yes Prediction (w/o induction): No Prediction (w/ induction): Yes #2. Q3:Juice is capable of drowning #1. Unequal leg length is where the legs are either differ-#1. Legs, arms and fingers are appendages. All appendages on ent lengths or ... a person are usually the same size. #2. Having one leg longer than the other is moderately normal. The condition is ... Prediction (w/ induction): Yes Prediction (w/o induction): No Answer: Yes commonly ... someone. #1. A physical dissertation on drowning: in which submersion, #1."
            },
            {
                "figure_label": "9",
                "figure_type": "table",
                "figure_id": "tab_12",
                "figure_caption": "Cases from StrategyQA to demonstrate the differences among the three prompting methods. Green indicates statements that support the answer, while red indicates otherwise.",
                "figure_data": "Q & ACoT PromptingTrivial PromptingInductive PromptingQ1: Are Christmas trees dissimilar to deciduous trees? Answer: YesChristmas trees are ever-green trees. Deciduous trees are tree that lose their leave. Thus, Christ-mas trees are not dissimi-lar to deciduous trees. So the answer is no.Christmas trees are conifer trees. Deciduous trees are trees that lose their leaves each year.Christmas trees, fir trees and pine trees are conif-erous trees. Deciduous trees are not conifer-ous.Q2: Do frogs feel disgust?Answer: Yes"
            },
            {
                "figure_label": "10",
                "figure_type": "table",
                "figure_id": "tab_13",
                "figure_caption": "Comparison of inductive knowledge generated by the student inductor at different optimization stages. Text colored in red indicates factual errors or contradictions to the ground-truth answer, and green indicates supporting evidence. Ontology is the study of the human mind. It requires knowledge and understanding. A scalpel is not required for ontology. #T1. Ontology is the study of philosophy and religion. Philosophy and religion don't require a scalpel. Ontology is the study of the inner workings of human beings. It requires a scalpel.",
                "figure_data": "Q & AInductive Knowledge after DistillationInductive Knowledge after TAILBACKQ1: Does ontology require a scalpel? #D1. Answer: No #D2."
            }
        ],
        "formulas": [
            {
                "formula_id": "formula_0",
                "formula_text": "p n = p(a * |\u03b8 gen , q, K n , R), n \u2208 [1, N ], (1)",
                "formula_coordinates": [
                    4.0,
                    330.18,
                    453.44,
                    194.98,
                    21.19
                ]
            },
            {
                "formula_id": "formula_1",
                "formula_text": "{p n } N n=1 following p \u2032 n = p n \u2212 \u00b5 \u03c3 , pn = exp(p \u2032 n ) N i=1 exp(p \u2032 j ) ,(2)",
                "formula_coordinates": [
                    4.0,
                    306.14,
                    504.26,
                    219.01,
                    66.53
                ]
            },
            {
                "formula_id": "formula_2",
                "formula_text": "L M ax = \u2212 yt\u2208K n log(p(y t |\u03b8 ind , q, y <t )),(",
                "formula_coordinates": [
                    4.0,
                    320.31,
                    752.16,
                    196.37,
                    24.62
                ]
            },
            {
                "formula_id": "formula_3",
                "formula_text": "L Weight = \u2212 N n=1 pn ( yt\u2208Kn log(p(y t |\u03b8 ind , q, y <t ))).",
                "formula_coordinates": [
                    5.0,
                    70.86,
                    367.73,
                    220.29,
                    34.87
                ]
            },
            {
                "formula_id": "formula_4",
                "formula_text": "3: { Kn , s n } N n=1 \u2190 beam_search(\u03b8 ind , q) 4:",
                "formula_coordinates": [
                    5.0,
                    312.26,
                    359.36,
                    202.98,
                    27.01
                ]
            },
            {
                "formula_id": "formula_5",
                "formula_text": "p n \u2190 p(a * |\u03b8 gen , q, K n , {R m } M m=1 ) 7:",
                "formula_coordinates": [
                    5.0,
                    312.26,
                    401.01,
                    206.04,
                    26.01
                ]
            },
            {
                "formula_id": "formula_6",
                "formula_text": "{ pn } N n=1 \u2190 normalize({p n } N n=1 ) 9: loss \u2190 N i=1 pi \u2022 s i 10:",
                "formula_coordinates": [
                    5.0,
                    307.78,
                    428.11,
                    185.99,
                    39.56
                ]
            },
            {
                "formula_id": "formula_7",
                "formula_text": "s n = softmax(p( Kn |\u03b8 ind , q)), n \u2208 [1, N ]. (5)",
                "formula_coordinates": [
                    5.0,
                    317.95,
                    608.93,
                    207.2,
                    21.41
                ]
            },
            {
                "formula_id": "formula_8",
                "formula_text": "L TAILBACK = \u2212 log N n=1 SG[p(a * |\u03b8 gen , q, Kn , R)] \u2022 p( Kn |\u03b8 ind , q). (6)",
                "formula_coordinates": [
                    5.0,
                    332.43,
                    724.47,
                    192.72,
                    58.45
                ]
            }
        ],
        "doi": ""
    },
    "Holistic Inter-Annotator Agreement and Corpus Coherence Estimation in a Large-scale Multilingual Annotation Campaign": {
        "authors": "Nicolas Stefanovitch; Jakub Piskorski",
        "pub_date": "",
        "abstract": "In this paper we report on the complexity of persuasion technique annotation in the context of a large multilingual annotation campaign involving 6 languages and approximately 40 annotators. We highlight the techniques that appear to be difficult for humans to annotate and elaborate on our findings on the causes of this phenomenon. We introduce Holistic IAA, a new word embedding-based annotator agreement metric and we report on various experiments using this metric and its correlation with the traditional Inter Annotator Agreement (IAA) metrics. However, given somewhat limited and loose interaction between annotators, i.e., only a few annotators annotate the same document subsets, we try to devise a way to assess the coherence of the entire dataset and strive to find a good proxy for IAA between annotators tasked to annotate different documents and in different languages, for which classical IAA metrics can not be applied.",
        "sections": [
            {
                "heading": "Introduction",
                "text": [
                    "In the recent years we have observed an emergence of automated tools for facilitating online media analysis for better understanding of the presented narratives around certain topics across countries, and to identify manipulative, deceptive and propagandistic content. Developing such tools requires annotated data of high quality.",
                    "We report on the complexity of annotating such manipulative devices, i.e., persuasion techniques, in the context of a large annotation campaign involving 6 languages and approximately 40 annotators, whose details are described in (Piskorski et al., 2023c). The persuasion technique taxonomy used in the campaign is an extension of the taxonomies used in different shared tasks, contains 23 techniques, and includes i.a., the techniques appealing to emotions, justifications and some forms of logical fallacies. The resulting dataset has been used in the SemEval 2023 Task 3: Detecting the Category, the Framing, and the Persuasion Techniques in Online News in a Multi-lingual Setup (Piskorski et al., 2023b). The primary objective of the work reported in this paper is threefold, namely:",
                    "\u2022 share some lessons learned from this large multi-lingual annotation campaign that might be beneficial for other researchers planing similar tasks,",
                    "\u2022 present a detailed analysis of the disagreements between annotators and potential causes thereof and try to measure the complexity of the annotation task, and",
                    "\u2022 propose a new concept of measuring Inter-Annotator Agreement (IAA) in a multilingual set-up, to overcome the limitations of the classical IAA metrics in such scenario.",
                    "We first highlight the techniques that appear to be difficult for humans to annotate using the classical Cohen's \u03ba (McHugh, 2012), and Krippendorff's \u03b1 (Krippendorff, 2009).",
                    "Classical IAA measures impose certain limitations. First, they only capture the coherence of the annotations in texts written in the same language. Secondly, considering annotations done for a single language, there were many annotators, but annotating totally different subsets of documents. The classical IAA metrics are computed using a tiny fraction of the whole dataset: the one where the annotators annotated the same articles, despite the fact that the exact same text could be annotated in different articles by different annotators. Finally, the classical IAA measures only capture agreement at the time of the annotation, but do not tell us anything about the coherence and quality of the final curated dataset.",
                    "In order to overcome the aforementioned limitations, we introduce Holistic IAA, a new multilingual word embedding-based IAA metric and we report on various experiments using it and its correlation with the traditional IAA metrics. However, given somewhat limited and loose interaction between annotators, i.e., only a few annotators annotate the same document subsets, we try to devise a way to assess the coherence of the entire dataset and strive to find a good proxy for IAA between annotators tasked to annotate different documents and in different languages. We present our preliminary results on this research problem with an ultimate goal of establishing a mechanism that allows to compare all annotators no matter which document they annotated, and to detect diverging annotations across languages. Our contributions can be summarized as follows: (i) we measure how confusing were the persuasion technique labels for different groups of annotators; (ii) we assess the coherence of the dataset using standard IAA measures; (iii) we introduce a new mutlilingual pancorpus IAA measure based on semantic similarity; (iv) we exploit this new measure on the raw and curated annotations of the annotators, and compare the resulting ranking of annotators to the one obtained by standard IAA measurements; (v) we comment on the self-coherence of the annotators using the new measure, as well as of the dataset language-wise.",
                    "This paper focuses primarily on the annotation agreement and complexity, whereas the description of the resulting dataset is kept to the minimum necessary for understanding the content. For further details please refer to (Piskorski et al., 2023c).",
                    "The paper is organized as follows. Section 2 reports on the related work. Section 3 introduces the persuasion technique taxonomy and describes the annotation process. Next, Section 4 reports on the annotation coherence computed using traditional IAA metrics and highlights the hard-to-annotate techniques. Subsequently, Section 5 introduces a new word embedding-based annotator agreement metric and reports on various experiments using it and correlating it with the traditional IAA metrics. We end with some concluding remarks in Section 6."
                ],
                "publication_ref": [
                    "b23",
                    "b22",
                    "b17",
                    "b16",
                    "b23"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Related Work",
                "text": [
                    "Persuasion detection in text is related to work on propaganda detection. The work in the latter area initially focused on document-level analysis and predictions, e.g., Rashkin et al. (2017) reports on prediction of 4 classes (trusted, satire, hoax, and propaganda) of documents, whereas Barr\u00f3n-Cedeno et al. (2019) presented a corpus of tagged either as propaganda or non-propaganda).",
                    "In parallel, other efforts focused on the detection of specific persuasion techniques. Habernal et al. (2017Habernal et al. ( , 2018) ) presented a corpus annotated with 5 fallacies that directly relate to propaganda techniques. A more fine-grained analysis was done by Da San Martino et al. (2019b), who developed a corpus of English news articles labelled with 18 propaganda techniques at span/sentence level. Somewhat related work on detection of use of propaganda techniques in memes is presented in (Dimitrov et al., 2021a), the relationship between propaganda and coordination (Hristakieva et al., 2022), and work studying COVID-19 related propaganda in social media (Nakov et al., 2021a,b). Bonial et al. (2022) reported on the creation of annotated text snippet dataset with logical fallacies for Covid-19 domain. Sourati et al. (2022) presents three-stage evaluation framework of detection, coarse-grained, and fine-grained classification of logical fallacies through adapting existing evaluation datasets, and evaluate various state-of-the-art models using this framework. Jin et al. (2022) proposed the task of logical fallacy detection and a new dataset of logical fallacies found in climate change claims. All the persuasion techniques and logical fallacy taxonomies introduced in the aforementioned works do overlap to a very high degree, but are structured differently, and use different naming conventions.",
                    "Various related shared tasks on the detection of persuasion techniques were organized recently, and various taxonomies were introduced (Da San Martino et al., 2020Martino et al., , 2019a;;Dimitrov et al., 2021b;Alam et al., 2022;Piskorski et al., 2023b).",
                    "Related work on IAA which explores going beyond the limitation of standard measures was reported in (Passonneau and Carpenter, 2014), proposing an idea similar to our in that they are able to compare all annotators between themselves, however, this comparison is done statistically on label distribution while we look at actual content of the annotate textd. Moreover, they are interested in assessing the gold label uncertainty, which is a similar concern to our effort of capturing the label definition difficulty. However, they treat it in a statistical fashion, while we provide simple descriptors. It would be an interesting future work to explore the combination of both approaches."
                ],
                "publication_ref": [
                    "b24",
                    "b1",
                    "b9",
                    "b10",
                    "b5",
                    "b7",
                    "b11",
                    "b2",
                    "b13",
                    "b3",
                    "b4",
                    "b8",
                    "b0",
                    "b22",
                    "b20"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Persuasion Technique Annotation",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Taxonomy",
                "text": [
                    "The taxonomy used in our annotation endeavour is an extension of the taxonomy introduced in Da San Martino et al. (2019b,c). At the top level, there are 6 coarse-grained types of persuasion techniques, namely: Attack on Reputation, Justification, Distraction, Simplification, Call, and Manipulative Wording, whose full definitions are provided in Appendix A. These core types are further subdivided into 23 fine-grained techniques. The 5 new techniques vis-a-vis the taxonomy presented in Da San Martino et al. (2019b,c) are: Appeal to Hypocrisy, Questioning the Reputation, Appeal to Values, Consequential Oversimplification, and Appeal To Time. The main drive beyond introducing these 5 new techniques is due to their frequent presence in news articles based on our empirical observations. The full two-tier taxonomy, including short definitions, and examples of each finegrained technique are provided in Figure 3 and 4 in Appendix A respectively."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Annotation Process",
                "text": [
                    "Our annotation task consisted of annotating persuasion techniques in a corpus consisting of circa 1600 news articles revolving around various globally discussed topics in six languages: English, French, German, Italian, Polish, and Russian, using the taxonomy introduced earlier. A balanced mix of mainstream media and \"alternative\" media sources that could potentially spread mis/disinformation were considered for the sake of creating the dataset. Furthermore, sources with different political orientation were covered as well.",
                    "The pool of annotators consisted of circa 40 persons, all native or near-native speakers of the language they annotated. Most of the annotators were either media analysts or researchers and experts in (computational) linguistics, where approximately 80% of the annotators had prior experience in performing linguistic annotations of news-like texts. A thorough training was provided to all annotators which consisted of: (a) reading a 60-page annotation guidelines (Piskorski et al., 2023a) -an excerpt thereof is provided in Appendix C), (b) participating in online multi-choice question-like training, (c) carrying out pilot annotations on sample documents, and (d) joint sharing experience with other annotators and discussions with the organisers of the annotation task. Subsequently, each document was annotated by at least two annotators independently. On a weekly basis reports were sent to annotator pairs highlighting complementary and potentially conflicting annotations in order to converge to a common understanding of the task, and regular meetings were held with all annotators to align and to discuss specific annotation cases.",
                    "Annotations were curated in two steps. In the first step (document-level curation) the independent annotations were jointly discussed by the annotators and a curator, where the latter was a more experienced annotator, whose role was to facilitate making a decision about the final annotations, including: (a) merging the complementary annotations (tagged only by one annotator), and (b) resolving the identified potential label conflicts. In the second step (corpus-level curation) a global consistency analysis was carried out. The rationale behind this second step was to identify inconsistencies that are difficult to spot using single-document annotation view and do comparison at corpus level, e.g., comparing whether identical or near-identical text snippets were tagged with the same or a similar label (which should be intuitively the case in most situations). The global consistency analysis sketched above proved to be essential to ensure the high quality of the annotations.",
                    "The annotation resulted in annotation of approx. 1600 documents with ca. 37K text spans annotated. The dataset is highly imbalanced. The class distribution and some statistics are provided in Annex B"
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Annotation Coherence & Complexity",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Traditional IAA",
                "text": [
                    "We measured the Inter-Annotator Agreement (IAA) using Krippendorff's \u03b1, achieving a value of 0.342. This is lower than the recommended threshold of 0.667, but we should note that this value represents the agreement level before curation, and as such, it is more representative of the curation difficulty rather than of the quality of the final consolidated annotations. We used the IAA during the campaign to allocate curation roles and to remove low-performing annotators.",
                    "We further studied the IAA by ranking the annotators by their performance with respect to the ground truth on the subset of documents they annotated. We split then the annotators into two groups: top and low based on subjective assessment by the curators after the end of the curation campaign, this assessment was then further confirmed numerically (see Annex E for details). Their respective average \u03b1 were 0.415 and 0.250. Finally, we considered the \u03b1 of the group of the curators, in order to make an approximate estimation of the coherence of the curated dataset, as we expect these curators to consistently curate the data with at least the same coherence they had when annotating documents. There are only two such curators, whose \u03b1 is of 0.588, which is lower but close to the recommended value."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Confusion matrix",
                "text": [
                    "In Figure 1 we present the confusion matrix between the annotations of annotators. A high count denotes both a frequent class and a tendency to confuse the given pair of labels.",
                    "One can see that Loaded Language (MW:LL) is the single label that is most confused with any other label, and the Name Calling (AR:NCL) is the label with which it co-occurs most, and indeed, these two labels have a very similar definition. The same applies to the pair Casting Doubt (AR:D) and Questioning the Reputation (AR:QCR). "
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_0"
                ],
                "table_ref": []
            },
            {
                "heading": "Techniques' Annotation Complexity",
                "text": [
                    "In order to study which persuasion techniques are more difficult to annotate we again divided the annotators in 3 groups: all which contains all the annotators, top which contains half of the annotators whose performance are the highest as measured by their average Cohen's \u03ba agreement, and low which contains the rest of the annotators.",
                    "For each of these groups, and for each of the persuasion techniques, we measured how annotators in a given group tend to disagree with each otherirrespective of the actual ground truth. More precisely, we compute for each pair of annotators and for all their overlapping annotations the percentage of disagreeing annotations for a given label divided by the total number of annotations between them with that label. Here, annotations of two annotators are considered overlapping if one is at most 10% longer or shorter than the other one, taking into account the exact position of the annotations in the text. We report these numbers in Table 1.",
                    "In order to interpret the results, it is also important to take into account that the 2 sub-groups, namely, top and low, also do interact with each other. We consider the following indicator of complexity: for each of the group if the disagreement is above a given threshold c that we fixed for illustration purpose at 0.25 in the table, the corresponding values are boldfaced. We also divide the techniques in the table (column 'difficulty') into four general annotation complexity classes based on the overall disagreement: very easy (all \u2264 .1, in light green), easy (all \u2264 .25, in green), moderate (all \u2264 .4, in orange), and difficult (all > .4, in red).",
                    "Additionally, we consider the following indicator: if top > all or if top > low (the techniques for which this applies are marked with an asterisk in the table ).",
                    "One can see that a high low value does not necessarily mean that the label is actually hard, for instance, the label False Dilemma is very well understood by the top group. High low value and low top value denotes a label whose understanding is not straightforward but does not pose special learning problem, in such case improving annotations for this label requires simply insisting on more basic training.",
                    "On the contrary, when the top value is higher than the others (techniques marked with an asterisk), it means that at least one of the groups agrees more with the other group than top group with itself, meaning that there is an inconsistent understanding of the label within the group. This could indicate a difficult label requiring additional clarification to be made to all annotators, or a potential inconsistency in the label definition. This is, for instance, the case for the label Repetition, which is indeed inconsistent as it includes two very different definitions of repetition.",
                    "The overall picture of the annotation complexity classes resembles to the per-label performances of classifier systems reported in (Piskorski et al., 2023c), where with a few exceptions the \"easiest\" labels are the ones with the highest F 1 score. It is important to note that these values are computed on the annotated labels before any curation had taken place, and as such do not reflect the quality of the final dataset, but are more and indication of the intrinsic difficulty of the labels for new annotators.",
                    "The class Doubt has one of the best reported F 1 scores, however, it has a difficult annotation complexity, the reason being that it is one of the most confused classes, as it is often a subpart of other techniques.",
                    "Some hard labels remain a challenge even for top annotators, and as such selecting 'reliable' annotators solely based on their overall IAA might not be sufficient to ensure the best quality of annotations, it is also important to identify for which labels additional training might be necessary.",
                    "Quantifying the annotation complexity of an annotation campaign in such a way gives an understanding of the difficulty of the task, and allows to identify incoherent understanding of the guidelines early on, and gives a more refined understanding of the quality of the annotations than considering IAA measures alone. "
                ],
                "publication_ref": [
                    "b23"
                ],
                "figure_ref": [],
                "table_ref": [
                    "tab_0"
                ]
            },
            {
                "heading": "Disagreement sources",
                "text": [
                    "On top of the findings on annotation complexity we additionally summarize here our findings on the sources of disagreements and annotation complexity from the continuous meetings with annotators and curators:",
                    "\u2022 disregarding small nuances in the definition of Loaded Language and Name Calling we noticed that disagreements and annotation or non-annotation of some instances were due to subjective perception linked to cultural differences, which was apparent when comparing annotations across languages,",
                    "\u2022 some annotators had problems with the Justification techniques, including, in particular, Appeal to Popularity, Appeal to Values, Appeal to Authority due to not understanding upfront that one subjective opinions on what is considered a value or an authority does not play a role for definition of these techniques, and not considering the role of negation, e.g., not understanding that making a reference to something not being popular falls per definition under Appeal to Popularity too,",
                    "\u2022 many annotators, who probably did not read the guidelines thoroughly, literally interpreted some persuasion technique definitions, e.g., in the context of Simplification techniques, instead of detecting certain logic patterns in text (see Annex A for definitions), the annotators literally interpreted the word 'simplification' and reasoned based on the base of whether the presentation of the information is too simplistic and certain facts were downplayed or exaggerated, which is actually linked to a different technique, i.e., Exaggeration-Minimisation,",
                    "\u2022 some of the media analysts who served as annotators were often using background knowledge (professional bias) to make decisions whether some text fragments are instances of persuasion techniques, which was strictly prohibited by the guidelines; this was mainly related to Simplifications and Distractions,",
                    "\u2022 some of the annotators, in particular, media analysts were making a direct link of persuasion technique labeling with fact verification, which was not in line with the guidelines.",
                    "To sum up, for the major fraction of persuasion techniques the disagreements resulted not from subjective perceptions of the annotators, but mainly due to not sticking strictly to the definitions provided in the 60-page guidelines and/or professional background bias that lead to misinterpretation of the persuasion technique definitions.",
                    "5 Embedding-based IAA Assessment"
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Holistic IAA",
                "text": [
                    "We introduce a new measure, namely, Holistic IAA, which allows to compare an annotator with any other, even if they did not annotate a single document in common and annotated documents in different languages. This metric exploits the property of multilingual aligned sentence embeddings, which are able to encode with similar vector representations sentences in different language with the same meaning, and different sentences with a similar meaning in a given language.",
                    "Formally, we introduce the following holistic agreement between two annotators as o \u03b8 l ,\u03b8s (a 1 , a 2 ) where a i is the function that maps input texts to label for a given annotator a i ; and for any two pair of strings \u03b8 l is the threshold on the length ratio and \u03b8 s is the threshold on the similarity measure defined for any embedding model M using the cosine distance between the embedding vector of the input strings (we denote it with o for the first letter of the word \"holos\" in Greek).",
                    "We define the set of Comparable Text Pairs (CTP) between two sets of texts X and Y as:",
                    "CT P \u03b8 l ,\u03b8s,M X,Y = {x,y\u2208X\u00d7Y : min(|x|,|y|) max(|x|,|y|) >\u03b8 l , sim(M (x),M (y))>\u03b8s}",
                    "Using this definition and defining S(a i ) as the function returning all the sentences annotated by annotator a i , we define the Holistic IAA for 2 annotators:",
                    "o \u03b8 l ,\u03b8s,M (a 1 ,a 2 ) =",
                    "x,y\u2208CT P \u03b8 l ,\u03b8s S(a 1 ),S(a 2 ) I a 1 (x)=a 2 (y)",
                    "|CT P \u03b8 l ,\u03b8s S(a 1 ),S(a 2 ) |",
                    "Extending to groups of annotators A and B, we get the more generic formulation: In a first step, the embedding for each annotated text span by each annotator is computed and stored in a vector database, and is associated with the following metadata: the document id, the annotator and the label. We use FAISS for the vector database, without quantization and with cosine distance (Johnson et al., 2019). While any multilingual embeddings could be used, we specifically use LASER embeddings (Schwenk and Douze, 2017) for simplicity reasons, i.e., our aim is to introduce a new paradigm to IAA computation, and we do not aim at determining which embeddings are the best, which is an exercise of more limited interest given the pace at which new embeddings emerge. Moreover, LASER embeddings do not require language specific thresholds. As such, one single cutoff to discriminate similar sentences can be used for all the languages, which is not generally the case for semantic similarity models (Isono, 2022). The drawback of these embeddings is that they are less discriminating than other models as the range of values corresponding to true positives largely intersects with the range of values corresponding to false positives. In a second step, for each annotator and corresponding annotated text spans, we consider the set of all similar text spans. In Figure 2 we illustrate in detail the behaviour of LASER on two sample queries reporting the L2 similarity. For the more complex query Q2, all but one retrieved spans are correct, but a divergence in meaning can be seen with decreasing semantic similarity. We use cosine distance in order to avoid the length of the vector to impact the measure. Moreover, in order to avoid comparing sentences of extremely different sizes, the length of the retrieved span and the query span is constrained by a threshold on the ratio of their respective lengths, i.e., \u03b8 l .",
                    "o \u03b8 l ,\u03b8s,M (A,B) = a,",
                    "Q1 \"\u043d\u0435\u0434\u043e\u043f\u0443\u0441\u0442\u0438\u043c\u044b\u043c\" (ru, unacceptable) : insupportable (fr, 0.03, unbearable), invisibile (it, 0.03, invisible), insostenibile (it, 0.04, unsustainable), Inacceptable (fr, 0.05, unacceptable) Q2 \"tout simplement, un mensonge\" (fr, all simply a lie) : \u00c8 tutta una menzogna (it, 0.04, it is all a lie), jawne k\u0142amstwo (pl, 0.06, a clear lie), questa \u00e8 una bugia (it, 0.06, this is a lie), \u00c9norme mensonge (fr, 0.07, an enormous lie), alles wieder eine gro\u00dfe L\u00fcge (de, 0.08, again a big lie), Wir glauben, dass wir belogen werden (de, 0.09, we believe we are being lied to), obficie ok\u0142amuj \u0105c (pl, 0.09, lying profusely), fatiscenti menzogne (it, 0.09, crumbling lies), \u043e\u0433\u043e\u043b\u0442\u0435\u043b\u043e\u0435 \u0432\u0440\u0430\u043d\u044c\u0435 (ru, 0.09, rabid lies), n'en faire qu'une bouch\u00e9e (fr, 0.09, deal with it easily), mensonges \u00e9hont\u00e9s (fr, 0.09, shameless lies)",
                    "Figure 2: Example of a query and retrieved sentences, for each span we report the language, L2 similarity and the English translation.",
                    "In Table 2 we provide an example of how text spans and their associated metadata can be queried and retrieved from the database. In this example, the retrieved texts all refer to the same concept as the query text, despite spelling variations in one language and different languages being used. How- ever, we can observe that the labels can disagree: This illustrates at the same time the difficulty of distinguishing between Loaded language and Name Calling, and that some annotators are not consistent in their annotations. Notably, the high rate of confusion between Loaded language (MW:LL) and Name Calling (AR:NCL) is observable."
                ],
                "publication_ref": [
                    "b14",
                    "b25",
                    "b12"
                ],
                "figure_ref": [],
                "table_ref": [
                    "tab_1"
                ]
            },
            {
                "heading": "Validation: Methodology",
                "text": [
                    "In order to validate the approach, we perform rank correlation analysis between the ranking computed by standard IAA techniques and the ones with our approach using Kendall's Tau rank correlation coefficient (Kendall, 1938). We consider 2 datasets: the raw annotations of the annotators, and the corpus (dataset of curated documents by curators).",
                    "The raw annotations allow us to compute pairwise IAA with Cohen's \u03ba between annotators, who have annotated the exact same documents. For each annotator, we consider the ranking of the annotators he can be compared to and which have at least 10 annotations in common.",
                    "Given the raw annotations dataset, we compute the Holistic IAA o value, and for each annotator we rank all the other annotators to which it can be compared to, as measured by the average level of agreement on labels for semantically similar text spans."
                ],
                "publication_ref": [
                    "b15"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Validation: Results",
                "text": [
                    "We compare the ranking of most 'similar' annotators for each annotator computed using Cohen's \u03ba with the ranking computed using Holistic IAA on the same subset of annotators. We consider 3 rankings: strict Cohen's \u03ba; same ranking is done on the same set of documents and annotators as the one used to compute Cohen's \u03ba; diff ranking is done on the same pair of annotators, but strictly on documents that were not jointly annotated by them.",
                    "We perform a simple grid search over the hyper-parameters \u03b8 s and \u03b8 l . In Table 3 we show a sample of the parameters searched, in Annex F we report the results of the full grid search performed. The correlation between strict and same is on overall higher than when comparing diff and strict as well as same and diff, and is even perfect or near perfect for a subset of the parameters. We selected the parameter as \u03b8 l = 0 and \u03b8 s = 0.75 for the rest of the paper, despite these being not the optimal.",
                    "Optimal parameters are too conservative and as such the CTP set was too small in order to compare all annotators or groups of annotators, and a such prevented from further studying the properties of Holistic IAA. This proves that the Holistic IAA can be used as a proxy for the pan-document pan-annotators agreement for some specific set of parameters, however, without the possibility to precisely link its value to other standard IAA measures, and with the caveat that the correlation is positive yet not perfect. As such, Holistic IAA can be used mainly to comment on the qualitative difference in agreement between different subsets of annotations. Table 3: Rank correlation between: Cohen's \u03ba computed on the original data (strict), Holistic IAA computed on the same documents as Cohen (same), Holistic IAA computed on all the other documents (diff)."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Validation: Error Analysis",
                "text": [
                    "We performed an error analysis of the confusions found using Holistic IAA: using the 33k+ confusions found by the approach over the dataset, for each pair of labels we evaluate up to 5 alleged confusions and graded the similarity between the corresponding texts on a 3-tier scale. Two texts are considered: identical if the meaning is so close that minor nuance in text would not alter the label chosen (e.g. \"op\u00e9ration sp\u00e9ciale\" (fr) and \"Spezialoperation\" (de) both meaning \"special operation\"); close if the meaning is substantially different, but semantically close enough making the label debatable and worthy to be flagged to a curator for review, for instance one text could be more generic than the other one (e.g. \"fin\u00ec molto male\" (it) =",
                    "\"it ended badly\" and \"durement mise \u00e0 mal\" (fr) = \"badly impacted\"); unrelated if the meaning is unrelated -even if the texts contain the same elements.",
                    "A total of 502 data points were annotated. Note that only texts containing at least one space were considered. In Table 4 we report the count in each category, and the mean, min and max similarity measure as given by the LASER embeddings. When adding the close and identical classes, we get that in a bit more than half of the cases the approach is able to correctly flag potential incoherent annotations.",
                    "We can also see the difficulty of setting cutoff boundaries as the range of minimum and maximum semantic distance is overlapping between all the 3 classes, and with close and identical having almost the same mean boundaries. We can nevertheless observe that the mean value of close is 0.75, making it a reasonable candidate for \u03b8 l .",
                    "These results show that about half of the annotations flagged by the system were indeed of interest to the curators. However, as such, the results are highly dependent on the model used. Future work will require to identify embeddings with a larger margin between the classes in order to make the work of the curators more efficient. Table 4: Statistics on the distance for 3 similarity classes using the LASER embeddings and cosine distance on a set of potential confusions flagged by Holistic IAA"
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Impact of the second curation step",
                "text": [
                    "In order to further evidentiate the behavior of Holistsic IAA, we use it to quantify the impact of the corpus-level curation step. This step was performed per-language after the usual documentlevel curation step was accomplished. The data was sorted per-label and the master curators looked at the overall coherence of the annotated text-span label pairs, the context of the spans was also provided. This step lead to several corrections and is understood to have boosted the overall coherence of the dataset, and should be reflected with a higher o value for the corpus.",
                    "In Table 5 we consider the agreement as measured by Holistic IAA after step 1 and 2 of the curation by considering the 4 most active cura-tors: a i and s i denote respectively the agreement percentage between annotators and the support at step i. For step 2, the o value is higher, and the average IAA is 1.6 pts higher, while the average intra-annotator agreement (self-agreement) is 3.5 pts higher. This demonstrates that Holistic IAA is able to capture and quantify the positive impact of the corpus-level curation.",
                    "In Table 6 we illustrate the impact of excluding Loaded Language (MW:LL) and Name Calling (AR:NCL) from the dataset as these labels constitute nearly half of the annotations and are frequently confused with each other by annotators in terms of absolute number (but not in proportion) as shown in Figure 1 and Table 1. We observe that the agreement between annotators can be label specific.",
                    "In Figure 8 we consider the whole curated dataset and measure the o value between pairs of languages. The columns a i report the value after step 1 and 2 considering the whole range of labels, while the columns a \u2032 i exclude the two labels MW:LL and AR:NCL. Doing so gives us an understanding of the agreement for the lower populated labels. Please note that all the Attacks on Reputation (AR:*) and Manipulative Wordings (MW:*) were excluded from the second step of the curation due to time constraints -except for DE and PL. The impact of the second curation step is almost always positive for all pairs of languages, except notably for one language for which the related o values deteriorate and which drags down the intra-language coherence score.",
                    "Overall, when considering the corpus we observe a quality increase as measured by the o value. "
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_0"
                ],
                "table_ref": [
                    "tab_4",
                    "tab_0"
                ]
            },
            {
                "heading": "Multilingual Dataset Coherence Estimation",
                "text": [
                    "Knowing the dataset coherence computed using standard IAA measures in a monolingual setting, and comparing it with values computed using Holistic IAA, we extrapolate from it the coherence of the entire multilingual dataset. Only two curators have jointly annotated the same set of documents while acting as annotators before the curation phase and taking on the curator role, as such we can compute the Krippendorff's \u03b1 between them, which is 0.588, a little under the recommended value. The o value between them on the same data is 0.420. A group of 3 \"master curators\" covered all the languages and curated most of the dataset. Their average o value on the raw annotations is of 0.565. This higher value illustrates the fact that the coherence of the annotations in the final dataset is higher than when measured on the raw annotations. We now consider only the curated dataset. In Figure 8 we can observe that the o value intra-language range has an average value of 0.538, slightly above the o value of 0.420 of the two reference annotators for which Krippendorff's \u03b1 could be computed. We can conclude that the coherence of the dataset restricted to each language is above the coherence of the reference annotators.",
                    "However, most of the inter-language o values are much lower than the intra-language values. We believe this to be due to 2 factors: 1) each curation was performed per-language, ignoring the others, thereby increasing the self coherence of each language; 2) as in the case of the diff vs. strict in Figure 3 Holistic IAA is less able to capture agreement than in the case of same vs. strict, thereby denoting a limitation of our approach. This could be partially alleviated by using 'better' embeddings. Nevertheless, even with a lower performance, a tool based on Holistic IAA to check for annotation coherence across languages would help to increase the quality of the dataset by flagging potential inconsistent annotations.",
                    "In Table 7 we can observe that the o value for the dataset is consistently higher after the second curation step vis-a-vis after the first step, suggesting that this new curation approach is of interest to increase the quality of annotations. "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_6"
                ]
            },
            {
                "heading": "Conclusions",
                "text": [
                    "We reported on the complexity of annotating persuasion techniques in a large-scale multilingual annotation campaign. We introduced the Holistic IAA paradigm, a new measure to serve as a proxy of the estimation of inter-annotator agreement and actual corpus coherence in settings that are fundamentally outside the scope of usual IAA measures. We demonstrate that annotator ranking computed using this new measure is positive and can highly correlates with ranking computed using Cohen's Kappa in some settings. Using it, we can observe the beneficial impact of the second step of our 2step curation phase, and also identify similarity and divergence between annotators for some subsets of labels. The experiment conducted in this study supports what was informally remarked regarding the estimation of the performance of the annotators and increased our confidence in the coherence of the final corpus. We believe that using Holistic IAA as part of the monitoring of multilingual or monolingual large-scale annotation campaigns could help to spot problems by flagging potential incoherence in the labels of semantically similar sentences at an early stage. In future work we envisage exploration of thresholds for finer interpretation and exploring the use of other semantic similarity models."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Limitations",
                "text": [
                    "Distribution Representativeness Although the underlying corpus of annotated news articles covers a wide range of topics as well as media from all sides of the political spectrum it should neither be seen as representative nor balanced in any specific way w.r.t. media in any country. Consequently, the distribution of the annotated persuasion techniques might, in principle, not be fully representative as well.",
                    "Biases Given that human data annotation involves some degree of subjectivity we created a comprehensive 60-page annotation guidelines document to clarify important cases during the annotation process. Nevertheless, some degree of intrinsic subjectivity might have impacted the techniques picked up by the annotators during the annotation, and impacted so the distribution thereof in the final dataset. Furthermore, although the taxonomy used in this annotation campaign covers most of the 'popular' techniques used in the media, we identified some persuasive attempts which could not have been matched with any of the techniques in the existing taxonomy, and were tagged as OTHER (less than 3% of all annotations) and were not considered in the reported work, which once again poses a certain limitation with respect to the representativeness of persuasion technique types used in the media. Methodology Soundness Our results are limited to certain extent, in particular, the introduced IAA metric should be considered as a proof of concept since certain approximations and simplifications were made and parameters were chosen, e.g., the choice for cutoff of maximal retrieved similar sentences, the length ratio to select sentence to be compared is constrained, and the choice of similarity metrics for computing semantic similarity that exploits a specific sentence embeddings model. Different settings and choices could yield different results. Disregarding of these shortcomings, the new metric helped to circumvent the limited scope and utility of classical IAA in such a large-scale multilingual campaign. We believe that the proposed methodology presented in this paper is too some extent generic, and would be of great interest to the community. The approach considers only the text of the annotation, as such their context is ignored. This limitation is mitigated in case the annotation guidelines do not specify that the span of annotation must contain all necessary information to unambiguously determine the label, which is the case in the campaign whose data was used to illustrate our approach."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Ethics Statement",
                "text": [
                    "Biases The news articles for the creation of the underlying dataset were sampled in such a way in order to have a balanced representation with respect to different points of view and type of media. We also strived to engage a mix of annotators with different backgrounds, i.e., both media analysts and computational linguists. Furthermore, the annotators were explicitly instructed not take their personal feeling about the particular topic and to objectively focus on identifying whether specific persuasion techniques were used. Disregarding the aforementioned efforts, the distribution of the various persuasion techniques annotated might not perfectly reflect the broader spectrum of the media landscape in the target languages, which should be taken into account in exploiting the related statistical information for any kind of analysis, etc. Analogously, the findings and statistics related to the annotation complexity are linked to the specific pool of annotators engaged in the campaign, and, consequently, they should be considered as approximative.",
                    "Intended Use and Misuse Potential The reported work focuses solely on sharing experience with the research community on annotating persuasion techniques in news articles in a large campaign, analysis of the difficulty of annotating such techniques, and ways of measuring annotation agreement and consistency across languages. The reported work is not linked to a release of the underlying annotated dataset, which is a subject of different publication and related ethical considerations."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A Persuasion Techniques",
                "text": [
                    "The two-tier persuasion technique taxonomy has 6 coarse-grained categories: Attack on reputation: The argument does not address the topic, but rather targets the participant (personality, experience, deeds) in order to question and/or to undermine their credibility. The object of the argumentation can also refer to a group of individuals, an organization, an object, or an activity. Justification: The argument is made of two parts, a statement and an explanation or an appeal, where the latter is used to justify and/or to support the statement. Simplification: The argument excessively simplifies a problem, usually regarding the cause, the consequence or the existence of choices. Distraction: The argument takes focus away from the main topic or argument to distract the reader. Call: The text is not an argument, but an encouragement to act or to think in a particular way. Manipulative wording: the text is not an argument, but uses specific language, which contains words or phrases that are either non-neutral, confusing, exaggerating, loaded, etc., in order to impact the reader emotionally. They are further subdivided into 23 fine-grained persuasion techniques. The full list of the finegrained techniques is presented in 3, whereas some examples of text snippets representing various persuasion techniques are provided in Figure 4."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_2"
                ],
                "table_ref": []
            },
            {
                "heading": "B Dataset Statistics",
                "text": [
                    "In Figure 5 we provide the distribution of the persuasion techniques per language. Name Calling and Loaded Language are by far the most populated classes across all languages, and are followed by Doubt and Questioning the Reputation. In total there were approx. 9K text spans (with persuasion techniques) annotated for English (536 documents), 7.2K for French (211 documents), 5.7K for German (177 documents), 8K for Italian (303 documents), 3.8K for Polish (194 documents), and 4.1K for Russian (191 documents)."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_3"
                ],
                "table_ref": []
            },
            {
                "heading": "C Annotation guidelines excerpt",
                "text": [
                    "This section provides an excerpt from the annotation guidelines (Piskorski et al., 2023a). The following general rules should be applied when annotating persuasion techniques:",
                    "\u2022 if one has doubts whether a given text fragment contains a persuasion technique then do not annotate it, (conservative approach)",
                    "\u2022 select the minimal amount of text 1 to annotate in case of doubts whether to include a longer text fragment or not,"
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "ATTACK ON REPUTATION",
                "text": [
                    "Name Calling or Labelling [AR:NCL]: a form of argument in which loaded labels are directed at an individual, group, object or activity, typically in an insulting or demeaning way, but also using labels the target audience finds desirable.",
                    "Guilt by Association [AR:GA]: attacking the opponent or an activity by associating it with a another group, activity or concept that has sharp negative connotations for the target audience.",
                    "Casting Doubt [AR:D]: questioning the character or personal attributes of someone or something in order to question their general credibility or quality.",
                    "Appeal to Hypocrisy [AR:AH]: the target of the technique is attacked on its reputation by charging them with hypocrisy/inconsistency. Questioning the Reputation [AR:QR]: the target is attacked by making strong negative claims about it, focusing specially on undermining its character and moral stature rather than relying on an argument about the topic."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "JUSTIFICATION",
                "text": [
                    "Flag Waiving [J:FW]: justifying an idea by exhaling the pride of a group or highlighting the benefits for that specific group. Appeal to Authority [J:AA]: a weight is given to an argument, an idea or information by simply stating that a particular entity considered as an authority is the source of the information.",
                    "Appeal to Popularity [J:AP]: a weight is given to an argument or idea by justifying it on the basis that allegedly \"everybody\" (or the large majority) agrees with it or \"nobody\" disagrees with it.",
                    "Appeal to Values [J:AV]: a weight is given to an idea by linking it to values seen by the target audience as positive.",
                    "Appeal to Fear, Prejudice [J:AF]: promotes or rejects an idea through the repulsion or fear of the audience towards this idea."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "DISTRACTION",
                "text": [
                    "Strawman [D:SM]: consists in making an impression of refuting an argument of the opponent's proposition, whereas the real subject of the argument was not addressed or refuted, but instead replaced with a false one.",
                    "Red Herring [D:RH]: consists in diverting the attention of the audience from the main topic being discussed, by introducing another topic, which is irrelevant. Whataboutism [D:W]: a technique that attempts to discredit an opponent's position by charging them with hypocrisy without directly disproving their argument."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "SIMPLIFICATION",
                "text": [
                    "Causal Oversimplification [S:CaO]: assuming a single cause or reason when there are actually multiple causes for an issue.",
                    "False Dilemma or No Choice [S:FDNC]: a logical fallacy that presents only two options or sides when there are many options or sides. In extreme, the author tells the audience exactly what actions to take, eliminating any other possible choices.",
                    "Consequential Oversimplification [S:CoO]: is an assertion one is making of some \"first\" event/action leading to a domino-like chain of events that have some significant negative (positive) effects and consequences that appear to be ludicrous or unwarranted or with each step in the chain more and more improbable. Appeal to Authority: Since the Pope said that this aspect of the doctrine is true we should add it to the creed."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "CALL",
                "text": [
                    "Appeal to Popularity: Because everyone else goes away to college, it must be the right thing to do.",
                    "Appeal to Values: It's standard practice to pay men more than women so we'll continue adhering to the same standards this company has always followed.",
                    "Appeal to Fear, Prejudice: It is a great disservice to the Church to maintain the pretense that there is nothing problematical about Amoris laetitia. A moral catastrophe is self-evidently underway and it is not possible honestly to deny its cause.",
                    "Strawman: Referring to your claim that providing medicare for all citizens would be costly and a danger to the free market, I infer that you don't care if people die from not having healthcare, so we are not going to support your endeavour.",
                    "Red Herring: Lately, there has been a lot of criticism regarding the quality of our product. We've decided to have a new sale in response, so you can buy more at a lower cost!.",
                    "Whataboutism: A nation deflects criticism of its recent human rights violations by pointing to the history of slavery in the United States.",
                    "Causal Oversimplification: School violence has gone up and academic performance has gone down since video games featuring violence were introduced. Therefore, video games with violence should be banned, resulting in school improvement."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "False Dilemma or No Choice:",
                "text": [
                    "There is no alternative to Pfizer Covid-19 vaccine. Either one takes it or one dies.",
                    "Consequential Oversimplification: If we begin to restrict freedom of speech, this will encourage the government to infringe upon other fundamental rights, and eventually this will result in a totalitarian state where citizens have little to no control of their lives and decisions they make Slogans: \"Immigrants welcome, racist not! Conversation Killer: I'm not so naive or simplistic to believe we can eliminate wars. You can't change human nature.",
                    "Appeal to Time: This is no time to engage in the luxury of cooling off or to take the tranquilizing drug of gradualism. Now is the time to make real the promises of democracy. Now is the time to rise from the dark and desolate valley of segregation to the sunlit path of racial justice.",
                    "Loaded Language: They keep feeding these people with trash. They should stop.   \u2022 avoid personal bias (i.e., opinion and emotions) on the topic being discussed as this has nothing to do with the annotation of persuasion techniques,",
                    "\u2022 do not exploit external knowledge to decide whether given text fragment should be tagged as a persuasion technique,",
                    "\u2022 do not confuse persuasion technique detection with fact checking. A given text fragment might contain a claim which is known to be true, but that does not imply there are no persuasion techniques to annotate in this particular text fragment,",
                    "\u2022 often, authors use irony (not being explicitly part of the taxonomy), which in most cases serves a purpose to persuade the reader, most frequently to attack the reputation of someone or something. In such cases the respective persuasion technique type should be used, or other if the use of irony does not fall under any persuasion technique type in the taxonomy,",
                    "\u2022 in case of quotations or reporting of what a given person said the annotation of the persuasion techniques within the boundaries of that quotation should be done from the perspective of that person who is making some statement or claim (point of reference) and not from the author perspective.",
                    "For each persuasion technique we have also specified what text fragment should be annotated in the document. The general rule is to annotate the minimum amount of text that can be considered as a trigger to spot the technique, even if it requires an understanding of the context that spans over more than one of the preceding sentences. Sometimes, the to-be-annotated text fragment might go beyond the boundaries of one single sentence. In the following we briefly summarize the rules for all the techniques.",
                    "Name Calling or Labelling: The noun phrase, the adjective that constitutes the label and/or the name. If quotation marks are used, they should be included in the annotation as well.",
                    "Guilt by Association: The part of text that refers to an entity and a mention of someone else (considered evil/negative) doing the same or similar thing that is considered negative. The mention of the activity of the target entity might be implicit.",
                    "Casting Doubt: Only the text fragment that questions the credibility and the object whose credibility is being questioned. There is no need to include the full context.",
                    "Appeal to Hypocrisy: The text phrase embracing a certain activity, and another one which is used as an argument to accuse the former as being a hypocrite.",
                    "Questioning the Reputation: Only the text fragments that refer to something negative being mentioned about the person/group/object.",
                    "Flag Waving: The part of the text that refers to patriotism or other group related values, and the conclusion/action it is supposed to support if it is present in the text.",
                    "Appeal to Authority: The part of the text that refers to the authority (and potentially some of his/her statement/opinion/action), and the conclusion it supports, in case the latter is present in the text.",
                    "Appeal to Popularity: The part of the text that refers to something that a majority does or seems to be widely supported and/or is popular together with the conclusion it is supposed to support.",
                    "Appeal to Values: The part of the text that refers to values, and include the conclusion it is supposed to support, in case the latter is included explicitly in the text. or a false conclusion drawn therefrom should be annotated, although, often not all parts of the pattern above are explicitly mentioned in the text.",
                    "False Dilemma or No Choice: The minimal text fragment that matches one of the following logical patterns should be annotated:",
                    "(a) Black & White Fallacy:",
                    "There are only two alternatives A and B to a given problem/task. It cannot be A. Therefore, the only solution is B (since A is not an option)."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "(b) Dictatorship",
                "text": [
                    "The only solution to a given problem/task is A.",
                    "although, often not all parts of the pattern above are explicitly mentioned in the text."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Consequential Oversimplification:",
                "text": [
                    "The entire text fragment that matches the above logical pattern should be annotated:",
                    "if A will happen then B, C, D, ... will happen where:",
                    "-A is something one is trying to reject (support) -B, C, D are perceived as some potential negative (positive) consequences happening if A happens."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Slogans:",
                "text": [
                    "The slogan only (no need to annotate the conclusion it supports), and in case it is surrounded Conversation Killer: A minimal text span that triggers ending the conversation, discussion, etc.",
                    "Appeal to Time: A minimal text span referring to the argument of time that calls for some action.",
                    "Both the call and the action should be annotated.",
                    "Loaded Language: Only the phrase containing loaded words, the context in which they appear should not be annotated. As a general rule one should consider to tag longer text fragment if and only if each of the words adds more emotional 'load' to the text fragment."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Obfuscation, Intentional Vagueness, Confusion:",
                "text": [
                    "The minimal text fragment that introduces confusion: it could be a word, but also a longer piece of text that requires to be read in order to understand the confusion it causes.",
                    "Exaggeration or Minimisation: The text fragment that provides the description that downplays or exaggerates the object of criticism. The latter should be included in the annotated text as well.",
                    "Repetition: All text fragments that repeat the same message or information that was introduced earlier.",
                    "The first occurrence of the message/information is to be annotated as well. If it is not clear what exactly to annotate then the entire sentence should be annotated. Furthermore, it is important to emphasize that a repetition of something per se is not always a persuasion technique, but could sometimes be used only to refer to a topic/issue being discussed."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "D Confusion Matrix based on Holistic IAA",
                "text": [
                    "In Figure 7 we report the confusion matrix found using Holistic IAA on the final curated dataset. De- In Figure 6 we report the confusion matrix on the set of annotations. It is closer the Figure 1 than Figure 7. This indicates that the curation process actually eliminated some common confusion in the annotations. The magnitude are different for two reasons that can not be measure independently: it contains less errors, and there are less overall pair-wise comparison performed as the total set of annotation considered is about two times smaller."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_5",
                    "fig_4",
                    "fig_0",
                    "fig_5"
                ],
                "table_ref": []
            },
            {
                "heading": "E Identifying the top and low groups of annotators",
                "text": [
                    "In order to split the annotators into two groups, in a first time the curators based on their subjective assessments established 2 groups of equal size. This was further corroborated in a second step using the following approach: the curated data was taken as ground truth and the annotators were considered as classifiers, whose annotations are considered as prediction. As such we computed the micro F 1 for each annotator, and ranking them along that measure, the median split validated the first subjective assessment which contained a few more annotators, which all ranked the highest in the lower split. The average micro F 1 score of the top and low groups are respectively of 0.603 +-0.119 and 0.284 +-0.081."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Acknowledgements",
                "text": [
                    "We are greatly indebted to all the annotators from different organizations, who participated in the annotation campaign, and without whom carrying out the reported study would not have been possible.",
                    "The work presented in this paper is financed by the Joint Research Centre of the European Commission."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "F Parameter search",
                "text": [
                    "We conducted an exhaustive parameter search in order to determine the optimal parameter \u03b8 l and \u03b8 s which maximise the rank correlation between the ranking of annotators produces by Cohen's Kappa and the one produces by Holistic IAA. We consider 3 groups of document-annotators pairs: strict, for which Cohen's \u03ba can be computed; same any document annotated by previous annotators; diff any documents not annotated jointly by previous annotators. The pairwise comparison of these sets with Kendall's Tau rank correlation is consider as 3 dimensions of a multi-criteria decision problem: A minimal number of 10 annotations in common is required for a pair of annotator to be considered, support is the total number of pairs being compared.",
                    "The table with the result of the parameter search are reported in Table 9."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            }
        ],
        "references": [
            {
                "ref_id": "b0",
                "title": "Overview of the WANLP 2022 shared task on propaganda detection in Arabic",
                "journal": "",
                "year": "2022",
                "authors": "Firoj Alam; Hamdy Mubarak; Wajdi Zaghouani; Giovanni Da San; Preslav Martino;  Nakov"
            },
            {
                "ref_id": "b1",
                "title": "Proppy: Organizing the news based on their propagandistic content",
                "journal": "Information Processing & Management",
                "year": "2019",
                "authors": "Alberto Barr\u00f3n-Cedeno; Israa Jaradat; Giovanni Da San; Preslav Martino;  Nakov"
            },
            {
                "ref_id": "b2",
                "title": "The search for agreement on logical fallacy annotation of an infodemic",
                "journal": "",
                "year": "2022",
                "authors": "Claire Bonial; Austin Blodgett; Taylor Hudson; Stephanie M Lukin; Jeffrey Micher; Douglas Summers-Stay; Peter Sutor; Clare Voss"
            },
            {
                "ref_id": "b3",
                "title": "SemEval-2020 task 11: Detection of propaganda techniques in news articles",
                "journal": "",
                "year": "2020",
                "authors": "Giovanni Da San; Alberto Martino; Henning Barr\u00f3n-Cede\u00f1o; Rostislav Wachsmuth; Preslav Petrov;  Nakov"
            },
            {
                "ref_id": "b4",
                "title": "Findings of the NLP4IF-2019 shared task on fine-grained propaganda detection",
                "journal": "Association for Computational Linguistics",
                "year": "2019",
                "authors": "Giovanni Da San; Alberto Martino; Preslav Barr\u00f3n-Cede\u00f1o;  Nakov"
            },
            {
                "ref_id": "b5",
                "title": "Fine-grained analysis of propaganda in news articles",
                "journal": "",
                "year": "2019",
                "authors": "Giovanni Da San; Seunghak Martino; Alberto Yu; Rostislav Barr\u00f3n-Cede\u00f1o; Preslav Petrov;  Nakov"
            },
            {
                "ref_id": "b6",
                "title": "Fine-grained analysis of propaganda in news articles",
                "journal": "",
                "year": "2019",
                "authors": "Giovanni Da San; Seunghak Martino; Alberto Yu; Rostislav Barron-Cedeno; Preslav Petrov;  Nakov"
            },
            {
                "ref_id": "b7",
                "title": "Detecting propaganda techniques in memes",
                "journal": "",
                "year": "2021",
                "authors": "Dimitar Dimitrov; Shaden Bishr Bin Ali; Firoj Shaar; Fabrizio Alam; Hamed Silvestri; Preslav Firooz; Giovanni Da San Nakov;  Martino"
            },
            {
                "ref_id": "b8",
                "title": "Task 6 at SemEval-2021: Detection of persuasion techniques in texts and images",
                "journal": "",
                "year": "2021",
                "authors": "Dimiter Dimitrov; Shaden Bishr Bin Ali; Firoj Shaar; Fabrizio Alam; Hamed Silvestri; Preslav Firooz; Giovanni Da San Nakov;  Martino"
            },
            {
                "ref_id": "b9",
                "title": "Argotario: Computational argumentation meets serious games",
                "journal": "",
                "year": "2017",
                "authors": "Ivan Habernal; Raffael Hannemann; Christian Pollak; Christopher Klamm; Patrick Pauli; Iryna Gurevych"
            },
            {
                "ref_id": "b10",
                "title": "Adapting serious game for fallacious argumentation to German: Pitfalls, insights, and best practices",
                "journal": "",
                "year": "2018",
                "authors": "Ivan Habernal; Patrick Pauli; Iryna Gurevych"
            },
            {
                "ref_id": "b11",
                "title": "The spread of propaganda by coordinated communities on social media",
                "journal": "",
                "year": "2022",
                "authors": "Kristina Hristakieva; Stefano Cresci; Giovanni Da San; Mauro Martino; Preslav Conti;  Nakov"
            },
            {
                "ref_id": "b12",
                "title": "Language agnostic multilingual sentence embedding models for semantic search",
                "journal": "",
                "year": "2022",
                "authors": "Fumika Isono"
            },
            {
                "ref_id": "b13",
                "title": "Logical fallacy detection",
                "journal": "Association for Computational Linguistics",
                "year": "2022",
                "authors": "Zhijing Jin; Abhinav Lalwani; Tejas Vaidhya; Xiaoyu Shen; Yiwen Ding; Zhiheng Lyu; Mrinmaya Sachan; Rada Mihalcea; Bernhard Schoelkopf"
            },
            {
                "ref_id": "b14",
                "title": "Billion-scale similarity search with GPUs",
                "journal": "IEEE Transactions on Big Data",
                "year": "2019",
                "authors": "Jeff Johnson; Matthijs Douze; Herv\u00e9 J\u00e9gou"
            },
            {
                "ref_id": "b15",
                "title": "A new measure of rank correlation",
                "journal": "Biometrika",
                "year": "1938",
                "authors": "G Maurice;  Kendall"
            },
            {
                "ref_id": "b16",
                "title": "Testing the reliability of content analysis data. The content analysis reader",
                "journal": "",
                "year": "2009",
                "authors": "Klaus Krippendorff"
            },
            {
                "ref_id": "b17",
                "title": "Interrater reliability: the kappa statistic",
                "journal": "Biochemia medica",
                "year": "2012",
                "authors": "L Mary;  Mchugh"
            },
            {
                "ref_id": "b18",
                "title": "COVID-19 in Bulgarian social media: Factuality, harmfulness, propaganda, and framing",
                "journal": "",
                "year": "2021",
                "authors": "Preslav Nakov; Firoj Alam; Shaden Shaar; Giovanni Da San; Yifan Martino;  Zhang"
            },
            {
                "ref_id": "b19",
                "title": "A second pandemic? Analysis of fake news about COVID-19 vaccines in Qatar",
                "journal": "",
                "year": "2021",
                "authors": "Preslav Nakov; Firoj Alam; Shaden Shaar; Giovanni Da San; Yifan Martino;  Zhang"
            },
            {
                "ref_id": "b20",
                "title": "The benefits of a model of annotation",
                "journal": "Transactions of the Association for Computational Linguistics",
                "year": "2014",
                "authors": "J Rebecca; Bob Passonneau;  Carpenter"
            },
            {
                "ref_id": "b21",
                "title": "Firoj Alam, and Preslav Nakov. 2023a. News categorization, framing and persuasion techniques: Annotation guidelines",
                "journal": "",
                "year": "",
                "authors": "Jakub Piskorski; Nicolas Stefanovitch; Valerie-Anne Bausier; Nicolo Faggiani; Jens Linge; Sopho Kharazi; Nikolaos Nikolaidis; Giulia Teodori; Brian Bertrand De Longueville; Jason Doherty; Camelia Gonin; Bonka Ignat; Eleonora Kotseva; Lorena Mantica; Enrico Marcaletti; Alessio Rossi; Marco Spadaro; Giovanni Verile;  Da San;  Martino"
            },
            {
                "ref_id": "b22",
                "title": "Semeval-2023 task 3: Detecting the category, the framing, and the persuasion techniques in online news in a multilingual setup",
                "journal": "",
                "year": "2023",
                "authors": "Jakub Piskorski; Nicolas Stefanovitch; Giovanni Da San; Preslav Martino;  Nakov"
            },
            {
                "ref_id": "b23",
                "title": "Multilingual multifaceted understanding of online news in terms of genre, framing, and persuasion techniques",
                "journal": "Long Papers",
                "year": "2023",
                "authors": "Jakub Piskorski; Nicolas Stefanovitch; Nikolaos Nikolaidis; Giovanni Da San; Preslav Martino;  Nakov"
            },
            {
                "ref_id": "b24",
                "title": "Truth of varying shades: Analyzing language in fake news and political fact-checking",
                "journal": "",
                "year": "2017",
                "authors": "Eunsol Hannah Rashkin; Jin Yea Choi; Svitlana Jang; Yejin Volkova;  Choi"
            },
            {
                "ref_id": "b25",
                "title": "Learning joint multilingual sentence representations with neural machine translation",
                "journal": "",
                "year": "2017",
                "authors": "Holger Schwenk; Matthijs Douze"
            },
            {
                "ref_id": "b26",
                "title": "Filip Ilievski, H\u00f4ng-\u00c2n Sandlin, and Alain Mermoud. 2022. Robust and explainable identification of logical fallacies in natural language arguments",
                "journal": "",
                "year": "",
                "authors": "Zhivar Sourati;  Vishnu Priya Prasanna; Darshan Venkatesh; Himanshu Deshpande;  Rawlani"
            }
        ],
        "figures": [
            {
                "figure_label": "1",
                "figure_type": "figure",
                "figure_id": "fig_0",
                "figure_caption": "Figure 1 :1Figure 1: Confusion matrix between single annotations of annotators, thereby denoting tendencies in confusion between the given pairs of labels. Values lower than 10 are blanked.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_1",
                "figure_caption": "b\u2208A\u00d7B x,y\u2208CT P \u03b8 l ,\u03b8s S(a 1 ),S(a 2 ) I a 1 (x)=a 2 (y) a,b\u2208A\u00d7B |CT P \u03b8 l ,\u03b8s S(a),S(b) | Finally, let An(D) denote the set of annotators of a dataset D. We can now define the Holistic IAA value for a dataset as: o \u03b8 l ,\u03b8s,M D = o \u03b8 l ,\u03b8s,M (An(D),An(D))",
                "figure_data": ""
            },
            {
                "figure_label": "4",
                "figure_type": "figure",
                "figure_id": "fig_2",
                "figure_caption": "Figure 4 :4Figure 4: Examples of text snippets with persuasion techniques. The text fragments highlighted in bold are the actual text spans annotated.",
                "figure_data": ""
            },
            {
                "figure_label": "5",
                "figure_type": "figure",
                "figure_id": "fig_3",
                "figure_caption": "Figure 5 :5Figure 5: Distribution of the persuasion techniques per language (in percentage).",
                "figure_data": ""
            },
            {
                "figure_label": "6",
                "figure_type": "figure",
                "figure_id": "fig_4",
                "figure_caption": "Figure 6 :6Figure 6: Confusion matrix on the annotations, as per Holistic IAA, for a minimal support of 50",
                "figure_data": ""
            },
            {
                "figure_label": "7",
                "figure_type": "figure",
                "figure_id": "fig_5",
                "figure_caption": "Figure 7 :7Figure 7: Confusion matrix on final corpus, as per Holistic IAA, for a minimal support of 10",
                "figure_data": ""
            },
            {
                "figure_label": "1",
                "figure_type": "table",
                "figure_id": "tab_0",
                "figure_caption": "Per-label disagreement of three groups of annotators: all, top and low and related complexity markers. The colours reflect the respective annotation complexity class. The techniques considered as potentially requiring additional clarification or whose definitions might exhibit inconsistencies are marked with an asterisk.",
                "figure_data": "Doubt AR:D Appeal to Hypocrisy AR:AH Questioning the Reputation AR:QR Flag Waving J:FW Appeal to Authority J:AA Appeal to Values J:AV Appeal to Popularity J:AP Appeal to Fear-Prejudice J:AF Causal Oversimplification S:CaO Consequential Oversimplification S:CoO False Dilemma-No Choice D:FDNC .400 .154 1.00 \u25a0 .426 .286 .456 \u25a0 .025 .033 .111 \u25a0 * .266 .213 .372 \u25a0 .286 .667 1.00 \u25a0 * .222 .100 1.00 \u25a0 .190 .133 .667 \u25a0 .231 .200 1.00 \u25a0 .091 .095 .158 \u25a0 * .368 .154 1.00 \u25a0 .250 .182 .078 \u25a0 * Strawman D:S .200 .429 1.00 \u25a0 * Red Herring D:RH .500 .600 1.00 \u25a0 * Whataboutism D:W .500 .500 1.00 \u25a0 Slogans C:S .200 .333 .200 \u25a0 * Conversation Killer C:CK .148 .100 .400 \u25a0 Appeal to Time C:AT .333 .750 .333 \u25a0 * Loaded Language MW:LL .042 .048 .089 \u25a0 * Obfuscation-Vagueness-Confusion MW:OVC .400 .600 1.00 \u25a0 * Exaggeration-Minimisation MW:EM .208 .176 .429 \u25a0 Repetition MW:R .444 .667 .400 \u25a0 *"
            },
            {
                "figure_label": "2",
                "figure_type": "table",
                "figure_id": "tab_1",
                "figure_caption": "Example of a query span and result span fetched from the database, L2 similarity is reported, as well as the associated labels and the annotator identifier.",
                "figure_data": "type query reply 0.036 fanatyk\u00f3w religijnych PL dist. span lang. label -religi\u00f6s-fanatische DE MW:LL E an. AR:NCL Dtype query reply 0.027 fascista sim. span -fassisti reply 0.031 faszyst \u0105 reply 0.036 Faschismus reply 0.038 faszy\u015bci reply 0.038 \u0444\u0430\u0448\u0438\u0441\u0442\u044b reply 0.043 fascistilang. label IT MW:LL A an. IT MW:LL F PL AR:NCL D DE MW:LL G PL AR:NCL D RU MW:R H IT MW:LL A"
            },
            {
                "figure_label": "5",
                "figure_type": "table",
                "figure_id": "tab_4",
                "figure_caption": "Curated dataset, agreement after step 1 and 2, where a i and s i denote respectively the o value between annotators and the support at step i.",
                "figure_data": "cur1cur2a1s1a2s2A A A A B B B C C DA B C D B C D C D D0.597 0.5 0.586 0.544 0.49 0.451 0.61 0.597 0.471 0.771193778 57351 45694 51327 10319 8575 11688 3185 6163 54730.603 0.517 0.595 0.548 0.523 0.434 0.625 0.647 0.41 0.798177604 54503 183937 123539 10210 29189 27113 54566 62387 35248o inter intra0.567 0.483 \u00b1 0.093 0.606 \u00b1 0.0930.574 0.499 \u00b1 0.101 0.641 \u00b1 0.090"
            },
            {
                "figure_label": "7",
                "figure_type": "table",
                "figure_id": "tab_6",
                "figure_caption": "o value for the curated data after each curation step for different values of \u03b8 s and fixed \u03b8 l = 0",
                "figure_data": "\u03b8s0.750.800.850.900.95step 1 step 20.537 0.5600.580 0.5920.729 0.7560.738 0.7620.828 0.851lang1 lang2 a1a2a1'a2'change change'FR FR FR FR IT IT IT PL PL RUFR IT PL RU IT PL RU PL RU RU0.612 0.653 0.45 0.585 0.592 0.168 0.223 +0.007 0.47 +0.041 0.435 0.401 0.451 0.484 -0.034 0.43 0.443 0.245 0.288 +0.013 0.593 0.6 0.458 0.458 +0.007 0.545 0.549 0.384 0.346 +0.004 0.509 0.524 0.229 0.234 +0.015 0.771 0.798 0.625 0.476 +0.027 0.608 0.618 0.312 0.255 +0.01 0.501 0.531 0.343 0.373 +0.03+0.02 +0.055 +0.033 +0.043 0.0 -0.038 +0.005 -0.149 -0.057 +0.03o inter intra0.567 0.574 0.323 0.346 +0.013 0.519 0.521 0.298 0.305 +0.002 0.619 0.646 0.469 0.444 +0.027+0.023 +0.007 -0.025Table 8: Curated dataset: impact of the two curation steps on the overall agreement between languages (inter) and inside languages (intra), when the labels MW:LL and AR:NCL are included (a1 and a2) and excluded (a1' and a2')"
            },
            {
                "figure_label": "",
                "figure_type": "table",
                "figure_id": "tab_7",
                "figure_caption": "Guilt by Association: Manohar is a big supporter for equal pay for equal work. This is the same policy that all those extreme feminist groups support. Extremists like Manohar should not be taken seriously.",
                "figure_data": "Name Calling or Labelling: 'Fascist' Anti-Vax Riot Sparks COVID Outbreak in Australia.Casting Doubt: This task is quite complex. Is his professional background, experience and the time left sufficient to accomplish the task at hand?Appeal to Hypocrisy: How can you demand that I eat less meat to reduce my carbon footprint if you yourself drive a big SUV and fly for holidays to Bali?Questioning the Reputation: I hope I presented my argument clearly. Now, my opponent will attempt to refute my argument by his own fallacious, incoherent, illogical version of historyFlag Waiving: We should make America great again, and restrict the immigration laws.Slogans [C:S]: a brief and striking phrase, often acting like emotional appeals, that may include labeling and stereotyping. Conversation Killer [A:CK]: words or phrases that discourage critical thought and meaningful discussion about a given topic. Appeal to Time [C:AT]: the argument is centred around the idea that time has come for a particular action.MANIPULATIVE WORDINGLoaded Language [MW:LL]: use of specific words and phrases with strong emotional implications (either positive or negative) to influence and convince the audience that an argument is valid. Obfuscation, Intentional Vagueness, Confusion [MW:OVC]: use of words that are deliberately not clear, vague or ambiguous so that the audience may have its own interpretations. Exaggeration or Minimisation [MW:EM]: consists of either representing something in an excessive manner or making something seem less important or smaller than it really is. Repetition [MW:R]: the speaker uses the same phrase repeatedly with the hopes that the repetition will lead to persuade the audience.Figure 3: Persuasion techniques taxonomy. The six coarse-grained techniques are subdivided into 23 fine-grained ones. An acronym for each technique is given in squared brackets."
            },
            {
                "figure_label": "",
                "figure_type": "table",
                "figure_id": "tab_8",
                "figure_caption": "Obfuscation, Intentional Vagueness, Confusion: Feathers can not be dark, because all feathers are light! Exaggeration or Minimisation: From the seminaries, to the clergy, to the bishops, to the cardinals, homosexuals are present at all levels, by the thousand Repetition: Hurtlocker deserves an Oscar. Other films have potential, but they do not deserve an Oscar like Hurtlocker does. The other movies may deserve an honorable mention but Hurtlocker deserves the Oscar.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "table",
                "figure_id": "tab_9",
                "figure_caption": "Appeal to Fear, Prejudice: The part of the text that refers to the fears, prejudices, e.g., of something that might happen. Strawman: When this technique is used, usually the relevant context might span across more sentences. However, one should only annotate the text fragment (sentence or part thereof), which introduces the distraction. Red Herring: When this technique is used, usually the relevant context might span across more sentences. However, one should only annotate the text fragment (sentence or part thereof), which introduces the distraction. Whataboutism: When this technique is used, usually the relevant context might span across multiple sentences. However, one should only annotate the text fragment (sentence or part thereof) that introduces the distraction. Causal Oversimplification: The minimal text fragment that matches the logical pattern should be annotated:",
                "figure_data": ""
            }
        ],
        "formulas": [
            {
                "formula_id": "formula_0",
                "formula_text": "CT P \u03b8 l ,\u03b8s,M X,Y = {x,y\u2208X\u00d7Y : min(|x|,|y|) max(|x|,|y|) >\u03b8 l , sim(M (x),M (y))>\u03b8s}",
                "formula_coordinates": [
                    6.0,
                    92.97,
                    420.43,
                    174.06,
                    27.85
                ]
            },
            {
                "formula_id": "formula_1",
                "formula_text": "o \u03b8 l ,\u03b8s,M (a 1 ,a 2 ) =",
                "formula_coordinates": [
                    6.0,
                    74.18,
                    523.02,
                    73.45,
                    10.04
                ]
            },
            {
                "formula_id": "formula_2",
                "formula_text": "o \u03b8 l ,\u03b8s,M (A,B) = a,",
                "formula_coordinates": [
                    6.0,
                    71.56,
                    592.37,
                    79.57,
                    18.54
                ]
            }
        ],
        "doi": "10.18653/v1/D19-5024"
    },
    "Evaluating and Modeling Attribution for Cross-Lingual Question Answering": {
        "authors": "Benjamin Muller; John Wieting; Jonathan H Clark; Tom Kwiatkowski; Sebastian Ruder; Livio Baldini Soares; Roee Aharoni; Jonathan Herzig; Xinyi Wang; Inria Paris; Google Deepmind; Google Research",
        "pub_date": "",
        "abstract": "Trustworthy answer content is abundant in many high-resource languages and is instantly accessible through question answering systems-yet this content can be hard to access for those that do not speak these languages. The leap forward in cross-lingual modeling quality offered by generative language models offers much promise, yet their raw generations often fall short in factuality. To improve trustworthiness in these systems, a promising direction is to attribute the answer to a retrieved source, possibly in a content-rich language different from the query. Our work is the first to study attribution for cross-lingual question answering. First, we introduce the XOR-AttriQA dataset to assess the attribution level of a state-of-theart cross-lingual question answering (QA) system in 5 languages. To our surprise, we find that a substantial portion of the answers is not attributable to any retrieved passages (up to 47% of answers exactly matching a gold reference) despite the system being able to attend directly to the retrieved text. Second, to address this poor attribution level, we experiment with a wide range of attribution detection techniques. We find that Natural Language Inference models and PaLM 2 fine-tuned on a very small amount of attribution data can accurately detect attribution. With these models, we improve the attribution level of a cross-lingual QA system. Overall, we show that current academic generative cross-lingual QA systems have substantial shortcomings in attribution and we build tooling to mitigate these issues. 1 1 The XOR-AttriQA dataset is available at https: //github.com/google-research/google-research/ tree/master/xor_attriqa. XOR-AttriQA includes approximately 10,000 annotated examples to foster research in the modeling and evaluation of attribution in cross-lingual settings. \u2020 Correspondence to {jwieting,jhclark}@google.com. \u2660 Work done as an intern at Google Research.",
        "sections": [
            {
                "heading": "Introduction",
                "text": [
                    "Open-Retrieval Question Answering (ORQA) delivers promising performance for informationseeking question answering in about 20 languages (Asai et al., 2021b(Asai et al., , 2022;;Muller et al., 2022). ORQA models typically consist of a retriever that retrieves documents in a large corpus, followed by a generator that generates a short answer based on the top-ranked documents.",
                    "Recent work in ORQA reached a new state of the art by not only retrieving documents in the same language as the query but by also retrieving passages cross-lingually, in additional languages (Asai et al., 2021b). This approach is particularly beneficial for languages with limited online written content (Kornai, 2013;Valentim et al., 2021), potentially allowing users to access information that may not be available in their language.",
                    "ORQA models are typically evaluated with string-matching metrics (e.g., Exact-Match) based on extensive collections of question and answer pairs in multiple languages (Clark et al., 2020;Longpre et al., 2021). However, these metrics are limited in three ways. First, they are inherently hard to scale to real-world applications, as they require the collection of gold answers for all the queries. Second, in some cases, the answer can be correct without any overlap with a gold reference (Bulian et al., 2022). Third, short answers are usually not enough to provide a trustworthy answer, and users may prefer to access the underlying source document. To address this last challenge, Bohnet et al. (2022) framed a new task called Attributed Question Answering (AQA). Given a query, AQA consists of predicting a short answer along with a supporting document retrieved from a large corpus (e.g. Wikipedia).",
                    "This work is the first study on Attributed Question Answering in the cross-lingual setting. 2 Mea- Figure 1: Attribution scenarios for cross-lingual Open-Retrieval Question Answering (XORQA). Given a query in a source language, a retrieval model (MDPR) retrieves source language and cross-lingual documents, which are then used by a generation model, MGEN, to produce a source language answer. For S1, in-language annotators assess attribution directly in the user's language while for S2, annotators validate attribution in English. We collect data for both scenarios in Bengali, Finnish, Japanese, Russian and Telugu.",
                    "suring attribution (Rashkin et al., 2021) in the crosslingual setting is more complex than in the monolingual case. Indeed, in this case, the document supporting the generated answer may be in a language different from the query and answer. Hence, attribution can be defined in various ways depending on the query, document, and answer languages. In this work, we introduce two attribution scenarios, namely (S1) in-language attribution for which the attribution is measured in the language of the query, and (S2) in-English attribution for which attribution is measured in English. We note that both scenarios may require translating a portion of the documents, the query, or the answer. We illustrate these scenarios in Figure 1.",
                    "Based on this framework, we first measure the attribution level of CORA (Asai et al., 2021b), a stateof-the-art cross-lingual ORQA system. We collect data in 5 languages: Bengali, Finnish, Japanese, Russian, and Telugu. To our surprise, a large portion of generated answers was found not attributable to any retrieved passage. For instance, in Japanese, up to 47% of answers exactly matching the gold reference are not attributable. This poor attribution may hurt the trust into our QA systems and limit their deployment.",
                    "To improve the attribution level of cross-lingual QA systems, we experiment with a wide range of attribution detection models. We show that PaLM 2 in any language, possibly in a language different from the query, as a cross-lingual QA system. (Anil et al., 2023) outperforms all the other models despite being fine-tuned on a very small sample of our collected data (250 examples). This result shows the potential of using large language models to create state-of-the-art cross-lingual attribution models using very little annotated data, allowing them to be inexpensively created for use in many of the languages of the world. Additionally, we find that for Bengali, Finnish, Japanese and Russian, a T5 model fine-tuned on a large natural language inference corpora reaches very high accuracy compared to the baselines.",
                    "Our analysis shows that PaLM 2 can detect more than 86% of attributed answers that are not exactly matching the gold reference, showing that it is a useful alternative to exact match evaluation. These answers may be answers that are not captured by the gold references but that are alternative correct answers or they can be answers that are semantically equivalent to the gold reference but that do not overlap with the gold reference (e.g. different units). We discuss these cases in Section 4.2.",
                    "In summary, we make the following four contributions: (i) Our work is the first to study attribution for question answering in a cross-lingual framework. We define two attribution scenarios, inlanguage attribution and in-English Attribution and annotate approximately 10,000 examples in five languages; (ii) Using this data, we evaluate the attribution of CORA, a state-of-the-art cross-lingual QA system. We show that a large portion (7%-47%, depending on the language) of the answers are not attributable-neither to in-language passages nor to cross-language ones; (iii) We show that PaLM 2 and NLI models can accurately detect attribution in the cross-lingual setting, significantly outperforming all other baselines and reaching above 90% accuracy for all 5 languages. Moreover, our work is the first to approach it with large language models, and we show that with scarce amounts of data (250 examples), they can outperform NLI models trained on millions of examples; and (iv) Using our attribution detection model as a reranker, we show that we reach an average of +55% in attribution compared to a model with no reranking.",
                    "2 Attribution for Cross-Lingual Question Answering"
                ],
                "publication_ref": [
                    "b3",
                    "b2",
                    "b23",
                    "b3",
                    "b21",
                    "b36",
                    "b12",
                    "b22",
                    "b5",
                    "b31",
                    "b3"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Attribution of Generative Language Models",
                "text": [
                    "Generative language models have made impressive progress in the past few years (Radford et al., 2019;Raffel et al., 2020;Brown et al., 2020;Chowdhery et al., 2022). They can now perform most NLP tasks with relatively high accuracy in zero-shot and few-shot settings. However, generating text without reference to human-written trusted sources can be harmful in the real world. Indeed, even the largest models may assign a high probability to false and potentially harmful utterances (Bender et al., 2021;Bommasani et al., 2021;Weidinger et al., 2022). To overcome this challenge, Rashkin et al. (2021) introduced the Attributable to Identified Sources (AIS), a human evaluation framework for identifying whether a source document supports the generated text, or in other words, whether the generations can be attributed to a given document."
                ],
                "publication_ref": [
                    "b28",
                    "b11",
                    "b4",
                    "b31"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Attributed Question Answering",
                "text": [
                    "The need for attribution is particularly vivid for information-seeking use cases. To address this need, Bohnet et al. (2022) defined the Attributed Question Answering (AQA) task. Given a query q and a large corpus of text C (e.g. Wikipedia), AQA consists of predicting an answer a and a passage p \u2208 C to attribute the predicted answer.",
                    "(AQA) (q, C) \u2212 \u2192 (a, p) (1) Bohnet et al. (2022) experimented with the AQA task where the questions, answers, and passages were in English. Our work is the first to study this task in a cross-lingual framework.",
                    "We build upon previous work that showed that for many languages (e.g., Japanese), crosslingual QA systems outperform monolingual systems (Asai et al., 2021b;Muller et al., 2022). In this setting, given a query in a language L, the goal is to generate an answer a using evidence passages from a multilingual corpus C."
                ],
                "publication_ref": [
                    "b5",
                    "b5",
                    "b3",
                    "b23"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "2.3",
                "text": [
                    "Modeling Attributed Cross-Lingual QA Asai et al. (2022) showed that the best systemsaccording to the Exact-Match metric-for question answering in languages other than English are based on a cross-lingual open-retrieval (XORQA) pipeline. We thus model attributed cross-lingual QA with CORA (Asai et al., 2021b), a state-of-theart XORQA model. Figure 1 (left-panel) illustrates a typical XORQA pipeline.",
                    "CORA consists of two components: a multilingual dense retriever (MDPR) which is based on mBERT (Devlin et al., 2019) fine-tuned for dense passage retrieval (Karpukhin et al., 2020), and a multilingual generator (MGEN) based on mT5-Base (Xue et al., 2021) fine-tuned for question answering. Given a query, MDPR ranks all the passages from Wikipedia regardless of their language. In practice, most of the top-ranked passages are either in the same language as the query or in English (we report the language distribution in Table 8 in the Appendix). Then, the top passages are fed to MGEN, which generates the answer. Depending on the languages (and their associated subword tokenization), the average number of passages varies between 5 (for Bengali) and 10 (for Japanese).",
                    "CORA is designed to generate a short answer using multiple passages. To use CORA for AQA, we must select a single passage supporting the answer. In this work, we consider the passages that have been ranked highest by MDPR and fed to the generator as our pool of potential attribution passages. We measure and report the attribution level of answers and passages (a, p) by taking the TOP-1-retrieved passage by MDPR as well as ALL the passages retrieved and fed to the generator. Finally, we report in Section 5.3 the attribution level of answers and passages (a, p) after reranking the top passages with our NLI-based attribution detection model.",
                    "Recall that the selected passage can be in any language but is typically in English or in the query language (cf. Table 8). This leads us to define two attribution evaluation scenarios."
                ],
                "publication_ref": [
                    "b2",
                    "b3",
                    "b13",
                    "b19"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Cross-Lingual QA Attribution Evaluation",
                "text": [
                    "We introduce two attribution evaluation scenarios illustrated in Figure 1.",
                    "(S1) In-Language Attribution Evaluation In this scenario, attribution is assessed in the language of the query, while the query, answer, and passage (q, a, p) are in the same language. From an application perspective, this scenario evaluates directly what a potential user of an attributed QA system would experience by receiving the answer to their question and the attributed source document in their language. As illustrated in Figure 1, this scenario involves automatically translating the portion of the passages retrieved in languages different from the query into the query language.",
                    "(S2) In-English Attribution Evaluation In this scenario, the query, answer, and passage (q, a, p) are all in English during human annotation; we automatically translate the query and answer into English along with the passages retrieved in languages other than English (cf. Figure 1). We implement this scenario as it favors scalability, since collecting data in English is usually easier than in other languages due to the availability of raters. Moreover, a significant portion of the passages retrieved by cross-lingual QA systems are in English, so assessing attribution directly in English is most straightforward for these passages. For polyglot users, this scenario is also appealing as they may understand English and be interested in accessing the attributed document in English along with the answer in their language. 3  For both scenarios, translation is performed automatically using the Google Translate API. 4   Evaluation Metric For both scenarios, we collect evaluation data to assess if a predicted answer can be attributed to a retrieved passage. Following Bohnet et al. (2022), we measure the accuracy of a system by counting the proportion of answers with an attributed passage. We refer to this score as AIS.",
                    "We note that this evaluation method fundamentally differs from traditional QA system metrics, which are usually based on string-matching methods, e.g., Exact-Match (EM; Rajpurkar et al., 2016;Petroni et al., 2021). Indeed, given a query, answer  1: Each example (q, a, p) is annotated by 3 independent raters. We report the agreement with consensus which measures the proportion of examples that agrees with the majority vote. We report statistics on the in-language attribution scenario (S1) and in the in-English attribution scenario (S2). We also report in the ratings collected in (S1) and (S2) ((S1)\u0338 =(S2)) and the disagreement on the portion of examples that have been translated from English ((S1)\u0338 =(S2) TR.).",
                    "and passage triplet (q, a, p), attribution evaluation measures the portion of answers a attributed to p.",
                    "In contrast, Exact-Match requires a gold answer \u00e3 to compare to the predicted answer a.",
                    "In Section 4.2, we show how Exact-Match differs from attribution. We show that some correct answers according to exact-match are not attributed to any retrieved passage, while some non-exactlymatching answers are legitimate answers attributed to reference passages."
                ],
                "publication_ref": [
                    "b5",
                    "b30",
                    "b25"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "The XOR-AttriQA Dataset",
                "text": [
                    "To the best of our knowledge, our work is the first to study the problem of attribution in the crosslingual setting. To make this study feasible, we collect the first multilingual attribution dataset. We use the attribution evaluation framework defined by Rashkin et al. (2021). We hire Bengali, Finnish, Japanese, Russian, and Telugu-speaking raters for the in-language scenario (S1) and English-speaking raters for the in-English scenario (S2). Our analysis is based on the XOR-TyDiQA dataset (Asai et al., 2021a) in Bengali, Finnish, Japanese, Russian and Telugu. To limit cost, we randomly sample about 50% of the validation set except for Bengali and Telugu (S1) annotations for which we take the entire set. We retrieve the passages and predict the answers using the CORA system. We only evaluate the passages that are fed to the generator. For each (query, answer, passage) triplet, we ask three raters to answer \"Is the answer attributed to the passage?\". 5 To ensure the quality of the data collected we report in Table 1 the inter-annotator agreement (IAA). The agreement is above 90% for both the in-language scenario and the In-English scenario for all languages except Japanese. Appendix B provides more detail on the annotation process as well as the agreement with expert annotations on a small sample of the data (cf. Table 9). For each example, we assign the attribution label based on the majority vote of the three raters.",
                    "In-English vs. In-Language Attribution As reported in Table 1, the inter-annotator agreement observed is similar whether we collect the data in the in-English scenario (S1) compared to the in-language scenario (S2). The only large differences are observed for Telugu, for which the IAA is 8 points above when we collect the data in Telugu.",
                    "In consequence, we will use the annotation from the in-language scenario (S1) as the gold labels to evaluate all our models (cf. 4 and 5). Indeed, (S1) evaluates what a potential user may experience. So given the fact that (S1) is as good (or better) as (S2) concerning data quality, we decide to select the data from (S1).",
                    "Impact of Translation on Attribution Assessment Both scenarios require translating a portion of the data automatically (cf. Fig. 1). We hypothesize that translating passages from English to the user language may lead, in some cases, to losing attribution. Indeed, assuming that a passage in English supports the answer, we can easily imagine cases in which translation errors could cause the translated passage not to carry the information that supports the answer. However, the disagreement between the annotation in (S1) and (S2) is not higher when we look at passages that have been translated compared to passages that have not for 4/5 languages (cf. comparison between row (S1)\u0338 =(S2) and row (S1)\u0338 =(S2) TR.) as reported in Table 1). In addition, after manually reviewing the data, we do not find any cases where translation errors cause disagreement.",
                    "2021) for an exhaustive definition of interpretability."
                ],
                "publication_ref": [
                    "b31",
                    "b1"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Raters' Demographic and Cultural Background",
                "text": [
                    "Even though translating passages does not lead to higher disagreement compared to the original passages, we do observe disagreement between (S1) and (S2) (between 4.1% and and 10.5% as reported in Table 1). We partially explain the disagreement by the demographic and cultural context of the raters. For instance, English speakers rated the example <Query: How many countries are there in the United States of America? Answer: 50> as attributed to the passage \"The United States of America (USA), commonly known as the United States (U.S. or US) or America, is a country composed of 50 states, a federal district, five major self-governing territories, and various possessions.\" while Telugu speakers did not do the same for the example translated into Telugu. We hypothesize that a familiarity with the USA and the concept of states made the raters understand the question more loosely and accept the \"50 states\" mention as supportive of the answer. We leave for future work the careful quantification of this phenomenon."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Attribution Evaluation of CORA",
                "text": [
                    "Based on our newly collected XOR-AttriQA dataset, we now evaluate the attribution level of CORA."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Lack of Attribution of XORQA Predictions",
                "text": [
                    "We start by focusing on the subset of answers that match the gold reference based on Exact Match (EM). We hypothesize that these answers are attributable in most cases and that non-attributable answers should be the exception, not the rule. Indeed, by design, CORA uses retrieved passages to generate answers. Intuitively, it is hard to conceive how the model could generate a correct answer without supporting passages. However, it is known that language models \"memorize\" knowledge in their parameters (Petroni et al., 2019;Roberts et al., 2020), which could enable this ability. We report in Table 2 the proportion of answers that match the gold reference and that are attributable to a retrieved passage. To our surprise, we find a very large number of non-attributable answers. For Japanese, only 53.1% of the answers are attributed to at least one passage.",
                    "We provide examples of non-attributed exactlymatching answers in Figure 2. We find that these non-attributed answers exactly-matching the refer- Burmese Gold Answer: Burmese Passage:",
                    "The Burmese language or the language of Myanmar is a language of the Lolo-Burmese sub-branch of the Tibeto-Burmese branch of the Sino-Tibetan language family. Exactly when the Burmese people came to Myanmar cannot be said. However, the oldest religious texts written in Burmese date back to the 10th century AD. Standard Burmese is thought to have originated from a dialect of the lower valleys of central Myanmar. Most people in present-day Myanmar speak some regional dialect of this Burmese language. Burmese was influenced first by Pali and then by Mon (12th-13th centuries). Then, from the 16th to the 19th century, the language came into contact with various European languages, such as Portuguese, Dutch, English and French. this ence are of various types. Some of these answers seem to be random guesses from the generator that happen to be matching the gold reference regardless of the quality of the retrieved passages. This is usually the case for Yes/No answers. Some answers are correct and seem to be using the information in the passage provided to the generator. However, in most cases, the information provided in the passage is incomplete to support the answer. This is the case for the second example in Figure 2: \"What is the name of the mother tongue of the Marma people?\" was answered with \"Burmese\". While the passage contains relevant information about the Burmese language, it does not draw a connection with the \"Marma people\" mentioned in the question.",
                    "These results show-without ambiguity-that ORQA systems, even when they generate correct answers, do not always provide a relevant source passage to support the generated answer. In other words, this means that for a significant portion of answers, ORQA systems are right but without any evidence-they are right for the wrong reasons."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_1",
                    "fig_1"
                ],
                "table_ref": [
                    "tab_1"
                ]
            },
            {
                "heading": "Analysis of CORA's Attribution Level",
                "text": [
                    "We now analyze the attribution level of all answers predicted by CORA, not only the correct ones. We report in Table 3 the attribution level of CORA. Depending on the language, between 11.8% (for JA) and 38.7% (for FI) of answers are attributed to the TOP-1 passage retrieved by MDPR. In addition, for all languages, we find that between 31.7-50.9% of answers are attributed to at least one passage in the ones provided to the generator (ALL).",
                    "Impact of Cross-Language Attribution One of the key ingredients of the performance of CORA is its ability to use passages cross-lingually (mainly in English) (Asai et al., 2021b). We now look at how often the generated answers are attributable to these cross-lingually retrieved passages. We find that between 0.3% and 4.0% of answers in Telugu and Finnish respectively can be attributed to an English passage (while not being attributed to any passage in the same language as the query; cf. EN row in Table 3).",
                    "Attribution vs. Exact-Match In Section 4.1, we found that a large portion of answers exactly matching the gold reference are not attributable. We now look at the answers that are not exactly matching the reference (cf. column non-EM in Table 3). We hypothesize that attribution can potentially complement string-matching metrics and find answers that otherwise would be considered incorrect. In Telugu, we find that 13.2% of such answers are attributed to the TOP-1 passage. We provide such examples in the Appendix in Figure 3. Some answers are semantically equivalent to the gold reference but are spelled differently or employ different measuring units (e.g., \"crore\" used in Telugu vs. \"ten million\"). Some answers are semantically different for the gold reference but are attributable to a passage (e.g., the liver as the largest organ)."
                ],
                "publication_ref": [
                    "b3"
                ],
                "figure_ref": [],
                "table_ref": [
                    "tab_2",
                    "tab_2",
                    "tab_2"
                ]
            },
            {
                "heading": "Attribution Detection for XORQA",
                "text": [
                    "So far, we found that state-of-the-art cross-lingual question answering systems lack attribution. We showed that a large portion of answers are not attributed to any passages, by collecting a large collection of attribution data in five languages.",
                    "However, collecting attribution data is costly and time consuming. In a deployment setting, it would simply be infeasible to annotate every (query, answer, passage) triplet. In order to address this issue, we explore automatic attribution detection techniques. We build upon previous work on grounding and factual consistency in English (Honovich et al., 2022). We also experiment with PaLM 2 (Anil et al., 2023) a new state-of-the-art multilingual large language model (LLM) in few-shot and scarce data (250 examples) settings."
                ],
                "publication_ref": [
                    "b16"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Attribution Detection Models",
                "text": [
                    "Given a query q, a short answer a and a passage candidate p, we frame attribution detection as a binary classification task:",
                    "(q, a, p) \u2212 \u2192 ais(2)",
                    "with ais \u2208 {0, 1}. 1 corresponds to the attributed class (i.e., the answer is attributed to the passage) and 0 corresponds to the non-attributed class. We note that query and answers are always in the same language (in Bengali, Finnish, Japanese, Russian or Telugu), while the passage may be in a different language (mainly English). Following Honovich et al. (2022), we model this task by prompting the models as follows: premise: \"$p\" hypothesis: the answer to the question \"$q\" is \"$a\" where p, q, and a are inserted appropriately.",
                    "MT5-QA We use the training splits of the TyDi QA dataset (Clark et al., 2020) to train the attribution detection model. We employ the query, passage, answer triplets from TyDi QA as our attributed examples (our positive class). For nonattributed examples, we mine negative passages as follows: given a query, we start with the entire Wikipedia document from TyDi QA that answers the query. We sample from this document 10 passages that are different from the positive passage (i.e. the passage that answers the query). This technique provides strong negative passages by providing passages that are topically closely related to the positive passage but that do not answer the question. It was used successfully by Garg et al. (2020). We fine-tune mT5-XXL (Xue et al., 2021) on the concatenation of the training data in English, Bengali, Finnish, Japanese, Russian and Telugu.",
                    "(M)T5-NLI Following Honovich et al. (2022) who found that NLI-fine-tuned T5 is accurate for factual consistency detection, we experiment with several English and multilingual NLI models. Similar to Bohnet et al. (2022), we make use of the best English NLI model from Honovich et al. (2022), a T5-11B model fine-tuned on a mixture of natural language inference datasets, fact verification, and paraphrase detection datasets. 6 We experiment with it in the translate-test setting (noted T5-NLI TRANSLATE-TEST) for which we translate the queries, passages, and answers to English. 7 To model attribution detection in multiple languages, we fine-tuned the mT5-XXL model (Xue et al., 2021) on translations of the mixture of the NLI datasets to the non-English languages (noted MT5-NLI TRANSLATE-TRAIN). To better model the portion of passages in a language different from the query, we also fine-tune the model by adding examples for which only the hypothesis has been translated while the premise is kept in English (noted MT5-NLI X-TRANSLATE-TRAIN).",
                    "PALM 2 FEW SHOT To avoid costly fine-tuning, we experiment with in-context learning using the  83.7 / 86.8 78.8 / 85.3 71.7 / 80.4 81.9 / 88.0 84.7 / 88.6 Table 4: Performance of Attribution detection models. We report the Accuracy / ROC AUC scores on the XOR-AttriQA dataset. The Accuracy is computed with the probability threshold that maximizes it on an independent set. For each language, the best Accuracy / ROC AUC scores are bolded and the second best scores are underlined.",
                    "PaLM 2 large language model (Anil et al., 2023). We use the Small version and evaluate the model after prompting the model with 4-shots with and without chain-of-thought prompting (Wei et al., 2022). Each language is evaluated with its own prompts, and two negative examples and two positive examples are sampled for each language. For each pair, one passage is chosen to be in-language while the other is chosen to be in-English. Chain-of-thought is done by manually writing a rationale that explains the attribution (or lack of attribution) of a given answer in English.",
                    "MT5 / PALM 2 -ATTRIBUTION Finally, we experiment with fine-tuning directly on a small sample of the attribution data we collected. We sample 250 examples in the 5 languages and finetune mT5-XXL (Xue et al., 2021) and PaLM 2 Small (Anil et al., 2023). For mT5 we fine-tune the entire model, while for PaLM 2, we both fine-tune on the whole dataset and also fine-tune with Low-Rank Adaptation (LoRA) (Hu et al., 2021) to avoid overfitting and reduce fine-tuning cost. For these experiments, we use the same constant learning rate of 0.0001, dropout rate (Srivastava et al., 2014) of 0.1, and batch size of 128 for tuning both mT5 and PaLM 2. For fine-tuning with LoRA, we used a learning rate of 0.00005 and tuned the model over ranks in {4, 16, 64, 256}. For all models, we used the validation set for checkpoint selection."
                ],
                "publication_ref": [
                    "b16",
                    "b12",
                    "b15",
                    "b16",
                    "b5",
                    "b16",
                    "b37",
                    "b17",
                    "b34"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "STRING-MATCH",
                "text": [
                    "We define a simple baseline. For answers that are not \"Yes\"/\"No\", if the string a is included in the passage p, we predict 1, otherwise 0. This means that we consider the answer to be attributed to the passage if it is included in it. For Yes/No answers, we predict 0 (the majority class). We also use it after translating the query, answer and passage to English. 8"
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Results",
                "text": [
                    "We report the accuracy and ROC-AUC (Flach et al., 2011) scores in Table 4. We compute the prediction with a decision threshold tuned on an independent validation dataset on which we measure the accuracy of the model. PaLM 2 outperforms all the other models despite being fine-tuned on a very small sample of data, which is encouraging as it shows we can leverage LLMs for crosslingual attribution with very little annotated data that is expensive to produce. We also found fewshot performance to also have strong results, that could probably be improved with more shots and leveraging larger LLMs. NLI fine-tuned models outperform MT5-QA and STRING-MATCH for all the languages in the translate-test setting. Finally, we report in Table 5 the portion of attributed answers not matching the gold references that the best AIS detection model accurately predicts. We find that PaLM 2 accurately predicts more than 86% of these answers (between 86.3 and 96.4% depending on the language). This shows the potential of using attribution detection to expand the space of legitimate answers beyond relying only on string-matching metrics.  "
                ],
                "publication_ref": [
                    "b14"
                ],
                "figure_ref": [],
                "table_ref": [
                    "tab_4"
                ]
            },
            {
                "heading": "NLI Model for Reranking",
                "text": [
                    "Using our best T5-based attribution detection model (T5-NLI TRANSLATE-TEST), we now come back to our original goal of improving the attribution level of our cross-lingual question answering system. We leave for future work the use of PaLM 2 for reranking. Given our pool of candidate passages, we use our attribution detection model as a reranker and select the passage which is the most likely to attribute the answer according to the model. We report the reranking attribution score in Table 6. We find that our NLI model can accurately rerank the passages. For instance for Telugu, we are able to increase the top-1 performance from 23.3 to 31.7, an improvement of +30.0%. Across all the languages, reranking with our NLI model leads to am average relative increase of 55.9% across the 5 languages."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_5"
                ]
            },
            {
                "heading": "Discussion and Future Directions",
                "text": [
                    "Language model-based NLP systems are making fast and continuous progress in generating fluent and helpful text. Despite this progress, these models still make a lot of factual errors, specifically in languages different from English. Attribution is the most promising approach in addressing this issue (Rashkin et al., 2021). Our work finds that even the best XORQA system predictions lack attribution. These results can be explained by the tendency of these models to memorize facts (Roberts et al., 2020) and to hallucinate answers (Ji et al., 2023), which are in some cases correct. This shows that we need to make progress in detecting and selecting attributed sources that support the generated answer of cross-lingual QA systems. In this work, we proposed to use a large language model (PaLM 2) and natural language inference models to detect and 8 Using translation ensures that everything is in the same language potentially improving the string-matching accuracy. rerank passages to improve the attribution-level of a state-of-the-art XORQA system.",
                    "Our result points to two critical research directions to further make progress in informationseeking QA. First, we observed that in some languages (e.g., Telugu), cross-lingual passages contribute very moderately to the attribution level. This shows that more progress is needed in cross-lingual retriever systems. Second, we showed that stringmatching metrics based on gold references are inherently imperfect evaluation methods for QA and showed that PaLM 2 can be used to detect relevant attributed passages accurately with only small amounts of training data. This means that large language models-based attribution detection can potentially be used as evaluation metrics for QA in multiple languages. Further work is needed to design robust LLM-based metrics for cross-lingual information-seeking QA."
                ],
                "publication_ref": [
                    "b31",
                    "b18"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Conclusion",
                "text": [
                    "By ensuring that the model predictions are supported by human-written text, attribution is one of the most promising ways to deploy NLP systems safely. In this work, we introduced and released the XOR-AttriQA dataset that includes approximately 10,000 examples in Bengali, Finnish, Japanese, Russian and Telugu. Thanks to XOR-AttriQA , we observe that state-of-the-art QA systems lack attribution in the cross-lingual setting. We showed that PaLM 2 and NLI models are promising methods to detect attributed passages in 5 typologically diverse languages for information-seeking QA. Having provided evidence for the lack of attribution in academic generative QA system, built tooling to detect and mitigate these issues, and releasing our collected attribution data in 5 languages, we hope to enable trustworthy cross-lingual QA systems to meet the information needs of people around the world."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Limitations",
                "text": [
                    "Our work focused on evaluating and improving the attribution level of a state-of-the-art XORQA pipeline. Given recent progress, LLMs are now increasingly used in a closed-book setting (Roberts et al., 2020) for question answering, i.e., without relying on any retrieved passages to answer a question. Attributing the generations of these models is therefore becoming critical. In addition to improving the attribution level of open-retrieval question answering pipeline, we hope XOR-AttriQA and the attribution detection experiments we presented will also be used to design attribution detection models for closed-book QA systems."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Contributions",
                "text": [
                    "In this section, we provide more detail about the contributions of each author. "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "General",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Acknowledgements",
                "text": [
                    "We thank the raters involved in the data collection process for their work. In addition, we want to thank Michael Collins, Dipanjan Das, Vitaly Nikolaev, Jason Riesa, and Pat Verga for the valuable discussion and feedback they provided on this project."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "",
                "text": "Appendices accompanying \"Evaluating and Modeling Attribution for Cross-Lingual Question Answering\" A System and Data",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.1 Codebase",
                "text": [
                    "To run inference with CORA (Asai et al., 2021b), we used the original codebase released by the authors available at https://github.com/ AkariAsai/CORA. To build attribution detection models with T5, we used the original checkpoints from (Xue et al., 2021) fine-tuned using the t5x library available at https://github.com/ google-research/t5x.  All our experiments are based on the XOR-TyDiQA dataset (Asai et al., 2021a) available at https://nlp.cs.washington.edu/xorqa/. We focused on Bengali, Finnish, Japanese, Russian and Telugu data. We only used the query and gold answers from XOR-TyDiQA (and ignored the gold passages for which we use a retriever). XOR-TyDiQA answers are of two types: Yes/No answers or short spans extracted from a Wikipedia passages (Clark et al., 2020). We report in Table 7 the difference in attribution between Yes/No and short span answers. We find that for most languages, Yes/No answers are less attributable compared to short answer spans. 5.9 7.9 1.5 2.1 4.2"
                ],
                "publication_ref": [
                    "b3",
                    "b1",
                    "b12"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.2 XOR-TyDiQA",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.3 Languages Distribution of MDPR",
                "text": [
                    "Table 8: Language distribution of passages retrieved by a multilingual dense retriever (MDPR from (Asai et al., 2021b)). IN-LANG means the passage is in the same language as the query.",
                    "Table 8 shows the language distribution of passages retrieved by MDPR. Most passages are either in the same language as the query or in English. We report in Table 9 the agreement between expert raters and hired raters on a small number of examples. We find that this agreement is above 90% for all languages in the in-language scenario (S1)."
                ],
                "publication_ref": [
                    "b3"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "B Data Collection",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "B.2 AIS Score",
                "text": [
                    "The AIS data collection framework (Rashkin et al., 2021) consists of two annotation steps. First, the raters are shown a question and answer and asked \"Is the answer interpretable to you\". If the response is positive, the rater is shown the source passage and asked \"Is the answer attributed to the passage\". At each step, the rater is asked to answer Yes, or No or to flag the example if it is corrupted. For each question, answer, and passage triplet (q, a, p), we collect the rating of three raters (for each annotation scenarios). These three ratings are aggregated to get a single label 0 or 1 for each (q, a, p) triplet with the following criterion:",
                    "\u2022 We only keep the examples that received at least two ratings. This means that we exclude examples flagged by two raters or more.",
                    "\u2022 We assign the label \"attributable\" (1) to the triplet if the example received at least two votes to the question \"Is the answer attributed to the passage\"; otherwise, we set the label to non-attributable (0).",
                    "The number of examples collected is available in Table 1."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "C Examples of Attribution without Exact-Match",
                "text": [
                    "Query:",
                    "What is the capital of Kenya? Answer Nairobi Gold answer: Nairobi Passage:",
                    "Kenya (English Republic of Kenya) The Republic of Kenya is a country in East Africa. It is bordered by Ethiopia to the north, Somalia to the northeast and Tanzania to the south. Its capital is Nairobi. Query: How many people died on average in World War II? Answer:",
                    "Six crores",
                    "Gold answer: 70-85 millions Passage:",
                    "crores. The countries involved faced a kind of perfect war situation (ie, all available, regardless of military-civilian distinctions, were involved in the war in some way). As a result, all the economic, industrial and technological resources of the respective countries had to be used for war purposes. This war is known as the bloodiest in the history of the world, which caused the death of about six crore people."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Query:",
                "text": [
                    "Which is the largest organ in the human body? Answer:",
                    "the skin Gold answer: the liver Passage:",
                    "Skin is the largest organ in our body. It has three important layers. The skin covers the entire body and protects the internal parts. Skin is lacking at the pores. It comes in different colors. The science of skin is called 'Dermatology'. The skin mainly has two layers namely epidermis and dermis. The epidermis is formed from the epidermis. Hairs and sweat glands belong to the epidermis. Nails are also formed from it. Africans are black. Northern Europeans are white. The people of some other parts of Asia are in between the two. The cause of these color differences is the pigment called 'melanin' in the skin. low melanin is called  3). We display a single passage fed to the generator, to which the answer is attributed."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            }
        ],
        "references": [
            {
                "ref_id": "b0",
                "title": "",
                "journal": "",
                "year": "",
                "authors": "Rohan Anil; M Andrew; Orhan Dai; Melvin Firat; Dmitry Johnson; Alexandre Lepikhin; Siamak Passos; Emanuel Shakeri; Paige Taropa; Zhifeng Bailey;  Chen"
            },
            {
                "ref_id": "b1",
                "title": "XOR QA: Cross-lingual open-retrieval question answering",
                "journal": "",
                "year": "2021",
                "authors": "Akari Asai; Jungo Kasai; Jonathan Clark; Kenton Lee; Eunsol Choi; Hannaneh Hajishirzi"
            },
            {
                "ref_id": "b2",
                "title": "MIA 2022 shared task: Evaluating cross-lingual openretrieval question answering for 16 diverse languages",
                "journal": "Association for Computational Linguistics",
                "year": "2022",
                "authors": "Akari Asai; Shayne Longpre; Jungo Kasai; Chia-Hsuan Lee; Rui Zhang; Junjie Hu; Ikuya Yamada; Jonathan H Clark; Eunsol Choi"
            },
            {
                "ref_id": "b3",
                "title": "One question answering model for many languages with cross-lingual dense passage retrieval",
                "journal": "Curran Associates, Inc",
                "year": "2021",
                "authors": "Akari Asai; Xinyan Yu; Jungo Kasai; Hanna Hajishirzi"
            },
            {
                "ref_id": "b4",
                "title": "On the dangers of stochastic parrots: Can language models be too big?",
                "journal": "Association for Computing Machinery",
                "year": "2021",
                "authors": "Emily M Bender; Timnit Gebru; Angelina Mcmillan-Major; Shmargaret Shmitchell"
            },
            {
                "ref_id": "b5",
                "title": "Attributed question answering: Evaluation and modeling for attributed large language models",
                "journal": "",
                "year": "2022",
                "authors": "Bernd Bohnet; Q Vinh; Pat Tran; Roee Verga; Daniel Aharoni; Livio Baldini Andor; Jacob Soares; Kuzman Eisenstein; Jonathan Ganchev; Kai Herzig;  Hui"
            },
            {
                "ref_id": "b6",
                "title": "On the opportunities and risks of foundation models",
                "journal": "",
                "year": "",
                "authors": "Rishi Bommasani; A Drew; Ehsan Hudson; Russ Adeli; Simran Altman;  Arora;  Sydney Von Arx; S Michael; Jeannette Bernstein;  Bohg"
            },
            {
                "ref_id": "b7",
                "title": "A large annotated corpus for learning natural language inference",
                "journal": "",
                "year": "2015",
                "authors": "R Samuel; Gabor Bowman; Christopher Angeli; Christopher D Potts;  Manning"
            },
            {
                "ref_id": "b8",
                "title": "",
                "journal": "",
                "year": "",
                "authors": "Tom Brown; Benjamin Mann; Nick Ryder; Melanie Subbiah; Jared D Kaplan; Prafulla Dhariwal; Arvind Neelakantan; Pranav Shyam; Girish Sastry"
            },
            {
                "ref_id": "b9",
                "title": "Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners",
                "journal": "Curran Associates, Inc",
                "year": "",
                "authors": "Sandhini Askell; Ariel Agarwal; Gretchen Herbert-Voss; Tom Krueger; Rewon Henighan; Aditya Child; Daniel Ramesh; Jeffrey Ziegler; Clemens Wu; Chris Winter; Mark Hesse; Eric Chen; Mateusz Sigler;  Litwin"
            },
            {
                "ref_id": "b10",
                "title": "2022. Tomayto, tomahto. beyond token-level answer equivalence for question answering evaluation",
                "journal": "",
                "year": "",
                "authors": "Jannis Bulian; Christian Buck; Wojciech Gajewski; Benjamin B\u00f6rschinger; Tal Schuster"
            },
            {
                "ref_id": "b11",
                "title": "Palm: Scaling language modeling with pathways",
                "journal": "",
                "year": "2022",
                "authors": "Aakanksha Chowdhery; Sharan Narang; Jacob Devlin; Maarten Bosma; Gaurav Mishra; Adam Roberts; Paul Barham;  Hyung Won; Charles Chung; Sebastian Sutton;  Gehrmann"
            },
            {
                "ref_id": "b12",
                "title": "TyDi QA: A benchmark for information-seeking question answering in typologically diverse languages",
                "journal": "Transactions of the Association for Computational Linguistics",
                "year": "2020",
                "authors": "Jonathan H Clark; Eunsol Choi; Michael Collins; Dan Garrette; Tom Kwiatkowski; Vitaly Nikolaev; Jennimaria Palomaki"
            },
            {
                "ref_id": "b13",
                "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
                "journal": "Association for Computational Linguistics",
                "year": "2019",
                "authors": "Jacob Devlin; Ming-Wei Chang; Kenton Lee; Kristina Toutanova"
            },
            {
                "ref_id": "b14",
                "title": "A coherent interpretation of auc as a measure of aggregated classification performance",
                "journal": "",
                "year": "2011",
                "authors": "A Peter; Jos\u00e9 Flach; C Hern\u00e1ndez-Orallo;  Ferri"
            },
            {
                "ref_id": "b15",
                "title": "Tanda: Transfer and adapt pre-trained transformer models for answer sentence selection",
                "journal": "",
                "year": "2020",
                "authors": "Siddhant Garg; Thuy Vu; Alessandro Moschitti"
            },
            {
                "ref_id": "b16",
                "title": "TRUE: Re-evaluating factual consistency evaluation",
                "journal": "Association for Computational Linguistics",
                "year": "2022",
                "authors": "Or Honovich; Roee Aharoni; Jonathan Herzig; Hagai Taitelbaum; Doron Kukliansy; Vered Cohen; Thomas Scialom; Idan Szpektor; Avinatan Hassidim; Yossi Matias"
            },
            {
                "ref_id": "b17",
                "title": "Lora: Low-rank adaptation of large language models",
                "journal": "",
                "year": "2021",
                "authors": "Edward Hu; Yelong Shen; Phil Wallis; Zeyuan Allen-Zhu; Yuanzhi Li; Lu Wang; Weizhu Chen"
            },
            {
                "ref_id": "b18",
                "title": "Survey of hallucination in natural language generation",
                "journal": "ACM Comput. Surv",
                "year": "2023",
                "authors": "Ziwei Ji; Nayeon Lee; Rita Frieske; Tiezheng Yu; Dan Su; Yan Xu; Etsuko Ishii; Ye Jin Bang; Andrea Madotto; Pascale Fung"
            },
            {
                "ref_id": "b19",
                "title": "Dense passage retrieval for opendomain question answering",
                "journal": "Online. Association for Computational Linguistics",
                "year": "2020",
                "authors": "Vladimir Karpukhin; Barlas Oguz; Sewon Min; Patrick Lewis; Ledell Wu; Sergey Edunov; Danqi Chen; Wen-Tau Yih"
            },
            {
                "ref_id": "b20",
                "title": "Scitail: A textual entailment dataset from science question answering",
                "journal": "",
                "year": "2018",
                "authors": "Tushar Khot; Ashish Sabharwal; Peter Clark"
            },
            {
                "ref_id": "b21",
                "title": "Digital language death",
                "journal": "PLOS ONE",
                "year": "2013",
                "authors": "Andr\u00e1s Kornai"
            },
            {
                "ref_id": "b22",
                "title": "MKQA: A linguistically diverse benchmark for multilingual open domain question answering",
                "journal": "",
                "year": "2021",
                "authors": "Shayne Longpre; Yi Lu; Joachim Daiber"
            },
            {
                "ref_id": "b23",
                "title": "Cross-lingual open-domain question answering with answer sentence generation",
                "journal": "Long Papers",
                "year": "2022",
                "authors": "Benjamin Muller; Luca Soldaini; Rik Koncel-Kedziorski; Eric Lind; Alessandro Moschitti"
            },
            {
                "ref_id": "b24",
                "title": "The RepEval 2017 shared task: Multi-genre natural language inference with sentence representations",
                "journal": "Association for Computational Linguistics",
                "year": "2017",
                "authors": "Nikita Nangia; Adina Williams; Angeliki Lazaridou; Samuel Bowman"
            },
            {
                "ref_id": "b25",
                "title": "KILT: a benchmark for knowledge intensive language tasks",
                "journal": "",
                "year": "2021",
                "authors": "Fabio Petroni; Aleksandra Piktus; Angela Fan; Patrick Lewis; Majid Yazdani; Nicola De Cao; James Thorne; Yacine Jernite; Vladimir Karpukhin; Jean Maillard; Vassilis Plachouras; Tim Rockt\u00e4schel; Sebastian Riedel"
            },
            {
                "ref_id": "b26",
                "title": "",
                "journal": "",
                "year": "",
                "authors": "Fabio Petroni; Tim Rockt\u00e4schel; Sebastian Riedel"
            },
            {
                "ref_id": "b27",
                "title": "Language models as knowledge bases?",
                "journal": "Association for Computational Linguistics",
                "year": "2019",
                "authors": "Alexander Miller"
            },
            {
                "ref_id": "b28",
                "title": "Language models are unsupervised multitask learners",
                "journal": "OpenAI blog",
                "year": "2019",
                "authors": "Alec Radford; Jeffrey Wu; Rewon Child; David Luan; Dario Amodei; Ilya Sutskever"
            },
            {
                "ref_id": "b29",
                "title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
                "journal": "J. Mach. Learn. Res",
                "year": "2020",
                "authors": "Colin Raffel; Noam Shazeer; Adam Roberts; Katherine Lee; Sharan Narang; Michael Matena; Yanqi Zhou; Wei Li; Peter J Liu"
            },
            {
                "ref_id": "b30",
                "title": "SQuAD: 100,000+ questions for machine comprehension of text",
                "journal": "Association for Computational Linguistics",
                "year": "2016",
                "authors": "Pranav Rajpurkar; Jian Zhang; Konstantin Lopyrev; Percy Liang"
            },
            {
                "ref_id": "b31",
                "title": "Measuring attribution in natural language generation models",
                "journal": "CoRR",
                "year": "2021",
                "authors": "Vitaly Hannah Rashkin; Matthew Nikolaev; Michael Lamm; Dipanjan Collins; Slav Das; Gaurav Petrov; Iulia Singh Tomar; David Turc;  Reitter"
            },
            {
                "ref_id": "b32",
                "title": "How much knowledge can you pack into the parameters of a language model",
                "journal": "Online. Association for Computational Linguistics",
                "year": "2020",
                "authors": "Adam Roberts; Colin Raffel; Noam Shazeer"
            },
            {
                "ref_id": "b33",
                "title": "Get your vitamin C! robust fact verification with contrastive evidence",
                "journal": "",
                "year": "2021",
                "authors": "Tal Schuster; Adam Fisch; Regina Barzilay"
            },
            {
                "ref_id": "b34",
                "title": "Dropout: a simple way to prevent neural networks from overfitting. The journal of machine learning research",
                "journal": "",
                "year": "2014",
                "authors": "Nitish Srivastava; Geoffrey Hinton; Alex Krizhevsky; Ilya Sutskever; Ruslan Salakhutdinov"
            },
            {
                "ref_id": "b35",
                "title": "FEVER: a large-scale dataset for fact extraction and VERification",
                "journal": "Association for Computational Linguistics",
                "year": "2018",
                "authors": "James Thorne; Andreas Vlachos; Christos Christodoulopoulos; Arpit Mittal"
            },
            {
                "ref_id": "b36",
                "title": "Tracking knowledge propagation across wikipedia languages",
                "journal": "",
                "year": "2021",
                "authors": "Rodolfo Vieira Valentim; Giovanni Comarela; Souneil Park; Diego S\u00e1ez-Trumper"
            },
            {
                "ref_id": "b37",
                "title": "Chain of thought prompting elicits reasoning in large language models",
                "journal": "ArXiv",
                "year": "2022",
                "authors": "Jason Wei; Xuezhi Wang; Dale Schuurmans; Maarten Bosma; Ed Huai Hsin Chi; F Xia; Quoc Le; Denny Zhou"
            },
            {
                "ref_id": "b38",
                "title": "Geoffrey Irving, and Iason Gabriel. 2022. Taxonomy of risks posed by language models",
                "journal": "Association for Computing Machinery",
                "year": "",
                "authors": "Laura Weidinger; Jonathan Uesato; Maribeth Rauh; Conor Griffin; Po-Sen Huang; John Mellor; Amelia Glaese; Myra Cheng; Borja Balle; Atoosa Kasirzadeh; Courtney Biles; Sasha Brown; Zac Kenton; Will Hawkins; Tom Stepleton; Abeba Birhane; Lisa Anne Hendricks; Laura Rimell; William Isaac"
            },
            {
                "ref_id": "b39",
                "title": "Aditya Barua, and Colin Raffel. 2021. mT5: A massively multilingual pre-trained text-to-text transformer",
                "journal": "Association for Computational Linguistics",
                "year": "",
                "authors": "Linting Xue; Noah Constant; Adam Roberts; Mihir Kale; Rami Al-Rfou; Aditya Siddhant"
            },
            {
                "ref_id": "b40",
                "title": "PAWS: Paraphrase adversaries from word scrambling",
                "journal": "Long and Short Papers",
                "year": "2019",
                "authors": "Yuan Zhang; Jason Baldridge; Luheng He"
            }
        ],
        "figures": [
            {
                "figure_label": "2",
                "figure_type": "figure",
                "figure_id": "fig_1",
                "figure_caption": "Figure 2 :2Figure 2: Examples of CORA correct answers not attributed to any passage. We illustrate how the model can be guided to generate correct answers which are not fully supported by the passage.",
                "figure_data": ""
            },
            {
                "figure_label": "2",
                "figure_type": "table",
                "figure_id": "tab_1",
                "figure_caption": "% of answers exactly-matching the gold answer attributed to at least one passage fed to the MGEN.",
                "figure_data": "% Attributable predictions (AIS) of EMBNFIJARUTE67.380.453.167.593.1"
            },
            {
                "figure_label": "3",
                "figure_type": "table",
                "figure_id": "tab_2",
                "figure_caption": "% of attributed answers to the TOP-1/ALL passages fed to MGEN. We report AIS (cf. sec. 2.4) on XOR-TyDiQA validation split. of EM corresponds to the % of attributable answers among the Exact-Matched answers. non-EM corresponds to the % of attributable answers among the non-Exact-Matched answers (i.e. that differ from the gold answer). We report the attribution-level considering passages in any languages (row ANY), only the English passages as our candidates (row EN), only the in-language passages (row LANG.) as our candidates.",
                "figure_data": "BNFIJARUTEAISof EMnon-EMAISof EMnon-EMAISof EMnon-EMAISof EMnon-EMAISof EMnon-EMANY LANG 25.0/40.2 41.8/65.5 22.3/36.1 36.5/46.0 64.3/75.0 25.7/34.7 11.8/34.8 22.4/51.0 8.2/20.6 26.4/39.8 45.0/67.5 23.4/36.6 22.9/31.4 69.0/93.1 13.2/18.9 27.9/45.6 41.8/67.3 25.2/40.5 38.7/50.9 67.9/80.4 27.1/39.6 11.8/37.3 22.4/53.1 8.2/23.7 27.5/40.9 45.0/67.5 24.8/37.9 23.3/31.7 72.4/93.1 13.2/19.2 EN 2.3/3.3 0.0/0.0 2.6/3.8 1.0/4.0 3.6/5.3 0.0/3.5 0.0/2.0 0.0/0.0 0.0/3.1 1.1/1.1 0.0/0.0 1.4/1.4 0.3/0.3 1.7/0.0 0.0/0.3Passage: \u30de\u30eb\u30af\u30b9\u4e3b\u7fa9(\u30de\u30eb\u30af\u30b9\u3057\u3085\u304e\u3001)\u3068\u306f\u3001\u30ab\u30fc\u30eb\u30fb\u30de\u30eb\u30af\u30b9\u3068\u30d5\u30ea\u30fc\u30c9\u30ea\u30d2\u30fb\u30a8\u30f3\u30b2\u30eb\u30b9\u306b\u3088\u3063\u3066\u5c55\u958b\u3055\u308c\u305f\u601d\u60f3\u3092\u30d9\u30fc\u30b9\u3068\u3057\u3066\u78ba\u7acb\u3055\u308c\u305f\u793e\u4f1a\u4e3b\u7fa9\u601d\u60f3\u4f53\u7cfb\u306e\u4e00\u3064\u3067\u3042\u308b\u3002\u3057\u3070\u3057\u3070\u79d1\u5b66\u7684\u793e\u4f1a\u4e3b\u7fa9(\u304b\u304c\u304f\u3066\u304d\u3057\u3083\u304b\u3044\u3057\u3085\u304e)\u3068\u3082\u8a00\u308f\u308c\u308b\u3002\u30de\u30eb\u30af\u30b9\u4e3b\u7fa9\u306f\u3001\u8cc7"
            },
            {
                "figure_label": "5",
                "figure_type": "table",
                "figure_id": "tab_4",
                "figure_caption": "% of attributed non-EM examples that are accurately detected by PALM 2.",
                "figure_data": "BNFIJARUTEAcc. 88.2 94.5 86.3 96.4 91.6"
            },
            {
                "figure_label": "6",
                "figure_type": "table",
                "figure_id": "tab_5",
                "figure_caption": "",
                "figure_data": ": % of attributed answers based on the top-1 MDPR-retrieved passage, ALL the passages retrieved fed to the generator, and the TOP-1 reranked passage (T5-NLI reranked) with T5-NLI-TRANSLATE-TEST, our best NLI fine-tuned model."
            },
            {
                "figure_label": "",
                "figure_type": "table",
                "figure_id": "tab_6",
                "figure_caption": "Overview Primary Contributors Benjamin Muller, John Wieting Major Contributors Jonathan H. Clark, Tom Kwiatkowski, Sebastian Ruder, Livio Baldini Soares Supporting Contributors Roee Aharoni, Jonathan Herzig, Xinyi Wang By Contribution Advising John Wieting, Jonathan H. Clark, Tom Kwiatkowski, Sebastian Ruder, Livio Baldini Soares, Roee Aharoni, Jonathan Herzig Code Benjamin Muller, John Wieting, Livio Baldini Soares, Roee Aharoni, Jonathan Herzig Data Collection Benjamin Muller, John Wieting Experiments Benjamin Muller, John Wieting Modeling Benjamin Muller, John Wieting, Xinyi Wang, Roee Aharoni, Jonathan Herzig Project Design Jonathan H. Clark, John Wieting, Benjamin Muller, Tom Kwiatkowski, Sebastian Ruder Project Initiation Jonathan H. Clark, Tom Kwiatkowski",
                "figure_data": ""
            }
        ],
        "formulas": [
            {
                "formula_id": "formula_0",
                "formula_text": "(q, a, p) \u2212 \u2192 ais(2)",
                "formula_coordinates": [
                    7.0,
                    146.84,
                    641.57,
                    143.02,
                    20.55
                ]
            }
        ],
        "doi": "10.18653/v1/W17-5301"
    },
    "PHD: Pixel-Based Language Modeling of Historical Documents": {
        "authors": "Nadav Borenstein; Phillip Rust; Desmond Elliott; Isabelle Augenstein",
        "pub_date": "",
        "abstract": "The digitisation of historical documents has provided historians with unprecedented research opportunities. Yet, the conventional approach to analysing historical documents involves converting them from images to text using OCR, a process that overlooks the potential benefits of treating them as images and introduces high levels of noise. To bridge this gap, we take advantage of recent advancements in pixel-based language models trained to reconstruct masked patches of pixels instead of predicting token distributions. Due to the scarcity of real historical scans, we propose a novel method for generating synthetic scans to resemble real historical documents. We then pre-train our model, PHD, on a combination of synthetic scans and real historical newspapers from the 1700-1900 period. Through our experiments, we demonstrate that PHD exhibits high proficiency in reconstructing masked image patches and provide evidence of our model's noteworthy language understanding capabilities. Notably, we successfully apply our model to a historical QA task, highlighting its utility in this domain.",
        "sections": [
            {
                "heading": "Introduction",
                "text": [
                    "Recent years have seen a boom in efforts to digitise historical documents in numerous languages and sources (Chadwyck, 1998;Groesen, 2015;Moss, 2009), leading to a transformation in the way historians work. Researchers are now able to expedite the analysis process of vast historical corpora using NLP tools, thereby enabling them to focus on interpretation instead of the arduous task of evidence collection (Laite, 2020;Gerritsen, 2012).",
                    "The primary step in most NLP tools tailored for historical analysis involves Optical Character Recognition (OCR). However, this approach poses several challenges and drawbacks. First, OCR *This paper shows dataset samples that are racist in nature strips away any valuable contextual meaning embedded within non-textual elements, such as page layout, fonts, and figures. 1 Moreover, historical documents present numerous challenges to OCR systems. This can range from deteriorated pages, archaic fonts and language, the presence of nontextual elements, and occasional deficiencies in scan quality (e.g., blurriness), all of which contribute to the introduction of additional noise. Consequently, the extracted text is often riddled with errors at the character level (Robertson and Goldwater, 2018;Bollmann, 2019), which most large language models (LLMs) are not tuned to process. Token-based LLMs are especially sensitive to this, as the discrete structure of their input space cannot handle well the abundance of out-of-vocabulary words that characterise OCRed historical documents (Rust et al., 2023). Therefore, while LLMs have proven remarkably successful in modern domains, their performance is considerably weaker when applied to historical texts (Manjavacas and Fonteyn, 2022;Baptiste et al., 2021, inter alia). Finally, for many languages, OCR systems either do not exist or perform particularly poorly. As training new OCR models is laborious and expensive (Li et al., 2021a), the application of NLP tools to historical documents in these languages is limited.",
                    "This work addresses these limitations by taking advantage of recent advancements in pixel-based language modelling, with the goal of constructing a general-purpose, image-based and OCR-free language encoder of historical documents. Specifically, we adapt PIXEL (Rust et al., 2023), a language model that renders text as images and is trained to reconstruct masked patches instead of predicting a distribution over tokens. PIXEL's training methodology is highly suitable for the historical domain, as (unlike other pixel-based language models) it does not rely on a pretraining dataset  Given the paucity of large, high-quality datasets comprising historical scans, we pretrain our model using a combination of 1) synthetic scans designed to resemble historical documents faithfully, produced using a novel method we propose for synthetic scan generation; and 2) real historical English newspapers published in the Caribbeans in the 18th and 19th centuries. The resulting pixelbased language encoder, PHD (Pixel-based model for Historical Documents), is subsequently evaluated based on its comprehension of natural language and its effectiveness in performing Question Answering from historical documents.",
                    "We discover that PHD displays impressive reconstruction capabilities, being able to correctly predict both the form and content of masked patches of historical newspapers ( \u00a74.4). We also note the challenges concerning quantitatively evaluating these predictions. We provide evidence of our model's noteworthy language understanding capabilities while exhibiting an impressive resilience to noise. Finally, we demonstrate the usefulness of the model when applied to the historical QA task ( \u00a75.4).",
                    "To facilitate future research, we provide the dataset, models, and code at https://gith ub.com/nadavborenstein/pixel-bw."
                ],
                "publication_ref": [
                    "b6",
                    "b14",
                    "b28",
                    "b20",
                    "b13",
                    "b35",
                    "b2",
                    "b36",
                    "b27",
                    "b23",
                    "b36"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Background",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "NLP for Historical Texts",
                "text": [
                    "Considerable efforts have been invested in improving both OCR accuracy (Li et al., 2021a;Smith, 2023) and text normalisation techniques for historical documents (Drobac et al., 2017;Robertson and Goldwater, 2018;Bollmann et al., 2018;Boll-mann, 2019;Lyu et al., 2021). This has been done with the aim of aligning historical texts with their modern counterparts. However, these methods are not without flaws (Robertson and Goldwater, 2018;Bollmann, 2019), and any errors introduced during these preprocessing stages can propagate to downstream tasks (Robertson and Goldwater, 2018;Hill and Hengchen, 2019). As a result, historical texts remain a persistently challenging domain for NLP research (Lai et al., 2021;De Toni et al., 2022;Borenstein et al., 2023b). Here, we propose a novel approach to overcome the challenges associated with OCR in historical material, by employing an image-based language model capable of directly processing historical document scans and effectively bypassing the OCR stage."
                ],
                "publication_ref": [
                    "b23",
                    "b12",
                    "b35",
                    "b3",
                    "b26",
                    "b35",
                    "b2",
                    "b35",
                    "b16",
                    "b19"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Pixel-based Models for NLU",
                "text": [
                    "Extensive research has been conducted on models for processing text embedded in images. Most existing approaches incorporate OCR systems as an integral part of their inference pipeline (Appalaraju et al., 2021;Li et al., 2021b;Delteil et al., 2022). These approaches employ multimodal architectures where the input consists of both the image and the output generated by an OCR system.",
                    "Recent years have also witnessed the emergence of OCR-free approaches for pixel-based language understanding. Kim et al. (2022) introduce Donut, an image-encoder-text-decoder model for document comprehension. Donut is pretrained with the objective of extracting text from scans, a task they refer to as \"pseudo-OCR\". Subsequently, it is finetuned on various text generation tasks, reminiscent of T5 (Roberts et al., 2020). While architecturally similar to Donut, Dessurt (Davis et al., 2023) and Pix2Struct (Lee et al., 2022) were pretrained by masking image regions and predicting the text in both masked and unmasked image regions. Unlike our method, all above-mentioned models predict in the text space rather than the pixel space. This presupposes access to a pretraining dataset comprised of instances where the image and text are aligned. However, this assumption cannot hold for historical NLP since OCR-independent ground truth text for historical scans is, in many times, unprocurable and cannot be used for training purposes.",
                    "Text-free models that operate at the pixel level for language understanding are relatively uncommon. One notable exception is Li et al. (2022), which utilises Masked Image Modeling for pretraining on document patches. Nevertheless, their focus lies primarily on tasks that do not necessitate robust language understanding, such as table detection, document classification, and layout analysis. PIXEL (Rust et al., 2023), conversely, is a text-free pixel-based language model that exhibits strong language understanding capabilities, making it the ideal choice for our research. The subsequent section will delve into a more detailed discussion of PIXEL and how we adapt it to our task."
                ],
                "publication_ref": [
                    "b0",
                    "b24",
                    "b10",
                    "b17",
                    "b21",
                    "b36"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Model",
                "text": [
                    "PIXEL We base PHD on PIXEL, a pretrained pixel-based encoder of language. PIXEL has three main components: A text renderer that draws texts as images, a pixel-based encoder, and a pixel-based decoder. The training of PIXEL is analogous to BERT (Devlin et al., 2019). During pretraining, input strings are rendered as images, and the encoder and the decoder are trained jointly to reconstruct randomly masked image regions from the unmasked context. During finetuning, the decoder is replaced with a suitable classification head, and no masking is performed. The encoder and decoder are based on the ViT-MAE architecture (He et al., 2022) and work at the patch level. That is, the encoder breaks the input image into patches of 16 \u00d7 16 pixels and outputs an embedding for each patch. The decoder then decodes these patch embeddings back into pixels. Therefore, random masking is performed at the patch level as well.",
                    "PHD We follow the same approach as PIXEL's pretraining and finetuning schemes. However, PIXEL's intended use is to process texts, not natural images. That is, the expected input to PIXEL is a string, not an image file. In contrast, we aim to use the model to encode real document scans. Therefore, we make several adaptations to PIXEL's training and data processing procedures to make it compatible with our use case ( \u00a74 and \u00a75).",
                    "Most crucially, we alter the dimensions of the model's input: The text renderer of PIXEL renders strings as a long and narrow image with a resolution of 16 \u00d7 8464 pixels (corresponding to 1 \u00d7 529 patches), such that the resulting image resembles a ribbon with text. Each input character is set to be not taller than 16 pixels and occupies roughly one patch. However, real document scans cannot be represented this way, as they have a natural twodimensional structure and irregular fonts, as "
                ],
                "publication_ref": [
                    "b11",
                    "b15"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Training a Pixel-Based Historical LM",
                "text": [
                    "We design PHD to serve as a general-purpose, pixel-based language encoder of historical documents. Ideally, PHD should be pretrained on a large dataset of scanned documents from various historical periods and different locations. However, large, high-quality datasets of historical scans are not easily obtainable. Therefore, we propose a novel method for generating historical-looking artificial data from modern corpora (see subsection 4.1). We adapt our model to the historical domain by continuously pretraining it on a medium-sized corpus of real historical documents. Below, we describe the datasets and the pretraining process of the model."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Artificially Generated Pretraining Data",
                "text": [
                    "Our pretraining dataset consists of artificially generated scans of texts from the same sources that BERT used, namely the BookCorpus (Zhu et al., 2015) and the English Wikipedia. 2 We generate the scans as follows.",
                    "We generate dataset samples on-the-fly, adopting a similar approach as Davis et al. (2023). First,  we split the text corpora into paragraphs, using the new-line character as a delimiter. From a paragraph chosen at random, we pick a random spot and keep the text spanning from that spot to the paragraph's end. We also sample a random font and font size from a pre-defined list of fonts (from Davis et al. ( 2023)). The text span and the font are then embedded within an HTML template using the Python package Jinja, 3 set to generate a Web page with dimensions that match the input dimension of the model. "
                ],
                "publication_ref": [
                    "b41"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Real Historical Scans",
                "text": [
                    "We adapt PHD to the historical domain by continuously pretraining it on a medium-sized corpus of scans of real historical newspapers. Specifically, we collect newspapers written in English from the \"Caribbean Newspapers, 1718-1876\" database, 5 the largest collection of Caribbean newspapers from the 18th-19th century available online. We extend this dataset with English-Danish newspapers published between 1770-1850 in the Danish Caribbean colony of Santa Cruz (now Saint Croix) downloaded from the Danish Royal Library's website. 6 See Tab 1 for details of dataset sizes. While confined in its geographical and temporal context, this dataset offers a rich diversity in terms of content and format, rendering it an effective test bed for evaluating PHD.",
                    "Newspaper pages are converted into a 368 \u00d7 368 pixels crops using a sliding window approach over the page's columns. This process is described in more detail in App A.2. We reserve 5% of newspaper issues for validation, using the rest for training. See "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Pretraining Procedure",
                "text": [
                    "Like PIXEL, the pretraining objective of PHD is to reconstruct the pixels in masked image patches. We randomly occlude 28% of the input patches with 2D rectangular masks. We uniformly sample their width and height from "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Pretraining Results",
                "text": [
                    "Qualitative Evaluation. We begin by conducting a qualitative examination of the predictions made by our model.    2023), unsurprisingly, prediction quality is high and the results are sharp for smaller masks and when words are only partially obscured. However, as the completions become longer, the text quality deteriorates, resulting in blurry text. It is important to note that evaluating these blurry completions presents a significant challenge. Unlike token-based models, where the presence of multiple words with high, similar likelihood can easily be detected by examining the discrete distribution, this becomes impossible with pixel-based models. In pixel-based completions, high-likelihood words may overlay and produce a blurry completion. Clear completions are only observed when a single word has a significantly higher probability compared to others. This limitation is an area that we leave for future work. We now move to analyse PHD's ability to fill in single masked words. We randomly sample test scans and OCRed them using Tesseract. 7 Next, we randomly select a single word from the OCRed text and use Tesseract's word-to-image location functionality to (heuristically) mask the word from the image. Results are presented in Fig 4 . Similar to our earlier findings, the reconstruction quality of single-word completion varies. Some completions are sharp and precise, while others appear blurry. In some few cases, the model produces a sharp reconstruction of an incorrect word (Fig 4c). Unfortunately, due to the blurry nature of many of the results (regardless of their correctness), a quantitative analysis of these results (e.g., by OCRing the reconstructed patch and comparing it to the OCR output of the original patch) is unattainable.",
                    "Semantic Search. A possible useful application of PHD is semantic search. That is, searching in a corpus for historical documents that are semantically similar to a concept of interest. We now analyse PHD's ability to assign similar historical scans with similar embeddings. We start by taking a random sample of 1000 images from our test set and embed them by averaging the patch embeddings of the final layer of the model. We then reduce the dimensionality of the embeddings with     "
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_10"
                ],
                "table_ref": []
            },
            {
                "heading": "Training for Downstream NLU Tasks",
                "text": [
                    "After obtaining a pretrained pixel-based language model adapted to the historical domain ( \u00a74), we now move to evaluate its understanding of natural language and its usefulness in addressing historically-oriented NLP tasks. Below, we describe the datasets we use for this and the experimental settings. "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Language Understanding",
                "text": [
                    "We adapt the commonly used GLUE benchmark (Wang et al., 2018) to gauge our model's understanding of language. We convert GLUE instances into images similar to the process described in \u00a74.1. Given a GLUE instance with sentences s 1 , s 2 (s 2 can be empty), we embed s 1 and s 2 into an HTML template, introducing a line break between the sentences. We then render the HTML files as images.",
                    "We generate two versions of this visual GLUE dataset -clean and noisy. The former is rendered using a single pre-defined font without applying degradations or augmentations, whereas the latter is generated with random fonts and degradations. Fig 6 presents a sample of each of the two dataset versions. While the first version allows us to measure PHD's understanding of language in \"sterile\" settings, we can use the second version to estimate the robustness of the model to noise common to historical scans."
                ],
                "publication_ref": [
                    "b40"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Historical Question Answering",
                "text": [
                    "QA applied to historical datasets can be immensely valuable and useful for historians (Borenstein et al., 2023a). Therefore, we assess PHD's potential for assisting historians with this important NLP task. We finetune the model on two novel datasets. The first is an adaptation of the classical SQuAD-v2 dataset (Rajpurkar et al., 2016), while the second is a genuine historical QA dataset.",
                    "SQuAD Dataset We formulate SQuAD-v2 as a patch classification task, as illustrated in Fig 11 in App C. Given a SQuAD instance with question q, context c and answer a that is a span in c, we render c as an image, I (Fig 11a). Then, each patch of I is labelled with 1 if it contains a part of a or 0 otherwise. This generates a binary label mask M for I, which our model tries to predict (Fig 11b). If any degradations or augmentations are later applied to I, we ensure that M is affected accordingly. Finally, similarly to Lee et al. (2022), we concatenate to I a rendering of q and crop the resulting image to the appropriate input size (Fig 11c).",
                    "Generating the binary mask M is not straightforward, as we do not know where a is located inside the generated image I. For this purpose, we first use Tesseract to OCR I and generate \u0109. Next, we use fuzzy string matching to search for a within \u0109. If a match \u00e2 \u2208 \u0109 is found, we use Tesseract to find the pixel coordinates of \u00e2 within I. We then map the pixel coordinates to patch coordinates and label all the patches containing \u00e2 with 1. In about 15% of the cases, Tesseract fails to OCR I properly, and \u00e2 cannot be found in \u0109, resulting in a higher proportion of SQuAD samples without an answer compared to the text-based version.",
                    "As with GLUE, we generate two versions of visual SQuAD, which we use to evaluate PHD's performance in both sterile and historical settings.",
                    "Historical QA Dataset Finally, we finetune PHD for a real historical QA task. For this, we use the English dataset scraped from the website of the Runaways Slaves in Britain project, a searchable database of over 800 newspaper adverts printed between 1700 and 1780 placed by enslavers who wanted to capture enslaved people who had selfliberated (Newman et al., 2019). Each ad was manually transcribed and annotated with more than 50 different attributes, such as the described gender and age, what clothes the enslaved person wore, and their physical description.",
                    "Following Borenstein et al. (2023a), we convert this dataset to match the SQuAD format: given an ad and an annotated attribute, we define the transcribed ad as the context c, the attribute as the answer a, and manually compose an appropriate question q. We process the resulting dataset similarly to how SQuAD is processed, with one key difference: instead of rendering the transcribed ad c as an image, we use the original ad scan. Therefore, we also do not introduce any noise to the images. See Figure 7 for an example instance. We reserve 20% of the dataset for testing."
                ],
                "publication_ref": [
                    "b4",
                    "b32",
                    "b21",
                    "b29",
                    "b4"
                ],
                "figure_ref": [
                    "fig_1",
                    "fig_1",
                    "fig_15"
                ],
                "table_ref": []
            },
            {
                "heading": "Training Procedure",
                "text": [
                    "Similar to BERT, PHD is finetuned for downstream tasks by replacing the decoder with a suitable head. Tab 4 in App A.1 details the hyperparameters used to train PHD on the different GLUE tasks. We use the standard GLUE metrics to evaluate our model. Since GLUE is designed for models of modern English, we use this benchmark to evaluate a checkpoint of our model obtained after training on the artificial modern scans, but before training on the real historical scans. The same checkpoint is also used to evaluate PHD on SQuAD. Conversely, we use the final model checkpoint (after introducing the historical data) to finetune on the historical QA dataset: First, we train the model on the noisy SQuAD and subsequently finetune it on the Runaways dataset (see App A.1 for training details).",
                    "To evaluate our model's performance on the QA datasets, we employ various metrics. The primary metrics include binary accuracy, which indicates whether the model agrees with the ground truth regarding the presence of an answer in the context. Additionally, we utilise patch-based accuracy, which measures the ratio of overlapping answer patches between the ground truth mask M and the predicted mask M , averaged over all the dataset instances for which an answer exists. Finally, we measure the number of times a predicted answer and the ground truth overlap by at least a single patch. We balance the test sets to contain an equal number of examples with and without an answer."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Results",
                "text": [
                    "Baselines We compare PHD's performance on GLUE to a variety of strong baselines, covering both OCR-free and OCR-based methods. First, we use CLIP with a ViT-L/14 image encoder in the lin- ear probe setting, which was shown to be effective in a range of settings that require a joint understanding of image and text-including rendered SST-2 (Radford et al., 2021). While we only train a linear model on the extracted CLIP features, compared to full finetuning in PHD, CLIP is about 5\u00d7 the size with \u223c427M parameters and has been trained longer on more data. Second, we finetune Donut ( \u00a72.2), which has \u223c200M parameters and is the closest and strongest OCR-free alternative to PHD. Moreover, we finetune BERT and PIXEL on the OCR output of Tesseract. Both BERT and PIXEL are comparable in size and compute budget to PHD.",
                    "Although BERT has been shown to be overall more effective on standard GLUE than PIXEL, PIXEL is more robust to orthographic noise (Rust et al., 2023). Finally, to obtain an empirical upper limit to our model, we finetune BERT and PIXEL on a standard, not-OCRed version of GLUE. Likewise, for the QA tasks, we compare PHD to BERT trained on a non-OCRed version of the datasets (the Runaways dataset was manually transcribed). We describe all baseline setups in App B.",
                    "GLUE Tab 2 summarises the performance of PHD on GLUE. Our model demonstrates noteworthy results, achieving scores of above 80 for five out of the nine GLUE tasks. These results serve as evidence of our model's language understanding capabilities. Although our model falls short when compared to text-based BERT by 13 absolute points on average, it achieves competitive results compared to the OCR-then-finetune baselines. Moreover, PHD outperforms other pixel-based models by more than 10 absolute points on average, highlighting the efficacy of our methodology.",
                    "Question Answering According to Tab 3, our model achieves above guess-level accuracies on these highly challenging tasks, further strengthening the indications that PHD was able to obtain impressive language comprehension skills. Although the binary accuracy on SQuAD is low, hovering around 60% compared to the 72% of BERT, the relatively high \"At least one overlap\" score of above 40 indicates that PHD has gained the ability to locate the answer within the scan correctly. Furthermore, PHD displays impressive robustness to noise, with only a marginal decline in performance observed between the clean and noisy versions of the SQuAD dataset, indicating its potential in handling the highly noisy historical domain. The model's performance on the Runaways Slaves dataset is particularly noteworthy, reaching a binary accuracy score of nearly 75% compared to BERT's 78%, demonstrating the usefulness of the model in application to historically-oriented NLP tasks. We believe that the higher metrics reported for this dataset compared to the standard SQuAD might stem from the fact that Runaways Slaves in Britain contains repeated questions (with different contexts), which might render the task more trackable for our model.",
                    "Saliency Maps Our patch-based QA approach can also produce visual saliency maps, allowing for a more fine-grained interpretation of model predictions and capabilities (Das et al., 2017). "
                ],
                "publication_ref": [
                    "b30",
                    "b36",
                    "b7"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Conclusion",
                "text": [
                    "In this study, we introduce PHD, an OCR-free language encoder specifically designed for analysing historical documents at the pixel level. We present a novel pretraining method involving a combination of synthetic scans that closely resemble historical documents, as well as real historical newspapers published in the Caribbeans during the 18th and 19th centuries. Through our experiments, we observe that PHD exhibits high proficiency in reconstructing masked image patches, and provide evidence of our model's noteworthy language understanding capabilities. Notably, we successfully apply our model to a historical QA task, achieving a binary accuracy score of nearly 75%, highlighting its usefulness in this domain. Finally, we note that better evaluation methods are needed to further drive progress in this domain."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Limitations",
                "text": [
                    "We see several limitations regarding our work. First, we focus on the English language only, a high-resource language with strong OCR systems developed for it. By doing so, we neglect lowresource languages for which our model can potentially be more impactful.",
                    "On the same note, we opted to pretrain our model on a single (albeit diverse) historical corpus of newspapers, and its robustness in handling other historical sources is yet to be proven. To address this limitation, we plan to extend our historical corpora in future research endeavours. Expanding the range of the historical training data would not only alleviate this concern but also tackle another limitation; while our model was designed for historical document analysis, most of its pretraining corpora consist of modern texts due to the insufficient availability of large historical datasets.",
                    "We also see limitations in the evaluation of PHD. As mentioned in Section 4.4, it is unclear how to empirically quantify the quality of the model's reconstruction of masked image regions, thus necessitating reliance on qualitative evaluation. This qualitative approach may result in a suboptimal model for downstream tasks. Furthermore, the evaluation tasks used to assess our model's language understanding capabilities are limited in their scope. Considering our emphasis on historical language modelling, it is worth noting that the evaluation datasets predominantly cater to models trained on modern language. We rely on a single historical dataset to evaluate our model's performance.",
                    "Lastly, due to limited computational resources, we were constrained to training a relatively smallscale model for a limited amount of steps, potentially impeding its ability to develop the capabilities needed to address this challenging task. Insufficient computational capacity also hindered us from conducting comprehensive hyperparameter searches for the downstream tasks, restricting our ability to optimize the model's performance to its full potential. This, perhaps, could enhance our performance metrics and allow PHD to achieve more competitive results on GLUE and higher absolute numbers on SQuAD. This package provides the location of every paragraph on the page, as well as their reading order.",
                    "As newspapers tend to be multi-columned, we \"linearise\" the page into a single-column document.",
                    "We crop each paragraph and resize it such that its width equals 368 pixels. We then concatenate all the resized paragraphs with respect to their reading order to generate a long, single-column document with a width of 368 pixels. Finally, we use a sliding window approach to split the linear page into 368 \u00d7 368 crops, applying a stride of 128 pixels. We reserve 5% of newspaper issues for validation, using the rest for training. See "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "B Historical GLUE Baselines",
                "text": [
                    "For all baselines below, we compute and average scores over 5 random initializations. Donut We finetune Donut-base using an adaptation of ClovaAI's official codebase. 11 We frame each of the GLUE tasks as image-to-text tasks: the model receives the (noisy) input image and is trained to produce an output text sequence such as <s_glue><s_class><positive/> </s_class></s>. In this example, taken from SST-2, the < X > tags are new vocabulary items added to Donut and the label is an added vocabulary item for the positive sentiment class. All classification tasks in GLUE can be represented in this way. For STS-B, where the label is a floating point value denoting the similarity score between two sentences, we follow Raffel et al. (2020) to round and convert the floats into strings. 12 We finetune with batch size 32 and learning rate between 1e\u22125 and 3e\u22125 for a maximum of 30 epochs or 15 000 steps on images resized to a resolution of 320 \u00d7 320 pixels.",
                    "OCR-free BERT/PIXEL For GLUE, we take results reported in (Rust et al., 2021). For SQuAD, we take a BERT model finetuned on SQuAD-v2, 13  and evaluate it on the validation set of SQuAD-v2, after being balanced for the existence of an answer. For the Runaways Slaves in Britain dataset, we finetune a BERT-base-cased model 14 on a manually transcribed version of the dataset. We use the default SQuAD-v2 hyperparameters reported in the official Huggingface repository for training on SQuAD-v2. 15 We then evaluate the model on a balanced test set, containing 20% of the ads."
                ],
                "publication_ref": [
                    "b37"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "C Additional Material",
                "text": [
                    "Figure 9 additional examples from our artificially generated dataset.",
                    "Figure 10 Sample scans from the real historical dataset, as described in Section 4.2.",
                    "Figure 11 The process of generating the Visual SQuAD dataset. We first render the context as an image (a), generate a patch-level label mask highlighting the answer (b), add noise and concatenate the question (c).",
                    "Figure 12 Additional examples of PHD's completions over test set samples.",
                    "Figure 13 Dimensionality reduction of embedding calculated by our model on historical scans. We see that scans are clustered based on visual similarity and page structure. However, further investigation is required to determine whether scans are also clustered based on semantic similarity. Figure 16 Examples of shipping ads Newspapers. Newspapers in the Caribbean region routinely reported on passenger and cargo ships porting and departing the islands. These ads are usually wellstructured and contain information such as relevant dates, the ship's captain, route, and cargo.",
                    "Figure 17 Input samples for PIXEL. The images are rolled, i.e., the actual input resolution is 16 \u00d7 8464 pixels. The grid represents the 16 \u00d7 16 patches that the inputs are broken into.",
                    "Figure 18 An example of a full newspaper page downloaded from the \"Caribbean project\".          "
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_20",
                    "fig_21",
                    "fig_1",
                    "fig_4",
                    "fig_24",
                    "fig_28",
                    "fig_29",
                    "fig_16"
                ],
                "table_ref": []
            },
            {
                "heading": "Acknowledgements",
                "text": [
                    "This research was partially funded by a DFF Sapere Aude research leader grant under grant agreement No 0171-00034B, the Danish-Israeli Study Foundation in Memory of Josef and Regine Nachemsohn, the Novo Nordisk Foundation (grant NNF 20SA0066568), as well as by a research grant (VIL53122) from VILLUM FONDEN. The research was also supported by the Pioneer Centre for AI, DNRF grant number P1."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A Reproducibility",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.1 Training",
                "text": [
                    "Pretraining We pretrain PHD for 1M steps on with the artificial dataset using a batch size of 176 (the maximal batch size that fits our system) using AdamW optimizer (Kingma and Ba, 2014;Loshchilov and Hutter, 2017) with a linear warmup over the first 50k steps to a peak learning rate of 1.5e\u22124 and a cosine decay to a minimum learning rate of 1e\u22125. We then train PHD for additional 100k steps with the real historical scans using the same hyperparameters but without warm-up. Pretraining took 10 days on 2 \u00d7 80GB Nvidia A100 GPUs.",
                    "GLUE Table 4 contains the hyperparameters used to finetune PHD on the GLUE benchmark. We did not run a comprehensive hyperparameter search due to compute limitations; these settings were manually selected based on a small number of preliminary runs.",
                    "SQuAD To finetune PHD on SQuAD, we used a learning rate of 6.75e\u22126, batch size of 128, dropout probability of 0.0 and weight decay of 1e\u22125. We train the model for 50 000 steps."
                ],
                "publication_ref": [
                    "b18",
                    "b25"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Runaways Slaves in Britain",
                "text": [
                    "To finetune PHD on the Runaways Slaves in Britain dataset, first trained the model on SQuAD using the hyperparameters mentioned above. Then, we finetuned the resulting model for an additional 1000 steps on the Runaways Slaves in Britain. The only hyperparameter we changed between the two runs is the dropout probability, which we increased to 0.2."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.2 Dataset Generation",
                "text": [
                    "List of dataset augmentations To generate the synthetic dataset described in Section 4.1, we applied the following transformations to the rendered images: text bleed-through effect; addition of random horizontal and lines; salt and pepper noise; Gaussian blurring; water stains effect; \"holes-inimage\" effect; colour jitters on image background; and random rotations.",
                    "Converting the Caribbean Newspapers dataset into 368 \u00d7 368 scans We convert full newspaper pages into a collection of 368 \u00d7 368 pixels using the following process. First, we extract the layout of the page using the Python package Eynollah. 8  "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            }
        ],
        "references": [
            {
                "ref_id": "b0",
                "title": "Docformer: End-to-end transformer for document understanding",
                "journal": "",
                "year": "2021",
                "authors": "Srikar Appalaraju; Bhavan Jasani; Yusheng Bhargava Urala Kota; R Xie;  Manmatha"
            },
            {
                "ref_id": "b1",
                "title": "Transferring modern named entity recognition to the historical domain: How to take the step?",
                "journal": "",
                "year": "2021",
                "authors": "Blouin Baptiste; Jeremy Benoit Favre; Christian Auguste;  Henriot"
            },
            {
                "ref_id": "b2",
                "title": "A large-scale comparison of historical text normalization systems",
                "journal": "Association for Computational Linguistics",
                "year": "2019",
                "authors": "Marcel Bollmann"
            },
            {
                "ref_id": "b3",
                "title": "Multi-task learning for historical text normalization: Size matters",
                "journal": "",
                "year": "2018",
                "authors": "Marcel Bollmann; Anders S\u00f8gaard; Joachim Bingel"
            },
            {
                "ref_id": "b4",
                "title": "Multilingual event extraction from historical newspaper adverts",
                "journal": "Association for Computational Linguistics",
                "year": "2023",
                "authors": "Nadav Borenstein; Natalia Da; Silva Perez; Isabelle Augenstein"
            },
            {
                "ref_id": "b5",
                "title": "and Isabelle Augenstein. 2023b. Measuring intersectional biases in historical documents. Association for Computational Linguistics",
                "journal": "",
                "year": "",
                "authors": "Nadav Borenstein; Karolina Sta\u0144czak; Thea Rolskov; Natacha Klein K\u00e4fer; Natalia Da; Silva Perez"
            },
            {
                "ref_id": "b6",
                "title": "Early english books online : Eebo",
                "journal": "",
                "year": "1998",
                "authors": " Chadwyck"
            },
            {
                "ref_id": "b7",
                "title": "Human attention in visual question answering: Do humans and deep networks look at the same regions? Computer Vision and Image Understanding",
                "journal": "",
                "year": "2017",
                "authors": "Abhishek Das; Harsh Agrawal; Larry Zitnick; Devi Parikh; Dhruv Batra"
            },
            {
                "ref_id": "b8",
                "title": "Chris Tensmeyer, Curtis Wigington, and Vlad Morariu. 2023. End-to-end document recognition and understanding with dessurt",
                "journal": "Springer-Verlag",
                "year": "2022",
                "authors": "Brian Davis; Bryan Morse; Brian Price"
            },
            {
                "ref_id": "b9",
                "title": "Enrique Manjavacas, Stefan Schweter, and Daniel Van Strien. 2022. Entities, dates, and languages: Zero-shot on historical texts with t0",
                "journal": "Association for Computational Linguistics",
                "year": "",
                "authors": "Francesco De Toni; Christopher Akiki; Javier De ; La Rosa; Cl\u00e9mentine Fourrier"
            },
            {
                "ref_id": "b10",
                "title": "MATrIX -Modality-Aware Transformer for Information eXtraction. arXiv e-prints",
                "journal": "",
                "year": "2022",
                "authors": "Thomas Delteil; Edouard Belval; Lei Chen; Luis Goncalves; Vijay Mahadevan"
            },
            {
                "ref_id": "b11",
                "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
                "journal": "Association for Computational Linguistics",
                "year": "2019",
                "authors": "Jacob Devlin; Ming-Wei Chang; Kenton Lee; Kristina Toutanova"
            },
            {
                "ref_id": "b12",
                "title": "Ocr and post-correction of historical finnish texts",
                "journal": "",
                "year": "2017",
                "authors": "Senka Drobac; Pekka Kauppinen; Krister Lind\u00e9n"
            },
            {
                "ref_id": "b13",
                "title": "Scales of a local: the place of locality in a globalizing world",
                "journal": "A Companion to World History",
                "year": "2012",
                "authors": "Anne Gerritsen"
            },
            {
                "ref_id": "b14",
                "title": "Digital gatekeeper of the past: Delpher and the emergence of the press in the dutch golden age",
                "journal": "Tijdschrift voor Tijdschriftstudies",
                "year": "2015",
                "authors": " Michiel Van Groesen"
            },
            {
                "ref_id": "b15",
                "title": "Masked autoencoders are scalable vision learners",
                "journal": "",
                "year": "2022",
                "authors": "Kaiming He; Xinlei Chen; Saining Xie; Yanghao Li; Piotr Doll\u00e1r; Ross Girshick"
            },
            {
                "ref_id": "b16",
                "title": "Quantifying the impact of dirty ocr on historical text analysis: Eighteenth century collections online as a case study",
                "journal": "Digital Scholarship in the Humanities",
                "year": "2019",
                "authors": "J Mark; Simon Hill;  Hengchen"
            },
            {
                "ref_id": "b17",
                "title": "Ocr-free document understanding transformer",
                "journal": "Springer-Verlag",
                "year": "2022-10-23",
                "authors": "Geewook Kim; Teakgyu Hong; Moonbin Yim; Jeongyeon Nam; Jinyoung Park; Jinyeong Yim; Wonseok Hwang; Sangdoo Yun; Dongyoon Han; Seunghyun Park"
            },
            {
                "ref_id": "b18",
                "title": "Adam: A method for stochastic optimization",
                "journal": "",
                "year": "2014",
                "authors": "P Diederik; Jimmy Kingma;  Ba"
            },
            {
                "ref_id": "b19",
                "title": "Event extraction from historical texts: A new dataset for black rebellions",
                "journal": "",
                "year": "2021",
                "authors": "Viet Lai; Minh Van Nguyen; Heidi Kaufman; Thien Huu Nguyen"
            },
            {
                "ref_id": "b20",
                "title": "The emmet's inch: Small history in a digital age",
                "journal": "Journal of Social History",
                "year": "2020",
                "authors": "Julia Laite"
            },
            {
                "ref_id": "b21",
                "title": "Pix2struct: Screenshot parsing as pretraining for visual language understanding",
                "journal": "",
                "year": "2022",
                "authors": "Kenton Lee; Mandar Joshi; Iulia Turc; Hexiang Hu; Fangyu Liu; Julian Eisenschlos; Urvashi Khandelwal; Peter Shaw; Ming-Wei Chang; Kristina Toutanova"
            },
            {
                "ref_id": "b22",
                "title": "Dit: Self-supervised pre-training for document image transformer",
                "journal": "Association for Computing Machinery",
                "year": "2022",
                "authors": "Junlong Li; Yiheng Xu; Tengchao Lv; Lei Cui; Cha Zhang; Furu Wei"
            },
            {
                "ref_id": "b23",
                "title": "Trocr: Transformer-based optical character recognition with pre-trained models",
                "journal": "",
                "year": "2021",
                "authors": "Minghao Li; Tengchao Lv; Jingye Chen; Lei Cui; Yijuan Lu; Dinei Florencio; Cha Zhang; Zhoujun Li; Furu Wei"
            },
            {
                "ref_id": "b24",
                "title": "Selfdoc: Self-supervised document representation learning",
                "journal": "",
                "year": "2021",
                "authors": "Peizhao Li; Jiuxiang Gu; Jason Kuen; I Vlad; Handong Morariu; Rajiv Zhao; Varun Jain; Hongfu Manjunatha;  Liu"
            },
            {
                "ref_id": "b25",
                "title": "",
                "journal": "",
                "year": "2017",
                "authors": "Ilya Loshchilov; Frank Hutter"
            },
            {
                "ref_id": "b26",
                "title": "Neural ocr post-hoc correction of historical corpora",
                "journal": "Transactions of the Association for Computational Linguistics",
                "year": "2021",
                "authors": "Lijun Lyu; Maria Koutraki; Martin Krickl; Besnik Fetahu"
            },
            {
                "ref_id": "b27",
                "title": "Adapting vs. Pre-training Language Models for Historical Languages",
                "journal": "Journal of Data Mining & Digital Humanities",
                "year": "2022",
                "authors": "Enrique Manjavacas; Lauren Fonteyn"
            },
            {
                "ref_id": "b28",
                "title": "Guides: News and newspapers: Historical newspaper collections. Iowa's University Libraries",
                "journal": "",
                "year": "2009",
                "authors": "Janalyn Moss"
            },
            {
                "ref_id": "b29",
                "title": "Runaway Slaves in Britain: bondage, freedom and race in the eighteenth century",
                "journal": "",
                "year": "2019",
                "authors": "P Simon; Stephen Newman; Nelson Mullen; Roslyn Mundell;  Chapman"
            },
            {
                "ref_id": "b30",
                "title": "Learning transferable visual models from natural language supervision",
                "journal": "PMLR",
                "year": "2021-07-24",
                "authors": "Alec Radford; Jong Wook Kim; Chris Hallacy; Aditya Ramesh; Gabriel Goh; Sandhini Agarwal; Girish Sastry; Amanda Askell; Pamela Mishkin; Jack Clark; Gretchen Krueger; Ilya Sutskever"
            },
            {
                "ref_id": "b31",
                "title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
                "journal": "J. Mach. Learn. Res",
                "year": "2020",
                "authors": "Colin Raffel; Noam Shazeer; Adam Roberts; Katherine Lee; Sharan Narang; Michael Matena; Yanqi Zhou; Wei Li; Peter J Liu"
            },
            {
                "ref_id": "b32",
                "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text",
                "journal": "",
                "year": "2016",
                "authors": "Pranav Rajpurkar; Jian Zhang; Konstantin Lopyrev; Percy Liang"
            },
            {
                "ref_id": "b33",
                "title": "Sentence-bert: Sentence embeddings using siamese bert-networks",
                "journal": "",
                "year": "2019",
                "authors": "Nils Reimers; Iryna Gurevych"
            },
            {
                "ref_id": "b34",
                "title": "How much knowledge can you pack into the parameters of a language model",
                "journal": "Online. Association for Computational Linguistics",
                "year": "2020",
                "authors": "Adam Roberts; Colin Raffel; Noam Shazeer"
            },
            {
                "ref_id": "b35",
                "title": "Evaluating historical text normalization systems: How well do they generalize?",
                "journal": "",
                "year": "2018",
                "authors": "Alexander Robertson; Sharon Goldwater"
            },
            {
                "ref_id": "b36",
                "title": "Language modelling with pixels. International Conference on Learning Representations",
                "journal": "",
                "year": "2023",
                "authors": "Phillip Rust; Jonas F Lotz; Emanuele Bugliarello; Elizabeth Salesky; Desmond Miryam De Lhoneux;  Elliott"
            },
            {
                "ref_id": "b37",
                "title": "How good is your tokenizer? on the monolingual performance of multilingual language models",
                "journal": "Long Papers",
                "year": "2021",
                "authors": "Phillip Rust; Jonas Pfeiffer; Ivan Vuli\u0107; Sebastian Ruder; Iryna Gurevych"
            },
            {
                "ref_id": "b38",
                "title": "2023. tesseract: Open source ocr engine",
                "journal": "",
                "year": "",
                "authors": "Ray Smith"
            },
            {
                "ref_id": "b39",
                "title": "Visualizing data using t-sne",
                "journal": "Journal of Machine Learning Research",
                "year": "2008",
                "authors": "Laurens Van Der Maaten; Geoffrey Hinton"
            },
            {
                "ref_id": "b40",
                "title": "GLUE: A multi-task benchmark and analysis platform for natural language understanding",
                "journal": "",
                "year": "2018",
                "authors": "Alex Wang; Amanpreet Singh; Julian Michael; Felix Hill; Omer Levy; Samuel Bowman"
            },
            {
                "ref_id": "b41",
                "title": "Aligning books and movies: Towards story-like visual explanations by watching movies and reading books",
                "journal": "",
                "year": "2015",
                "authors": "Yukun Zhu; Ryan Kiros; Rich Zemel; Ruslan Salakhutdinov; Raquel Urtasun; Antonio Torralba; Sanja Fidler"
            }
        ],
        "figures": [
            {
                "figure_label": "1",
                "figure_type": "figure",
                "figure_id": "fig_1",
                "figure_caption": "Figure 1 :1Figure 1: Our proposed model, PHD. The model is trained to reconstruct the original image (a) from the masked image (b), resulting in (c). The grid represents the 16 \u00d7 16 pixels patches that the inputs are broken into. composed of instances where the image and text are aligned. Fig 1 visualises our proposed training approach.Given the paucity of large, high-quality datasets comprising historical scans, we pretrain our model using a combination of 1) synthetic scans designed to resemble historical documents faithfully, produced using a novel method we propose for synthetic scan generation; and 2) real historical English newspapers published in the Caribbeans in the 18th and 19th centuries. The resulting pixelbased language encoder, PHD (Pixel-based model for Historical Documents), is subsequently evaluated based on its comprehension of natural language and its effectiveness in performing Question Answering from historical documents.We discover that PHD displays impressive reconstruction capabilities, being able to correctly predict both the form and content of masked patches of historical newspapers ( \u00a74.4). We also note the challenges concerning quantitatively evaluating these predictions. We provide evidence of our model's noteworthy language understanding capabilities while exhibiting an impressive resilience to noise. Finally, we demonstrate the usefulness of the model when applied to the historical QA task ( \u00a75.4).To facilitate future research, we provide the dataset, models, and code at https://gith ub.com/nadavborenstein/pixel-bw.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_2",
                "figure_caption": "Fig 1a demonstrates (and compare to Fig 17a in App C). Therefore, we set the input size of PHD to be 368 \u00d7 368 pixels (or 23 \u00d7 23 patches).",
                "figure_data": ""
            },
            {
                "figure_label": "2",
                "figure_type": "figure",
                "figure_id": "fig_4",
                "figure_caption": "Figure 2 :2Figure 2: Process of generating a single artificial scan. Refer to \u00a74.1 for detailed explanations.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_5",
                "figure_caption": "Finally, we use the Python package WeasyPrint 4 to render the HTML file as a PNG image. Fig 2a visualises this process' outcome.In some cases, if the text span is short or the selected font is small, the resulting image contains a large empty space (as in Fig2a). When the empty space within an image exceeds 10%, a new image is generated to replace the vacant area. We create the new image by randomly choosing one of two options. In 80% of the cases, we retain the font of the original image and select the next paragraph. In 20% of the cases, a new paragraph and font are sampled. This pertains to the common case where a historical scan depicts a transition of context or font (e.g., Fig1a). This process can repeat multiple times, resulting in images akin toFig 2b. Finally, to simulate the effects of scanning ageing historical documents, we degrade the image by adding various types of noise, such as blurring, rotations, salt-and-pepper noise and bleed-through effect (see Fig 2c and Fig 9 in App C for examples). App A.2 enumerates the full list of the degradations and augmentations we use.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_6",
                "figure_caption": "Fig 10 in App C for dataset examples.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_7",
                "figure_caption": "[2, 6] and [2, 4] patches, respectively, and then place them in random image locations (See Fig 1b for an example). Training hyperparameters can be found in App A.1.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_8",
                "figure_caption": "Fig 3 presents a visual representa-",
                "figure_data": ""
            },
            {
                "figure_label": "3",
                "figure_type": "figure",
                "figure_id": "fig_9",
                "figure_caption": "Figure 3 :3Figure 3: Examples of some image completions made by PHD . Masked regions marked by dark outlines.",
                "figure_data": ""
            },
            {
                "figure_label": "4",
                "figure_type": "figure",
                "figure_id": "fig_10",
                "figure_caption": "Figure 4 :4Figure 4: Single word completions made by our model. Figure captions depict the missing word. Fig (a) depicts a successful reconstruction, whereas Fig (b) and (c) represent fail-cases.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_11",
                "figure_caption": "(a) Semantic search target. (b) Retrieved scans.",
                "figure_data": ""
            },
            {
                "figure_label": "5",
                "figure_type": "figure",
                "figure_id": "fig_12",
                "figure_caption": "Figure 5 :5Figure 5: Semantic search using our model. (a) is the target of the search, and (b) are scans retrieved from the newspaper corpus.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_13",
                "figure_caption": "FigFig 13, however, does not provide insights regarding the semantic properties of the clusters. Therefore, we also directly use the model in semantic search settings. Specifically, we search our newspapers corpus for scans that are semantically similar to instances of the Runaways Slaves in Britain dataset, as well as scans containing shipping ads (See Fig 16 in App C for examples).To do so, we embed 1M random scans from the corpus. We then calculate the cosine similarity between these embeddings and the embedding of samples from the Runaways Slaves in Britain and embeddings of shipping ads. Finally, we manually examine the ten most similar scans to each sample.Our results (Fig 5 and Fig 14 in App C) are encouraging, indicating that the embeddings capture not only structural and visual information, but also the semantic content of the scans. However, the results are still far from perfect, and many retrieved scans are not semantically similar to the search's target. It is highly plausible that additional specialised finetuning (e.g., SentenceBERT's(Reimers and Gurevych, 2019) training scheme) is necessary to produce more semantically meaningful embeddings.",
                "figure_data": ""
            },
            {
                "figure_label": "6",
                "figure_type": "figure",
                "figure_id": "fig_14",
                "figure_caption": "Figure 6 :6Figure 6: Samples from the clean and noisy visual GLUE datasets.",
                "figure_data": ""
            },
            {
                "figure_label": "7",
                "figure_type": "figure",
                "figure_id": "fig_15",
                "figure_caption": "Figure 7 :7Figure 7: Example from the Runaways Slaves in Britain dataset, rendered as visual question answering task. The gray overlay marks the patches containing the answer.",
                "figure_data": ""
            },
            {
                "figure_label": "8",
                "figure_type": "figure",
                "figure_id": "fig_16",
                "figure_caption": "Figure 8 :8Figure 8: Saliency maps of PHD fine-tuned on the Runaways Slaves in Britain dataset. Ground truth label in a grey box. The figures were cropped in post-processing.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_17",
                "figure_caption": "Fig 8 presents two such saliency maps produced by applying the model to test samples from the Runaways Slaves in Britain dataset, including a failure case (Fig 8a) and a successful prediction (Fig 8b). More examples can be found in Fig 15 in App C.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_18",
                "figure_caption": "Fig 10 in App C for dataset examples.",
                "figure_data": ""
            },
            {
                "figure_label": "14",
                "figure_type": "figure",
                "figure_id": "fig_19",
                "figure_caption": "Figure 1414Figure9additional examples from our artificially generated dataset. Figure10Sample scans from the real historical dataset, as described in Section 4.2. Figure11The process of generating the Visual SQuAD dataset. We first render the context as an image (a), generate a patch-level label mask highlighting the answer (b), add noise and concatenate the question (c). Figure12Additional examples of PHD's completions over test set samples. Figure13Dimensionality reduction of embedding calculated by our model on historical scans. We see that scans are clustered based on visual similarity and page structure. However, further investigation is required to determine whether scans are also clustered based on semantic similarity. Figure14Using PHD for semantic search. Figure14aand is the target of the search (the concept we are looking for), while Figure14band are the retrieved scans. Figure15Additional examples of PHD's saliency maps for samples from the test set of the Runaways Slaves in Britain dataset. Figure16Examples of shipping ads Newspapers. Newspapers in the Caribbean region routinely reported on passenger and cargo ships porting and departing the islands. These ads are usually wellstructured and contain information such as relevant dates, the ship's captain, route, and cargo. Figure17Input samples for PIXEL. The images are rolled, i.e., the actual input resolution is 16 \u00d7 8464 pixels. The grid represents the 16 \u00d7 16 patches that the inputs are broken into. Figure18An example of a full newspaper page downloaded from the \"Caribbean project\".",
                "figure_data": ""
            },
            {
                "figure_label": "9",
                "figure_type": "figure",
                "figure_id": "fig_20",
                "figure_caption": "Figure 9 :9Figure 9: Samples of our artificially generated dataset, and compare to Figure 10.",
                "figure_data": ""
            },
            {
                "figure_label": "10",
                "figure_type": "figure",
                "figure_id": "fig_21",
                "figure_caption": "Figure 10 :10Figure 10: Sample scans from the real historical dataset.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_22",
                "figure_caption": "(a) Rendering context c as an image I. (b) Generating a label mask M . (c) Adding q and degradations.",
                "figure_data": ""
            },
            {
                "figure_label": "1112",
                "figure_type": "figure",
                "figure_id": "fig_23",
                "figure_caption": "Figure 11 :Figure 12 :1112Figure 11: Process of generating the Visual SQuAD dataset. We first render the context as an image (a), generate a patch-level label mask highlighting the answer (b), add noise and concatenate the question (c).",
                "figure_data": ""
            },
            {
                "figure_label": "13",
                "figure_type": "figure",
                "figure_id": "fig_24",
                "figure_caption": "Figure 13 :13Figure 13: Dimensionality reduction of embedding calculated by our model on historical scans.",
                "figure_data": ""
            },
            {
                "figure_label": "14",
                "figure_type": "figure",
                "figure_id": "fig_26",
                "figure_caption": "Figure 14 :14Figure 14: Semantic search using our model. (a) is the target of the search, and (b) are scans retrieved from the newspaper corpus.",
                "figure_data": ""
            },
            {
                "figure_label": "15",
                "figure_type": "figure",
                "figure_id": "fig_27",
                "figure_caption": "Figure 15 :15Figure 15: Additional examples of PHD's saliency maps for samples from the test set of the Runaways Slaves in Britain dataset.",
                "figure_data": ""
            },
            {
                "figure_label": "16",
                "figure_type": "figure",
                "figure_id": "fig_28",
                "figure_caption": "Figure 16 :16Figure16: Shipping ads samples. Newspapers in the Caribbean region routinely reported on passenger and cargo ships porting and departing the islands. These ads are usually well-structured and contain information such as relevant dates, the ship's captain, route, and cargo.",
                "figure_data": ""
            },
            {
                "figure_label": "17",
                "figure_type": "figure",
                "figure_id": "fig_29",
                "figure_caption": "Figure 17 :17Figure 17: Input samples for PIXEL. The images are rolled, i.e., the actual input resolution is 16 \u00d7 8464 pixels. The grid represents the 16 \u00d7 16 patches that the inputs are broken into.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "",
                "figure_caption": "",
                "figure_data": ""
            },
            {
                "figure_label": "1",
                "figure_type": "table",
                "figure_id": "tab_0",
                "figure_caption": "Statistics of the newspapers dataset.",
                "figure_data": "Source#Issues#Train Scans#Test ScansCaribbean Project7 487 1 675 17287 721Danish Royal Library5 661300 78015 159Total13 148 1 975 952102 880"
            },
            {
                "figure_label": "2",
                "figure_type": "table",
                "figure_id": "tab_1",
                "figure_caption": "Results for PHD finetuned on GLUE. The metrics are F 1 score for QQP and MRPC, Matthew's correlation for COLA, Spearman's \u03c1 for STS-B, and accuracy for the remaining datasets. Bold values indicate the best model in category (noisy/clean), while underscored values indicate the best pixel-based model.",
                "figure_data": "Noise Images ModelMNLI QQP 393k 364kQNLI SST-2 COLA STS-B MRPC RTE 105k 67k 8.6k 5.8k 3.7k 2.5kWNLI AVG 635\u2717BERT PIXEL84.1 78.587.6 84.591.0 87.892.6 89.660.3 38.488.8 81.190.2 88.269.5 60.551.8 53.880.0 74.1\u2717\u2713CLIP lin Donut Ours50.2 64.0 70.164.7 77.8 82.767.4 69.7 82.379.8 82.1 82.54.2 13.9 15.956.4 14.4 80.274.1 81.7 83.451.5 54.0 59.925.6 57.7 54.152.7 57.2 67.9OCR+BERT OCR+PIXEL71.7 70.677.5 78.582.7 81.585.5 83.639.7 30.368.4 68.886.9 84.758.8 59.751.3 58.669.2 68.5\u2713\u2713CLIP lin Donut Ours45.3 61.6 68.067.4 74.1 80.464.4 75.1 81.879.2 75.5 83.93.5 10.2 15.157.9 20.6 80.478.8 81.9 83.647.3 56.7 58.532.7 60.0 57.852.9 57.3 67.2"
            },
            {
                "figure_label": "3",
                "figure_type": "table",
                "figure_id": "tab_2",
                "figure_caption": "Results for PHD finetuned on our visual SQuAD (S) and the Runaways Slaves (R) datasets.",
                "figure_data": "Task Model Noise / ImageBinary accPatch accOne OverlapSBERT Ours Ours\u2717/ \u2717 \u2717/ \u2713 \u2713/ \u271372.3 60.3 61.747.3 16.4 14.453.9 42.2 41.2RBERT Ours-/ \u2717 -/ \u271378.3 74.752.0 20.055.8 48.8"
            },
            {
                "figure_label": "4",
                "figure_type": "table",
                "figure_id": "tab_3",
                "figure_caption": "The hyperparameters used to train PHD on GLUE tasks.",
                "figure_data": "ParameterMNLI QQP QNLI SST-2 COLA STS-B MRPC RTE WNLIClassification-head-pooling Optimizer Adam \u03b2 Adam \u03f5 Weight decay Learning rate Learning rate warmup steps Learning rate schedule Batch size Max steps Early stopping Eval interval (steps/epoch) Dropout probability172 500172 500128 500128 500Mean AdamW (0.9, 0.999) 1e\u22128 1e\u22125 5e\u22122 100 Cosine annealing 128 128 10 000 \u2713 100 100 0.0172 100172 250172 100"
            }
        ],
        "formulas": [],
        "doi": "10.18653/v1/N19-1389"
    },
    "Primacy Effect of ChatGPT": {
        "authors": "Yiwei Wang; Yujun Cai; Muhao Chen; Yuxuan Liang; Bryan Hooi; Angeles \u2021 Meta",
        "pub_date": "",
        "abstract": "Instruction-tuned large language models (LLMs), such as ChatGPT, have led to promising zero-shot performance in discriminative natural language understanding (NLU) tasks. This involves querying the LLM using a prompt containing the question, and the candidate labels to choose from. The question-answering capabilities of ChatGPT arise from its pre-training on large amounts of human-written text, as well as its subsequent fine-tuning on human preferences, which motivates us to ask: Does ChatGPT also inherit humans' cognitive biases? In this paper, we study the primacy effect of ChatGPT: the tendency of selecting the labels at earlier positions as the answer. We have two main findings: i) ChatGPT's decision is sensitive to the order of labels in the prompt; ii) ChatGPT has a clearly higher chance to select the labels at earlier positions as the answer. We hope that our experiments and analyses provide additional insights into building more reliable ChatGPT-based solutions. We release the source code at https: //github.com/wangywUST/PrimacyEffectGPT.",
        "sections": [
            {
                "heading": "Introduction",
                "text": [
                    "Humans tend to recall information presented at the start of a list better than information at the middle or end. This phenomenon is known as the primacy effect (Asch, 1946), which is a cognitive bias that relates to humans' attention spans (Crano, 1977), rehearsal (Tan and Ward, 2000), and memory systems (Li, 2010). Similarly, in advertisement systems and search engines, humans tend to interact with items in higher positions regardless of the items' actual relevance (Chen et al., 2023). Primacy effect influences humans' behaviors to make unfair decisions. Similarly, if it exists in machine learning models, it may lead to worse performance. * Equal contribution. Recently, instruction-tuned large language models (LLMs), represented by ChatGPT (OpenAI, 2022), have received wide attention on their capabilities of imitating humans in question-answering and problem-solving. However, this underlying behavioral similarity between ChatGPT and humans naturally leads to an intriguing question: Is Chat-GPT also affected by the primacy effect?",
                    "ChatGPT provides a convenient way to achieve the discriminative natural language understanding (NLU) (Li et al., 2023;Wei et al., 2023;Yuan et al., 2023). People only need to list the labels in the prompt and asking ChatGPT to select the label(s) that match the input text. In this work, to analyze the primacy effect of ChatGPT, we start by testing with random label shuffling, i.e., shuffling labels listed in the prompt before every prediction. We compare the predictions on the same instance with two different label orders. Then, we count the predicted label indices on many instances with label shuffling. The motivation is that: a fair NLU model should give the same prediction on an input instance regardless of how the labels are ordered; consequently, it should produce uniformly distributed label indices under label shuffling for any instance.",
                    "Through extensive experiments with a series of NLU datasets, we find that \u2022 ChatGPT's prediction is sensitive to the order of labels in the prompt. Specifically, Chat-GPT's prediction changes after a label shuffling on 87.9% of the instances in TACRED.",
                    "\u2022 ChatGPT is affected by the primacy effect: ChatGPT tends to select labels in earlier positions in the prompt (see Fig. 1), which present clear bias with respect to the label order.",
                    "On the whole, our work contributes to a better understanding of ChatGPT's behaviors and building more faithful ChatGPT-based NLU solutions."
                ],
                "publication_ref": [
                    "b2",
                    "b9",
                    "b33",
                    "b20",
                    "b42"
                ],
                "figure_ref": [
                    "fig_0"
                ],
                "table_ref": []
            },
            {
                "heading": "Primacy Effect of ChatGPT",
                "text": [
                    "In this section, we first introduce the general prompt design of ChatGPT in discriminative natural language understanding (NLU). Then, we analyze the primacy effect of ChatGPT using label shuffling in prompts."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Prompts for ChatGPT",
                "text": [
                    "Prompts are a key component to the effective use of ChatGPT on discriminative NLU tasks (Wei et al., 2023;Yuan et al., 2023). Generally, prompts for such tasks involve two key components: (i) label definitions, and (ii) a task description and input text (see an example in Fig. 2).",
                    "ChatGPT's capability of understanding instructions in the prompt benefits from its training with human feedback (OpenAI, 2022), but this also creates the risk of inheriting humans' cognitive biases. In this paper, we discuss a cognitive bias in Chat-GPT: the primacy effect, which indicates the tendency of selecting labels in earlier positions in the prompt."
                ],
                "publication_ref": [
                    "b42"
                ],
                "figure_ref": [
                    "fig_2"
                ],
                "table_ref": []
            },
            {
                "heading": "Analysis with Label Shuffling",
                "text": [
                    "Analyzing the primacy effect requires us to distill the effects of label orders in the prompts. However, this is non-trivial because there are many factors influencing ChatGPT's decisions, such as the input text and label definitions. In our work, to distinguish the primacy effect of ChatGPT from other factors, we conduct random shuffling for labels listed in the prompts. Specifically, before every prediction, we shuffle the labels as visualized in Fig. 3. Label shuffling erases the discriminative semantics of the specific label orders in the prompts.  Ideally, a fair model should return the same prediction when labels are shuffled, and consequently, the predicted label index should follow a uniform distribution under random shuffling.",
                    "Next, we introduce our two ways of using random label shuffling to analyze ChatGPT."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_3"
                ],
                "table_ref": []
            },
            {
                "heading": "Prediction Comparison on an Instance",
                "text": [
                    "A reliable and consistent classifier is expected to consistently choose the same label for the same instance irrespective of the label order. To evaluate such consistency of ChatGPT, we perform the random shuffling for the same instance twice to produce two prompts. We feed these two prompts to Chat-GPT and compare the corresponding two predictions with each other. We apply the above process to all the test instances and compute the fraction of the instances where the prediction changed after label shuffling. The higher the fraction is, the more sensitive ChatGPT is to the label order."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Statistics of Predicted Indices",
                "text": [
                    "Taking a further step, we perform statistical analysis on the predicted indices for instances where the prediction changed after label shuffling. If ChatGPT does not have any preference on the label orders, its predicted label indices should be uniformly distributed. By comparing the predicted label index distribution of ChatGPT to the uniform distribution, we can assess its fairness and preferences regarding label orders."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Experiments",
                "text": [
                    "We analyze the primacy effect based on the aforementioned strategies using three relation extraction datasets and an intent detection dataset. "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Experiment Setup",
                "text": [
                    "We mainly chose relation extraction and intent detection tasks in our experiments since these tasks naturally come with adequately sized decision spaces to illustrate the underlying primacy effect of labels. For relation extraction, we experiment on three benchmark datasets including TACRED (Zhang et al., 2017), TACREV (Alt et al., 2020), and Re-TACRED (Stoica et al., 2021). For intent detection, we conducted experiments on Banking77 (Casanueva et al., 2020a) and MASSIVE (FitzGerald et al., 2022). MASSIVE (FitzGerald et al., 2022) is a parallel dataset of massive utterances with annotations for the Natural Language Understanding tasks of intent prediction. Utterances span 60 intents.",
                    "We additionally conducted experiments on the NLP datasets: GoEmotions (Demszky et al., 2020) and 20 Newsgroups (Albishre et al., 2015) for a more comprehensive evaluation. GoEmotions (Demszky et al., 2020) is a dataset for fine-grained emotion classification. It is a corpus of 58k carefully curated comments extracted from Reddit, with human annotations for 27 emotion categories and a neutral one. The 20 Newsgroups (Albishre et al., 2015) dataset is a collection of approximately 20,000 newsgroup documents, partitioned across 20 different newsgroups.",
                    "We follow the existing work (Wei et al., 2023;Li et al., 2023) to apply ChatGPT to these tasks via the OpenAI API gpt-3.5-turbo. Specifically, we set the temperature as 0.0 to minimize the randomness of ChatGPT's outputs. For comparison, we adopt the existing work (Casanueva et al., 2020b;Zhou and Chen, 2022) to fine-tune the BERT model with an MLP classification head."
                ],
                "publication_ref": [
                    "b44",
                    "b1",
                    "b30",
                    "b4",
                    "b13",
                    "b10",
                    "b0",
                    "b10",
                    "b0",
                    "b5"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Consistency under Label Shuffling",
                "text": [
                    "First, we observe the low consistency of ChatGPT confronted under label shuffling. As shown in Table 1, ChatGPT changes its label prediction after label shuffling in over 85% of the test instances on the TACRED, TACREV, and Re-TACRED datasets, and in 35.7% of instances on Banking77. Also, ChatGPT changes its label prediction after label shuffling in over 69% of the test instances on the datasets of GoEmotions and in more than 30% of instances on MASSIVE and 20 Newsgroups. In contrast, the fine-tuned BERT classifier maintains consistent predictions after label shuffling. This discrepancy challenges the widely-held belief that ChatGPT can comprehend human instructions and provide consistent responses. One possible explanation is that ChatGPT's understanding of the prompt is obtained by training on human-labeled data, which inherits humans' cognitive bias of treating labels at different positions unfairly.",
                    "It is worth noting that the ratio of instances with changed predictions is consistently high across the relation extraction datasets but lower on intent detection. This discrepancy can be attributed to the fact that information extraction tasks are shown to be challenging for ChatGPT and other LLMs (Wang et al., 2023;Li et al., 2023). In more difficult tasks, ChatGPT lacks sufficient discriminative semantic understanding from the input text and may be more affected by the label order."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Primacy Effect of ChatGPT",
                "text": [
                    "The empirical results in Section 3.2 indicate that ChatGPT's predictions are affected by label order. To deeper delve into the effects of label orders on ChatGPT, we analyze the distribution of predicted label indices (e.g., if the prediction is the first label, the label index is 1), as introduced in Section 2.2. We visualize the distributions in Fig. 4   the distribution of ChatGPT's predictions consistently deviates from the uniform distribution, displaying a consistent bias towards smaller indices across different datasets. In contrast, BERT exhibits no preference for label orders and consistently demonstrates a uniform distribution in its predicted label indices. We term this tendency of ChatGPT as the primacy effect, where the model tends to favor the labels presented earlier in the prompt. The magnitude of these primacy effects varies across tasks, as illustrated in Fig. 4. Notably, the influence of primacy effects is higher in more challenging tasks. This observation aligns with the results discussed in Sec. 3.3, wherein the impact of primacy effects is greater when ChatGPT tackles more difficult tasks. In the next section, we will quantitatively analyze the primacy effects of ChatGPT."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_4",
                    "fig_4"
                ],
                "table_ref": []
            },
            {
                "heading": "Evaluation on Fairness",
                "text": [
                    "The fairness of a trained model can be assessed by examining the imbalance or skewness in its predictions (Sweeney and Najafian, 2019). Following prior studies (Xiang et al., 2020;Sweeney and Najafian, 2019;Qian et al., 2021;Wang et al., 2022), we employ the JS divergence (Fuglede and Topsoe, 2004) as the metric to evaluate how imbalanced/skewed/unfair a prediction P is. The measurement is symmetric (i.e., JS(P \u2225U ) = JS(U \u2225P )) and strictly scoped.",
                    "To evaluate the label order bias of ChatGPT, we compute the average relative label order imbalance (LOI): LOI is defined as the JS divergence between the predicted label index distribution P and the uniform distribution U :",
                    "LOI = JS(P (x|x \u2208 D), U ),(1)",
                    "where x represents an input instance, D is the test set, P (x) is the predicted label index, and U is the uniform distribution. LOI captures the disparity between the predicted indices and a uniform distribution.",
                    "We conduct the fairness evaluation following the experimental settings described in Section 3.3, and the results are presented in Table 2. The findings demonstrate that ChatGPT exhibits unfair treatment of label indices when making relation label predictions for input texts. Furthermore, the degree of unfairness increases with the task's difficulty, which aligns with the empirical results discussed in Sections 3.2 and 3.3. In contrast, BERT demonstrates significantly better fairness, as its predictions are not influenced by label orders.",
                    "We additionally test the performance of Chat-GPT with CoT (Chain-of-thoughts) (Wei et al., 2022). With CoT, ChatGPT still exhibits the primacy effect. The above results show that with or without CoT, ChatGPT consistently exhibits the primacy effect. A reason for this phenomenon could be that the CoT encourages the LLMs for \"slow thinking\" about the question but does not neces-sarily mitigate the cognitive bias in the reasoning steps of CoT."
                ],
                "publication_ref": [
                    "b32",
                    "b41",
                    "b32",
                    "b26",
                    "b14",
                    "b39"
                ],
                "figure_ref": [],
                "table_ref": [
                    "tab_1"
                ]
            },
            {
                "heading": "Related Work",
                "text": [
                    "Large Language Models (LLMs) (Brown et al., 2020;Rae et al., 2021;Thoppilan et al., 2022;Smith et al., 2022), such as GPT-3 (Brown et al., 2020), LaMDA (Thoppilan et al., 2022) and PaLM (Chowdhery et al., 2022), refer to large scale pretrained models that contain more than a hundred billion parameters. Based on the highly parallelizable Transformer architecture (Vaswani et al., 2017), these Large Language models have shown powerful capability to produce reasonable results with very few samples or task descriptions as input.",
                    "A key milestone in the development process of LLMs is ChatGPT, which is developed by Ope-nAI based on InstructGPT (Ouyang et al., 2022). ChatGPT is able to interact with humans through multiple turns of dialogue, understand user intent, accomplish instructions, and return human-like responses. This attracts huge attention from research field, motivating numerous recent work (Zhang et al., 2022;Ma et al., 2023;Wan et al., 2023;Zhong et al., 2023;Susnjak, 2023) to utilize Chat-GPT to different tasks.",
                    "As ChatGPT is a proprietary model, and OpenAI does not disclose its training specifics, researchers are actively investigating its associated implications and capabilities. There has been some work analyzing the performance, robustness, faithfulness, and explain-ability of ChatGPT (Gao et al., 2023;Han et al., 2023;Li et al., 2023). For example, (Malinka et al., 2023) investigates the educational integrity of ChatGPT and evaluates the ChatGPT's abilities to solve assignments of various levels in computer security specialization. (Haque et al., 2022) and (Kr\u00fcgel et al., 2023) investigate the ethical risks of ChatGPT.",
                    "Before ChatGPT, LLMs' inference has been accompanied by in-context learning (ICL) which adds a few demonstrations in the prompt (Dong et al., 2022;Fei et al., 2023). Accordingly, some work investigates the effects of demonstration orders for the LLMs before ChatGPT (Lu et al., 2021). (Zhao et al., 2021) finds the majority label, recency, and common token biases of LLMs' ICL.",
                    "Different from the above work, we focus on a new phenomenon of ChatGPT: the primacy effect, which is the tendency of selecting the first labels as the answer. The primary effect seriously influences ChatGPT's fairness. Collectively, our findings provide a new understanding of how ChatGPT works given the instructional prompts."
                ],
                "publication_ref": [
                    "b3",
                    "b28",
                    "b34",
                    "b29",
                    "b3",
                    "b34",
                    "b8",
                    "b35",
                    "b25",
                    "b25",
                    "b22",
                    "b46",
                    "b31",
                    "b15",
                    "b16",
                    "b23",
                    "b18",
                    "b37",
                    "b21",
                    "b45"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Conclusion",
                "text": [
                    "While previous work often takes ChatGPT as a universal method applicable to all text-related tasks, we argue that its flexibility comes with the risk of inheriting human's cognitive biases. These biases lead to unfair judgments which can affect the performance of the machine learning model. This work studies a cognitive bias of ChatGPT: primacy effects. We propose a simple yet effective label shuffling method to analyze the influence of label orders on ChatGPT. We discover the primacy effect of ChatGPT and finds that it highly influences the fairness of ChatGPT in NLU. Our work contributes to a better understanding of the behaviors of ChatGPT and building more faithful solutions with ChatGPT in NLU applications."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Limitation",
                "text": [
                    "Our work has a few potential limitations. Firstly, we primarily evaluate the primacy effect of Chat-GPT, which is one of the most widely-used instruction-legacy models for each task. It would be beneficial to assess this effect on other LLMs models (such as Google Bard, vicuna (Chiang et al., 2023)) and explore additional tasks to examine this primacy effect. Secondly, this work focused on analyzing the primacy effect of ChatGPT through experiments. We encourage further studies to propose effective solutions that can mitigate the negative impacts associated with the primacy effect."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Acknowledgement",
                "text": [
                    "The authors would like to thank the anonymous reviewers for their discussion and feedback. Yiwei Wang and Bryan Hooi are supported by NUS ODPRT Grant A-0008067-00-00, NUS ODPRT Grant R252-000-A81-133, and Singapore Ministry of Education Academic Research Fund Tier 3 under MOEs official grant number MOE2017-T3-1-007. Muhao   "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            }
        ],
        "references": [
            {
                "ref_id": "b0",
                "title": "Effective 20 newsgroups dataset cleaning",
                "journal": "IEEE",
                "year": "2015",
                "authors": "Khaled Albishre; Mubarak Albathan; Yuefeng Li"
            },
            {
                "ref_id": "b1",
                "title": "TACRED revisited: A thorough evaluation of the TACRED relation extraction task",
                "journal": "",
                "year": "2020",
                "authors": "Christoph Alt; Aleksandra Gabryszak; Leonhard Hennig"
            },
            {
                "ref_id": "b2",
                "title": "Forming impressions of personality",
                "journal": "The Journal of Abnormal and Social Psychology",
                "year": "1946",
                "authors": "E Solomon;  Asch"
            },
            {
                "ref_id": "b3",
                "title": "Language models are few-shot learners",
                "journal": "",
                "year": "2020",
                "authors": "Tom Brown; Benjamin Mann; Nick Ryder; Melanie Subbiah; Jared D Kaplan; Prafulla Dhariwal; Arvind Neelakantan; Pranav Shyam; Girish Sastry; Amanda Askell"
            },
            {
                "ref_id": "b4",
                "title": "Efficient intent detection with dual sentence encoders",
                "journal": "",
                "year": "2020",
                "authors": "I\u00f1igo Casanueva; Tadas Temcinas; Daniela Gerz; Matthew Henderson; Ivan Vulic"
            },
            {
                "ref_id": "b5",
                "title": "Efficient intent detection with dual sentence encoders",
                "journal": "",
                "year": "2020",
                "authors": "I\u00f1igo Casanueva; Tadas Tem\u010dinas; Daniela Gerz; Matthew Henderson; Ivan Vuli\u0107"
            },
            {
                "ref_id": "b6",
                "title": "Bias and debias in recommender system: A survey and future directions",
                "journal": "ACM Transactions on Information Systems",
                "year": "2023",
                "authors": "Jiawei Chen; Hande Dong; Xiang Wang; Fuli Feng; Meng Wang; Xiangnan He"
            },
            {
                "ref_id": "b7",
                "title": "Ion Stoica, and Eric P. Xing. 2023. Vicuna: An opensource chatbot impressing gpt-4 with 90%* chatgpt quality",
                "journal": "",
                "year": "",
                "authors": "Wei-Lin Chiang; Zhuohan Li; Zi Lin; Ying Sheng; Zhanghao Wu; Hao Zhang; Lianmin Zheng; Siyuan Zhuang; Yonghao Zhuang; Joseph E Gonzalez"
            },
            {
                "ref_id": "b8",
                "title": "Palm: Scaling language modeling with pathways",
                "journal": "",
                "year": "2022",
                "authors": "Aakanksha Chowdhery; Sharan Narang; Jacob Devlin; Maarten Bosma; Gaurav Mishra; Adam Roberts; Paul Barham;  Hyung Won; Charles Chung; Sebastian Sutton;  Gehrmann"
            },
            {
                "ref_id": "b9",
                "title": "Primacy versus recency in retention of information and opinion change",
                "journal": "The Journal of Social Psychology",
                "year": "1977",
                "authors": "D William;  Crano"
            },
            {
                "ref_id": "b10",
                "title": "Goemotions: A dataset of fine-grained emotions",
                "journal": "",
                "year": "2020",
                "authors": "Dorottya Demszky; Dana Movshovitz-Attias; Jeongwoo Ko; Alan Cowen; Gaurav Nemade; Sujith Ravi"
            },
            {
                "ref_id": "b11",
                "title": "Xu Sun, Jingjing Xu, and Zhifang Sui. 2022. A survey for in-context learning",
                "journal": "",
                "year": "",
                "authors": "Qingxiu Dong; Lei Li; Damai Dai; Ce Zheng; Zhiyong Wu; Baobao Chang"
            },
            {
                "ref_id": "b12",
                "title": "Mitigating label biases for in-context learning",
                "journal": "",
                "year": "2023",
                "authors": "Yu Fei; Yifan Hou; Zeming Chen; Antoine Bosselut"
            },
            {
                "ref_id": "b13",
                "title": "Massive: A 1m-example multilingual natural language understanding dataset with 51 typologically-diverse languages",
                "journal": "",
                "year": "2022",
                "authors": "Jack Fitzgerald; Christopher Hench; Charith Peris; Scott Mackie; Kay Rottmann; Ana Sanchez; Aaron Nash; Liam Urbach; Vishesh Kakarala; Richa Singh"
            },
            {
                "ref_id": "b14",
                "title": "Jensenshannon divergence and hilbert space embedding",
                "journal": "IEEE",
                "year": "2004",
                "authors": "Bent Fuglede; Flemming Topsoe"
            },
            {
                "ref_id": "b15",
                "title": "Is chatgpt a good causal reasoner? a comprehensive evaluation",
                "journal": "",
                "year": "2023",
                "authors": "Jinglong Gao; Xiao Ding; Bing Qin; Ting Liu"
            },
            {
                "ref_id": "b16",
                "title": "Is information extraction solved by chatgpt? an analysis of performance, evaluation criteria, robustness and errors",
                "journal": "",
                "year": "2023",
                "authors": "Ridong Han; Tao Peng; Chaohao Yang; Benyou Wang; Lu Liu; Xiang Wan"
            },
            {
                "ref_id": "b17",
                "title": "Zarrin Tasnim Sworna, Roshan Namal Rajapakse, and Hussain Ahmad. 2022. \" i think this is the most disruptive technology",
                "journal": "",
                "year": "",
                "authors": "Isuru Mubin Ul Haque;  Dharmadasa"
            },
            {
                "ref_id": "b18",
                "title": "The moral authority of chatgpt",
                "journal": "",
                "year": "2023",
                "authors": "Sebastian Kr\u00fcgel; Andreas Ostermaier; Matthias Uhl"
            },
            {
                "ref_id": "b19",
                "title": "Evaluating chatgpt's information extraction capabilities: An assessment of performance, explainability, calibration, and faithfulness",
                "journal": "",
                "year": "2023",
                "authors": "Bo Li; Gexiang Fang; Yang Yang; Quansen Wang; Wei Ye; Wen Zhao; Shikun Zhang"
            },
            {
                "ref_id": "b20",
                "title": "Primacy effect or recency effect? a long-term memory test of super bowl commercials",
                "journal": "Journal of Consumer Behaviour: An International Research Review",
                "year": "2010",
                "authors": "Cong Li"
            },
            {
                "ref_id": "b21",
                "title": "Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity",
                "journal": "",
                "year": "2021",
                "authors": "Yao Lu; Max Bartolo; Alastair Moore; Sebastian Riedel; Pontus Stenetorp"
            },
            {
                "ref_id": "b22",
                "title": "Large language model is not a good few-shot information extractor",
                "journal": "",
                "year": "2023",
                "authors": "Yubo Ma; Yixin Cao"
            },
            {
                "ref_id": "b23",
                "title": "On the educational impact of chatgpt: Is artificial intelligence ready to obtain a university degree",
                "journal": "",
                "year": "2023",
                "authors": "Kamil Malinka; Martin Peres\u00edni; Anton Firc; Ondrej Hujnak; Filip Janus"
            },
            {
                "ref_id": "b24",
                "title": "",
                "journal": "OpenAI. 2022. Introducing chatgpt",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b25",
                "title": "Training language models to follow instructions with human feedback",
                "journal": "Advances in Neural Information Processing Systems",
                "year": "2022",
                "authors": "Long Ouyang; Jeffrey Wu; Xu Jiang; Diogo Almeida; Carroll Wainwright; Pamela Mishkin; Chong Zhang; Sandhini Agarwal; Katarina Slama; Alex Ray"
            },
            {
                "ref_id": "b26",
                "title": "Counterfactual inference for text classification debiasing",
                "journal": "",
                "year": "2021",
                "authors": "Chen Qian; Fuli Feng; Lijie Wen; Chunping Ma; Pengjun Xie"
            },
            {
                "ref_id": "b27",
                "title": "Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Language Processing",
                "journal": "Long Papers",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b28",
                "title": "Scaling language models: Methods, analysis & insights from training gopher",
                "journal": "",
                "year": "2021",
                "authors": "Sebastian Jack W Rae; Trevor Borgeaud; Katie Cai; Jordan Millican; Francis Hoffmann; John Song; Sarah Aslanides; Roman Henderson; Susannah Ring;  Young"
            },
            {
                "ref_id": "b29",
                "title": "Using deepspeed and megatron to train megatron-turing nlg 530b, a large-scale generative language model",
                "journal": "",
                "year": "2022",
                "authors": "Shaden Smith; Mostofa Patwary; Brandon Norick; Patrick Legresley; Samyam Rajbhandari; Jared Casper; Zhun Liu; Shrimai Prabhumoye; George Zerveas; Vijay Korthikanti"
            },
            {
                "ref_id": "b30",
                "title": "Re-tacred: Addressing shortcomings of the tacred dataset",
                "journal": "",
                "year": "2021",
                "authors": "George Stoica"
            },
            {
                "ref_id": "b31",
                "title": "Applying bert and chatgpt for sentiment analysis of lyme disease in scientific literature",
                "journal": "",
                "year": "2023",
                "authors": "Teo Susnjak"
            },
            {
                "ref_id": "b32",
                "title": "A transparent framework for evaluating unintended demographic bias in word embeddings",
                "journal": "",
                "year": "2019",
                "authors": "Chris Sweeney; Maryam Najafian"
            },
            {
                "ref_id": "b33",
                "title": "A recency-based account of the primacy effect in free recall",
                "journal": "Journal of Experimental Psychology: Learning, Memory, and Cognition",
                "year": "2000",
                "authors": "Lydia Tan; Geoff Ward"
            },
            {
                "ref_id": "b34",
                "title": "Lamda: Language models for dialog applications",
                "journal": "",
                "year": "2022",
                "authors": "Romal Thoppilan; Daniel De Freitas; Jamie Hall; Noam Shazeer; Apoorv Kulshreshtha;  Heng-Tze; Alicia Cheng; Taylor Jin; Leslie Bos; Yu Baker;  Du"
            },
            {
                "ref_id": "b35",
                "title": "Attention is all you need",
                "journal": "",
                "year": "2017",
                "authors": "Ashish Vaswani; Noam Shazeer; Niki Parmar; Jakob Uszkoreit; Llion Jones; Aidan N Gomez; \u0141ukasz Kaiser; Illia Polosukhin"
            },
            {
                "ref_id": "b36",
                "title": "Gpt-re: In-context learning for relation extraction using large language models",
                "journal": "",
                "year": "2023",
                "authors": "Zhen Wan; Fei Cheng; Zhuoyuan Mao; Qianying Liu; Haiyue Song; Jiwei Li; Sadao Kurohashi"
            },
            {
                "ref_id": "b37",
                "title": "A causal view of entity bias in (large) language models",
                "journal": "",
                "year": "2023",
                "authors": "Fei Wang; Wenjie Mo; Yiwei Wang; Wenxuan Zhou; Muhao Chen"
            },
            {
                "ref_id": "b38",
                "title": "Should we rely on entity mentions for relation extraction? debiasing relation extraction with counterfactual analysis",
                "journal": "",
                "year": "2022",
                "authors": "Yiwei Wang; Muhao Chen; Wenxuan Zhou; Yujun Cai; Yuxuan Liang; Dayiheng Liu; Baosong Yang; Juncheng Liu; Bryan Hooi"
            },
            {
                "ref_id": "b39",
                "title": "Chain-of-thought prompting elicits reasoning in large language models",
                "journal": "Advances in Neural Information Processing Systems",
                "year": "2022",
                "authors": "Jason Wei; Xuezhi Wang; Dale Schuurmans; Maarten Bosma; Fei Xia; Ed Chi; V Quoc; Denny Le;  Zhou"
            },
            {
                "ref_id": "b40",
                "title": "Zeroshot information extraction via chatting with chatgpt",
                "journal": "",
                "year": "2023",
                "authors": "Xiang Wei; Xingyu Cui; Ning Cheng; Xiaobin Wang; Xin Zhang; Shen Huang; Pengjun Xie; Jinan Xu; Yufeng Chen; Meishan Zhang"
            },
            {
                "ref_id": "b41",
                "title": "Learning from multiple experts: Self-paced knowledge distillation for long-tailed classification",
                "journal": "Springer",
                "year": "2020",
                "authors": "Liuyu Xiang; Guiguang Ding; Jungong Han"
            },
            {
                "ref_id": "b42",
                "title": "Zero-shot temporal relation extraction with chatgpt",
                "journal": "",
                "year": "2023",
                "authors": "Chenhan Yuan; Qianqian Xie; Sophia Ananiadou"
            },
            {
                "ref_id": "b43",
                "title": "Daijun Ding, and Liwen Jing. 2022. How would stance detection techniques evolve after the launch of chatgpt? arXiv preprint",
                "journal": "",
                "year": "",
                "authors": "Bowen Zhang"
            },
            {
                "ref_id": "b44",
                "title": "Position-aware attention and supervised data improve slot filling",
                "journal": "",
                "year": "2017",
                "authors": "Yuhao Zhang; Victor Zhong; Danqi Chen; Gabor Angeli; Christopher D Manning"
            },
            {
                "ref_id": "b45",
                "title": "Calibrate before use: Improving few-shot performance of language models",
                "journal": "PMLR",
                "year": "2021",
                "authors": "Zihao Zhao; Eric Wallace; Shi Feng; Dan Klein; Sameer Singh"
            },
            {
                "ref_id": "b46",
                "title": "Can chatgpt understand too? a comparative study on chatgpt and fine-tuned bert",
                "journal": "",
                "year": "2023",
                "authors": "Qihuang Zhong; Liang Ding; Juhua Liu; Bo Du; Dacheng Tao"
            },
            {
                "ref_id": "b47",
                "title": "An improved baseline for sentence-level relation extraction",
                "journal": "",
                "year": "2022",
                "authors": "Wenxuan Zhou; Muhao Chen"
            }
        ],
        "figures": [
            {
                "figure_label": "1",
                "figure_type": "figure",
                "figure_id": "fig_0",
                "figure_caption": "Figure 1 :1Figure 1: Primacy Effect of ChatGPT: ChatGPT tends to return labels in earlier positions as the answer. This plot shows the distribution of ChatGPT's predicted label indices in TACRED (42 classes), where we randomly shuffle labels before every prediction (see Sec. 2.2).",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_1",
                "figure_caption": "I need a new PIN. Which Label matches the intent expressed in the Target Text?",
                "figure_data": ""
            },
            {
                "figure_label": "2",
                "figure_type": "figure",
                "figure_id": "fig_2",
                "figure_caption": "Figure 2 :2Figure 2: A prompt example for ChatGPT.",
                "figure_data": ""
            },
            {
                "figure_label": "3",
                "figure_type": "figure",
                "figure_id": "fig_3",
                "figure_caption": "Figure 3 :3Figure 3: We analyze the primacy effects of ChatGPT by randomly shuffling the labels in the prompts.",
                "figure_data": ""
            },
            {
                "figure_label": "4",
                "figure_type": "figure",
                "figure_id": "fig_4",
                "figure_caption": "Figure 4 :4Figure 4: The distribution of predicted indices of the test instances with label shuffling before every prediction.",
                "figure_data": ""
            },
            {
                "figure_label": "1",
                "figure_type": "table",
                "figure_id": "tab_0",
                "figure_caption": ". Notably, Fraction of the instances that have their predicted label changed after a label shuffling.",
                "figure_data": "MethodTACRED TACREV Re-TACRED Banking77 GoEmotions MASSIVE 20 NewsgroupsChatGPT w/ Prompt BERT w/ MLP87.9 0.085.9 0.088.6 0.035.7 0.069.3 0.032.8 0.034.1 0.0"
            },
            {
                "figure_label": "2",
                "figure_type": "table",
                "figure_id": "tab_1",
                "figure_caption": "",
                "figure_data": "MethodTACRED TACREV Re-TACRED Banking77ChatGPT w/ Prompts ChatGPT w/ CoT BERT w/ MLP57.9 57.6 1.857.8 57.9 1.958.1 58.3 2.318.8 18.6 2.1"
            }
        ],
        "formulas": [
            {
                "formula_id": "formula_0",
                "formula_text": "LOI = JS(P (x|x \u2208 D), U ),(1)",
                "formula_coordinates": [
                    4.0,
                    352.77,
                    426.61,
                    172.38,
                    20.55
                ]
            }
        ],
        "doi": ""
    },
    "Decoding the Silent Majority: Inducing Belief Augmented Social Graph with Large Language Model for Response Forecasting": {
        "authors": "Chenkai Sun; Jinning Li; Yi R Fung; Hou Pong Chan; Tarek Abdelzaher; Chengxiang Zhai; Heng Ji",
        "pub_date": "",
        "abstract": "Automatic response forecasting for news media plays a crucial role in enabling content producers to efficiently predict the impact of news releases and prevent unexpected negative outcomes such as social conflict and moral injury. To effectively forecast responses, it is essential to develop measures that leverage the social dynamics and contextual information surrounding individuals, especially in cases where explicit profiles or historical actions of the users are limited (referred to as lurkers). As shown in a previous study, 97% of all tweets are produced by only the most active 25% of users. However, existing approaches have limited exploration of how to best process and utilize these important features. To address this gap, we propose a novel framework, named SOCIALSENSE, that leverages a large language model to induce a belief-centered graph on top of an existent social network, along with graph-based propagation to capture social dynamics. We hypothesize that the induced graph that bridges the gap between distant users who share similar beliefs allows the model to effectively capture the response patterns. Our method surpasses existing state-of-the-art in experimental evaluations for both zero-shot and supervised settings, demonstrating its effectiveness in response forecasting. Moreover, the analysis reveals the framework's capability to effectively handle unseen user and lurker scenarios, further highlighting its robustness and practical applicability.",
        "sections": [
            {
                "heading": "Introduction",
                "text": [
                    "\"Your beliefs become your thoughts. Your thoughts become your words. Your words become your actions.\"",
                    "-Mahatma Gandhi Automatic response forecasting (Figure 1) on receivers for news media is a burgeoning field of",
                    "The code is available at https://github.com/ chenkaisun/SocialSense research that enables numerous influential applications, such as offering content producers a way to efficiently estimate the potential impact of their messages (aiding the prevention of unexpected negative outcomes) and supporting human writers in attaining their communication goals (Sun et al., 2023) for risk management. This direction is especially important nowadays as the proliferation of AI-generated misinformation, propaganda, and hate speech are becoming increasingly elusive to detection (Hsu and Thompson, 2023;Owen and Zahn, 2023). In this context, accurately forecasting the responses from different audiences or communities to news media messages becomes critical. One of the primary challenges in personalized response forecasting lies in developing effective user representations. A crucial aspect to consider when representing a user is the integration of social dynamics (e.g., social interactions around a user) as well as their individual beliefs and interests. This becomes particularly relevant for users who lack explicit profiles or historical activities (commonly referred to as lurkers). Previous efforts, however, have yet to explore the types of structural information that are helpful and how to best utilize such information (Lin and Chen, 2008;Giachanou et al., 2018;Yang et al., 2019;Wu et al., 2021).",
                    "During our preliminary analysis, we observed that users who share similar beliefs, specifically social values, are often situated in distant communities within the explicit social network. To provide further context, our findings reveal that a significant portion (over 44.6%) of users in the network data we collected for our experiment share beliefs with other users who are at least two hops away in the network. This emphasizes the importance of considering the connections between users with similar beliefs, even if they are not directly linked in the social network. Furthermore, previous research has indicated that user history plays a significant role in the model's performance. However, it is often directly utilized without processing in existing approaches, leading to the introduction of noise in the modeling process.",
                    "Motivated by these findings, we introduce SO-CIALSENSE (where Sense refers to the understanding and perception of social dynamics and behaviors within the online realm), a novel framework for modeling user beliefs and the social dynamics surrounding users in a social network. In this work, we conduct experiments using the SOCIALSENSE framework in the context of response forecasting. Our approach aims to capture the pattern of how \"similar neighbors respond to similar news similarly\". To harness the potential of network features, we curated a new user-user graph comprising 18k users from Twitter (the data will be anonymized when released), augmenting the original dataset (Sun et al., 2023). The SOCIALSENSE framework consists of three key stages: (1) inducing latent user personas using the Large Language Model (e.g., ChatGPT (Liu et al., 2023)), (2) building a belief-centered network on top of the existing social network, and (3) propagating information across multiple levels.",
                    "We demonstrate the effectiveness of our method through experiments on the dataset from Sun et al. (2023). Our results show that our framework outperforms existing baselines consistently across metrics in both zero-shot and fully-supervised settings. We further conduct a detailed analysis to address research questions concerning the model's general-izability to unseen users and its predictive capabilities for lurkers. Our findings reveal two additional key insights: (1) the model performs exceptionally well in scenarios involving lurkers, outperforming the baseline by over 10% accuracy score in sentiment polarity forecasting, and, (2) compared to baseline approaches, the model exhibits consistently better generalization capabilities when applied to unseen users. Additionally, our analysis underscores the significance of various components within the belief-augmented social network, revealing that both the belief-centered graph and the user-news interaction network play vital roles in determining the network's overall performance."
                ],
                "publication_ref": [
                    "b17",
                    "b38",
                    "b28",
                    "b11"
                ],
                "figure_ref": [
                    "fig_0"
                ],
                "table_ref": []
            },
            {
                "heading": "Task Formulation",
                "text": [
                    "In the task of Response Forecasting on Personas for News Media, our objective is to predict how users will respond to news media messages. Specifically, we focus on analyzing the sentiment intensity and polarity of these responses. Formally, given a persona P (representing the user) and a news media message M, our goal is to predict the persona's sentiment polarity \u03d5 p (categorized as either Positive, Negative, or Neutral) and intensity \u03d5 int (measured on a scale of 0 to 3) of the persona's response. We frame this task as a multi-class prediction problem."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "SOCIALSENSE",
                "text": [
                    "To accurately predict individuals' responses, it is crucial to develop an effective user representation that captures their personas. While previous studies have utilized user profiles and historical data to model individuals' interests with reasonable accuracy, there is a significant oversight regarding the behavior of a large number of internet users who are passive participants, commonly referred to as lurkers. This phenomenon is exemplified by statistics showing that only 25% of highly active users generate 97% of the content on Twitter (McClain et al., 2021). Consequently, the sparse historical data available for lurkers makes it challenging to infer their responses reliably. To address this issue, a social network-based approach can be employed to leverage users' social connections, gathering information from their neighbors. However, it is important to question whether relying solely on social networks is sufficient.",
                    "In this work, we introduce a novel perspective by borrowing the concept of belief and defining it in terms of social values. By considering so- "
                ],
                "publication_ref": [
                    "b35"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Attributes Operator",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "LLM-based Propagation",
                "text": [
                    "For Zero-Shot only"
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Network Construction",
                "text": [
                    "Figure 2: The figure illustrates our framework. In the first stage, we use an LLM to extract latent persona from the user's profile and historical posts. These moral and human value attributes from the latent personas, combined with the social network and news media messages, collectively shape the belief-augmented social network. Graph-based propagation is then used to update user representation. In the zero-shot setting, the LLM itself also assumes the role of an information propagator that combines information from neighbors (more details in Section 3.4). cial values, which encompass human values and moral values, we capture individuals' deeply held convictions, principles, and ethical standards that significantly shape their perspectives, behaviors, and responses within a social context. Our preliminary analysis reveals that individuals who share beliefs are often distantly connected, beyond residing in the same community. Specifically, we found that over 44.6% of users in our collected network data share beliefs with others who are at least two hops away in the network. This finding highlights the potential value of bridging these distant users and incorporating their beliefs as valuable features in response forecasting.",
                    "In this study, we present SOCIALSENSE (Figure 2), an innovative framework for modeling user beliefs and the social dynamics within a social network by automatically curating a belief-centered social network using a Large Language Model (e.g., ChatGPT). Our approach consists of three stages:",
                    "(1) extracting latent personas using a Large Language Model, (2) constructing a belief-centered network on top of the existing social network, and (3) information propagation. In addition to the supervised method, we further explore how to achieve zero-shot prediction with social networks by simu-lating graph propagation with SOCIAL PROMPT."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Unmasking Latent Persona with Large Language Model",
                "text": [
                    "Although the user's past posts can provide insights into their interests, they often contain noise that makes them challenging for models to consume. For instance, they may describe life events without providing context, such as \"@user Waited all day next to phone. Just got a msg...\". Furthermore, relying solely on raw historical data discourages explainability in response forecasting since past utterances are influenced by a person's internal beliefs rather than being the sole determinant of their future response.",
                    "In recent months, the Large Language Models (LLMs), particularly ChatGPT, have been shown to surpass human annotators in various tasks given their effective training techniques and access to vast amounts of pretraining data (Gilardi et al., 2023). This breakthrough presents unprecedented opportunities in analyzing users comprehensively without being scoped by previously established research.",
                    "For the first time, we leverage a large language model (specifically, ChatGPT in our experiment) to extract users' internal beliefs and construct beliefs suitable for downstream consumption.",
                    "In this initial stage of our framework, we design a prompt P l that enables us to extract latent information not available anywhere online. This includes dimensions such as human values, moral values, views on entities and issues, professions, and more. The prompt we have developed is shown in the Appendix. We refer to the latent persona extracted from the LLM for a user as User L . In other words, User L = LLM(profile, history, P l )",
                    "(1)"
                ],
                "publication_ref": [
                    "b12"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Belief-Augmented Social Network",
                "text": [
                    "To capture social interactions and bridge distant communities, our approach incorporates both existing and induced social information to construct a network that focuses on modeling users' beliefs. Our graph can be formally defined as follows: it comprises three sets of nodes, namely V M representing the news media messages, V U representing the users, and V B representing a fixed set of belief nodes. The graph consists of three types of edges: E I , E F , and E B . For each edge (u, m) \u2208 E I , where u \u2208 V U and m \u2208 V M , it indicates that user u has interacted with the news media message m. For each edge (u 1 , u 2 ) \u2208 E F , where u 1 , u 2 \u2208 V U , it signifies that user u 1 follows user u 2 . Lastly, for each edge Building upon the network from the previous stage, we establish connections between users and their associated values in an undirected manner. This connection type offers two key benefits. Firstly, it introduces shortcuts between users who share similar beliefs or mindsets, facilitating the propagation of information across distant nodes. Secondly, it allows the prediction results of user responses to potentially be attributed to the belief  nodes (instead of past utterances), thereby enhancing the explainability of the process."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Information Propagation",
                "text": [
                    "Given the constructed belief graph, we utilize a Graph Neural Network (GNN) (Zhou et al., 2020) to propagate information and learn an updated user representation, enabling us to infer user responses.",
                    "Node Initialization To train the GNN, we first need to initialize the node representations. For user nodes V U , we leverage a Pretrained Language Model (PLM) such as DeBERTa (He et al., 2020) to encode the user's profile and history, yielding a d-dimensional dense vector u. Similarly, we initialize media nodes V M by encoding the news headline message by the PLM, obtaining vector m.",
                    "The embeddings for the fixed set of belief nodes V B , b, are initialized by random vectors.",
                    "Graph Propagation We consider response forecasting as a reasoning process over the connections among news media, user, and belief nodes in the social graph. Leveraging the social homophily phenomenon, we posit that the constructed social ties lead to the formation of communities reflecting similarities and differences in beliefs, both within and across communities. To capture the interactions across different types of graph components, we employ a Heterogeneous Graph Transformer (HGT) (Hu et al., 2020), which was inspired by the architecture of the classic Transformer (Vaswani et al., 2017). Unlike homogeneous GNNs, HGT effectively handles different edge and node types as separate meta paths, facilitating the learning of user representations from various types of contextual nodes. Upon obtaining the updated user representations from HGT, we concatenate them with the news embeddings. The resulting vector is passed through an MLP layer followed by a softmax activation function for classification. The model is trained using cross-entropy loss, where the labels are sentiment intensity/polarity."
                ],
                "publication_ref": [
                    "b16",
                    "b44"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Zero-Shot Prediction by Simulating Propagation with Social Prompts",
                "text": [
                    "To forecast responses in a zero-shot fashion, one approach involves directly feeding user profiles, historical data, and news headlines into large language models like ChatGPT. However, this approach lacks the inclusion of the user's social network and encounters challenges when dealing with lurkers who have limited background information.",
                    "As demonstrated in the experiment section, including social context provides a clear advantage in response forecasting. In this section, we introduce the concept of SOCIAL PROMPT to simulate information propagation in the supervised setting.",
                    "Neighborhood Filtering To aggregate information, one needs to select information from neighbors. Since language models have a limited context window and a user typically has hundreds of followers/followings, we filter the set of neighbors by ranking the neighbors based on their influence on the user's opinion. In our design, we utilize the concept of authority from the persuasion techniques (Braca and Dondio, 2023), using the number of followers a neighbor has to determine their level of influence. We select the top-K neighbors N K as the filtered set to represent the social context of the central user.",
                    "Aggregation and Prediction Given the latent user personas attributes, User n L extracted for each neighbor n \u2208 N K of central node c, extracted from Section 3.1 for each neighbor, and the filtered neighborhood from the previous step, we construct a prompt P s (shown in the Appendix) that allows the LLM to produce a socially aware persona User S . Finally, we design a prediction prompt P p , which utilizes both User L and User S of the central node to make predictions. Formally,",
                    "R = LLM(P p , U c L , LLM(P s , {U n L } n\u2208N K ))(2)",
                    "where U abbreviates User, U c indicates the current central user, and R indicates the prediction results."
                ],
                "publication_ref": [
                    "b3"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Experiment",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Data Construction",
                "text": [
                    "We use the dataset from (Sun et al., 2023) (denoted as RFPN) as the base for evaluation. The dataset consists of 13.3k responses from 8.4k users to 3.8k news headlines collected from Twitter. More details are shown in the Appendix.",
                    "Network Data To test SOCIALSENSE, we curate a social network using the official Twitter API 1 . We initialize the network with the users in RFPN X s . We collect all the users that each user u \u2208 X s follows and denote them as X t . We then select the top 10000 followed accounts from X t \u222a X s as the most influential nodes, and denote them X f . Lastly, we merge the top influencers with the original user set X s into the final set V U = X f \u222a X s . Our final graph consists of 18, 634 users and 1, 744, 664 edges."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Experimental Setup",
                "text": [
                    "Evaluation Metrics We evaluate the prediction of sentiment intensity using the Spearman and Pearson correlation, which are denoted as r s and r, respectively. For the classification of sentiment polarity, we evaluate with the Micro-F1 score (or equivalently accuracy in the multi-class case) and Macro-F1 score, denoted as MiF1 and MaF1.",
                    "Baselines We conduct a comparative analysis of SOCIALSENSE with several baseline models, including DeBERTa (He et al., 2020) (upon which our node initialization is based) and RoBERTa (Liu et al., 2019b), which are state-of-the-art pretrained language models known for their performance across various downstream tasks like sentiment analysis and information extraction. Additionally, we compare our approach with the InfoVGAE model (Li et al., 2022), a state-of-the-art graph representation learning model specifically designed for social polarity detection. InfoVGAE constructs a graph that captures the edges between users and news articles to learn informative node embeddings. We extend this model by incorporating user-user edges and also an additional two-layer MLP classifier head to adapt it for our supervised tasks. Furthermore, we include two naive baselines, namely Random and Majority. The Ran-dom baseline makes predictions randomly, while the Majority baseline follows the majority label. These baselines serve as simple reference points for comparison. Lastly, we compare our response forecasting results with ChatGPT, a state-of-theart zero-shot instruction-following large language model (LLM) (Yang et al., 2023). To predict the sentiment intensity and polarity using ChatGPT, we use the prompt P p from Section 3.4 that incorporates the user profile, user history, and the news media message as the input. We leverage the official OpenAPI with the gpt-3.5-turbo model 2 for sentiment prediction.",
                    "To illustrate the effectiveness of SOCIAL PROMPTS (Section 3.4), we compare three models: baseline ChatGPT, ChatGPT L , and SocialSense Zero . In ChatGPT L , we incorporate the latent persona User L from Section 3.1, while in SocialSense Zero , we leverage the aggregated social context User S generated by SOCIAL PROMPT in addition to User L (Section 3.4). We use K = 25 for SOCIAL PROMPT. Similarly, we utilize the prompt P p for response prediction. The detailed prompts can be found in the Appendix. Implementation and Environments Our neural models are implemented using Pytorch (Paszke et al., 2019) and Huggingface Transformers (Wolf et al., 2020). The intensity label in the dataset follows the definition in the SemEval-2018 Task 1 3 (Mohammad et al., 2018), where the sign is also considered during evaluation. More implementation details and discussions of reproducibility and hyperparameters can be found in the Appendix."
                ],
                "publication_ref": [
                    "b16",
                    "b32",
                    "b25",
                    "b31",
                    "b39",
                    "b47",
                    "b36"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Results Discussion",
                "text": [
                    "We conduct an evaluation of the proposed SO-CIALSENSE model and the baseline models introduced in Section 4.2 for the supervised response forecasting task. The evaluation results are presented in Table 1. While the state-of-the-art models demonstrate competitive performance, SO-CIALSENSE outperforms all other models across all evaluation metrics consistently. Although Chat-GPT is designed and proven effective for zero-shot instruction-following text generation, we observe that its performance in sentiment forecasting of responses is comparatively limited, yielding lower scores compared to the other supervised models. This highlights that the task can not be fully addressed by a zero-shot model alone.",
                    "On the other hand, the RoBERTa and DeBERTa models, despite being smaller pre-trained models, exhibit relatively better correlation and F1 scores after fine-tuning for our response prediction task on news articles. However, these models only utilize textual information from news articles and user profiles, disregarding potential interaction patterns and shared beliefs among users. This explains why their correlations and F1 scores are, on average, 10.28% and 5.99% lower than those achieved by the proposed SOCIALSENSE framework. Additionally, the graph-based InfoVGAE model achieves higher scores compared to the text-based DeBERTa and RoBERTa baselines, highlighting the significance of graph-structured data in enhancing response forecasting performance. However, the evaluation metrics of the InfoVGAE model remain lower than those of SOCIALSENSE. While the InfoV-GAE model constructs a graph primarily based on user-user and user-news interaction edges, SO-CIALSENSE goes a step further by inducing and integrating additional belief nodes and edges. This novel approach results in a heterogeneous graph that forges connections among users who share similar perspectives and ideologies, thereby facilitating the learning of intricate social dynamics and bolstering the model's predictive capabilities."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_1"
                ]
            },
            {
                "heading": "Ablation Study",
                "text": [
                    "We conduct an ablation study on different components of SOCIALSENSE to evaluate their impact on performance. The results are presented in Table 1. Belief-Centered Graph To assess the effectiveness of the Belief-Centered Graph in Section 3.2, we conduct an experiment where we removed the belief nodes from the graph, including the nodes representing moral values and human values. This leads to a decrease of 1.91% in correlations and 4.83% in F1 scores. These findings support our hypothesis that incorporating belief nodes is effective in modeling the shared beliefs and values among users. By including belief nodes, we enable the graph learning framework to capture the association between the underlying principles and moral frameworks that guide users' behaviors and response patterns. User-News Edges In this experiment, we exclude the user-news edges while constructing the beliefaugmented heterogeneous graph. The results show that modeling the user-news interaction as edges results in an improvement of up to 6.63% in correlation metrics for sentiment intensity prediction. This indicates that modeling users' interests and historical interactions with media is crucial for accurately predicting sentiment intensity. User Profile and Historical Posts The ablation study reveals the important roles of user profile data and historical post data in response forecasting. Excluding user profile data leads to a drop of 1.93% and 6.32% on average in the respective tasks, emphasizing its significance in predicting sentiment polarity. Removing historical post data results in a decrease of approximately 4.45% in correlations and 2.66% in F1 scores for sentiment polarity prediction. These findings highlight the importance of both data types, with profile data influencing intensity prediction more and historical data affecting polarity prediction more. Node Initialization Instead of using the text representations of users' profiles and historical posts, we randomly initialize the node features. This results in a decrease of 3.57% in correlations and a significant decrease of 8.97% in F1 scores for polarity classification, emphasizing the significance of text features in predicting sentiment polarity."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_1"
                ]
            },
            {
                "heading": "Zero-Shot Evaluation",
                "text": [
                    "In addition to supervised response forecasting, we also evaluate our framework under the zeroshot setting (Section 3.4). The results are presented in Table 2. Based on the higher scores attained by ChatGPT L , it is evident that the in-  clusion of latent structured persona information indeed aids the model in comprehending the user more effectively. Furthermore, our model, SO-CIALSENSE Zero , achieves the highest scores consistently across all metrics. This demonstrates the efficacy of our method for zero-shot social context learning and provides compelling evidence that even in the zero-shot setting, social context plays a crucial role in response forecasting."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_2"
                ]
            },
            {
                "heading": "Evaluation on Lurker and Unseen User Scenarios",
                "text": [
                    "We evaluate the performance of proposed models and baselines on the task of response forecasting for lurker users, who are characterized as users with only a small amount of historical posts. In the experiment, we define the lurkers as the users with less than 50 historical responses (less than 85% of the users in the dataset), and the scenario consequently contains 745 test samples. The scores are shown in Table 3. Compared to the previous evaluation results in Table 1, we observe that the overall evaluation scores for all the models are significantly lower. This can be attributed to the fact that lurkers have a much smaller background context, making response prediction more challeng-ing. The lurker case is especially difficult for those baselines relying heavily on historical responses. In this challenging scenario, SOCIALSENSE not only achieves significantly higher scores than others in all of the metrics but also maintains its performance on the polarity measures. Specifically, the advantage of our proposed model over DeBERTa and RoBERTa expands from 5.99% to 11.26% in terms of F1 scores for sentiment polarity prediction. These results demonstrate that even in cases where user textual information is extremely limited, our framework can still accurately infer responses, showcasing the robustness of our method. Furthermore, it is worth noting that the intensity score was noticeably lower compared to the regular setting, indicating that predicting the intensity of responses becomes more challenging when historical information is limited. We conduct further evaluation of the proposed model and baselines on unseen users, which refers to the responders who only appear in the evaluation dataset. This case study on unseen users provides insights into the generalization of the models. The evaluation results are presented in Table 3. The results indicate that the unseen user scenario presents a more challenging task compared to previous settings. Moreover, SOCIALSENSE demonstrates significantly higher performance across all metrics compared to other baselines. This outcome underscores the framework's ability to effectively generalize to unseen users, likely attributed to its robust modeling of the social network and encoding of relationships between users."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_3",
                    "tab_1",
                    "tab_3"
                ]
            },
            {
                "heading": "Related Work",
                "text": [
                    "Existing research has focused on predicting the individual-level response using additional textual features as well as deep neural networks (DNN) (Lin and Chen, 2008;Artzi et al., 2012;Li et al., 2019;Wang et al., 2020). However, these existing methods neglected the important information about users' personas as well as the modeling of graph-structured interactions among users with the social items. Another line of related works formulates the response forecasting as text-level generation task (Yang et al., 2019;Wu et al., 2021;Lu et al., 2022;Wang et al., 2021). However, these lack a quantitative measure for analyzing the response (such as in the sentiment dimensions), limiting their applicability in downstream tasks like sentiment prediction on impact evaluation of news (Sun et al., 2023). In contrast, we propose a novel framework that leverages large language models to induce the graph structure and integrates disentangled social values to forecast responses, whether in a supervised or zero-shot manner. Our work demonstrates that effectively modeling the social context and beliefs of users provides a clear advantage in the social media response forecast task. This can ultimately benefit various downstream applications such as assisting fine-grained claim frame extraction (Gangi Reddy et al., 2022) and situation understanding (Reddy et al., 2023).",
                    "In the field of Social-NLP, related research has focused on applying NLP techniques, large language models (LLM), and prompting strategies to model, analyze, and understand text data generated in social contexts. For instance, progress has been made in misinformation detection (Fung et al., 2021;Wu et al., 2022;Huang et al., 2023b) and correction (Huang et al., 2023a), propaganda identification (Martino et al., 2020;Oliinyk et al., 2020;Yoosuf and Yang, 2019), stance detection (Zhang et al., 2023), ideology classification (Kulkarni et al., 2018;Kannangara, 2018), LM detoxification (Han et al., 2023), norms grounding (Fung et al., 2023), popularity tracking (He et al., 2016;Chan and King, 2018), and sentiment analysis (Araci, 2019;Liu et al., 2012;Azzouza et al., 2020). The emergence of advanced decoder language models like ChatGPT has led to extensive research on prompting techniques and their application across various NLP tasks (Zhou et al., 2022;Kojima et al., 2022;Zhao et al., 2021;Diao et al., 2023;Sun et al., 2022). Indeed, experiments have shown that Chat-GPT even outperforms crowd workers in certain annotation tasks (Gilardi et al., 2023). However, when it comes to social tasks like response forecasting, relying solely on large-scale models without taking into account the social context and users' personas may not yield optimal performance (Li et al., 2023). Our experiments demonstrate that incorporating social context in the prompt consistently enhances the LLM's performance, as showcased in our simulation of information propagation using large language models. operates on the premise that connecting distant users in social networks facilitates the modeling of implicit communities based on shared beliefs. Through comprehensive evaluations, we demonstrate the superior performance of our framework compared to existing methods, particularly in handling lurker and unseen user scenarios. We also highlight the importance of the different components within the framework. In future research, it would be valuable to explore the application of belief-augmented social networks in other domains and to develop an effective social prompting strategy for general-purpose applications. Furthermore, it is worth investigating how response forecasting models can adapt efficiently to dynamically evolving data, especially given the swift changes observed in real-world social media platforms (de Barros et al., 2023;Cheang et al., 2023)."
                ],
                "publication_ref": [
                    "b28",
                    "b1",
                    "b33",
                    "b45",
                    "b10",
                    "b40",
                    "b8",
                    "b48",
                    "b20",
                    "b19",
                    "b52",
                    "b23",
                    "b21",
                    "b15",
                    "b4",
                    "b0",
                    "b29",
                    "b2",
                    "b22",
                    "b54",
                    "b7",
                    "b12",
                    "b5"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Limitations",
                "text": [
                    "While the proposed SOCIALSENSE framework demonstrates promising results in response forecasting, there are limitations to consider. Firstly, the performance of the model heavily relies on the quality and availability of social network data. In scenarios where these sources are extremely limited or noisy, the model's predictive capabilities may be compromised. Additionally, the generalizability of the framework to different domains and cultural contexts needs to be further explored and evaluated."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Ethics Statements",
                "text": [
                    "The primary objective of this study is to enable content producers to predict the impact of news releases, thereby mitigating the risk of unforeseen negative consequences such as social conflict and moral injury. By providing a stronger and more robust framework for forecasting responses, we aim to contribute to the creation of a safer online environment. In our process of collecting the network data using Twitter API, we strictly adhere to the Twitter API's Terms of Use 4 . As part of our commitment to responsible data handling, we will release only an anonymized version of the network data when making the code repository publicly available. dimensions from {128, 256}. We perform our experiments on a single NVIDIA RTX A6000 48 GB. Our model consists of 10, 484, 424 tuning parameters and it takes less than 30 minutes to fine-tune."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.2 Analysis of Belief Data",
                "text": [
                    "We perform additional analysis on the belief data. Specifically, we show the distribution of the belief data (Figure 4), for which the moral value of care is dominant among the users. We have also segregated the model's performance in sentiment prediction based on the users' belief values and show it in Table 6. Empirical results indicate that the model is more accurate when predicting sentiments for users characterized by universalism and degradation. Conversely, the model finds it challenging to predict sentiments for users in the categories of security and stimulation. We further sampled 50 ChatGPT extraction results from user histories and distributed them among three human raters to assess the accuracy of the extracted profiles. These raters are graduate students who qualified through an initial quiz comprising eight samples. On evaluation, the raters assigned an average score of 3.9 out of 5 for accuracy. While not flawless, these extracted beliefs play a significant role in boosting the model's performance. Such finding indicates that refining the ChatGPT extraction process could potentially lead to enhanced performance outcomes."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_4"
                ],
                "table_ref": []
            },
            {
                "heading": "A.3 Prompts Templates",
                "text": [
                    "We show all prompts used in the work in Figure 5, Figure 6, Figure 7, Figure 8, and Figure 9. They represent P l , P s , P p for the baseline ChatGPT, P p for ChatGPT L , and P p for SocialSense Zero respectively.    "
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_5",
                    "fig_6",
                    "fig_7"
                ],
                "table_ref": []
            },
            {
                "heading": "Acknowledgement",
                "text": [
                    "This research is based upon work supported in part by U.S. DARPA INCAS Program No. HR001121C0165. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of DARPA, or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation therein."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A Appendix",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.1 Implementation Details",
                "text": [
                    "We implement the training framework using the 4.8.2 version of Huggingface Transformer library 5 (Wolf et al., 2020). For the graph model implementation in Section 3.3, we use the 2.0.3 version of PyG 6 . The hyperparameters for the experiment are shown in Table 4 and the ones not listed in the table are set to be default values from the transformer library. We use RAdam (Liu et al., 2019a) as the optimizer. We perform greedy hyperparameter search on the gnn_layer from {1,2,3}, learning rate from {5e-5, 1e-4, 5e-4, 1e-3}, # attention heads from {2, 4, 6, 8}, activation from {tanh, relu}, # epochs from {350, 1000}, and node   "
                ],
                "publication_ref": [
                    "b47",
                    "b30"
                ],
                "figure_ref": [],
                "table_ref": []
            }
        ],
        "references": [
            {
                "ref_id": "b0",
                "title": "Finbert: Financial sentiment analysis with pre-trained language models",
                "journal": "",
                "year": "2019",
                "authors": "Dogu Araci"
            },
            {
                "ref_id": "b1",
                "title": "Predicting responses to microblog posts",
                "journal": "",
                "year": "2012",
                "authors": "Yoav Artzi; Patrick Pantel; Michael Gamon"
            },
            {
                "ref_id": "b2",
                "title": "Twitterbert: Framework for twitter sentiment analysis based on pre-trained language model representations",
                "journal": "Springer",
                "year": "2020",
                "authors": "Noureddine Azzouza; Karima Akli-Astouati; Roliana Ibrahim"
            },
            {
                "ref_id": "b3",
                "title": "Persuasive communication systems: a machine learning approach to predict the effect of linguistic styles and persuasion techniques",
                "journal": "Journal of Systems and Information Technology",
                "year": "2023",
                "authors": "Annye Braca; Pierpaolo Dondio"
            },
            {
                "ref_id": "b4",
                "title": "Thread popularity prediction and tracking with a permutationinvariant model",
                "journal": "",
                "year": "2018-10-31",
                "authors": "Pong Hou; Irwin Chan;  King"
            },
            {
                "ref_id": "b5",
                "title": "Can LMs Generalize to Future Data? An Empirical Analysis on Text Summarization",
                "journal": "",
                "year": "2023",
                "authors": "Chi Seng Cheang; Derek F Hou Pong Chan; Xuebo Wong; Zhaocong Liu; Yanming Li; Shudong Sun; Lidia S Liu;  Chao"
            },
            {
                "ref_id": "b6",
                "title": "A survey on embedding dynamic graphs",
                "journal": "ACM Comput. Surv",
                "year": "2023",
                "authors": "R F Matheus; Alex Borges Mendon\u00e7a; Artur Vieira;  Ziviani"
            },
            {
                "ref_id": "b7",
                "title": "Active prompting with chain-ofthought for large language models",
                "journal": "",
                "year": "2023",
                "authors": "Shizhe Diao; Pengcheng Wang; Yong Lin; Tong Zhang"
            },
            {
                "ref_id": "b8",
                "title": "Infosurgeon: Cross-media fine-grained information consistency checking for fake news detection",
                "journal": "Long Papers",
                "year": "2021",
                "authors": "Yi Fung; Christopher Thomas; Revanth Gangi Reddy; Sandeep Polisetty; Heng Ji; Shih-Fu Chang; Kathleen Mckeown; Mohit Bansal; Avirup Sil"
            },
            {
                "ref_id": "b9",
                "title": "Normsage: Multi-lingual multi-cultural norm discovery from conversations on-the-fly",
                "journal": "",
                "year": "2023",
                "authors": "Yi R Fung; Tuhin Chakraborty; Hao Guo; Owen Rambow; Smaranda Muresan; Heng Ji"
            },
            {
                "ref_id": "b10",
                "title": "NewsClaims: A new benchmark for claim detection from news with attribute knowledge",
                "journal": "",
                "year": "2022",
                "authors": " Revanth Gangi Reddy; Zhenhailong Sai Chetan Chinthakindi; Yi Wang; Kathryn Fung; Ahmed Conger; Martha Elsayed; Preslav Palmer; Eduard Nakov; Kevin Hovy; Heng Small;  Ji"
            },
            {
                "ref_id": "b11",
                "title": "Emotional influence prediction of news posts",
                "journal": "",
                "year": "2018",
                "authors": "Anastasia Giachanou; Paolo Rosso; Ida Mele; Fabio Crestani"
            },
            {
                "ref_id": "b12",
                "title": "Chatgpt outperforms crowd-workers for textannotation tasks",
                "journal": "",
                "year": "2023",
                "authors": "Fabrizio Gilardi; Meysam Alizadeh; Ma\u00ebl Kubli"
            },
            {
                "ref_id": "b13",
                "title": "Matt Motyl, Peter Meindl, Carol Iskiwitch, and Marlon Mooijman",
                "journal": "",
                "year": "2018",
                "authors": "Jesse Graham; Jonathan Haidt"
            },
            {
                "ref_id": "b14",
                "title": "Lm-switch: Lightweight language model conditioning in word embedding space",
                "journal": "",
                "year": "2023",
                "authors": "Chi Han; Jialiang Xu; Manling Li; Yi Fung; Chenkai Sun; Nan Jiang; Tarek Abdelzaher; Heng Ji"
            },
            {
                "ref_id": "b15",
                "title": "Deep reinforcement learning with a combinatorial action space for predicting popular reddit threads",
                "journal": "The Association for Computational Linguistics",
                "year": "2016-11-01",
                "authors": "Ji He; Mari Ostendorf; Xiaodong He; Jianshu Chen; Jianfeng Gao; Lihong Li; Li Deng"
            },
            {
                "ref_id": "b16",
                "title": "Deberta: Decoding-enhanced bert with disentangled attention",
                "journal": "",
                "year": "2020",
                "authors": "Pengcheng He; Xiaodong Liu; Jianfeng Gao; Weizhu Chen"
            },
            {
                "ref_id": "b17",
                "title": "Disinformation researchers raise alarms about a.i. chatbots",
                "journal": "",
                "year": "2023",
                "authors": "Tiffany Hsu; Stuart A Thompson"
            },
            {
                "ref_id": "b18",
                "title": "Heterogeneous graph transformer",
                "journal": "",
                "year": "2020",
                "authors": "Ziniu Hu; Yuxiao Dong; Kuansan Wang; Yizhou Sun"
            },
            {
                "ref_id": "b19",
                "title": "Zero-shot faithful factual error correction",
                "journal": "Long Papers",
                "year": "2023-07-09",
                "authors": "Kung-Hsiang Huang; Heng Hou Pong Chan;  Ji"
            },
            {
                "ref_id": "b20",
                "title": "Manitweet: A new benchmark for identifying manipulation of news on social media",
                "journal": "",
                "year": "2023",
                "authors": "Kung-Hsiang Huang; Hou Pong Chan; Kathleen R Mckeown; Heng Ji"
            },
            {
                "ref_id": "b21",
                "title": "Mining twitter for finegrained political opinion polarity classification, ideology detection and sarcasm detection",
                "journal": "",
                "year": "2018",
                "authors": "Sandeepa Kannangara"
            },
            {
                "ref_id": "b22",
                "title": "Large language models are zero-shot reasoners",
                "journal": "",
                "year": "2022",
                "authors": "Takeshi Kojima; Shane Shixiang; Machel Gu; Yutaka Reid; Yusuke Matsuo;  Iwasawa"
            },
            {
                "ref_id": "b23",
                "title": "Multi-view models for political ideology detection of news articles",
                "journal": "",
                "year": "2018",
                "authors": "Vivek Kulkarni; Junting Ye; Steven Skiena; William Yang Wang"
            },
            {
                "ref_id": "b24",
                "title": "Senti2pop: sentiment-aware topic popularity prediction on social media",
                "journal": "IEEE",
                "year": "2019",
                "authors": "Jinning Li; Yirui Gao; Xiaofeng Gao; Yan Shi; Guihai Chen"
            },
            {
                "ref_id": "b25",
                "title": "Unsupervised belief representation learning with informationtheoretic variational graph auto-encoders",
                "journal": "",
                "year": "2022",
                "authors": "Jinning Li; Huajie Shao; Dachun Sun; Ruijie Wang; Yuchen Yan; Jinyang Li; Shengzhong Liu"
            },
            {
                "ref_id": "b26",
                "title": "",
                "journal": "",
                "year": "",
                "authors": "Sha Li; Chi Han; Pengfei Yu; Carl Edwards; Manling Li; Xingyao Wang; Yi R Fung; Charles Yu; Joel R "
            },
            {
                "ref_id": "b27",
                "title": "2023. Defining a new nlp playground. ACL Findings",
                "journal": "",
                "year": "",
                "authors": "Heng Tetreault;  Hovy; H; Eduard;  Ji"
            },
            {
                "ref_id": "b28",
                "title": "Ranking reader emotions using pairwise loss minimization and emotional distribution regression",
                "journal": "Association for Computational Linguistics",
                "year": "2008",
                "authors": "Kevin Hsin-Yih Lin; Hsin-Hsi Chen"
            },
            {
                "ref_id": "b29",
                "title": "Emoticon smoothed language models for twitter sentiment analysis",
                "journal": "",
                "year": "2012",
                "authors": " Kun-Lin; Wu-Jun Liu; Minyi Li;  Guo"
            },
            {
                "ref_id": "b30",
                "title": "On the variance of the adaptive learning rate and beyond",
                "journal": "",
                "year": "2019",
                "authors": "Liyuan Liu; Haoming Jiang; Pengcheng He; Weizhu Chen; Xiaodong Liu; Jianfeng Gao; Jiawei Han"
            },
            {
                "ref_id": "b31",
                "title": "Summary of chatgpt/gpt-4 research and perspective towards the future of large language models",
                "journal": "",
                "year": "2023",
                "authors": "Yiheng Liu; Tianle Han; Siyuan Ma; Jiayue Zhang; Yuanyuan Yang; Jiaming Tian; Hao He; Antong Li; Mengshen He; Zhengliang Liu"
            },
            {
                "ref_id": "b32",
                "title": "Roberta: A robustly optimized bert pretraining approach",
                "journal": "",
                "year": "2019",
                "authors": "Yinhan Liu; Myle Ott; Naman Goyal; Jingfei Du; Mandar Joshi; Danqi Chen; Omer Levy; Mike Lewis; Luke Zettlemoyer; Veselin Stoyanov"
            },
            {
                "ref_id": "b33",
                "title": "Partner personas generation for dialogue response generation",
                "journal": "",
                "year": "2022",
                "authors": "Hongyuan Lu; Wai Lam; Hong Cheng; Helen Meng"
            },
            {
                "ref_id": "b34",
                "title": "2020. A survey on computational propaganda detection",
                "journal": "",
                "year": "",
                "authors": "Giovanni Da San; Stefano Martino; Alberto Cresci; Seunghak Barr\u00f3n-Cede\u00f1o; Roberto Di Yu; Preslav Pietro;  Nakov"
            },
            {
                "ref_id": "b35",
                "title": "The behaviors and attitudes of us adults on twitter",
                "journal": "",
                "year": "2021",
                "authors": "Colleen Mcclain; Regina Widjaya; Gonzalo Rivero; Aaron Smith"
            },
            {
                "ref_id": "b36",
                "title": "Semeval-2018 task 1: Affect in tweets",
                "journal": "",
                "year": "2018",
                "authors": "Saif Mohammad; Felipe Bravo-Marquez; Mohammad Salameh; Svetlana Kiritchenko"
            },
            {
                "ref_id": "b37",
                "title": "Khrystyna Mykich, and V\u00edtor Basto Fernandes. 2020. Propaganda detection in text data based on nlp and machine learning",
                "journal": "",
                "year": "",
                "authors": "Victoria Vitaliia-Anna Oliinyk; Yevhen Vysotska;  Burov"
            },
            {
                "ref_id": "b38",
                "title": "Avoiding potential 'extinction event' from ai requires action, us official says",
                "journal": "",
                "year": "2023",
                "authors": "Quinn Owen; Max Zahn"
            },
            {
                "ref_id": "b39",
                "title": "Pytorch: An imperative style, high-performance deep learning library",
                "journal": "",
                "year": "2019",
                "authors": "Adam Paszke; Sam Gross; Francisco Massa; Adam Lerer; James Bradbury; Gregory Chanan; Trevor Killeen; Zeming Lin; Natalia Gimelshein; Luca Antiga"
            },
            {
                "ref_id": "b40",
                "title": "Smartbook: Aiassisted situation report generation",
                "journal": "",
                "year": "2023",
                "authors": "Yi R Revanth Gangi Reddy; Qi Fung; Manling Zeng; Ziqi Li; Paul Wang;  Sullivan"
            },
            {
                "ref_id": "b41",
                "title": "Universals in the content and structure of values: Theoretical advances and empirical tests in 20 countries",
                "journal": "Elsevier",
                "year": "1992",
                "authors": "H Shalom;  Schwartz"
            },
            {
                "ref_id": "b42",
                "title": "Measuring the effect of influential messages on varying personas",
                "journal": "",
                "year": "2023",
                "authors": "Chenkai Sun; Jinning Li; Chengxiang Hou Pong Chan; Heng Zhai;  Ji"
            },
            {
                "ref_id": "b43",
                "title": "Incorporating task-specific concept knowledge into script learning",
                "journal": "",
                "year": "2022",
                "authors": "Chenkai Sun; Tie Xu; Chengxiang Zhai; Heng Ji"
            },
            {
                "ref_id": "b44",
                "title": "Attention is all you need",
                "journal": "",
                "year": "2017",
                "authors": "Ashish Vaswani; Noam Shazeer; Niki Parmar; Jakob Uszkoreit; Llion Jones; Aidan N Gomez; \u0141ukasz Kaiser; Illia Polosukhin"
            },
            {
                "ref_id": "b45",
                "title": "Generating diversified comments via reader-aware topic modeling and saliency detection",
                "journal": "",
                "year": "2021",
                "authors": "Wei Wang; Piji Li; Hai-Tao Zheng"
            },
            {
                "ref_id": "b46",
                "title": "Sentiment forecasting in dialog",
                "journal": "",
                "year": "2020",
                "authors": "Zhongqing Wang; Xiujun Zhu; Yue Zhang; Shoushan Li; Guodong Zhou"
            },
            {
                "ref_id": "b47",
                "title": "Transformers: State-of-the-art natural language processing",
                "journal": "Association for Computational Linguistics",
                "year": "2020",
                "authors": "Thomas Wolf; Lysandre Debut; Victor Sanh; Julien Chaumond; Clement Delangue; Anthony Moi; Pierric Cistac; Tim Rault; Remi Louf; Morgan Funtowicz; Joe Davison; Sam Shleifer; Clara Patrick Von Platen; Yacine Ma; Julien Jernite; Canwen Plu; Teven Le Xu; Sylvain Scao; Mariama Gugger; Quentin Drame; Alexander Lhoest;  Rush"
            },
            {
                "ref_id": "b48",
                "title": "Cross-document misinformation detection based on event graph reasoning",
                "journal": "",
                "year": "2022",
                "authors": "Xueqing Wu; Kung-Hsiang Huang; Yi Fung; Heng Ji"
            },
            {
                "ref_id": "b49",
                "title": "2021. Personalized response generation via generative split memory network",
                "journal": "Online. Association for Computational Linguistics",
                "year": "",
                "authors": "Yuwei Wu; Xuezhe Ma; Diyi Yang"
            },
            {
                "ref_id": "b50",
                "title": "Qizhang Feng, Haoming Jiang, Bing Yin, and Xia Hu. 2023. Harnessing the power of llms in practice: A survey on chatgpt and beyond",
                "journal": "",
                "year": "",
                "authors": "Jingfeng Yang; Hongye Jin; Ruixiang Tang; Xiaotian Han"
            },
            {
                "ref_id": "b51",
                "title": "Read, attend and comment: A deep architecture for automatic news comment generation",
                "journal": "",
                "year": "2019",
                "authors": "Ze Yang; Can Xu; Wei Wu; Zhoujun Li"
            },
            {
                "ref_id": "b52",
                "title": "Fine-grained propaganda detection with fine-tuned bert",
                "journal": "",
                "year": "2019",
                "authors": "Shehel Yoosuf; Yin Yang"
            },
            {
                "ref_id": "b53",
                "title": "Vibe: Topicdriven temporal adaptation for twitter classification",
                "journal": "",
                "year": "2023",
                "authors": "Yuji Zhang; Jing Li; Wenjie Li"
            },
            {
                "ref_id": "b54",
                "title": "Calibrate before use: Improving few-shot performance of language models",
                "journal": "PMLR",
                "year": "2021",
                "authors": "Zihao Zhao; Eric Wallace; Shi Feng; Dan Klein; Sameer Singh"
            },
            {
                "ref_id": "b55",
                "title": "Least-to-most prompting enables complex reasoning in large language models",
                "journal": "",
                "year": "",
                "authors": "Denny Zhou; Nathanael Sch\u00e4rli; Le Hou; Jason Wei; Nathan Scales; Xuezhi Wang; Dale Schuurmans; Olivier Bousquet"
            },
            {
                "ref_id": "b56",
                "title": "Graph neural networks: A review of methods and applications. AI open",
                "journal": "",
                "year": "2020",
                "authors": "Jie Zhou; Ganqu Cui; Shengding Hu; Zhengyan Zhang; Cheng Yang; Zhiyuan Liu; Lifeng Wang; Changcheng Li; Maosong Sun"
            }
        ],
        "figures": [
            {
                "figure_label": "1",
                "figure_type": "figure",
                "figure_id": "fig_0",
                "figure_caption": "Figure 1 :1Figure 1: An example illustrating the task. The input consists of user attributes such as the profile and social context together with a news media message. The model is asked to predict response in multiple dimensions.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_2",
                "figure_caption": "(u, b) \u2208 E B , where u \u2208 V U and b \u2208 V B , it denotes that user u believes in the value represented by node b. An illustrative example sub-graph of the network is shown in Figure 3. Social Relation Network The first layer of our network consists of the user-user social network, where edges from User a to b indicate that User a follows User b. This network captures the interests of users and the relationships between users. User-Media Interactions The second component of our network comprises news nodes and response edges indicating the users in the network have responded to these news nodes in the dataset. This feature offers two advantages. Firstly, it serves as a representation of users' interests. Secondly, it facilitates the connection of users who are geographically distant in the network but might share interests in news topics, thus enabling the expansion of the set of potentially reliable neighbors for any user we would like to predict. Belief-Centered Graph Lastly, we introduce belief nodes, composed of moral and human values (principles that guide behaviors) from the Latent Personas. MORAL VALUES: Moral values are derived from a set of principles that guide individuals or societies in determining what is right or wrong, good or bad, and desirable or undesirable. We define the set of Moral Values based on the Moral Foundations Theory (Graham et al., 2018), which includes Care/Harm, Fairness/Cheating, Loyalty/Betrayal, Authority/Subversion, and Purity/Degradation. HUMAN VALUES: Human values are defined based on the Schwartz Theory of Basic Values (Schwartz, 1992), encompassing Conformity, Tradition, Security, Power, Achievement, Hedonism, Stimulation, Self-Direction, Universalism, and Benevolence. These values represent desirable goals in human life that guide the selection or evaluation of actions and policies.",
                "figure_data": ""
            },
            {
                "figure_label": "3",
                "figure_type": "figure",
                "figure_id": "fig_3",
                "figure_caption": "Figure 3 :3Figure 3: An example illustrating a snapshot of the belief-centered social network. The latent persona attributes serve as a bridge between (potentially distant) users who share values. The arrow on the top left refers to the response we aim to forecast.",
                "figure_data": ""
            },
            {
                "figure_label": "4",
                "figure_type": "figure",
                "figure_id": "fig_4",
                "figure_caption": "Figure 4 :4Figure 4: Distribution of belief values",
                "figure_data": ""
            },
            {
                "figure_label": "6",
                "figure_type": "figure",
                "figure_id": "fig_5",
                "figure_caption": "Figure 6 :6Figure 6: Prompt template P s used for aggregating neighbor information in Section 3.4. It takes a list of latent profiles from neighbors, where the latent profiles are output from P l .",
                "figure_data": ""
            },
            {
                "figure_label": "7",
                "figure_type": "figure",
                "figure_id": "fig_6",
                "figure_caption": "Figure 7 :7Figure 7: Prompt template P p used for predicting responses given only news message, user profile text, and concatenated user historical posts as input. It is used for evaluating the baseline ChatGPT.",
                "figure_data": ""
            },
            {
                "figure_label": "8",
                "figure_type": "figure",
                "figure_id": "fig_7",
                "figure_caption": "Figure 8 :8Figure 8: Prompt template P p using user latent profile in addition to input Figure 7. It is used for evaluating ChatGPT L .",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "",
                "figure_caption": "",
                "figure_data": ""
            },
            {
                "figure_label": "1",
                "figure_type": "table",
                "figure_id": "tab_1",
                "figure_caption": "Response forecasting results. We report the Spearman and Pearson correlations for the forecasting of sentiment intensity, as well as Micro F1 and Macro F1 scores for the sentiment polarity prediction. The best overall performance is in bold. Our framework outperforms the baselines consistently.",
                "figure_data": "Method\u03d5int (%) rs r\u03d5p (%) MiF1 MaF1Majority Random ChatGPT DeBERTa RoBERTa InfoVGAE SocialSense-0.62 43.80 44.15 58.61 48.67 -43.41 20.18 0.41 35.51 30.55 50.81 50.58 64.77 59.30 52.09 53.00 65.26 59.02 58.61 58.37 67.46 60.05 61.82 61.98 70.45 65.71w/o belief w/o user-news 55.43 55.35 66.51 61.96 59.92 60.06 66.80 59.70 w/o profile 59.94 60.01 64.49 59.04 w/o history 57.60 57.29 67.95 62.89 w/ random init 58.25 58.40 61.79 56.44"
            },
            {
                "figure_label": "2",
                "figure_type": "table",
                "figure_id": "tab_2",
                "figure_caption": "The above Zero-Shot Response forecasting results highlight that the SOCIAL PROMPT from Section 3.4 consistently offers an advantage.",
                "figure_data": "Method\u03d5int (%) rs r\u03d5p (%) MiF1 MaF1ChatGPT ChatGPTL SocialSenseZero 46.64 47.22 60.54 51.30 43.8 44.15 58.61 48.67 44.43 44.76 59.77 48.69Method\u03d5int (%) rs r\u03d5p (%) MiF1 MaF1Case Study: Lurker UsersDeBERTa RoBERTa InfoVGAE SocialSense 50.30 53.57 71.01 63.88 39.58 36.72 59.20 51.98 43.21 41.67 60.81 52.74 37.37 36.60 61.34 47.61Case Study: Unseen UsersDeBERTa RoBERTa InfoVGAE SocialSense 44.40 44.27 62.55 55.37 41.72 39.32 55.56 48.80 38.06 35.71 55.20 47.99 36.08 35.06 56.27 47.86"
            },
            {
                "figure_label": "3",
                "figure_type": "table",
                "figure_id": "tab_3",
                "figure_caption": "The case studies for Lurker and Unseen User Scenarios demonstrate that our framework exhibits significantly improved generalization capabilities when the user is unseen or has limited background context.",
                "figure_data": ""
            }
        ],
        "formulas": [
            {
                "formula_id": "formula_0",
                "formula_text": "R = LLM(P p , U c L , LLM(P s , {U n L } n\u2208N K ))(2)",
                "formula_coordinates": [
                    5.0,
                    80.52,
                    745.69,
                    209.35,
                    28.42
                ]
            }
        ],
        "doi": "10.18653/v1/d18-1376"
    },
    "Fine-grained Conversational Decoding via Isotropic and Proximal Search": {
        "authors": "Yuxuan Yao; Han Wu; Qiling Xu; Linqi Song",
        "pub_date": "",
        "abstract": "General-purpose text decoding approaches are usually adopted for dialogue response generation. Although the quality of the generated responses can be improved with dialogue-specific encoding methods, conversational decoding methods are still under-explored. Inspired by Wu et al. ( 2023) that a good dialogue feature space should follow the rules of locality and isotropy, we present a fine-grained conversational decoding method, termed isotropic and proximal search (IPS). Our method is designed to generate the semantic-concentrated response, while still maintaining informativeness and discrimination against the context. Experiments show that our approach outperforms existing decoding strategies in the dialogue field across both automatic and human evaluation metrics. More in-depth analyses further confirm the effectiveness of our approach.",
        "sections": [
            {
                "heading": "Introduction",
                "text": [
                    "Dialogue response generation (Li et al., 2017;Wang et al., 2020) aims to generate the utterance that forms a coherent and fluent continuation given a dialogue context. Generic text decoding strategies (Rieser et al., 2014;Ritter et al., 2011;Chen et al., 2017) are usually adopted to produce grammatical and contextual responses. As an independent technique, decoding strategy can also enhance the generation quality of large language models.",
                    "Existing text decoding methods have been explored in various generic text generation tasks, but lack tailoring for dialogue generation, e.g., capturing dialogue-specific features and generating an informative and discriminative dialogue response (Su et al., 2021;Wu et al., 2023). Early maximizationbased methods, e.g., greedy search (Li et al., 2016b) and beam search (Wiseman et al., 2017), may lead to dullness and degeneration (Fan et al., 2018;Holtzman et al., 2018). Later sampling-based improvements are proposed to tackle these problems, including top-k sampling (Fan et al., 2018) and nucleus search (Holtzman et al., 2018). While alleviating degeneration, these sampling methods introduce critical semantic inconsistency and are not aligned with human-written prefix (Basu et al., 2021). Specifically, a bunch of studies (Ethayarajh, 2019;Su and Collier, 2023) have asserted that the problem of anisotropy, i.e., a distribution pattern in the latent space with features occupying a narrow cone in the space, leads to inconsistency and degradation of the generation. Although contrastive search (Su et al., 2022) has been proposed correspondingly to mitigate the issue, as a generalized text decoding strategy, it still ignores dialoguespecific features, such as utterance dependencies and conversational structure information. Therefore, research on conversational decoding methods is warmly needed.",
                    "In this work, we propose a fine-grained conversational decoding method, namely isotropic and proximal search (IPS). Different from traditional approaches, we consider the previous tokens and contexts separately from a granular perspective. Acknowledging that locality and isotropy are two important properties for refining the dialogue feature space, we design our IPS following these rules: (i) the generated output should be selected from the most probable candidate set predicted by the dialogue model; (ii) the generated tokens in the same utterance should be proximal to each other for expressing a concentrated idea; and (iii) the newly generated utterance should be discriminative enough with respect to the context utterances. In this way, our method encourages informativeness and discrimination among different utterances as well as maintains a concentrated idea within an utterance. We evaluate our approach on two commonly-used dialogue datasets, DailyDialog (Li et al., 2017) in English and LCCC (Wang et al., 2020) in Chinese. Both human and automatic evaluation results, i.e., indicators based on GPT3.5, consistently show that IPS can generate more fluent, coherent, and human-like responses than existing decoding methods."
                ],
                "publication_ref": [
                    "b9",
                    "b19",
                    "b14",
                    "b15",
                    "b1",
                    "b18",
                    "b21",
                    "b8",
                    "b20",
                    "b3",
                    "b4",
                    "b3",
                    "b4",
                    "b0",
                    "b2",
                    "b16",
                    "b17",
                    "b9",
                    "b19"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Methodology",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Preliminary",
                "text": [
                    "Dialogue response generation Given a dialogue context D = {u 1 , u 2 , ..., u N } composed of N utterances, where u i = x i,1 , x i,2 , ..., x i,|u i | is a sequence of consecutive words, the task of dialogue response generation is to produce the continuation utterance u r = {w 1 , w 2 , ..., w |ur| }, (r = N + 1).",
                    "There are generally two key steps to finish the task, including context encoding and response decoding. For the first step, we obtain the context representations H from the language model by concatenating the utterances into a sequence.",
                    "H = PrLM(u 1 [EOU] u 2 [EOU] ... u N [EOU]),",
                    "where [EOU] is the special token inserted as the last token of each utterance.",
                    "For the decoding step, the response is generally produced in an auto-regressive manner as follows",
                    "p(w 1:|ur| ) = |ur| i=1 p(w i |w <i , D)(1)",
                    "Dialogue modeling Wu et al. (2023) has demonstrated that locality and isotropy are two key properties for building a good conversational feature space. Specifically, locality encourages the model to aggregate the representations of tokens within an utterance while isotropy pushes away the representations of distinct utterances."
                ],
                "publication_ref": [
                    "b21"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Isotropic and Proximal Search",
                "text": [
                    "We present a fine-grained conversational decoding method, i.e., isotropic and proximal search (IPS). Specifically, we expect the generated response to satisfy two requirements: 1) representations of the response tokens are nearby to convey a concentrated idea, saying proximity; 2) the response representation is discriminative to the context utterance representations, saying isotropy. During the decoding stage, for proximal search, we try to select the candidate token having the shortest average distance to the existing generated tokens. For isotropic search, we try to choose the token that enables the response representation most discriminative to representations of context utterances. As the response representation cannot be determined during the decoding stage, we calculate it in an approximate way, i.e., averaging the representations of the already generated tokens, as follows:",
                    "h RT = 1 T T i=1 h w i (2)",
                    "where h RT is the response representation which will be dynamically updated along with the generation process, and T is the number of already generated tokens.",
                    "Up to now, the problem changes to how to generate the first token for starting the isotropic and proximal search since the method is heavily dependent on the previous tokens. To address this problem, we attempt to finish the first n-steps generation by traditional decoding methods, such as beam search, top-k sampling or nucleus sampling. On the other hand, as IPS is essentially a deterministic decoding strategy, this solution also enables it to produce diverse responses by using different decoding strategies in the first n steps. Therefore, in each step t after the first sampling stage, we calculate the proximal and isotropic values as follows:",
                    "p_value t = 1 t \u2212 1 t\u22121 i=1 s(h wt , h w i ) (3) i_value t = 1 N N i=1 s(h RT , h u i ) (4",
                    ")",
                    "where s is the cosine similarity. h u i are the utterance representations obtained from the special token [EOU]. The proximal value measures the average distance between the candidate token and the already generated tokens while the isotropic value stands for the average similarity between the undergoing response representation and all utterance representations. Next, the selection of the candidate token w t is formulated as,",
                    "w t = argmax wt\u2208V (m) {\u03b1 \u00d7 p(w t | w <t , D) model confidence + (1 \u2212 \u03b1) \u00d7 (p_value t \u2212 i_value t )",
                    "isotropic and proximal penalty",
                    "} (5)",
                    "where V (m) is the set of top-m predictions from the model's probability distribution p(w t | w <t , D) and m, is typically set as 4 \u223c 8. In Eq. ( 5), the first term, model confidence, is the probability of the candidate w t predicted by the model. The second term, isotropic and proximal penalty, aims to maximize the discrimination between the undergoing response and previous utterances and minimize the  (Zhang* et al., 2020), MV represents MAUVE (Pillutla et al., 2021), and GE represents G-Eval (Liu et al., 2023).",
                    "token difference within the response. The hyperparameter \u03b1 \u2208 [0, 1] regulates the importance of these two components. When \u03b1 = 1, our method degenerates to the greedy search method. We claim our method is fine-grained because the generic auto-regressive generation predicts the next token by jointly considering the already generated tokens w <t and the context D, formulated as p(w t |w <t , D) while IPS splits these two factors. Specifically, proximity value only focuses on the effects of the already generated tokens, i.e., p_value t \u223c p(w t |w <t ), and isotropy value pays more attention to the context, i.e., i_value t \u223c p(w t |D, (w <t )) wherein w <t is just used to obtain the undergoing response representation h RT ."
                ],
                "publication_ref": [
                    "b22",
                    "b13",
                    "b11"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Experiments",
                "text": [
                    "Dataset We evaluate our method on two commonly-used datasets, DailyDialog (Li et al., 2017) in English and LCCC (Wang et al., 2020) in Chinese. Both of them are open-domain multi-turn dialogue datasets, collected from social media. For LCCC, owing to the academic-level computing resource, we follow previous work (Su et al., 2022), and sample a subset of the dataset, consisting of 100,000 dialogue examples.",
                    "Baselines Following Wu et al. (2023), we use BART (Lewis et al., 2020) as our backbone. We evaluate the performance of decoding strategies with different models, including vanilla BART, BART with SimCTG (Su et al., 2022), and BART with SimDRC (Wu et al., 2023). We compare IPS to greedy search, beam search, top-k sampling (Fan et al., 2018), nucleus sampling (Holtzman et al., 2018) and contrastive search (Su et al., 2022). MAUVE (Pillutla et al., 2021), Distinct2/4 (Li et al., 2016a), and G-Eval, an automatic evaluation metric based on GPT3.5 (Liu et al., 2023).",
                    "We also conduct a human evaluation with the help of recruited proficient English/Chinese speakers. We randomly sample 100 dialogue examples from DailyDialog and LCCC test sets. For each dialogue context, we generate responses using the aforementioned backbone models (BART, BART+SimCTG, BART+SimDRC) with six different inference strategies. Five annotators are hired independently to measure these samples. Annotators are instructed to give a score ranging from 1 to 5 over the following aspects, including fluency, informativeness, coherence, and semantic coverage 1 ."
                ],
                "publication_ref": [
                    "b9",
                    "b19",
                    "b17",
                    "b21",
                    "b6",
                    "b17",
                    "b21",
                    "b3",
                    "b4",
                    "b17",
                    "b13",
                    "b7",
                    "b11"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Results and Discussion",
                "text": [
                    "Table 1 lists the automatic evaluation results of the different methods with different decoding strategies. Similar results can be also found in human evaluation, as shown in Table 2. We can see that the models, collaborating with IPS, can produce more semantically consistent(high BERTScores and MAUVE scores) and human-like (high G-Eval scores) responses. Although contrastive search can generate more novel and diverse tokens (high Distinct scores), it usually suffers from the problem of prediction deviation, i.e., the predicted token being weakly related to the main idea of the response. This is also in line with the worse performance of contrastive search on other metrics, such as BERTScore, and G-Eval, indicating that the diverse responses produced by contrastive search are not accurate and human-like enough. Different from contrastive search, IPS tries to concentrate on the core meaning of the response and express it clearly, thus a slightly lower Distinct score is acceptable and expected. Note that IPS still has better distinct scores than other traditional decoding methods since it encourages discrimination and isotropy among utterances.",
                    "1 Details of human evaluation are in Appendix A.1.",
                    "Although IPS can be directly used with different models and achieve good performance, the models trained with SimDRC are the best testbed for IPS. We can see that SimDRC+IPS can mostly achieve the best performance across the board on both automatic and human evaluation. This is reasonable because the training process of SimDRC is greatly consistent with the search criterion of IPS, and they both push away the inter-utterance features and pull close the intra-utterance features.",
                    "Ablation Study Figure 1 shows the ablation studies on different components of the method, including the first n steps, the sampling strategy for the first n-step decoding, and the weight \u03b1. As shown in Figure 1(a), our method consistently outperforms the contrastive search no matter the number of first steps. We find some performance drops with the increase of the first-stage sampling steps. We think this is because more generic tokens are selected by traditional search methods, thus weakening the proximity and isotropy of the response. For strategies in the first n steps, we attempt beam search, top-k sampling, and nucleus sampling. We finally select top-k sampling as our first stage's strategy owing to its better performance in the comparisons. Figure 1(b) shows the results of different k values adopted in top-k sampling. We can see that our method exceeds the baseline by a large margin when k > 5. The effect of weight \u03b1 is also studied, as shown in Figure 1(c). Our method consistently outperforms the baseline with the different weights, suggesting the robustness of our method.",
                    "Hyperparameter Analysis To explore the effects of isotropy and proximity, in our experiments, we introduced a hyperparameter \u03b2 to balance the p_value and i_value as:",
                    "(1 \u2212 \u03b2) \u00d7 p_value \u2212 \u03b2 \u00d7 i_value (6)",
                    "We tried the effects of \u03b2 ranging from 0.2 to 0.8. We surprisingly found that the balance of proximal value and isotropy value leads to the best performance, saying \u03b2 equals 0.5. This finding is a bit different from the observations in SimDRC (Wu et al., 2023) which suggests that larger isotropy loss weight is needed to balance the two properties in the training stage. We think this is because our method is a decoding strategy, rather than the training optimization process. The sparse isotropy values would not cause the model bias in the decoding stage. So, the harmonious balance of proximity and isotropy can be simply achieved by giving a moderate value of \u03b2."
                ],
                "publication_ref": [
                    "b21"
                ],
                "figure_ref": [
                    "fig_0",
                    "fig_0",
                    "fig_0",
                    "fig_0"
                ],
                "table_ref": [
                    "tab_0",
                    "tab_2"
                ]
            },
            {
                "heading": "Conclusion",
                "text": [
                    "In this work, we present a fine-grained conversational decoding strategy, namely isotropic and proximal search (IPS) to encourage the generation of isotropic and conversational tokens. Superior to existing decoding methods, IPS decouples the previous tokens and the context. Experiments show that our method achieves impressive performance on both automatic and human evaluation."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Ackonwledgements",
                "text": [
                    "This work was supported in part by the InnoHK initiative, the Government of the HKSAR, Laboratory for AI-Powered Financial Technologies."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Limitations",
                "text": [
                    "During the experiments, we found that for a single piece of data in the DailyDialog test set, traditional text decoding methods such as beam search, top-k sampling and beam search take less than 1 second, the contrastive search takes about 5.07s, and the decoding time required by our proposed IPS is about 2.16s. Although our approach takes longer than the traditional text decoding method, our calculation speed is obviously faster than contrastive search. How to further improve the computing speed is still the direction we need to work on."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Ethics Statement",
                "text": [
                    "In this work, we use publicly released datasets to auxiliary our dialogue response generation. Generally, these previous works have considered ethical issues when creating the datasets. We have manually checked some samples for the datasets we used in this work, and do not find any obvious ethical concerns, such as violent or offensive content. We will also release the source decoding code with friendly instructions to support its correct use. However, we still need to emphasize that text generation is not as controllable as we think. It still would generate some novel or unexpected words occasionally. We may take actions to decrease generation diversity to alleviate this problem.",
                    "\u2022 2: The text has major errors in both grammar and spelling. The errors make the text hard to read.",
                    "\u2022 1: The text does not make sense and it is unreadable."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.1.2 Informativeness",
                "text": [
                    "This measures whether the generated text has diverse, informative, novel, or logically related content. The definitions of different scores are:",
                    "\u2022 5: The text contains very diverse, informative, and novel content. It is enjoyable to read the text.",
                    "\u2022 4: The text contains many informative and novel contents. (Choose this score when you hesitate between 3 and 5.)",
                    "\u2022 3: The text contains some new information but also contains a few repetitions of the context.",
                    "\u2022 2: The text only contains a few informative and new terms. (Choose this score when you hesitate between 1 and 3.)",
                    "\u2022 1: The text is dull, repetitive, and has no new information. All contents are from the dialogue context."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.1.3 Coherence",
                "text": [
                    "This measures whether the generated text is semantically and factually consistent with the dialogue context. The definitions of different scores are:",
                    "\u2022 5: The text is semantically, factually, and topically consistent with the dialogue context. All contents of the text are related to the source text or can be inferred from the source.",
                    "\u2022 4: The text is very related to the context but has minor inconsistencies or contradictions that do not affect its overall relevance.",
                    "\u2022 3: The text is related to the context but has some obvious inconsistencies and contradictions.",
                    "\u2022 2: The text is slightly consistent with the context. Many inconsistencies and contradictions in the context can be found.",
                    "\u2022 1: The text is totally inconsistent with the context. It semantically or factually contradicted the context."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.1.4 Semantic Coverage",
                "text": [
                    "This measures how many semantic content units from the target response are covered by the generated text. The definitions of different scores are:",
                    "\u2022 5: All semantic content units of the target text can be found in the generated text. They are semantically consistent.",
                    "\u2022 4: Most of the content units of the target text can be found from the generated text while a few missing units do not affect the overall coverage.",
                    "\u2022 3: Some semantic content units can be found in the generated text but also miss some important units.",
                    "\u2022 2: Most of the semantic content units are not covered. Only a few insignificant units can be found in the generated text.",
                    "\u2022 1: The text does not have any overlapping semantic content units with the target text.",
                    "We recruit five human workers to annotate 3,600 samples. To make sure the workers are fairly paid, we pay 0.1 dollars for each sample. Therefore, the total amount spent on participant compensation is 360 dollars. The annotators take 24 hours to finish the task, suggesting the hourly wage for each worker is 15 dollars."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.2 More Details of the Task",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.2.1 Evaluation of G-EVAL Score",
                "text": [
                    "The API we used to test G-EVAl is gpt-3.5-turbo, and the following is the prompt (Liu et al., 2023):",
                    "You will be given a conversation between two individuals. You will then be given one potential response for the next turn in the conversation. Your task is to give a final score for utterance. Please make sure you read and understand these instructions carefully.",
                    "The evaluation aspects are:",
                    "1. Engagingness: Is the response dull or interesting?",
                    "3. Informativeness: This measures whether the generated text has diverse, informative, novel, or logically related content.",
                    "4. Coherence: This measures whether the generated text is semantically and factually consistent with the dialogue context.",
                    "The evaluation steps are:",
                    "1. Read the conversation, the corresponding label, and the response carefully.",
                    "2. Considering the above evaluation aspects, return a comprehensive final score ranging from 1 to 5 for each conversation.",
                    "3. Please only return 1 overall score, without any extra text descriptions. The return format should be like Score:1. Now please read the following conversation, and return the score."
                ],
                "publication_ref": [
                    "b11"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.2.2 More Experimental Results",
                "text": [
                    "Table 2 lists the results of human evaluation."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_2"
                ]
            },
            {
                "heading": "A.3 Surface-level Analysis",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.3.1 Score Distribution According to the Length of the Previous Context",
                "text": [
                    "Table 3 and Table 4 illustrate the relations between the context length and the human evaluation metrics while using the IPS (the above one) and beam search (the below one) decoding strategies. Observing the table, when the context length is particularly short (<10), we speculate that the context may consist of simple greetings or introductions, resulting in lower difficulty of generation and thus higher scores. When the context length varies in the range of approximately 10 to 40, due to differences in the complexity of context content and semantics, the scores exhibit a fluctuating trend. As the length continues to increase, the information provided by the previous context becomes richer, leading to improved effectiveness of both decoding methods. We also note that when faced with exceptionally long contexts, the generation quality of IPS is superior to the baselines."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.3.2 Utterance Length Analysis",
                "text": [
                    "Table 5 shows that both IPS and contrastive search tend to produce shorter sentences than traditional methods. We explain in the main text that by incorporating isotropy, achieved through contrastive search and IPS, redundancy is minimized, resulting in more concise generated text compared to previous methods. Considering the nature of the conversation, our IPS strategy expects proximity and does not enlarge the token distance in the same utterance, thus responses of IPS are slightly longer than that of contrastive search.",
                    "A.4 Qualitative Analysis"
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_3"
                ]
            },
            {
                "heading": "A.4.1 Instances Illustration",
                "text": [
                    "Some examples are presented to illustrate the effect of our IPS search.",
                    "In summation, according to Table 6 and Table 7, some qualitative observations are as follows:",
                    "\u2022 Replies generated by IPS are more natural and accurate.",
                    "\u2022 IPS tends to generate relatively concise responses.",
                    "\u2022 With more complex previous contexts, we observed that IPS does not prioritize shortening the length of response. IPS can generate responses that are more in line with the situation based on the characteristics of the conversation."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_5"
                ]
            },
            {
                "heading": "A.5 Cosine Similarity Heatmap",
                "text": [
                    "To ensure utterances generated by our IPS are isotropic and proximal, and observe the representations produced by different decoding methods, we showcase the cosine similarity matrix of token representations correspondingly.",
                    "The larger color difference between different sentences represents greater isotropy, indicating discrimination among utterances; while the darker the color within the same sentence, the greater the proximity, conveying a more concentrated thought.",
                    "Choosing SimDRC as the backbone model, cosine similarity heatmaps of different inference methods are shown as follows. Tokens generated by IPS exhibit brighter colors in the heatmap, indicating increased proximity within the same sentence, while tokens from IPS showcase darker colors for different sentences, signifying greater isotropy. Contrastingly, traditional methods like beam search showed anisotropy(i.e. features occupy a narrow cone in the vector space, thus leading to the problem of degeneration.) in the figures.   Table 3: Relations between the context length and the human evaluation metrics while using the IPS."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.6 Examples of Generated Texts",
                "text": [
                    "For non-native Chinese speakers, translations of Table 9 are presented in Table 10. The quality of the LCCC dataset still requires optimization, as it contains numerous colloquial and slang expressions. We are not professional translators, and in our attempts, we noticed that the translated meanings sometimes diverged from the original Chinese. We apologize for the inconvenience.    "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_7",
                    "tab_0"
                ]
            },
            {
                "heading": "",
                "text": "Settings We fine-tune the models on DailyDialog and LCCC datasets for 6k steps and 7k steps, respectively. We use a batch size of 64 and truncate the training samples to a maximum length of 256. The parameters of the models are initialized from HuggingFace libraries and updated by Adam optimizer (Kingma and Ba, 2017) with a learning rate of 3e-5. We adopt the margin values of SimCTG and SimDRC suggested in their work, i.e., \u03c1 = 0.5 for SimCTG and \u03b4 = 0.7, \u03b1 = 0.3 for SimDRC. We conduct the isotropic and proximal search with the first n = 2 steps adopting top-k sampling (k = 7). The weight \u03b1 is 0.6. We run all experiments with five different seeds and report the average score.",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A Appendix",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.1 Human Evaluation Instructions",
                "text": [
                    "Please rate the quality of the generated response based on the given dialogue context and the target response over the following aspects: (1) Fluency;",
                    "(2) Informativeness; (3) Coherence; (4) Semantic Coverage. We provide some instructions for your rating."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.1.1 Fluency",
                "text": [
                    "This measures whether the generated text has no formatting problems, capitalization errors, or obviously ungrammatical sentences (e.g., fragments, missing components) that make the text difficult to read. The definitions of different scores are:",
                    "\u2022 5: The text is fluent, grammatically correct, and has no errors. It is easy to read.",
                    "\u2022 4: The text is grammatically correct but has a few spelling or capitalization errors, which does not affect your understanding.",
                    "\u2022 3: The text has minor errors in both grammar and spelling. The errors slightly affect your understanding.  "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            }
        ],
        "references": [
            {
                "ref_id": "b0",
                "title": "Mirostat: A neural text decoding algorithm that directly controls perplexity",
                "journal": "",
                "year": "2021",
                "authors": "Sourya Basu; Govardana Sachitanandam Ramachandran; Nitish Shirish Keskar; Lav R Varshney"
            },
            {
                "ref_id": "b1",
                "title": "A survey on dialogue systems",
                "journal": "ACM SIGKDD Explorations Newsletter",
                "year": "2017",
                "authors": "Hongshen Chen; Xiaorui Liu; Dawei Yin; Jiliang Tang"
            },
            {
                "ref_id": "b2",
                "title": "How contextual are contextualized word representations? Comparing the geometry of BERT, ELMo, and GPT-2 embeddings",
                "journal": "Association for Computational Linguistics",
                "year": "2019",
                "authors": "Kawin Ethayarajh"
            },
            {
                "ref_id": "b3",
                "title": "Hierarchical neural story generation",
                "journal": "Association for Computational Linguistics",
                "year": "2018",
                "authors": "Angela Fan; Mike Lewis; Yann Dauphin"
            },
            {
                "ref_id": "b4",
                "title": "Learning to write with cooperative discriminators",
                "journal": "Long Papers",
                "year": "2018",
                "authors": "Ari Holtzman; Jan Buys; Maxwell Forbes; Antoine Bosselut; David Golub; Yejin Choi"
            },
            {
                "ref_id": "b5",
                "title": "Adam: A method for stochastic optimization",
                "journal": "",
                "year": "2017",
                "authors": "P Diederik; Jimmy Kingma;  Ba"
            },
            {
                "ref_id": "b6",
                "title": "BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
                "journal": "",
                "year": "2020",
                "authors": "Mike Lewis; Yinhan Liu; Naman Goyal; Marjan Ghazvininejad; Abdelrahman Mohamed; Omer Levy; Veselin Stoyanov; Luke Zettlemoyer"
            },
            {
                "ref_id": "b7",
                "title": "A diversity-promoting objective function for neural conversation models",
                "journal": "Association for Computational Linguistics",
                "year": "2016",
                "authors": "Jiwei Li; Michel Galley; Chris Brockett; Jianfeng Gao; Bill Dolan"
            },
            {
                "ref_id": "b8",
                "title": "Deep reinforcement learning for dialogue generation",
                "journal": "Association for Computational Linguistics",
                "year": "2016",
                "authors": "Jiwei Li; Will Monroe; Alan Ritter; Dan Jurafsky; Michel Galley; Jianfeng Gao"
            },
            {
                "ref_id": "b9",
                "title": "DailyDialog: A manually labelled multi-turn dialogue dataset",
                "journal": "Long Papers",
                "year": "2017",
                "authors": "Yanran Li; Hui Su; Xiaoyu Shen; Wenjie Li; Ziqiang Cao; Shuzi Niu"
            },
            {
                "ref_id": "b10",
                "title": "ROUGE: A package for automatic evaluation of summaries",
                "journal": "Association for Computational Linguistics",
                "year": "2004",
                "authors": "Chin-Yew Lin"
            },
            {
                "ref_id": "b11",
                "title": "G-eval: Nlg evaluation using gpt-4 with better human alignment",
                "journal": "",
                "year": "2023",
                "authors": "Yang Liu; Dan Iter; Yichong Xu; Shuohang Wang; Ruochen Xu; Chenguang Zhu"
            },
            {
                "ref_id": "b12",
                "title": "Bleu: a method for automatic evaluation of machine translation",
                "journal": "Association for Computational Linguistics",
                "year": "2002",
                "authors": "Kishore Papineni; Salim Roukos; Todd Ward; Wei-Jing Zhu"
            },
            {
                "ref_id": "b13",
                "title": "MAUVE: Measuring the gap between neural text and human text using divergence frontiers",
                "journal": "",
                "year": "2021",
                "authors": "Krishna Pillutla; Swabha Swayamdipta; Rowan Zellers; John Thickstun; Sean Welleck; Yejin Choi; Zaid Harchaoui"
            },
            {
                "ref_id": "b14",
                "title": "Natural language generation as incremental planning under uncertainty: Adaptive information presentation for statistical dialogue systems",
                "journal": "IEEE/ACM Trans. Audio, Speech and Lang. Proc",
                "year": "2014",
                "authors": "Verena Rieser; Oliver Lemon; Simon Keizer"
            },
            {
                "ref_id": "b15",
                "title": "Data-driven response generation in social media",
                "journal": "",
                "year": "2011",
                "authors": "Alan Ritter; Colin Cherry; William B Dolan"
            },
            {
                "ref_id": "b16",
                "title": "Contrastive search is what you need for neural text generation. Transactions on Machine Learning Research",
                "journal": "",
                "year": "2023",
                "authors": "Yixuan Su; Nigel Collier"
            },
            {
                "ref_id": "b17",
                "title": "A contrastive framework for neural text generation",
                "journal": "",
                "year": "2022",
                "authors": "Yixuan Su; Tian Lan; Yan Wang; Dani Yogatama; Lingpeng Kong; Nigel Collier"
            },
            {
                "ref_id": "b18",
                "title": "Prototype-tostyle: Dialogue generation with style-aware editing on retrieval memory",
                "journal": "IEEE/ACM Transactions on Audio, Speech, and Language Processing",
                "year": "2021",
                "authors": "Yixuan Su; Yan Wang; Deng Cai; Simon Baker; Anna Korhonen; Nigel Collier"
            },
            {
                "ref_id": "b19",
                "title": "A large-scale chinese short-text conversation dataset",
                "journal": "Springer-Verlag",
                "year": "1418",
                "authors": "Yida Wang; Pei Ke; Yinhe Zheng; Kaili Huang; Yong Jiang; Xiaoyan Zhu; Minlie Huang"
            },
            {
                "ref_id": "b20",
                "title": "Challenges in data-to-document generation",
                "journal": "Association for Computational Linguistics",
                "year": "2017",
                "authors": "Sam Wiseman; Stuart Shieber; Alexander Rush"
            },
            {
                "ref_id": "b21",
                "title": "Learning locality and isotropy in dialogue modeling",
                "journal": "",
                "year": "2023",
                "authors": "Han Wu; Haochen Tan; Mingjie Zhan; Gangming Zhao; Shaoqing Lu; Ding Liang; Linqi Song"
            },
            {
                "ref_id": "b22",
                "title": "Bertscore: Evaluating text generation with bert",
                "journal": "",
                "year": "2020",
                "authors": "Tianyi Zhang; * ; Varsha Kishore; * ; Felix Wu; * ; Kilian Q Weinberger; Yoav Artzi"
            },
            {
                "ref_id": "b23",
                "title": "Table 4: Relations between the context length and the human evaluation metrics while using the beam search. Sentence_Len dd-drc dd-ctg dd-bart lccc-drc lccc-ctg lccc-bart Greedy",
                "journal": "",
                "year": "",
                "authors": ""
            }
        ],
        "figures": [
            {
                "figure_label": "1",
                "figure_type": "figure",
                "figure_id": "fig_0",
                "figure_caption": "Figure 1 :1Figure 1: Ablation study on the DailyDialog dataset.",
                "figure_data": ""
            },
            {
                "figure_label": "2",
                "figure_type": "figure",
                "figure_id": "fig_1",
                "figure_caption": "Figure 2 :2Figure 2: An image of a cosine similarity heatmap",
                "figure_data": ""
            },
            {
                "figure_label": "1",
                "figure_type": "table",
                "figure_id": "tab_0",
                "figure_caption": "Automatic evaluation results on DailyDialog and LCCC, where BS means F1 value of BERTScore",
                "figure_data": "DailyDialogLCCCModelStrategy greedyBS \u2191 0.1275 0.569 MV \u2191 GE \u2191 2.17Distinct Dis2 \u2191 Dis4 \u2191 0.344 0.776BS \u2191 0.0636 0.062 MV \u2191 GE \u2191 1.88Distinct Dis2 \u2191 Dis4 \u2191 0.126 0.437beam0.1317 0.5992.290.3410.7550.0639 0.1451.910.1550.466BARTtop-k nucleus0.1312 0.623 0.1298 0.6422.20 2.340.350 0.3520.780 0.7910.0648 0.154 0.0626 0.1781.94 1.910.152 0.1560.487 0.534contrastive 0.1147 0.6222.070.3960.8100.0538 0.2051.900.1900.583IPS0.1335 0.6472.430.3550.7980.0653 0.2121.980.1760.540greedy0.1099 0.4472.210.3060.7090.0678 0.0881.820.1370.470beam0.1196 0.5562.270.3140.7130.0692 0.2062.020.1790.539SimCTGtop-k0.1169 0.5442.060.3220.7330.0695 0.1952.110.1680.534(\u03c1 = 0.5)nucleus0.1169 0.5712.320.3270.7530.0680 0.2232.100.1690.575contrastive 0.1123 0.6082.170.3950.8070.0607 0.2781.980.1970.618IPS0.1293 0.6282.360.3590.7870.0704 0.2942.310.1960.580greedy0.1255 0.5602.060.3450.7740.0699 0.0902.210.1360.471SimDRC (\u03b4 = 0.7, \u03b1 = 0.3)beam top-k nucleus contrastive 0.1174 0.653 0.1315 0.632 0.1068 0.648 0.1284 0.6322.18 2.20 2.16 2.160.338 0.345 0.353 0.3970.745 0.773 0.793 0.8190.0715 0.196 0.0720 0.203 0.0697 0.226 0.0613 0.2712.11 2.19 1.88 2.210.180 0.166 0.166 0.1970.543 0.540 0.569 0.614IPS0.1336 0.6652.460.3660.8000.0722 0.2722.320.1920.569"
            },
            {
                "figure_label": "2",
                "figure_type": "table",
                "figure_id": "tab_2",
                "figure_caption": "Results of human evaluation on DailyDialog and LCCC datasets, where SC means the semantic coverage, info. means informativeness.",
                "figure_data": "Length Fluency Informativeness Coherence Semantic Coverage num[0,10)4.944.564.673.069[10,20)4.933.53.622.7713[20,30)4.73443.0911[30,40)4.753.5642.6712[40,50)4.853.673.562.289[50,75)4.953.523.612.4517[75,100)4.83.523.792.8415over 1004.933.794.212.9614"
            },
            {
                "figure_label": "5",
                "figure_type": "table",
                "figure_id": "tab_3",
                "figure_caption": "Sentence-level Analysis",
                "figure_data": "label\"Damn it! I'm injured here. We could wait all day for the police.\"greedy\"Alright. I'll go get it.\"beam/top-p/top-k \"I don't feel like making a police report. I need to get to the hospital.\"contrastive\"Alright. I'll call the police.\"IPS\"Oh, I don't think I can afford to wait for the police. I need to get to the hospital.\""
            },
            {
                "figure_label": "6",
                "figure_type": "table",
                "figure_id": "tab_4",
                "figure_caption": "Qualitative Instance A",
                "figure_data": "A: Good afternoon! Did you call for a plumber?contextB: Yes, yes I did. Please come in! I'm so glad you came! This old house is falling apart!Come on into the bathroom. See, here, there's water leaking everywhere!greedy\"Well, it's leaking because of the leaking faucet in the shower.\"beam/top-p \"Well, it's leaking because of the leaking faucet in the shower.\"top-k\"I'm sorry, madam, but I don't think that water is leaking. I'm going to have to check it out.\""
            },
            {
                "figure_label": "7",
                "figure_type": "table",
                "figure_id": "tab_5",
                "figure_caption": "Qualitative Instance B content A: I didn't receive an unemployment check this week and need to know why. B: Did you mail us your last Continued Claim Form? A: I am afraid that I forgot to send it in. B: We cannot pay you unless you turn that form in every two weeks. A: Is it too late to mail the Continued Claim Form in now? greedy I will mail it in right now. beam search It's too late to mail it in now. You will receive your check this week. top-k sampling I will mail it in right now if you can't wait. nucleus search It's too late to mail it in now. You will receive your check this week. contrastive search Yes, you can do it now. IPS Yes, it is. content A: Hello, this is Mike, Kara. B: Mike! Good to hear from you. How are you? A: Everything is fine, and how are you? B: Things are going well with me. A: Kara, I had fun the other night at the movies and was wondering if you would like to go out again this Friday. greedy I was thinking of it, but I am not feeling too well. I have to go to the hospital for a couple of days. beam search That sounds great. I would love to go out with you top-k sampling I would love to, but I have to work late on Friday. nucleus search That sounds great. I would love to go out with you. contrastive search Mike, I was thinking of it. IPS That sounds great. I would love to. content A: What do you think I should do, doctor? greedy I think you should have a good rest for three days. beam search I think you'd better have a good rest for three days top-k sampling I think you should go to see the head of the family. nucleus search I think you'd better have a good rest for three days. contrastive search Well, it's hard to say. You look a little pale, don't you? IPS Well, you should have a good rest for three days. Then you'll feel better.",
                "figure_data": ""
            },
            {
                "figure_label": "8",
                "figure_type": "table",
                "figure_id": "tab_6",
                "figure_caption": "Results of generation texts of DailyDialog.",
                "figure_data": "A: \u59d0\u505a\u7684\u597d\u559dcontentB: \u8fd9\u53e5\u59d0\u559c\u6b22 A: \u5982\u679c\u505a\u7ed9\u4ffa\u559d\uff0c\u90a3\u7edd\u5bf9\u662f\u7f8e\u5473\u554a\uff0c\u4eba\u95f4\u6781\u54c1\uff0c\u4f73\u80b4\u4e2d\u6ef4\u4f73\u80b4B:\u5bb6\u91cc\u6709\u8543\u8304\u4f46\u73b0\u5728\u59d0\u4e0d\u60f3\u505a\u54e9greedy\u6211\u4e5f\u559c\u6b22\u559d\uff0c\u4f46\u662f\u6211\u4e0d\u4f1a\u505a\u7ed9\u4f60\u559dbeam search\u6211\u4e5f\u4e0d\u60f3\u505a\uff0c\u6211\u559c\u6b22\u5403\u756a\u8304top-k sampling\u6211\u4e5f\u559c\u6b22\u5403\u8fd9\u79cd\u7f8e\u5473nucleus search\u6211\u4e5f\u4e0d\u60f3\u505a\u4e86\uff0c\u5c31\u662f\u559c\u6b22\u5403\"contrastive search \u6211\u4e5f\u4e0d\u60f3\u505a\uff0c\u5c31\u662f\u559c\u6b22\u5403\u8fd9\u79cd\u4e1c\u897f\u800c\u5df2IPS\u6211\u4e5f\u4e0d\u60f3\u505a\uff0c\u4f46\u662f\u6211\u559c\u6b22\u5403contentA: \u9b54\u90fd\u90fd\u4e0d\u51b7\u4e86\uff1f B: \u8fd9\u4e24\u5929\u6709\u70b9\u53cd\u5e38\u5427\u2026\u4f30\u8ba1\u8fc7\u4e24\u5929\u4f1a\u51b7\u4e0b\u53bb\u2026greedy\u6211\u4eec\u8fd9\u91cc\u4e5f\u662fbeam search\u6211\u4eec\u8fd9\u91cc\u4e5f\u662f\u8fd9\u6837\u7684\u5929\u6c14top-k sampling\u6211\u4eec\u8fd9\u91cc\u4e5f\u662f\u8fd9\u6837\u7684\u5929\u6c14nucleus search\u8fd9\u4e24\u5929\u6709\u70b9\u51b7\uff0c\u4f46\u662f\u4e5f\u4e0d\u662f\u7279\u522b\u51b7contrastive search \u8fd9\u4e24\u5929\u597d\u51b7\u554a\uff0c\u4f30\u8ba1\u660e\u5929\u5f00\u59cb\u5c31\u51b7IPS\u8fd9\u4e24\u5929\u5929\u6c14\u4e0d\u9519\uff0c\u4e0d\u8fc7\u4eca\u5929\u6709\u70b9\u51b7contentA: \u6211\u997f\u4e86\u3002greedy\u6211\u4e5f\u997f\u4e86\u3002beam search\u6211\u4e5f\u60f3\u5403\uff0c\u4f46\u662f\u6ca1\u6709\u65f6\u95f4\u3002top-k sampling\u6211\u997f\u4e86\uff0c\u6211\u8981\u53bb\u5403\u996d\u4e86\u3002nucleus search\u4f60\u600e\u4e48\u8fd9\u4e48\u65e9\u5c31\u7761\u4e86\u3002contrastive search \u6211\u4e5f\u997f\u4e86\u3002IPS\u6211\u4e5f\u997f\u4e86\uff0c\u4f60\u5403\u4e86\u5417\uff1f"
            },
            {
                "figure_label": "9",
                "figure_type": "table",
                "figure_id": "tab_7",
                "figure_caption": "Results of generation texts of LCCC.",
                "figure_data": ""
            }
        ],
        "formulas": [
            {
                "formula_id": "formula_0",
                "formula_text": "H = PrLM(u 1 [EOU] u 2 [EOU] ... u N [EOU]),",
                "formula_coordinates": [
                    2.0,
                    73.63,
                    324.8,
                    212.72,
                    13.76
                ]
            },
            {
                "formula_id": "formula_1",
                "formula_text": "p(w 1:|ur| ) = |ur| i=1 p(w i |w <i , D)(1)",
                "formula_coordinates": [
                    2.0,
                    106.31,
                    416.36,
                    183.55,
                    24.98
                ]
            },
            {
                "formula_id": "formula_2",
                "formula_text": "h RT = 1 T T i=1 h w i (2)",
                "formula_coordinates": [
                    2.0,
                    367.72,
                    123.24,
                    157.44,
                    25.77
                ]
            },
            {
                "formula_id": "formula_3",
                "formula_text": "p_value t = 1 t \u2212 1 t\u22121 i=1 s(h wt , h w i ) (3) i_value t = 1 N N i=1 s(h RT , h u i ) (4",
                "formula_coordinates": [
                    2.0,
                    334.08,
                    393.63,
                    191.07,
                    62.19
                ]
            },
            {
                "formula_id": "formula_4",
                "formula_text": ")",
                "formula_coordinates": [
                    2.0,
                    520.91,
                    435.53,
                    4.24,
                    13.15
                ]
            },
            {
                "formula_id": "formula_5",
                "formula_text": "w t = argmax wt\u2208V (m) {\u03b1 \u00d7 p(w t | w <t , D) model confidence + (1 \u2212 \u03b1) \u00d7 (p_value t \u2212 i_value t )",
                "formula_coordinates": [
                    2.0,
                    321.76,
                    592.95,
                    168.66,
                    50.81
                ]
            },
            {
                "formula_id": "formula_6",
                "formula_text": "} (5)",
                "formula_coordinates": [
                    2.0,
                    491.72,
                    615.34,
                    33.43,
                    28.41
                ]
            },
            {
                "formula_id": "formula_7",
                "formula_text": "(1 \u2212 \u03b2) \u00d7 p_value \u2212 \u03b2 \u00d7 i_value (6)",
                "formula_coordinates": [
                    4.0,
                    338.74,
                    726.32,
                    186.41,
                    20.55
                ]
            }
        ],
        "doi": "10.1145/3166054.3166058"
    },
    "Evaluating the Rationale Understanding of Critical Reasoning in Logical Reading Comprehension": {
        "authors": "Akira Kawabata; Saku Sugawara; Tom Brown; Benjamin Mann; Nick Ryder; Melanie Subbiah; Jared D Kaplan; Prafulla Dhariwal; Arvind Neelakantan; Pranav Shyam; Girish Sastry; Amanda Askell; Sandhini Agarwal; Ariel Herbert-Voss; Gretchen Krueger; Tom Henighan; Rewon Child; Aditya Ramesh; Daniel Ziegler; Jeffrey Wu; Clemens Winter; Chris Hesse; Mark Chen; Eric Sigler; Ma- Teusz Litwin; Scott Gray; Benjamin Chess; Jack Clark; Christopher Berner; Sam Mccandlish; Alec Radford; Ilya Sutskever; Dario 2020 Amodei; Dallas Card; Peter Henderson; Urvashi Khandelwal; Robin Jia; Kyle Mahowald; Dan 2020 Jurafsky; Wei-Lin Chiang; Zhuohan Li; Zi Lin; Ying Sheng; Zhanghao Wu; Hao Zhang; Lianmin Zheng; Siyuan Zhuang; Yonghao Zhuang; Joseph E Gonzalez; Ion Stoica; Eric P 2023 Xing;  Vicuna; Hyung Won; Le Hou; Shayne Longpre; Barret Zoph; Yi Tay; William Fedus; Yunxuan Li; Xuezhi Wang; Mostafa Dehghani; Siddhartha Brahma; Al- Bert Webson; Shane Shixiang; Zhuyun Gu; Mirac Dai; Xinyun Suzgun; Aakanksha Chen; Alex Chowdh- Ery; Marie Castro-Ros; Kevin Pellat; Dasha Robinson; Sharan Valter; Gaurav Narang; Adams Mishra; Vincent Yu; Yanping Zhao; Andrew Huang; Hongkun Dai; Slav Yu; Ed H Petrov; Jeff Chi; Ja- Cob Dean; Adam Devlin; Denny Roberts; Quoc V Zhou;  Le; Bhavana Dalvi; Peter Jansen; Oyvind Tafjord; Zhengnan Xie; Hannah Smith; Leighanna Pipatanangkura; Matt Gardner; Yoav Artzi; Victoria Basmov; Jonathan Berant; Ben Bogin; Sihao Chen; Pradeep Dasigi; Dheeru Dua; Yanai Elazar; Ananth Gottumukkala; Nitish Gupta; Hannaneh Hajishirzi; Gabriel Ilharco; Daniel Khashabi; Kevin Lin; Jiangming Liu; Nel- Son F Liu; Phoebe Mulcaire; Qiang Ning; Sameer Singh; Noah A Smith; Sanjay Subramanian; Reut Tsarfaty; Eric Wallace; Ally Zhang; Ben Zhou; Long Ouyang; Xu Jiang; Diogo Almeida; Carroll Wainwright; Pamela Mishkin; Chong Zhang; Katarina Slama; Alex Ray; John Schulman; Jacob Hilton; Fraser Kelton; Luke Miller; Maddie Simens; Peter Welinder; Paul F Christiano; Jan Leike; Ryan 2022 Lowe; Danilo Neves Ribeiro; Shen Wang; Xiaofei Ma; Swarnadeep Saha; Peter Hase; Nazneen Rajani; Prateek Yadav; Lisa Bauer; Mohit Bansal;  Explagraphs; Freda Shi; Xinyun Chen; Kanishka Misra; Nathan Scales; David Dohan; Ed H Chi; Nathanael Sch\u00e4rli; Denny Zhou;  Large; Vinh Q Tran; Xavier Garcia; Jason Wei; Won Chung; Dara Bahri; Tal Schuster; Steven Zheng; Neil Houlsby; Donald Metzler;  Ul2; Hugo Touvron; Thibaut Lavril; Gautier Izacard; Xavier Martinet; Marie-Anne Lachaux; Timoth\u00e9e Lacroix; Baptiste Rozi\u00e8re; Naman Goyal; Eric Hambro; Faisal Azhar; Aurelien Rodriguez; Armand Joulin; Louis Martin; Kevin Stone; Peter Al- Bert; Amjad Almahairi; Yasmine Babaei; Nikolay Bashlykov; Soumya Batra; Prajjwal Bhargava; Shruti Bhosale; Dan Bikel; Lukas Blecher; Cristian Canton Ferrer; Moya Chen; Guillem Cucurull; David Esiobu; Jude Fernandes; Jeremy Fu; Wenyin Fu; Brian Fuller; Cynthia Gao; Vedanuj Goswami; An- Thony Hartshorn; Saghar Hosseini; Rui Hou; Hakan Inan; Marcin Kardas; Viktor Kerkez; Madian Khabsa; Isabel Kloumann; Artem Korenev; Singh Koura; Jenya Lee; Di- Ana Liskovich; Yinghai Lu; Yuning Mao; Xavier Mar- Tinet; Todor Mihaylov; Pushkar Mishra; Igor Moly- Bog; Yixin Nie; Andrew Poulton; Jeremy Reizen- Stein; Rashi Rungta; Kalyan Saladi; Alan Schelten; Ruan Silva; Eric Michael Smith; Ranjan Subrama- Nian; Ellen Tan; Binh Tang; Ross Tay- Lor; Adina Williams; Jian Xiang Kuan; Puxin Xu; Zheng Yan; Iliyan Zarov; Yuchen Zhang; Angela Fan; Melanie Kambadur; Sharan Narang; Aurelien Ro- Driguez; Robert Stojnic; Sergey Edunov",
        "pub_date": "",
        "abstract": "To precisely evaluate a language model's capability for logical reading comprehension, we present a dataset for testing the understanding of the rationale behind critical reasoning. For questions taken from an existing multiplechoice logical reading comprehension dataset, we crowdsource rationale texts that explain why we should select or eliminate answer options, resulting in 3,003 multiple-choice subquestions that are associated with 943 main questions. Experiments on our dataset show that recent large language models (e.g., InstructGPT) struggle to answer the subquestions even if they are able to answer the main questions correctly. We find that the models perform particularly poorly in answering subquestions written for the incorrect options of the main questions, implying that the models have a limited capability for explaining why incorrect alternatives should be eliminated. These results suggest that our dataset encourages further investigation into the critical reasoning ability of language models while focusing on the elimination process of relevant alternatives. Mana Ashida and Saku Sugawara. 2022. Possible stories: Evaluating situated commonsense reasoning under multiple possible scenarios. In",
        "sections": [
            {
                "heading": "Introduction",
                "text": [
                    "Critical reasoning, a type of logical reasoning not tied to formal logic, is a core ability of humans that is required for thoughtful reading of text. It involves not only understanding what a passage explicitly says but also comprehending its underlying assumptions, argument structure, and supported conclusions. Developing systems capable of critical reasoning as reliably as humans is one of the ultimate goals of natural language processing. Recent studies have proposed datasets that evaluate logical reasoning including critical reasoning ability (Yu et al., 2020;Liu et al., 2020) in reading comprehension. Owing to the recent development of large language models (LLMs; Brown et al., 2020;He et al., 2023), the performance of the stateof-the-art models is nearing that of humans (Jiao et al., 2022;Wang et al., 2022). "
                ],
                "publication_ref": [
                    "b13",
                    "b5"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Passage",
                "text": [
                    "The argument proceeds by doing which one of the following?"
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Main Question",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Sub Question (on the rationale of eliminating Option A)",
                "text": [
                    "A. deriving implications of a generalization that it assumes to be true. B. showing how evidence that apparently contradicts supports the conclusion. C. enumerating problems for which it proposes a general solution. D. citing examples in support of its conclusion."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "\ud83e\udd16 \ud83e\uddd4",
                "text": [
                    "Why is the method of drawing implications from an assumed true generalization not considered the way in which the argument proceeds?  (Yu et al., 2020) and its subquestion we create to test the understanding of implicit rationale. We find that even if the model can answer the original question correctly, it cannot answer subquestions that should be answerable.",
                    "However, current multiple-choice questions in existing logical reading comprehension datasets may not sufficiently test the ability of critical reasoning. The example illustrated in Figure 1 shows that even if a model can answer a question taken from the ReClor dataset (Yu et al., 2020) that has questions for graduate admission examinations, it cannot answer an auxiliary question that queries the implicit rationale for eliminating a relevant alternative. This behavior might be due to the model's limited generalizability that is exposed by input perturbation (Si et al., 2021;Lin et al., 2021;Shi et al., 2023) or characterized as shortcut reasoning (Niven and Kao, 2019;Geirhos et al., 2020). Because a single question cannot fully ask the rationale of why we select an option as the correct answer and eliminate the others as the incorrect ones, current datasets may not be sufficient to comprehensively evaluate the process of critical reasoning.",
                    "Recent studies propose methods for probing the reasoning process using auxiliary generation tasks such as in the form of simple commonsense facts (Aggarwal et al., 2021), logical graphs (Huang et al., 2022), and arithmetic equations (Ribeiro et al., 2023). However, this line of approach may not be suitable to capture the implicit rationale of critical reasoning. In particular, it cannot explicitly consider the selection and elimination process of relevant alternatives in logical reasoning. In addition, the format of such auxiliary tasks is usually not the same as that of the main task, which may fail to evaluate the target abilities consistently.",
                    "As a first step to address these limitations, we construct a benchmark that comprehensively evaluates language models' ability of critical reasoning in logical reading comprehension. Our dataset, rationale understanding for logical reasoning evaluation (RULE), consists of main questions taken from ReClor and auxiliary subquestions that we newly create for this study. The process of constructing our dataset is illustrated in Figure 2. Our core idea is that for each answer option in a main question, we crowdsource a free-form human-written rationale that explains why that option should be selected or eliminated, and use those rationales to create a set of subquestions that are associated with the main question. After manual filtering to ensure human answerability, in addition to 943 main questions, we obtain 3,003 subquestions for the testonly purpose. The common multiple-choice format of the main questions and subquestions enables us to evaluate the models' capability of critical reasoning concisely and consistently.",
                    "In our experiments using strong baseline models including LLMs, e.g., Flan-UL2, (Tay et al., 2023), LLaMA 2 (Touvron et al., 2023b), and Instruct-GPT (Ouyang et al., 2022), we observe that the models cannot answer the main questions and subquestions consistently, showing a larger than 30% gap against humans in our strict consistency metric. In particular, we find that the models struggle to answer eliminative subquestions, which are pertinent to the rationale of eliminating incorrect options, showing a large gap (\u2248 20% accuracy) between humans and the best-performing LLM. Conversely, the models tend to correctly answer selective subquestions, which are pertinent to the rationale of selecting the correct option. This clear contrast suggests that these models provide the correct answer without fully understanding why the other options are incorrect. Our analysis using a follow-up task and manual annotations supports this observation. We also compare our human-written rationales with model-generated ones using an LLM, finding that our rationales are likely to be more detailed and supportive than the model-generated ones.",
                    "Our contributions are as follows: (i) Based on an existing logical reading comprehension dataset, we create a dataset including over 3,000 auxiliary questions designed to test a model's consistent ability for critical reasoning. (ii) We evaluate cuttingedge models, including LLMs, across finetuned, few-shot, and zero-shot settings, showing that even the best model falls short of human performance, particularly lagging in understanding eliminative rationales for incorrect answer options. (iii) Our annotation analysis also highlights the model's deficiency in understanding eliminative rationales and shows that our human-written rationales are of higher quality than model-generated ones. 1"
                ],
                "publication_ref": [
                    "b13",
                    "b13",
                    "b1",
                    "b0",
                    "b7"
                ],
                "figure_ref": [
                    "fig_1"
                ],
                "table_ref": []
            },
            {
                "heading": "Related Works",
                "text": [
                    "Critical and Logical Reasoning Critical reasoning is one of the core abilities of logical reasoning that humans perform, along with analytical reasoning (Zhong et al., 2022) and abductive reasoning (Bhagavatula et al., 2020). This reasoning is related to understanding the structure of practical arguments that is generally composed of ground (premise), warrant (rationale), and claim (conclusion). As formulated by Toulmin (2003), given facts or data as the ground, we provide the warrant that acts as a bridge between the ground and the claim we are making. Recent research includes developing ways to model this behavior in tasks such as argument mining and question answering (QA) (e.g., ReClor). For example, Habernal et al. (2018) propose a task of identifying implicit rationale (i.e., warrant) in arguments. However, Niven and Kao (2019) find that successful systems on the argument reasoning task exploit superficial input features. Similarly, QA systems have been shown to exhibit shallow understanding by input perturbation (Si et al., 2021;Lin et al., 2021;Shi et al., 2023). For example, Lin et al. (2021) demonstrate that QA performance significantly decreases when incorrect options are replaced with irrelevant texts in an adversarial manner. This means that successful models on those datasets do not nec- "
                ],
                "publication_ref": [
                    "b4"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Option D",
                "text": [
                    "deriving implications of a generalization that it assumes to be true Option A"
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "RationaleD",
                "text": [
                    "Figure 2: Our dataset construction process. We first ask crowdworkers to write the rationale for each answer option. After validating the collected rationale by aligning them to the source options, we use a large language model to generate subquestion texts. We finally ensure the human answerability of the generated subquestions.",
                    "essarily exhibit generalizable capabilities in other datasets. These findings necessitate the explainability of the (informal) logical reasoning process for better evaluation of intended reasoning abilities (e.g., the critical reasoning in this study).",
                    "Reasoning Explanation Although some studies explain the rationale behind commonsense and logical reasoning using graphs (Saha et al., 2021;Ribeiro et al., 2023), others explain it as a decomposition (Khot et al., 2020;Dalvi et al., 2021;Geva et al., 2021), a combination of supporting textual spans in the input (Yang et al., 2018;Inoue et al., 2020), commonsense rules (Saha et al., 2022), or underlying facts (Aggarwal et al., 2021). The work most similar to ours is MetaLogic (Huang et al., 2022), which focuses on generating graphs explaining the logical relations between sentences in Re-Clor examples, aiming to model the valid reasoning process. In contrast, we employ free-text rationales that explain the process of critical reasoning, enabling us to construct multiple-choice questions about the understanding of rationales. We also aim to faithfully test the models' performance on the main questions as well as auxiliary subquestions in the multiple-choice discrimination task, instead of the generation of the reasoning process in a different format from the original task."
                ],
                "publication_ref": [
                    "b2",
                    "b12",
                    "b0",
                    "b7"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "RULE Data Collection",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Design Choices",
                "text": [
                    "We construct a new dataset, RULE (rationale understanding for logical reasoning evaluation), to evaluate the consistent rationale understanding in logical reading comprehension. The dataset comprises main questions and their auxiliary questions (subquestions). The subquestions are designed to test the understanding of the rationale necessary for answering the main questions correctly. In constructing our dataset, we make three decisions in its design choices.",
                    "Source Dataset Among existing datasets for testing logical reading comprehension, we use ReClor for the following reasons: (1) It covers various types of logical reasoning required in the multiplechoice format, (2) its context passages are of sufficient length to compose a meaningful rationale (e.g., the contexts in LogiQA (Liu et al., 2020) are shorter), and (3) it contains a sufficient number of examples to create an auxiliary benchmarking dataset. We cannot find other candidate datasets, but our approach is applicable to similar ones."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Rationale Collection",
                "text": [
                    "The task of writing implicit rationales from scratch for logical reasoning questions is not straightforward because the reasoning process can involve multiple steps with differing granularity. Therefore, to facilitate rationale writing, we use answer options in the multiplechoice questions. To answer a question with four options, the reasoning process should involve the rationale of both identifying the correct option and eliminating the three incorrect options. By focusing on the correctness of each option, we can decompose the complex task of rationale writing into smaller intuitive tasks. In addition, we collect human-written free-form rationales to expect benefits over model-generated rationales (Sun et al., 2022), in particular for covering the implicit process of critical reasoning.",
                    "Task Format We also aim to design auxiliary questions so that we can easily evaluate models on both main questions and subquestions in the same task format. To this end, we use four rationales collected for a main question as the four answer options of its subquestion. A single main question has at most four subquestions that share the same set of answer options, which can be seen as questionwise contrastive evaluation (Gardner et al., 2020;Ashida and Sugawara, 2022)."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Collecting Rationales",
                "text": [
                    "We use crowdsourcing to collect rationales for creating our subquestions. Appendix A shows our crowdsourcing instructions and examples.",
                    "Qualification We conduct a two-stage qualification test to recruit crowdworkers for our tasks. The first stage is a QA task to identify workers who carefully answer logical reading comprehension questions. The task consists of ten questions taken from ReClor, and workers achieving \u2265 80% accuracy advance to the next test. In the second stage, workers are presented with a single ReClor question that is randomly sampled from a pool of ten questions. The task is to write four implicit rationales (one sentence each) behind each option's (in)correctness. To guide them, we provide detailed instructions with eight writing examples.",
                    "Through preliminary pilot studies, we define two essential criteria for writing rationales: specificity and necessity. Specificity requires rationales to be well informed and support the corresponding options exclusively. This requirement is crucial because non-specific rationales could support multiple options, rendering them unsuitable for options in subquestions. Necessity emphasizes the importance of ensuring that the rationale is essential for validating the option's correctness. Even if a detailed rationale is provided, it must be aligned with the main question's point to preserve its validity.",
                    "Following these criteria, the authors manually assess the rationales provided by the workers. We identify 57 workers through this qualification process. These workers are invited to both the rationale writing and subsequent validation tasks."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Rationale Writing",
                "text": [
                    "We take 1,200 questions from the training set of ReClor. As with the second phase of the qualification task, we present workers with a context, question, and four options marked as either correct or incorrect, and then ask workers to write rationale sentences for each option. Of these qualified individuals, 50 were actively engaged in this task. We collect 4,800 rationales in total and send them to the rationale validation step."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Rationale Validation",
                "text": [
                    "To validate the collected rationales, we first focus on their specificity, which is critical for creating a set of reasonable subquestions about a given main question. Because assessing the necessity of rationales may not be straightforward, we analyze the reasoning types involved in understanding rationales in Section 5.",
                    "For the validation, we conduct an alignment test between a set of rationales and answer options. In this test, workers are presented with one main question, its four options, and one rationale. They are then asked to identify which one of the options is supported by the given rationale. If a rationale is insufficiently detailed and could potentially support other options, it would be difficult for workers to correctly match the rationale to its corresponding option. We ensure that the worker who validates a rationale is different from the one who wrote it.",
                    "This test enables us to refine our initial pool of 4,800 rationales down to 3,828, ensuring that each rationale is sufficiently specific to support its corresponding option."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Subquestion Construction",
                "text": [
                    "Question Generation We then generate question texts to construct subquestions using a language model. Given one main question and one of its options, the model is instructed to generate a subquestion that asks about the reason for the correctness of the option. For example, when we input the prompt \"What mistake does the argument make in its reasoning?\" and the incorrect answer option \"It confuses probability and certainty,\" the model generates the question \"What evidence is there that the argument does not make the mistake of confusing probability and certainty?\" We use different prompts for the correct and incorrect options to avoid the problem of the model omitting negatives (e.g., \"not\") when generating eliminative subquestions. For the generation, we use Instruct-GPT (text-davinci-003), which is one of the strong large language models. Appendix B shows an example of our prompt.",
                    "Subquestion Construction Coupling the validated rationales with generated question texts, we construct at most four subquestions for a single main question. Each subquestion corresponds to each of the four answer options in the main question. The four answer options of the subquestions are identical to the four rationales written for the main question. The correct answer option of a sub-question is the rationale written for the option that the subquestion is made from.",
                    "A subquestion must have four validated rationales to compose the multiple-choice format. However, when we look at a main question, all four rationales are not always valid, which could largely decrease the number of possible subquestions. To mitigate this issue, we create a subquestion even if three out of the four rationales are valid, by replacing the invalid rationale with the \"None of the above choices\" option. Through this process, we obtain 3,824 subquestions. We discard a main question if it has no valid subquestions."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Human Validation",
                "text": [
                    "As the final step of our data collection, we validate the answerability of the subquestions by humans. Despite the ensured specificity of rationales, the complexity of the subquestion texts could potentially make the subquestions unanswerable. To address this issue, we ask three workers to answer each subquestion to evaluate its human answerability. A subquestion is considered answerable if at least two workers answer it correctly, or if all workers select \"None of the above choices.\" In the latter scenario, we replace the correct answer in the question with \"None of the above choices.\" This process results in 3,003 answerable subquestions with 943 main questions. We expect the number of questions in our dataset can demonstrate statistical power for meaningful model benchmarking and comparison (Card et al., 2020).",
                    "We then ask different workers to answer the questions, collecting three additional labels for each question to measure human accuracy."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Dataset Statistics",
                "text": [
                    "Table 1 shows the dataset statistics. Compared to the main questions (ReClor), our subquestions have longer questions and answer options. The subquestions that have \"None of the above choices\" as the correct answer comprise 7.4% (222/3,003) of the dataset, which is comparable to a similar multiplechoice reading comprehension dataset (6.7% in CosmosQA; Huang et al., 2019). We also report the crowdsourcing details in Appendix C."
                ],
                "publication_ref": [
                    "b6"
                ],
                "figure_ref": [],
                "table_ref": [
                    "tab_1"
                ]
            },
            {
                "heading": "Baseline Performance on RULE",
                "text": [
                    "We measure the baseline performance of recent state-of-the-art models on our dataset. Because the main purpose of our dataset is to perform an exten- sive evaluation of the models tested on ReClor, we use all of our main questions and subquestions as a test set. Our hypothesis is that if the models can effectively generalize to understand the rationale behind the correct answer, they should exhibit a similar degree of performance on both the main questions and subquestions.",
                    "Evaluation Metrics In addition to the simple accuracy over the main questions (MainQ Accuracy) and subquestions (SubQ Accuracy), we calculate the accuracy across the subquestions written for the correct and incorrect original options (Selective and Eliminative SubQ Accuracy), respectively. We also calculate the Consistency score to see how often a model answers both the main question and all of its subquestions correctly and thereby shows the comprehensive capability of critical reasoning.",
                    "Because the SubQ accuracy is a micro average, we also report a macro average for reference (MainQwise SubQ Accuracy). To compute these scores for humans, we take a majority vote of the three labels for each main question and subquestion."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Models and Settings",
                "text": [
                    "The models we evaluate are either in the fullyfinetuned setting on the training set of ReClor (excluding our main questions), few-shot of ReClor, and zero-shot that uses only the task instruction.",
                    "Fully-Finetuned Models We use DeBERTa-v3 (large; He et al., 2023) and UnifiedQA-v2 (base, large, and 3B;Khashabi et al., 2020Khashabi et al., , 2022)). Both models are reported to exhibit strong generalization performance on QA datasets.  (text-davinci-003;Ouyang et al., 2022). In the few-shot setting, the input prompt has five Re-Clor exemplars. Because some models only accept a limited length of input, we only report one-shot results of those models. For reference, we report few-shot results using RULE examples. The zeroshot prompt only has the task instruction. We also include Chain-of-Thoughts (CoT; Wei et al., 2022) and zero-shot CoT (Kojima et al., 2022) of Instruct-GPT, providing the models with explanatory examples to potentially enhance their performance. In CoT, the prompt includes ReClor exemplars each of which is followed by the rationale of the correct answer option that is collected in this study."
                ],
                "publication_ref": [
                    "b5"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Few-and",
                "text": [
                    "Appendix D shows examples of our CoT prompt.",
                    "In the few-and zero-shot settings, we follow the test split approach used by Ravichander et al. ( 2022) and split our dataset into five disjoint sets to measure the variability of models' performance. Appendix E describes the details."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Results",
                "text": [
                    "Table 2 presents our main results. In the fullyfinetuned setting, we observe that the SubQ accuracy does not significantly exceed the chance rate (25.0%), which is far below the zero-shot performance of UnifiedQA-v2 as well as the human performance. This degradation may be due to overfitting to ReClor examples, by which the models rely heavily on superficial features of answer options that are not useful in answering the subquestions. In our dataset, a group of subquestions shares the same set of four rationales, which requires that the models closely examine the question texts.",
                    "In the few-and zero-shot settings, we observe that the highest accuracy is 80.3% on the main questions by LLaMA 2 70B with five-shot exemplars of ReClor and 65.7% on the subquestions by Flan-UL2 in the zero-shot setting. Both the MainQ and the SubQ accuracies are lower than the human accuracy by large margins (\u2206 = 11.2%, 16.9%), highlighting a severe limitation in the models' rationale understanding; in most cases, the models may only understand part of the necessary rationales for the comprehension process.",
                    "Although it is not our intended task setting, when we use a part of the subquestions for in-context learning, the highest SubQ accuracy is 70.1% by InstructGPT in the five-shot setting. This result is still below the human accuracy by a noticeable margin. Interestingly, the in-context learning on subquestions is not helpful for smaller models such as Vicuna 7B and 13B.",
                    "Looking at the best Selective and Eliminative SubQ Accuracies, we find that although the former accuracy (five-shot LLaMA 2 70B, 90.0%) is close to the human performance, the latter accuracy (zero-shot Flan-UL2, 59.1%) is significantly below the human performance (78.9%). This contrast shows that answering the eliminative subquestions is difficult for the models, highlighting the limited capacity of LLMs: Even if the models can choose the correct answer option, they may not understand why incorrect answer options should be refuted.",
                    "Consistency and MainQ-wise SubQ Accuracy also conform to this trend. Although the consistency by humans is not high (52.9%), probably owing to the difficulty of the subquestions, a large margin still exists between the human consistency and the best consistency by InstructGPT (18.2%). MainQ-wise SubQ Accuracy provides a bit more intuitive observation: The best model answers only 64.3% of the subquestions per one main question, although humans get them wrong less often (81.5%). We report the detailed number of MainQ-wise SubQ Accuracy in Appendix F.",
                    "Contrary to our expectations, CoT does not improve the performance of InstructGPT. Rather, it leads to a decline in the MainQ and SubQ accuracies. This result is consistent with findings on the unreliable nature of CoT (Wang et al., 2023;Turpin et al., 2023), which may be exposed by the complexity of critical reasoning.",
                    "Does the Model Answer \"None of the above choices\" Questions Correctly? Some of our subquestions contain \"None of the above choices,\" which might make the questions challenging. In particular, the model performance on this type of question might be strongly affected by the incontext learning of exemplars. To investigate this hypothesis, we calculate the accuracy of the subquestions that include the \"None\" option. In the five-shot InstructGPT using RULE examples, we find that although the model achieves 62.7% ac- curacy for the subquestions that have the \"None\" option, it shows 32.0% when \"None\" is the correct answer. This low accuracy is decomposed into 40.9% accuracy if the prompt includes the \"None\" option as the correct answer and 13.7% accuracy otherwise. These results demonstrate that using exemplars helps to answer those questions to some extent but not significantly. Table 3 reports the accuracy of five-shot InstructGPT across the five batches.",
                    "We report the complementary results of the main experiment in Appendix G, in which the one-shot setting does not improve the model performance consistently. Appendix H shows the SubQ accuracy only for the main questions the models answer correctly. Appendix I shows the performance plot across the question and option length."
                ],
                "publication_ref": [
                    "b9",
                    "b8"
                ],
                "figure_ref": [],
                "table_ref": [
                    "tab_3",
                    "tab_4"
                ]
            },
            {
                "heading": "Analysis",
                "text": [
                    "To qualitatively investigate the models' behavior observed in Section 4, we aim to answer the following research questions.",
                    "Why Are the Eliminative Subquestions Difficult? As discussed in the previous section, we find a performance discrepancy between the selective and eliminative subquestions. We attribute this discrepancy to two potential reasons. First, the eliminative subquestions are inherently complex because of the negation included in their question text, which the models may find difficult to handle (Ravichander et al., 2022). Second, the model may lack the ability to comprehend why certain options are incorrect, which is partially supported by studies that highlight the susceptibility for distractors in the multiple-choice QA (Si et al., 2021).",
                    "To distinguish between the difficulty of comprehending complex questions and that of refuting relevant alternatives in the eliminative subquestions, we develop a follow-up task, rationale alignment. In this task, given a context, the main question, one of the main options, and four rationales, the model selects one out of the four rationales that validates the correctness of the given option. We use Instruct-GPT in the five-shot setting and report the average results from five different prompts. Appendix J provides the input prompt.",
                    "Because the subquestion text is not used in this task, we expect that the results are not affected by the complexity of subquestion texts. The result is 89.7% and 31.5% accuracy for the correct and incorrect answer options, respectively, showing a distinct difference between them. This discrepancy suggests the model's serious deficiency in comprehending eliminative rationales.",
                    "Is the Model Better at Writing Rationales than Humans? Given that CoT does not improve the model performance, we are interested in the quality and potential usefulness of model-generated rationales compared to our human-written rationales. We use a similar prompt to that used in our CoT setting, instructing InstructGPT to generate rationales for 50 options. We then randomly shuffle the order of human-written and model-generated rationales, and manually annotate which rationale is better in terms of necessity and specificity. The result is 35 wins by humans and 15 wins by the model among the 50 comparisons, showing that the human-written rationales are likely to be more detailed and supportive than the model-generated ones. In particular, we find that the model rationales struggle to capture the implicit rationale necessary for certifying the validity of the target option. When the rationale is explicit and described well in the context, the model rationale looks convincing and close to the human rationale. Among the 15 examples where humans lose, we find five examples unsatisfactory to validate the target option, implying that approximately 10% of unreasonable rationales are potentially included in our dataset.",
                    "What Types of Reasoning are Required in the Rationale Understanding? To qualitatively analyze the collected rationales, we first sample 100 subquestions to annotate reasoning types. We define two dichotomies: direct/indirect and contextual/external. Direct reasoning occurs if a rationale involves an explicit description for the certification of a target option's (in)validity, whereas indirect reasoning only provides relevant facts for the validity. Context reasoning includes facts (or their interpretation and summarization) described in the context, while external reasoning is pertinent to commonsense and norms that are not described in the context. For comparative error analysis, we also sample 100 subquestions among those that InstructGPT answers incorrectly. We report our annotation results in Table 4. The number of the direct and contextual rationales is the largest among the other types, which further increases when we look at the error cases of In-structGPT. We find that our dataset covers a sufficient number of indirect and external reasoning, i.e., various modes of rationale understanding. Error examples for the four reasoning types are reported in Appendix K. Although we also examine the reasoning types originally labeled in the ReClor dataset, we do not observe any remarkable trends in the subquestion accuracy (Appendix L).",
                    "Do the Rationales Help the Model to Answer the Main Questions? Because the collected rationales are expected to support the decision of selecting and eliminating answer options, we investigate whether adding the rationales to the main questions improves the performance in the five-shot Instruct- GPT. We append the rationale to the context, main question, and four options with the Rationale: label. The results are shown in Table 5. We observe an improvement when the selective rationale is added; however, degradation occurs when we add the eliminative rationale, even if it is provided with the selective rationale. This result adds insight to the observation by Sun et al. (2022), showing that the model cannot use eliminative rationales for answering main questions and becomes confused by those rationales. We also investigate the context-ablated setting in Appendix M."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_5",
                    "tab_6"
                ]
            },
            {
                "heading": "Conclusion",
                "text": [
                    "We construct a dataset to evaluate the models' ability of critical reasoning in logical reading comprehension. We crowdsource free-form rationale for main questions taken from an existing dataset and use an LLM to generate subquestion texts. Resulting questions ask about the underlying rationales for why a certain answer option should be selected and the others should be eliminated. We find that LLMs are particularly bad at answering eliminative subquestions, highlighting that those models do not necessarily have the comprehensive ability of critical reasoning. For future work, we will develop a more efficient pipeline for data collection and facilitate better rationale generation by LLMs."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Ethical Consideration",
                "text": [
                    "We use crowdsourcing in our data collection. We make sure to be responsible to the crowdworkers and to make fair compensation for their work. We do not collect any personal information other than worker IDs on the platform, which are removed in our data release. Before the workers accept our tasks, we inform them of our purpose for the data collection. This study is approved by the internal review board of the authors' institutes."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Limitations",
                "text": [
                    "We recognize the following limitations in this study.",
                    "Task Format In this study, we focus on the multiple-choice QA task. This task format allows us to flexibly ask about various linguistic phenomena and human reasoning by selecting and eliminating alternatives, and we consider solving such a discriminative task would be a minimal requirement for human-like linguistic behaviors. However, it has an inherent limitation in assessing the ability of natural language understanding. For example, we cannot evaluate the models' ability to produce an intended output.",
                    "Annotation Analysis We conduct the annotation analysis in Section 5, in which we define the reasoning types and manually review the sampled examples. Although we make our annotation data and guideline publicly available for ensuring the reproducibility of annotation results, the results of our annotation analysis inevitably involve our subjective judgments.",
                    "Source Dataset We create our auxiliary questions on top of an existing English logical reading comprehension dataset, ReClor. Although our methodology of the data collection (i.e., writing the rationale for selecting and eliminating alternatives) is widely applicable to other datasets and languages, using the single dataset in the single language would limit the generalizability of our findings. "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "B Question Generation Prompt",
                "text": [
                    "Figure 14 shows an example of our prompt used for generating subquestions in Section 3.3."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_3"
                ],
                "table_ref": []
            },
            {
                "heading": "C Crowdsourcing Details",
                "text": [
                    "To access a pool of crowdworkers, we used Amazon Mechanical Turk. The crowdworkers who took the qualification test are based in the United States, United Kingdom, or Canada, have an approval rate of at least 98%, and have at least 1,000 approved tasks. We ensure that the average payments exceed $12.00 USD per hour for each task. The rationale writing task costs $2.00 per main question (estimating that it takes seven to ten minutes to write the rationales), the rationale validation task costs $0.30 per rationale (one minute), and the human validation task $1.50 per five questions (five minutes). The rationale writing tasks, rationale validation tasks, QA validation tasks, and human performance tasks are taken by 48, 39, 52, and 24 workers, respectively. We use the crowdsourcing tool used in Nangia et al. ( 2021)."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "D Chain-of-Thought Prompt",
                "text": [
                    "Figure 15 shows an example of the prompt used in our chain-of-thought experiment. We insert the rationale between the Answer: label and the correct option label, with an expectation that it would help the model (InstructGPT) select the correct option."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_1"
                ],
                "table_ref": []
            },
            {
                "heading": "E Test Split Setting",
                "text": [
                    "The in-context learning performance of LLMs may vary depending on the exemplars of the prompt, but it incurs a high computational cost (or financial cost for proprietary models) if we repeatedly evaluate the models on the entire dataset using various sets of different exemplars to take the average performance. Because of this cost limitation, we follow the test split approach used by Ravichander et al. ( 2022), splitting our dataset into five disjoint sets and testing the models on each set with different exemplars to measure the performance variance across the disjoint sets. Note that we do not split the set of the main questions, because it has only 943 examples; hence, in the few-shot setting, we take the average across five runs on all main questions. In the few-shot setting using ReClor, we sample questions disjointly from its training set, whereas  in using RULE, the exemplars are sampled from the corresponding disjoint set."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "F MainQ-wise SubQ Results of InstructGPT",
                "text": [
                    "Because a single main question has multiple subquestions in our dataset, we report the detailed numbers of correctly-answered SubQ by Instruct-GPT in Figure 3. Table 6: Complementary results of the model performance on our dataset including the models in the one-shot setting and omitting those in the five-shot and zero-shot settings."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_2"
                ],
                "table_ref": []
            },
            {
                "heading": "G Complementary Few-Shot and Zero-Shot Results",
                "text": [
                    "In Table 6, we report the complementary results of few-shot settings, including the models on the one-129    shot setting. We also report the results of LLaMA (7B to 65B; Touvron et al., 2023a) for reference."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "H Main Results of the Subquestions for the Correctly-Answered Main Questions",
                "text": [
                    "Table 8 shows the main results of the model performance on the subquestions for the main questions that are correctly answered by the model. Overall, we observe similar trends to the main results with the standard SubQ accuracy. Interestingly, the models' SubQ accuracies do not significantly improve even when we focus only on the correctly-answered main questions."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_10"
                ]
            },
            {
                "heading": "I Relationship between Question and Option Length and Model Performance",
                "text": [
                    "In Figures 4 to 10, we plot the distribution of the questions and options length and the model performance according to those lengths."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "J Rationale Alignment Task",
                "text": [
                    "In the rationale alignment task, we test Instruct-GPT in the five-shot setting. Similar to the main experiment, we report the average results from five prompts. Each prompt is composed of five exemplars, with two exemplars presenting the correct option and three exemplars presenting the incorrect option. Figure 12 shows an example of our prompt.",
                    "The results with and without the task instruction are shown in Table 7. The performance gap between the correct and incorrect options implies that such advanced models may simply infer the correct answer without properly discriminating against incorrect options. Such a situation raises two issues: (1) the inability to reason logically like a human, and (2) the limitations of ability measurement using distractors. The first issue suggests that the model may not be able to make a clear distinction between what is correct and what is incorrect. The second issue is that the alternatives in the multiple-choice QA task are generally expected to distinguish between test takers with and without sufficient knowledge (Gierl et al., 2017), but such an expectation may not be met in our dataset."
                ],
                "publication_ref": [
                    "b3"
                ],
                "figure_ref": [
                    "fig_1"
                ],
                "table_ref": [
                    "tab_9"
                ]
            },
            {
                "heading": "K Reasoning Type Annotation",
                "text": [
                    "Table 10 shows examples of reasoning types we define in the annotation analysis. See Table 11 for a full example that has the main question and two subquestions."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_1",
                    "tab_13"
                ]
            },
            {
                "heading": "L ReClor Reasoning Types and Subquestion Accuracy",
                "text": [
                    "Figure 13 shows the relation between the subquestion accuracy and the reasoning types defined in the original ReClor dataset. Although we do not observe significant performance differences, we see higher accuracy in Match Structures, Evaluation, Strengthen, and Weaken reasoning, and lower accuracy in Sufficient Assumptions, Technique, and Role reasoning."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_2"
                ],
                "table_ref": []
            },
            {
                "heading": "M Context-Ablation Analysis",
                "text": [
                    "We try to answer the question \"Does the context help in answering subquestions?\" in the contextablation setting. By removing the context, we analyze the model performance on the subquestions (and the main questions for reference) to see the dependency between question texts and answer options. The results in Table 9 show the performance reduction by approximately 4 points in the zeroshot setting and no reduction in the five-shot setting. This result implies question texts depend on answer options to some extent, which potentially makes the subquestions difficult for the models, given the first analysis in this section."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_11"
                ]
            },
            {
                "heading": "N Similarity of Rationale with MainQ Option",
                "text": [
                    "In our process to validate specificity, even if a rationale has the same meaning as the MainQ's option, we can not exclude it. This implies that some rationales might have the similar meaning as the option and not serve as a valid rationale. To examine this potential issue, we sample 50 random questions from both the selective SubQ and the eliminative SubQ. We then count how many of these rationales are semantically similar to the MainQ's option. We found three such instances in the selective SubQ and one in the eliminative SubQ, which are shown in Table 12. 132",
                    "In a given context, you'll be given a question, an answer, and four rationales. Your task is to identify the rationale that explains the correctness of the provided option the best. If the option is wrong, choose the rationale that explains why it is wrong. Conversely, if the option is correct, choose the rationale that explains why it is correct.",
                    "Context: Teachers should not do anything to cause their students to lose respect for them. And students can sense when someone is trying to hide his or her ignorance. Therefore, a teacher who does not know the answer to a question a student has asked should not pretend to know the answer. Question: The conclusion is properly drawn if which one of the following is assumed? Question: The conclusion is properly drawn if which one of the following is assumed?",
                    "Option: Students' respect for a teacher is independent of the amount of knowledge they attribute to that teacher. Rationale0: The ranking of students' respect for honesty is not relevant to the conclusion of a teacher shouldn't pretend to know an answer to question they don't know the answer to."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_14"
                ]
            },
            {
                "heading": "Rationale1:",
                "text": [
                    "The assumption is that students' respect for the teacher is based on how much knowledge the teacher has. Rationale2: The conclusion is that teachers shouldn't pretend to know the answer to a question that they don't know, so the assumption is that student's respect for a teacher is interlinked to the student's perceived knowledge of the teacher. Rationale3: The conclusion does not have anything to do with a teacher being effective.",
                    "Answer: The answer is Rationale2",
                    "Context: Miguel has four family members who plan to come to his graduation on Sunday afternoon, but it is likely that only three of them will be allowed to attend.",
                    "Normally graduation is held in the football stadium, where there is no limit on the number of family members who can attend. However, the ceremony is relocated to the gymnasium if it rains, and each graduate receives just three admission tickets for use by family members."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Question:",
                "text": [
                    "The conclusion of the argument is most strongly supported if which one of the following is assumed?",
                    "Option: The weather service has indicated that there is a very high likelihood of rain on Sunday afternoon."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Rationale0:",
                "text": [
                    "No mention is made of whether un-needed spaces can be transferred between students, and so this cannot be assumed to impact the number of spaces available to Miguel's family. Rationale1: Abnormally large class size may not preclude Miguel from having more than three family members attend, as the football stadium is a possible venue and has no limitation on the number who may attend. Rationale2: A family member who cannot attend the graduation has no relevance to how many may be allowed to attend. Rationale3: Rain would preclude the use of the stadium which has no limit of the number of family members attending and force the use of the gymnasium, which limits the number attending to three.",
                    "Answer: The answer is Rationale3",
                    "[\u2026]",
                    "Exemplars with Task Instruction"
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Test Instance",
                "text": [
                    "Context: Because it permits a slower and more natural rhythm of life, living in the country is supposed to be more healthy and relaxed than living in the city. But surveys show that people living in the country become ill as often and as seriously as people living in the city, and that they experience an equal amount of stress."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Question:",
                "text": [
                    "The statements above, if true, provide the most support for which one of the following?",
                    "Rationale0: This passage kind of disputes this line of thinking, living in the country should have a slower rhythm yet they experience the same amount of stress as a city dweller. Rationale1: This passage is not saying this specifically, just that a natural rhythm might not have as many benefits as people want to believe."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Rationale2:",
                "text": [
                    "The passage kind of focuses on both the thoughts that living in the country should be healthier but surveys show that it is not the case.  "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Direct External",
                "text": [
                    "A just government never restricts the right of its citizens to act upon their desires except when their acting upon their desires is a direct threat to the health or property of other of its citizens.",
                    "Which one of the following judgments most closely conforms to the principle cited above?",
                    "A just government would not censor writings of Shakespeare, but it could censor magazines and movies that criticize the government.",
                    "FALSE A just government would not censor magazines and movies that criticize the government because these things do not threaten the health or property of its citizens."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Indirect Contextual",
                "text": [
                    "Doctor: The practice of using this therapy to treat the illness cannot be adequately supported by the claim that any therapy for treating the illness is more effective than no therapy at all. What must also be taken into account is that this therapy is expensive and complicated.",
                    "Which one of the following most accurately expresses the main point of the doctor's argument?",
                    "The therapy's possible effectiveness in treating the illness is not sufficient justification for using it. TRUE Therapy's other costs must be considered before enlisting the treatment as it is not cheap and not simple."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Indirect External",
                "text": [
                    "On average, corporations that encourage frequent social events in the workplace show higher profits than those that rarely do. This suggests that the EZ Corporation could boost its profits by having more staff parties during business hours.",
                    "Which one of the following, if true, most weakens the argument above?",
                    "Frequent social events in a corporate workplace leave employees with less time to perform their assigned duties than they would otherwise have. FALSE Frequent social events in a corporate workplace can reenergize employees, like a lunch break does.",
                    "Table 10: Examples of the reasoning types with a passage, a question, an option, the correctness of the option, and its human-written rationale.",
                    "Combine Question and Option and generate a new sentence that asks the reason as follows.",
                    "Question: Which one of the following is an assumption required by the department store manager's argument? Option: Either few customers would want free gift wrapping or most customers would want it. Answer: Which of the following reasoning justifies that the department store manager's argument requires the assumption that either few customers would want free gift wrapping or most customers would want it? Question: The main point made in Kim's argument is that Option: replacing gasoline-powered cars with battery-powered electric cars will require building more generating facilities. Answer: Why is it valid to conclude that Kim's argument focuses on the claim that replacing gasoline-powered cars with battery-powered electric cars will require building more generating facilities? Question: The argument's conclusion follows logically if which one of the following is assumed? Option: A work of science fiction cannot achieve greatness unless it contains compelling characters. Answer: Why does the argument's conclusion follow logically if it is assumed that a work of science fiction cannot achieve greatness unless it contains compelling characters? Paragraph: Trisha: Today' s family is declining in its ability to carry out its functions of child-rearing and providing stability for adult life. There must be a return to the traditional values of commitment and responsibility. Jerod: We ought to leave what is good enough alone. Contemporary families may be less stable than traditionally, but most people do not find that to be bad. Contemporary criticisms of the family are overblown and destructive."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_1"
                ]
            },
            {
                "heading": "MainQ",
                "text": [
                    "Question: Trisha and Jerod disagree over whether the institution of the family is Options: 1) valued by most people. 2) changing over time.",
                    "3) adequate as it is. 4) no longer traditional."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Selective SubQ",
                "text": [
                    "Question: What is the source of the disagreement between Trisha and Jerod regarding whether the institution of the family is adequate as it is? Options:",
                    "1) The argument does not mention value to the people. 2) Trisha is arguing that things were better with traditional families and Jerod is arguing that they are good now, the argument is about the quality of the relationship now.",
                    "3) Both Trisha and Jerod agree that families are no longer traditional, this is not what the argument is about. 4) None of the above choices."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Eliminative SubQ",
                "text": [
                    "Question: What evidence is there to suggest that Trisha and Jerod's disagreement over whether the institution of the family is no longer traditional is not valid? Options: 1) Both Trisha and Jerod agree that families are no longer traditional, this is not what the argument is about. 2) Trisha is arguing that things were better with traditional families and Jerod is arguing that they are good now, the argument is about the quality of the relationship now.",
                    "3) The argument does not mention value to the people. 4) None of the above choices. "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Question Type Option Rationale",
                "text": [
                    "Selective Delays in the communication of discoveries will have a chilling effect on scientific research. Delays in communicating discoveries would limit the time other scientists have to investigate and contribute. Kimmy is a highly compensated and extremely popular television and movie actress.",
                    "All the information in the passage indicates that Kimmy is affluent and renowned. Before new therapeutic agents reach the marketplace, they do not benefit patients.",
                    "The passage states that new therapies aid patients only after they are introduced to the marketplace."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Eliminative",
                "text": [
                    "The speed of eye orientation correlates with intelligence, not overall health.",
                    "The speed at which one can orient one's eye to a stimulus has been closely associated with overall health. Context: Teachers should not do anything to cause their students to lose respect for them. And students can sense when someone is trying to hide his or her ignorance. Therefore, a teacher who does not know the answer to a question a student has asked should not pretend to know the answer. Question: The conclusion is properly drawn if which one of the following is assumed? Option0: Students respect honesty above all else. Option1: Students lose respect for teachers whenever they sense that the teachers are trying to hide their ignorance. Option2: Students' respect for a teacher is independent of the amount of knowledge they attribute to that teacher. Option3: A teacher cannot be effective unless he or she retains the respect of students."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Answer:",
                "text": [
                    "The assumption is that students' respect for the teacher is based on how much knowledge the teacher has. Therefore the answer is Option1",
                    "Context: Miguel has four family members who plan to come to his graduation on Sunday afternoon, but it is likely that only three of them will be allowed to attend. Normally graduation is held in the football stadium, where there is no limit on the number of family members who can attend. However, the ceremony is relocated to the gymnasium if it rains, and each graduate receives just three admission tickets for use by family members. Question: The conclusion of the argument is most strongly supported if which one of the following is assumed? Option0: Miguel has several friends who have fewer than three family members coming to graduation. Option1: Miguel's graduating class is much larger than usual. Option2: Miguel has a fifth family member who is unable to come to his graduation. Option3: The weather service has indicated that there is a very high likelihood of rain on Sunday afternoon.",
                    "Answer: Rain would preclude the use of the stadium which has no limit of the number of family members attending and force the use of the gymnasium, which limits the number attending to three. Therefore the answer is Option3 [\u2026] Exemplars with CoT"
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Test Instance",
                "text": [
                    "Context: Because it permits a slower and more natural rhythm of life, living in the country is supposed to be more healthy and relaxed than living in the city. But surveys show that people living in the country become ill as often and as seriously as people living in the city, and that they experience an equal amount of stress. Question: The statements above, if true, provide the most support for which one of the following? Option0: Living in the country is neither healthier nor more relaxing than living in the city. Option1: The amount of stress a person experiences depends on that person's rhythm of life. Option2: People whose rhythm of life is slow and natural recover quickly from illness.       "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Solve reading comprehension questions!",
                "text": [
                    "This is a HIT of answering multiple choice reading comprehension questions. Spend up to five minutes for answering five questions (no rejection happens). You can take up to 30 HITs for this batch.",
                    "Passage 1 / 3 1. uses as evidence a source that there is reason to believe is unreliable 2. fails to consider that several different effects may be produced by a single cause 3. treats one main factor considered in the selection of plays to perform as though it were a condition that must be met in order for a play to be selected 4. takes a condition necessary for a playwright's being critically acclaimed to be a condition sufficient for a playwright's being critically acclaimed 5.",
                    "Clark: Our local community theater often produces plays by critically acclaimed playwrights. In fact, the production director says that critical acclaim is one of the main factors considered in the selection of plays to perform. So, since my neighbor Michaela' s new play will be performed by the theater this season, she must be a critically acclaimed playwright."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Question",
                "text": [
                    "The reasoning in Clark's argument is most vulnerable to criticism on the grounds that the argument Options Invalid or unanswerable question Go to the next passage "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Acknowledgments",
                "text": [
                    "We would like to thank the anonymous reviewers for their helpful comments. This work was supported by JST PRESTO Grant Number JP-MJPR20C4 and JSPS KAKENHI Grant Number 22K17954."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Evaluate explanation for reading comprehension Instructions",
                "text": [
                    "In this task, you are given a passage, question about it, and four answer options where one option is the correct answer and the others are incorrect (the check and cross marks indicate it). In addition, you are given a rationale, which corresponds to one of the options and its correctness. You are asked to answer which option the given rationale corresponds to by checking the radio button. You can accept up to 160 HITs for this batch.",
                    "Passage 1 / 1 Match the Rationale \u2192 Completed A university study reported that between 1975 and 1983 the length of the average workweek in a certain country increased significantly. A governmental study, on the other hand, shows a significant decline in the length of the average workweek for the same period. Examination of the studies shows, however, that they used different methods of investigation; thus there is no need to look further for an explanation of the difference in the studies' results."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Question",
                "text": [
                    "The argument's reasoning is flawed because the argument fails to Options \u274c recognize that varying economic conditions result in the average workweek changing in length \u2705 recognize that two different methods of investigation can yield identical results \u274c distinguish between a study produced for the purposes of the operation of government and a study produced as part of university research \u274c distinguish between a method of investigation and the purpose of an investigation Rationale It does not fail to distinguish the different studies, it blatantly says that one study was a university and one was by the government.",
                    "Answer which option corresponds to the ratinale! Submit your answer "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            }
        ],
        "references": [
            {
                "ref_id": "b0",
                "title": "Explanations for Common-senseQA: New Dataset and Models",
                "journal": "Long Papers",
                "year": "2021",
                "authors": "Shourya Aggarwal; Divyanshu Mandowara; Vishwajeet Agrawal; Dinesh Khandelwal; Parag Singla; Dinesh Garg"
            },
            {
                "ref_id": "b1",
                "title": "Shortcut learning in deep neural networks",
                "journal": "Nature Machine Intelligence",
                "year": "2020",
                "authors": "Robert Geirhos; J\u00f6rn-Henrik Jacobsen; Claudio Michaelis; Richard Zemel; Wieland Brendel; Matthias Bethge; Felix A Wichmann"
            },
            {
                "ref_id": "b2",
                "title": "Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies",
                "journal": "Transactions of the Association for Computational Linguistics",
                "year": "2021",
                "authors": "Mor Geva; Daniel Khashabi; Elad Segal; Tushar Khot; Dan Roth; Jonathan Berant"
            },
            {
                "ref_id": "b3",
                "title": "Developing, analyzing, and using distractors for multiple-choice tests in education: A comprehensive review",
                "journal": "Review of Educational Research",
                "year": "2017",
                "authors": "Mark Gierl; Okan Bulut; Qi Guo; Xinxin Zhang"
            },
            {
                "ref_id": "b4",
                "title": "The argument reasoning comprehension task: Identification and reconstruction of implicit warrants",
                "journal": "Long Papers",
                "year": "2018",
                "authors": "Ivan Habernal; Henning Wachsmuth; Iryna Gurevych; Benno Stein"
            },
            {
                "ref_id": "b5",
                "title": "DeBERTav3: Improving deBERTa using ELECTRAstyle pre-training with gradient-disentangled embedding sharing",
                "journal": "",
                "year": "2023",
                "authors": "Pengcheng He; Jianfeng Gao; Weizhu Chen"
            },
            {
                "ref_id": "b6",
                "title": "Cosmos QA: Machine reading comprehension with contextual commonsense reasoning",
                "journal": "",
                "year": "2019",
                "authors": "Lifu Huang; Le Ronan; Chandra Bras; Yejin Bhagavatula;  Choi"
            },
            {
                "ref_id": "b7",
                "title": "MetaLogic: Logical reasoning explanations with finegrained structure",
                "journal": "",
                "year": "2022",
                "authors": "Yinya Huang; Hongming Zhang; Ruixin Hong; Xiaodan Liang; Changshui Zhang; Dong Yu"
            },
            {
                "ref_id": "b8",
                "title": "Language models don't always say what they think: Unfaithful explanations in chain-of-thought prompting",
                "journal": "",
                "year": "2023",
                "authors": "Miles Turpin; Julian Michael; Ethan Perez; Samuel R Bowman"
            },
            {
                "ref_id": "b9",
                "title": "Towards understanding chain-of-thought prompting: An empirical study of what matters",
                "journal": "Association for Computational Linguistics",
                "year": "2023",
                "authors": "Boshi Wang; Sewon Min; Xiang Deng; Jiaming Shen; You Wu; Luke Zettlemoyer; Huan Sun"
            },
            {
                "ref_id": "b10",
                "title": "Logic-driven context extension and data augmentation for logical reasoning of text",
                "journal": "Association for Computational Linguistics",
                "year": "2022",
                "authors": "Siyuan Wang; Wanjun Zhong; Duyu Tang; Zhongyu Wei; Zhihao Fan; Daxin Jiang; Ming Zhou; Nan Duan"
            },
            {
                "ref_id": "b11",
                "title": "Chain-of-thought prompting elicits reasoning in large language models",
                "journal": "Curran Associates, Inc",
                "year": "2022",
                "authors": "Jason Wei; Xuezhi Wang; Dale Schuurmans; Maarten Bosma; Fei Xia; Ed Chi; V Quoc; Denny Le;  Zhou"
            },
            {
                "ref_id": "b12",
                "title": "HotpotQA: A dataset for diverse, explainable multi-hop question answering",
                "journal": "",
                "year": "2018",
                "authors": "Zhilin Yang; Peng Qi; Saizheng Zhang; Yoshua Bengio; William Cohen; Ruslan Salakhutdinov; Christopher D Manning"
            },
            {
                "ref_id": "b13",
                "title": "ReClor: A reading comprehension dataset requiring logical reasoning",
                "journal": "",
                "year": "2020",
                "authors": "Weihao Yu; Zihang Jiang; Yanfei Dong; Jiashi Feng"
            },
            {
                "ref_id": "b14",
                "title": "Analytical reasoning of text",
                "journal": "Association for Computational Linguistics",
                "year": "2022",
                "authors": "Wanjun Zhong; Siyuan Wang; Duyu Tang; Zenan Xu; Daya Guo; Yining Chen; Jiahai Wang; Jian Yin; Ming Zhou; Nan Duan"
            }
        ],
        "figures": [
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_0",
                "figure_caption": "Statistical records of crime rates probably often reflect as much about the motives and methods of those who compile or cite them [...]. The police may underreport crime [...] or overreport crime [...]. Politicians may magnify crime rates to [...]. Newspapers often sensationalize [...].",
                "figure_data": ""
            },
            {
                "figure_label": "1",
                "figure_type": "figure",
                "figure_id": "fig_1",
                "figure_caption": "Figure 1 :1Figure 1: Example of ReClor(Yu et al., 2020) and its subquestion we create to test the understanding of implicit rationale. We find that even if the model can answer the original question correctly, it cannot answer subquestions that should be answerable.",
                "figure_data": ""
            },
            {
                "figure_label": "3",
                "figure_type": "figure",
                "figure_id": "fig_2",
                "figure_caption": "Figure 3 :3Figure 3: Distribution of correctly answered subquestions (C) out of the total number of subquestions (N ), for both InstructGPT (top) and humans (bottom).",
                "figure_data": ""
            },
            {
                "figure_label": "4",
                "figure_type": "figure",
                "figure_id": "fig_3",
                "figure_caption": "Figure 4 :4Figure 4: Distribution of the question length (#tokens) of the main questions.",
                "figure_data": ""
            },
            {
                "figure_label": "57",
                "figure_type": "figure",
                "figure_id": "fig_4",
                "figure_caption": "Figure 5 :Figure 7 :57Figure 5: Comparison between the model and human accuracy and question length for the main questions.",
                "figure_data": ""
            },
            {
                "figure_label": "9",
                "figure_type": "figure",
                "figure_id": "fig_5",
                "figure_caption": "Figure 9 :9Figure 8: Distribution of the option length (#tokens) of the main questions.",
                "figure_data": ""
            },
            {
                "figure_label": "10",
                "figure_type": "figure",
                "figure_id": "fig_6",
                "figure_caption": "Figure 10 :10Figure 10: Comparison between the model and human accuracy and option length for the subquestions.",
                "figure_data": ""
            },
            {
                "figure_label": "11",
                "figure_type": "figure",
                "figure_id": "fig_7",
                "figure_caption": "Figure 11 :11Figure 11: Distribution of the option length (#tokens) of the subquestions.",
                "figure_data": ""
            },
            {
                "figure_label": "1213",
                "figure_type": "figure",
                "figure_id": "fig_8",
                "figure_caption": "Figure 12 :Figure 13 :1213Figure 12: Example of the prompt used for rationale alignment task.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_9",
                "figure_caption": "Figure 14: Example of the prompt used to generate subquestions.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_10",
                "figure_caption": "Figure 15: Example of the prompt using the chain-of-thought approach.",
                "figure_data": ""
            },
            {
                "figure_label": "16",
                "figure_type": "figure",
                "figure_id": "fig_11",
                "figure_caption": "Figure 16 :16Figure 16: Instructions for the rationale writing task (1/4).",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_12",
                "figure_caption": "136",
                "figure_data": ""
            },
            {
                "figure_label": "17",
                "figure_type": "figure",
                "figure_id": "fig_13",
                "figure_caption": "Figure 17 :17Figure 17: Instructions for the rationale writing task (2/4).",
                "figure_data": ""
            },
            {
                "figure_label": "20",
                "figure_type": "figure",
                "figure_id": "fig_14",
                "figure_caption": "Figure 20 :20Figure 20: Rationale writing task interface. The workers are given a context, question, and four options along with their correctness, and are asked to provide a rationale for each choice.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_15",
                "figure_caption": "140",
                "figure_data": ""
            },
            {
                "figure_label": "21",
                "figure_type": "figure",
                "figure_id": "fig_16",
                "figure_caption": "Figure 21 :21Figure 21: Instructions for the rationale validation task.",
                "figure_data": ""
            },
            {
                "figure_label": "23",
                "figure_type": "figure",
                "figure_id": "fig_17",
                "figure_caption": "Figure 23 :23Figure 23: Human validation task interface. The workers asked to answer subquestions.",
                "figure_data": ""
            },
            {
                "figure_label": "1",
                "figure_type": "table",
                "figure_id": "tab_1",
                "figure_caption": "Dataset statistics of our RULE dataset. S/E indicates the numbers of two types of subquestions written about the correct (selective) or incorrect (eliminative) options of their main questions, respectively. The question and option lengths of the main questions are separately reported in parentheses for comparison. \"None\" denotes \"None of the above choices.\"",
                "figure_data": "# Main / Sub Questions943 / 3,003# SubQ / MainQ3.18# Selective / Eliminative (S/E)785 / 2,218Avg. context length73.8Avg. question length31.4 (15.5)Avg. option length23.5 (17.7)Avg. correct option length24.0 (18.6)# Question vocabulary8,843 (1,085)# Option vocabulary9,849 (9,652)# SubQ w/ \"None\" (# answer)1,102 (222)"
            },
            {
                "figure_label": "",
                "figure_type": "table",
                "figure_id": "tab_2",
                "figure_caption": "Zero-Shot Models We include recent LLMs such as Chung et al.,   ",
                "figure_data": "2022), Flan-UL2 (20B; Tay et al., 2023), Vi-cuna (7B and 13B; Chiang et al., 2023), LLaMA2 (7B to 70B; Touvron et al., 2023b), Mis-tral (7B; Jiang et al., 2023) and InstructGPT"
            },
            {
                "figure_label": "2",
                "figure_type": "table",
                "figure_id": "tab_3",
                "figure_caption": "",
                "figure_data": "Model# ParamMainQ Acc.SubQ Acc.Selective SubQ Acc.Eliminative SubQ Acc.Consist.MainQ-wise SubQ Acc.DEBERTA-V3-LARGE UNIFIEDQA-V2-BASE UNIFIEDQA-V2-LARGE UNIFIEDQA-V2-3B VICUNA 13B FLAN-UL2 INSTRUCTGPT INSTRUCTGPT + COT LLAMA2 13B LLAMA2 70B MISTRAL 7B VICUNA 13B FLAN-UL2 INSTRUCTGPT LLAMA2 13B LLAMA2 70B MISTRAL 7B UNIFIEDQA-V2-3B UNIFIEDQA-V2-11B FLAN-T5-XXL VICUNA 13B FLAN-UL2 INSTRUCTGPT INSTRUCTGPT+ COT LLAMA2 13B LLAMA2 70B MISTRAL 7B304M 220M 770M 3B 13B 20B N/A N/A 13B 70B 7B 13B 20B N/A 13B 70B 7B 3B 11B 11B 13B 20B N/A N/A 13B 70B 7BFully Finetuned on ReClor 33.1 56.1 25.8 21.3 25.0 19.9 25.3 21.8 Five-Shot on ReClor 46.2\u00b10.7 66.0 40.5 57.7 66.8 50.0\u00b14.4 78.2\u00b13.0 58.5\u00b10.3 65.5\u00b15.1 88.0\u00b14.0 71.8\u00b11.0 65.3\u00b11.8 88.4\u00b12.5 67.8\u00b10.5 63.2\u00b12.1 88.5\u00b12.5 48.5\u00b12.5 44.6\u00b13.2 75.3\u00b13.4 80.3\u00b10.4 60.0\u00b12.6 90.0\u00b11.1 59.9\u00b10.9 55.3\u00b13.4 83.6\u00b13.4 Five-Shot on RULE (for reference) 43.9\u00b11.3 44.2\u00b12.7 72.6\u00b12.6 57.9\u00b10.2 66.0\u00b14.9 87.7\u00b14.6 70.2\u00b10.4 70.1\u00b12.3 90.0\u00b13.5 47.7\u00b13.0 46.3\u00b14.0 80.0\u00b12.1 78.9\u00b10.6 64.0\u00b14.8 90.6\u00b12.5 58.2\u00b11.6 57.5\u00b15.4 88.1\u00b13.0 Zero-Shot 45.5 47.9\u00b12.1 71.6\u00b12.9 55.2 57.3\u00b12.7 74.8\u00b15.2 60.0 64.3\u00b14.0 86.2\u00b15.4 44.2 49.5\u00b12.7 77.1\u00b11.7 56.2 65.7\u00b15.2 84.5\u00b14.4 64.1 62.8\u00b12.2 89.9\u00b12.0 63.8 62.3\u00b11.0 89.6\u00b11.5 43.8 44.4\u00b13.0 75.3\u00b13.1 70.8 58.0\u00b13.7 88.1\u00b13.4 54.0 55.9\u00b13.2 85.9\u00b12.025.0 27.4 26.8 26.6 40.1\u00b14.6 57.6\u00b15.4 57.1\u00b11.5 54.2\u00b12.8 33.8\u00b14.0 49.4\u00b12.9 45.4\u00b13.6 34.2\u00b12.6 58.4\u00b15.0 63.0\u00b12.0 34.4\u00b14.7 54.6\u00b15.5 46.7\u00b17.3 39.4\u00b12.2 51.1\u00b12.7 56.5\u00b13.3 39.7\u00b12.7 59.1\u00b15.1 53.2\u00b12.1 52.6\u00b11.5 33.5\u00b12.5 47.3\u00b14.0 45.3\u00b13.62.4 0.7 1.4 1.4 5.6 16.9 18.2 17.2 5.3 17.7 9.0 4.1 17.8 23.1 5.1 21.1 9.4 5.7 9.7 14.7 6.2 14.7 15.5 14.2 4.7 14.1 8.632.8 26.0 24.7 25.2 49.4 64.3 64.0 61.8 44.7 59.3 54.4 44.0 64.9 69.2 47.1 63.5 57.2 47.8 56.5 63.4 49.4 64.2 61.8 61.2 44.5 57.3 55.0HUMAN-91.582.693.078.952.981.5#170.1010.3#269.7025.9#372.900.0#471.3143.8#566.0140.6Avg.70.10.432.0"
            },
            {
                "figure_label": "3",
                "figure_type": "table",
                "figure_id": "tab_4",
                "figure_caption": "Accuracy of the subquestions that have \"None of the above choices\" as the correct answer (None Acc), compared to that of all subquestions (Acc). None in shot indicates how many \"None\" examples are included in the few-shot prompt for each test split.",
                "figure_data": ""
            },
            {
                "figure_label": "4",
                "figure_type": "table",
                "figure_id": "tab_5",
                "figure_caption": "Annotation results of rationale types on 100 examples randomly sampled from all subquestions (left) and from the error examples by InstructGPT (right).",
                "figure_data": "Direct Indirect TotalContextual 37 / 47 28 / 22 65 / 69External22 / 20 13 / 11 35 / 31Total59 / 67 41 / 33100"
            },
            {
                "figure_label": "5",
                "figure_type": "table",
                "figure_id": "tab_6",
                "figure_caption": "MainQ accuracy of InstructGPT that uses the selective or eliminative rationales in the input.",
                "figure_data": "InputAccuracyContext72.2+ Selective Rationale91.4+ Eliminative Rationale66.0+ Both89.6"
            },
            {
                "figure_label": "7",
                "figure_type": "table",
                "figure_id": "tab_9",
                "figure_caption": "Result of the rationale alignment task with and without the task instruction.",
                "figure_data": ""
            },
            {
                "figure_label": "8",
                "figure_type": "table",
                "figure_id": "tab_10",
                "figure_caption": "Main results of the model performance on our dataset focusing on the subquestions for the main questions that are correctly answered by the model.",
                "figure_data": "Model# ParamMainQ Acc.SubQ Acc.Selective SubQ Acc.Eliminative SubQ Acc.Consist.MainQ-wise SubQ Acc.DEBERTA-V3-LARGE UNIFIEDQA-V2-BASE UNIFIEDQA-V2-LARGE UNIFIEDQA-V2-3B FLAN-UL2 LLAMA 7B LLAMA 13B LLAMA 33B LLAMA 65B VICUNA 7B VICUNA 13B INSTRUCTGPT INSTRUCTGPT + COT LLAMA2 13B LLAMA2 70B MISTRAL 7B FLAN-UL2 LLAMA 7B LLAMA 13B LLAMA 33B LLAMA 65B VICUNA 7B VICUNA 13B INSTRUCTGPT INSTRUCTGPT + COT LLAMA2 13B LLAMA2 70B MISTRAL 7B UNIFIEDQA-V2-BASE UNIFIEDQA-V2-LARGE UNIFIEDQA-V2-3B UNIFIEDQA-V2-11B FLAN-T5-XXL FLAN-UL2 LLAMA 7B LLAMA 13B LLAMA 33B LLAMA 65B VICUNA 7B VICUNA 13B INSTRUCTGPT INSTRUCTGPT + COT LLAMA2 13B LLAMA2 70B MISTRAL 7B304M 220M 770M 3B 20B 7B 13B 33B 65B 7B 13B N/A N/A 13B 70B 7B 20B 7B 13B 33B 65B 7B 13B N/A N/A 13B 70B 7B 220M 770M 3B 11B 11B 20B 7B 13B 33B 65B 7B 13B N/A N/A 13B 70B 7BFully Finetuned on ReClor 33.1 60.4 25.8 19.7 25.0 17.3 25.3 19.9 Five-Shot on ReClor 58.5\u00b10.3 66.0 40.5 57.7 66.8 66.3\u00b16.3 89.6\u00b14.6 25.8\u00b11.6 28.5\u00b17.5 34.3\u00b112.2 38.7\u00b12.7 37.0\u00b14.0 65.0\u00b16.7 58.5\u00b11.2 47.7\u00b14.2 77.5\u00b16.3 69.1\u00b10.9 54.4\u00b11.7 85.5\u00b12.8 33.4\u00b12.6 40.0\u00b15.1 62.7\u00b16.9 46.2\u00b10.7 48.5\u00b16.1 76.0\u00b18.8 71.8\u00b11.0 64.1\u00b13.5 89.2\u00b13.8 67.8\u00b10.5 62.9\u00b13.1 89.5\u00b14.2 48.5\u00b12.5 45.8\u00b14.2 79.1\u00b14.0 80.3\u00b10.4 59.9\u00b12.5 90.7\u00b11.9 59.9\u00b10.9 54.7\u00b14.4 84.5\u00b12.8 Five-Shot on RULE (for reference) 57.9\u00b10.2 67.2\u00b16.2 89.4\u00b14.4 29.1\u00b12.3 34.6\u00b13.2 66.2\u00b18.0 36.8\u00b13.5 35.1\u00b13.2 67.4\u00b15.3 53.6\u00b10.4 48.5\u00b16.0 78.5\u00b15.9 66.2\u00b10.7 57.2\u00b15.1 86.4\u00b13.1 35.0\u00b11.1 40.3\u00b13.1 61.4\u00b18.8 43.9\u00b11.3 43.9\u00b12.6 73.0\u00b13.1 70.2\u00b10.4 70.2\u00b13.5 91.0\u00b14.6 67.8\u00b10.5 62.9\u00b13.1 89.5\u00b14.2 47.7\u00b13.0 46.9\u00b14.7 79.4\u00b16.3 78.9\u00b10.6 63.7\u00b14.2 90.8\u00b12.5 58.2\u00b11.6 56.2\u00b15.1 88.0\u00b13.6 Zero-Shot 30.4 43.0\u00b12.9 51.0\u00b17.5 41.4 43.9\u00b14.1 59.9\u00b17.6 45.5 49.3\u00b12.4 75.4\u00b14.1 55.2 56.8\u00b12.9 77.6\u00b17.1 60.0 63.2\u00b13.4 87.3\u00b14.8 56.2 65.3\u00b15.9 86.0\u00b14.8 27.7 27.0\u00b14.5 37.5\u00b12.8 31.7 35.5\u00b13.0 55.9\u00b14.0 54.5 50.2\u00b14.6 81.8\u00b14.3 52.1 47.5\u00b12.2 80.1\u00b12.5 36.7 40.8\u00b12.8 77.5\u00b12.8 44.2 48.9\u00b14.8 76.9\u00b13.4 64.1 61.9\u00b12.9 89.8\u00b12.9 63.8 60.9\u00b11.4 89.1\u00b12.4 43.8 45.5\u00b13.7 77.6\u00b15.3 70.8 57.2\u00b14.0 88.2\u00b13.2 54.0 54.7\u00b13.4 85.1\u00b15.522.5 26.7 27.7 25.7 57.2\u00b15.1 24.2\u00b15.7 25.9\u00b13.8 38.3\u00b15.8 46.9\u00b15.6 30.0\u00b13.0 42.2\u00b15.4 60.7\u00b16.1 55.8\u00b13.6 33.1\u00b15.2 50.5\u00b17.2 46.8\u00b12.8 57.1\u00b13.6 23.7\u00b11.3 24.4\u00b12.6 36.8\u00b15.4 53.7\u00b110.3 32.4\u00b14.8 34.2\u00b13.7 64.3\u00b12.4 55.8\u00b13.6 33.6\u00b14.6 55.2\u00b19.2 49.4\u00b17.9 39.8\u00b11.7 39.0\u00b12.7 38.9\u00b13.1 53.0\u00b13.8 59.2\u00b14.6 60.5\u00b14.7 23.6\u00b13.9 27.5\u00b13.8 41.4\u00b15.5 38.0\u00b15.4 29.4\u00b12.8 40.4\u00b11.8 55.8\u00b13.6 55.9\u00b13.2 33.3\u00b13.0 49.9\u00b15.4 47.1\u00b14.33.7 1.8 2.4 2.1 28.8 3.4 7.4 10.6 16.0 8.5 12.1 25.1 24.9 11.1 21.8 15.0 30.9 5.4 6.6 10.6 18.3 9.5 9.4 32.7 24.9 11.0 26.5 16.3 8.7 7.9 12.6 17.5 24.6 26.2 3.1 4.3 12.5 10.4 6.6 13.9 24.2 22.3 10.7 19.9 15.932.2 25.0 24.6 24.1 65.1 27.2 37.2 47.3 54.1 39.7 48.1 62.8 61.5 45.8 59.4 53.7 66.2 34.9 35.0 47.6 56.0 40.8 43.4 69.3 61.5 47.0 63.0 55.6 43.4 42.5 49.5 55.9 62.7 63.7 26.9 35.9 50.2 46.6 40.3 48.2 60.8 59.7 45.4 56.3 53.3HUMAN-91.582.992.879.357.881.6SettingMainQSubQSelective SubQEliminat. SubQ0-shot 5-shot41.0\u221223.0 58.8\u22124.2 86.4\u22123.7 42.5\u221229.7 70.5+0.0 86.9\u22123.153.4\u22124.3 64.7+1.7"
            },
            {
                "figure_label": "9",
                "figure_type": "table",
                "figure_id": "tab_11",
                "figure_caption": "Context-ablated accuracy. The subscript values indicate the accuracy gap against the full-input setting.",
                "figure_data": ""
            },
            {
                "figure_label": "11",
                "figure_type": "table",
                "figure_id": "tab_13",
                "figure_caption": "Examples of the main questions and subquestions in our dataset. The options in bold indicate the correct answer.",
                "figure_data": ""
            },
            {
                "figure_label": "12",
                "figure_type": "table",
                "figure_id": "tab_14",
                "figure_caption": "Rationales that are semantically similar to the MainQ's option in Selective and Eliminative SubQs.",
                "figure_data": ""
            }
        ],
        "formulas": [],
        "doi": "10.18653/v1/2021.acl-long.238"
    },
    "Absolute Position Embedding Learns Sinusoid-like Waves for Attention Based on Relative Position": {
        "authors": "Yuji Yamamoto; Takuya Matsuzaki",
        "pub_date": "",
        "abstract": "Attention weight is a clue to interpret how a Transformer-based model makes an inference. In some attention heads, the attention focuses on the neighbors of each token. This allows the output vector of each token to depend on the surrounding tokens and contributes to make the inference context-dependent. We analyze the mechanism behind the concentration of attention on nearby tokens. We show that the phenomenon emerges as follows: (1) learned position embedding has sinusoid-like components, (2) such components are transmitted to the query and the key in the selfattention, (3) the attention head shifts the phases of the sinusoid-like components so that the attention concentrates on nearby tokens at specific relative positions. In other words, a certain type of Transformer-based model acquires the sinusoidal positional encoding to some extent on its own through Masked Language Modeling.",
        "sections": [
            {
                "heading": "Introduction",
                "text": [
                    "The architecture of Transformer (Vaswani et al., 2017) is symmetric with respect to the token position and it captures word order only through the position embedding included in the input. Thanks to this design, Transformer can flexibly learn relationships between tokens while allowing parallelization. To derive a representation of a context, previous language models have used, for instance, recurrent units to process tokens in the given token order, or convolution to aggregate tokens within a given range. In these models, the property of translation invariance of language has been captured through the architecture of the models. In contrast, Transformer receives all tokens at the same time and does not restrict the positions of the tokens on which each token depends; in exchange for it, the translation invariance has to be learned rather than imposed by the architecture.",
                    "Position embedding is thus the key to make inferences in Transformer context-dependent. While Transformer uses deterministic sinusoidal position embedding, BERT (Devlin et al., 2019) uses a learnable absolute position embedding. The latter learns the positional representation only through word cooccurrences. Clark et al. (2019) and Kovaleva et al. (2019) investigated the attention weights of the self-attention in BERT and found that the attention in some heads is largely determined by relative positions (Figure 1). This implies that even when the absolute position embedding is used, self-attention can make an inference depending on relative position. Wang et al. (2021) compared various position embedding methods based on the performance in downstream tasks. Their results showed that local translation invariance and asymmetric position bias with respect to the direction improved the performance. Ravishankar and S\u00f8gaard (2021) observed that some columns of absolute position embedding were periodic. Chang et al. (2022) showed that position representation was periodic even in hidden representations. However, it is not clear how the periodicity is used in the model.",
                    "In this work, we analyze how attention depends on relative position. As a result, we show that the relative positional dependence of attention emerges due to the following factors.",
                    "\u2022 The learnable absolute position embedding has sinusoid-like waves with several limited frequencies ( \u00a74.1.1).",
                    "\u2022 Attention heads extract periodic components derived from position embedding from the hidden states. It is made explicit by applying Singular Value Decomposition to the parameters of the pre-trained language model ( \u00a74.2).",
                    "\u2022 The self-attention shifts the phase of the periodic components in the query and the key to decide the direction of attention ( \u00a74.3, \u00a74.4).",
                    "Thus, it becomes partially clear how the selfattention equipped with learnable absolute position embeddings makes inferences based on context. However, it is suggested that, when the attention is strongly concentrated on the adjacent tokens, the word embedding is also a factor that enables inference based on relative position ( \u00a75)."
                ],
                "publication_ref": [
                    "b16",
                    "b2",
                    "b1",
                    "b6",
                    "b17",
                    "b13",
                    "b0"
                ],
                "figure_ref": [
                    "fig_0"
                ],
                "table_ref": []
            },
            {
                "heading": "Background",
                "text": [
                    "In this section, we review the multi-head selfattention mechanism and position embedding."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Multi-Head Self-Attention",
                "text": [
                    "The self-attention mixes the representations of tokens at different positions. The input to the l-th attention layer is a matrix X l \u2208 R T \u00d7d whose kth row corresponds to the hidden representation of the k-th token as a vector in R d . The output of the self-attention layer is defined as follows:",
                    "A lh = softmax ( X l W Q lh (X l W K lh ) T \u221a d/n ) (1) O lh = A lh X l W V lh (2) MultiHead l = concat(O l1 , . . . , O ln )W O l(3)",
                    "where",
                    "W Q lh , W K lh , W V lh \u2208 R d\u00d7(d/n",
                    ") and W O l \u2208 R d\u00d7d are the parameters, n is the number of attention heads per layer, and the subscripts l and h are the indices of the layer and the head, respectively.",
                    "In this paper, we refer to the h-th head in the l-th layer as \"head(l, h)\" for short, and omit the subscripts l, h when the discussions are common to all layers and heads. The matrices XW Q , XW K , and A are called query, key, and attention weight, respectively. If the (i, j) element of A is large, it is interpreted that the i-th token in the sentence attends to the j-th token."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Position Embedding",
                "text": [
                    "Transformer's position embedding is defined as follows (Sinusoidal Position Embedding; SPE):",
                    "SP E (pos,2i) = sin(pos/10000 2i/d ) (4)",
                    "SP E (pos,2i+1) = cos(pos/10000 2i/d ).",
                    "(5) Vaswani et al. (2017) hypothesized that it allows the model to easily learn to attend by relative positions, since the offset between two tokens can be expressed as a matrix product:",
                    "[ sin x i cos x i ] [ cos \u03b8 \u2212 sin \u03b8 sin \u03b8 cos \u03b8 ] = [ sin(x i + \u03b8) cos(x i + \u03b8) ] .(6)",
                    "BERT's position embedding is a learnable parameter. It is called the Absolute Position Embedding (APE) because each row represents an absolute position in the input sequence.",
                    "RoBERTa (Liu et al., 2019) is identical to BERT in architecture. RoBERTa is pre-trained with 512 tokens for all steps whereas BERT is pre-trained with 128 tokens for 90% of the steps. Hence, RoBERTa's APE recieves the same number of updates regardless of the positions. Wang and Chen (2020) showed that RoBERTa's APE is more orderly than BERT's. We thus use RoBERTa for all experiments to analyze the position dependence of inference."
                ],
                "publication_ref": [
                    "b16",
                    "b9",
                    "b18"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Relative Position Dependence of Attention",
                "text": [
                    "In this section, we demonstrate that the attention depends on the relative position. Specifically, we analyze in how many heads the attention is dependent on the relative position, and the variation in the direction and concentration of the attention across the heads. The visualizations of the attention weight A lh in Figure 1 shows that, in (a) and (d), each token strongly attends only to the adjacent token, while in (b) and (e), the attention is put on a few nearby tokens on the left or right side. We show that such a pattern is largely invariant with respect to the inputs, by clustering the patterns of the attention on different inputs.",
                    "To focus on the relation between the attention and the relative positions, we summarized the attention weight for each input in each head into a vector and applied k-means clustering to them. For that, we defined t-offset trace tr t as follows:",
                    "tr t (A) = { \u2211 T \u2212t i=1 (A) i,i+t (t \u2265 0) \u2211 T +t i=1 (A) i\u2212t,i (t < 0)(7)",
                    "and transformed A lh to a vector:",
                    "a lh = [tr \u221210 (A lh ), . . . , tr 10 (A lh )] \u2208 R 21 . (8",
                    ")",
                    "These vectors represent the trend of attention A lh with respect to relative position. We input 100 sentences of length 512 created from wikitext-2 (Merity et al., 2017) into RoBERTa and computed vectors a lh for every head. Figure 2 shows the results of applying the k-means to a total of 100 \u00d7 12 \u00d7 12 vectors a lh when the number of clusters was set to 6. In the clusters named leftward and next-to-left (resp. rightward and next-to-right), the attention is concentrated on the nearby tokens on the left (resp. right). Particularly, in the clusters named next-to-left and next-to-right, the attention is strongly concentrated on the adjacent tokens. We found that, for each head, the vectors a lh corresponding to the 100 inputs were grouped into one or two clusters. This means that there are some heads that always attended to the same direction for all the input."
                ],
                "publication_ref": [
                    "b10"
                ],
                "figure_ref": [
                    "fig_0",
                    "fig_1"
                ],
                "table_ref": []
            },
            {
                "heading": "Attention to Nearby Tokens",
                "text": [
                    "In this section, we show that the attention depends on relative position due to periodic components in the position embeddings. First, we show that the learnable absolute position embeddings acquire several limited frequency components. Second, we show that some attention heads extract the periodicity derived from position embeddings. Finally, we show that the concentration of attention on the nearby tokens is due to the periodicity."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Learned Representation of Positions",
                "text": [
                    "First, we show that APE includes sinusoid-like components using the Discrete Fourier Transform (DFT). Next, we show that the position embeddings are confined to a relatively low-dimensional subspace (~15 dimensions) using Principal Component Analysis (PCA). Finally, we show that the encoded positional information occupies a similar number of dimensions in the hidden states as in the position embedding, and the dimensionality becomes smaller in the higher layers using Canonical Correlation Analysis (CCA)."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "APE Includes Sinusoid-like Waves",
                "text": [
                    "We view the RoBERTa's position embedding E pos \u2208 R T \u00d7d as a collection of d time series of length T . We computed the amplitude spectrum of each column of E pos by applying DFT:",
                    "spec i = abs(DFT(E pos e i ))(9)",
                    "where e i \u2208 R d is the i-th elementary unit vector. The vector E pos e i is hence the i-th column of E pos .",
                    "Figure 3a shows the mean and the quartile range of the amplitude spectra of d = 768 time series. The amplitude spectra peak at some frequencies, indicating that the learnable APE has acquired periodicity through pre-training, even though it is not explicitly defined using sinusoidal waves as in Transformer. In contrast, there are no peaks in the amplitude spectrum of a word embedding sequence of a sample text. 1 The periodicity is thus an unique property of learned position embeddings.",
                    "We investigated whether similar properties are present in pre-trained models other than RoBERTa (Figure 3b and 13). The amplitude spectra of the encoder-only models are similar to RoBERTa regardless of language, but ones of GPT-2 (Radford et al., 2019) are higher at lower frequencies.",
                    "The decoder model probably can focus attention on the neighboring tokens of itself without periodicity-based mechanisms ( \u00a74.3). For example, if attention is paid more strongly to the backward token, in BERT, attention is focused on the end of the sentence, but in a decoder with causal attention mask, attention is focused on itself. We leave it to future research to clarify whether this Blue line is the mean of spec i and blue area is the quartile range. Orange line is the spectrum of word embeddings for an input before adding position embeddings. phenomenon really occurs in the causal model, and in this paper we focus on the case where selfattention is symmetric with respect to position."
                ],
                "publication_ref": [
                    "b11"
                ],
                "figure_ref": [
                    "fig_2",
                    "fig_10"
                ],
                "table_ref": []
            },
            {
                "heading": "Dimensionality of Positional Representation",
                "text": [
                    "We applied PCA to the position embeddings to see how many dimensions were used to represent the positions. The cumulative principal component contribution rate of the position embedding was 50.51% for the top 4 dimensions, and 92.23% for the top 12 dimensions (see Figure 12 in Appendix A for a plot). This means that the positions are mostly encoded in a low dimensional subspace.",
                    "We then employed CCA to show how much the input to the self-attention layers included the positional representation. CCA is a method for investigating the relation of two sets of variables by finding the parameters a and b that maximizes the correlation between two synthetic variables Xa and Y b given two inputs X and Y . Raghu et al. (2017) showed that CCA allows layer-to-layer comparison of deep learning models. We used the representation of neurons and layers proposed by them and computed the correlation between the hidden layer and the position embeddings.",
                    "In this study, the i-th neuron z l i of layer l and the l-th layer Z l are represented as follows:",
                    "z l i = [ z l i (x 1 ), . . . , z l i (x m )",
                    "] T (10) where z l i (x j ) is the response of the i-th neuron to input x j . We input 200 sentences of length 512 created from wikitext-2 into RoBERTa and collected the responses of each layer for the input of m = 200 \u00d7 512 tokens. We then maximized their correlation coefficients \u03c1 k :",
                    "Z l = [ z l 1 , . . . , z l n ](11)",
                    "\u03c1 k = max a k ,b k Corr(Z l 1 a k , Z l 2 b k ) (12)",
                    "where a k is chosen such that it is orthogonal to a 1 , . . . , a k\u22121 and similarly for b k . The CCA coefficients in Figure 4 show that the hidden states of higher layers have lower correlations with the position embeddings. This is in agreement with Lin et al.'s (2019) result that BERT phases out positional information as it passes through the layers.",
                    "The CCA result indicates that the number of components that are highly correlated with position embedding is only 5~20-dimensions, and the PCA result suggests that it is enough to accommodate the positional representation. This indicates that the hidden states include positional representation in a low-dimensional subspace, similarly to position embedding."
                ],
                "publication_ref": [
                    "b12"
                ],
                "figure_ref": [
                    "fig_9",
                    "fig_3"
                ],
                "table_ref": []
            },
            {
                "heading": "Positional Representation in",
                "text": [
                    "Self-Attention",
                    "It is not at all clear how the positional representation in the hidden states contribute to the inference in self-attention. We thus analyzed how attention weight is calculated, which is one of the most important process in self-attention."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Rethinking About Query and Key",
                "text": [
                    "The attention weight A is determined by the inner product of the rows of the query and the key matrix. We thus expect that the relative position dependence of the attention can be explained by analyzing the relationship between the query and the key. We begin by rethinking about their definition. The two parameter matrices W Q and W K contribute to the attention only through their product W Q (W K ) T (Eq. ( 1)). Hence, they can be seen as a parametrization of a rank-restricted d \u00d7 d matrix, and we may consider another decomposition of the product W Q (W K ) T . We found that some sinusoid-like components were obtained from the query and the key by applying Singular Value Decomposition (SVD) to W Q (W K ) T . Specifically, the query and the key are redefined as the product of the hidden state and the singular vectors:",
                    "W Q (W K ) T = U Q S(U K ) T (13) Q = XU Q , K = XU K (14)",
                    "where the matrix S \u2208 R d\u00d7d is a diagonal matrix diag(s 1 , . . . , s d/n , 0, . . . , 0) and each element s i is a singular value. In the rest of this paper, we refer to Q and K defined above as the query and the key, respectively. As shown in Figure 5, in the head in which the attention depends on relative position, sinusoid-like waves appear in several columns of the redefined query Q and the key K. Moreover, a sine wave is paired with a cosine wave of the same frequency, as the 5-th and the 6-th column for head(1, 1) shown in Figure 5. Furthermore, the introduction of SVD provides a new theoretical interpretation of self-attention. Let R be the orthogonal matrix R = (U Q ) T U K . Then U K can be written as U K = U Q R due to the orthogonality of the singular vectors. Thus, the key K can be written as:",
                    "K = XU K = XU Q R = QR (15)",
                    "That is to say, the rows of the key are the result of an orthogonal transformation of the rows of the query. The relation between the query and the key is thus summarized in the matrix R.",
                    "In addition, since the singular value matrix S is diagonal, the product of the query and the key can be written as follows:",
                    "XW Q (XW K ) T = QSK T = d/n \u2211 i=1 s i q i k T i (16)",
                    "where q i and k i are the i-th columns of Q and K, respectively. Eq. ( 16) says that the subsets of queries [q i ] and keys [k i ] corresponding to the top singular values [s i ] are more important in the calculation of the attention distribution. We hereafter call the matrix QSK T attention score (i.e., attention before applying softmax)."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_4",
                    "fig_4"
                ],
                "table_ref": []
            },
            {
                "heading": "Spectral Analysis of Query and Key",
                "text": [
                    "We computed the amplitude spectrum of each column of the query Q lh in each head, using the same procedure for the position embeddings in \u00a74.1.1:",
                    "spec lhi = abs(DFT(Q lh e i )) (17) max-spec l = [max h,i (spec lhi ) f ] f =0,...,T /2 . (18",
                    ")",
                    "By taking the maximum of spec lhi among the heads and the columns of Q lh , we check if there are high peaks in the spectra of the queries in the l-th layer (similarly for the keys and hidden states).",
                    "Figure 6 show that the query and key spectra peak at the same frequency bands as the position embeddings, indicating that attention heads extract periodic representations derived from the position embeddings. Furthermore, some of the peaks disappear in the higher layers (downward in the Figure 6), indicating that the periodic components derived from the position embeddings are not dominant in the higher layers. This is consistent with the result that the correlation between the position embeddings and the hiddem states of each layer gradually decreases ( \u00a74.1.2). It also agrees with the result shown by Lin et al. ( 2019) that position information is discarded between the 3rd and 4th layers."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_5",
                    "fig_5"
                ],
                "table_ref": []
            },
            {
                "heading": "Attention Based on Relative Position is due to the Phase Shift",
                "text": [
                    "As shown in Figure 5, there are phase shifts in the sinusoid-like components of the query and the key.",
                    "In this subsection, we focus on the phase shifts, and clarify that the direction and the width of the phase shifts determine where the attention is concentrated. We measure the direction and the width of the phase shift by cross-covariance and crosscorrelation, defined as follows:",
                    "xcov j (t) = { \u2211 T \u2212t i=1 q i,j k i+t,j (t \u2265 0) \u2211 T +t i=1 q i\u2212t,j k i,j (t < 0) (19) xcorr j (t) = xcov j (t) \u2212 E t [xcov j (t)] \u2225q j \u2225\u2225k j \u2225(20)",
                    "For example, Figure 7 shows the cross-correlation between the queries and keys in Figure 5. Both xcorr 5 (t) and xcorr 6 (t) attain a maximal value at t = \u22122 and t = \u22123. It means that the phase shift between the queries and the keys are approximately 2.5 tokens.",
                    "It can be explained theoretically that the direction of phase shift coincides with the direction of attention. The cross-covariance is related to the product of query and key (Eq. ( 16)): where tr t is the t-offset trace defined in Eq. ( 7) and s 1 , . . . , s d/n are the singular values of W Q (W K ) T . According to Eq. (21-23), the sum of the attention scores at relative position t is equal to the weighted sum of the inner product of q j and k j shifted by t. Therefore if the xcov j (t)s corresponding to the top singular values attain maximal values at the same t, the attention is likely to be concentrated around relative position t. Figure 8 and 9 show that it is actually the case. Figure 9 presents the cross-correlations of the query q j and the key k j for js corresponding to the top singular values. We can see how the concentration of attention on nearby tokens is formed by the weighted superposition of the crosscorrelations. In head(1, 1), the maxima of the cross-correlations near t = \u22121 stack up, while the maxima away from t = \u22121 cancel with the minima of other components. Since there are multiple periodic components with different frequencies (Figure 3a), the attention is not concentrated away from each token. In contrast, in head(8, 9), some cross-correlations have narrow peaks only at t = \u22121, and it makes the attention be very concentrated only on the adjacent tokens. However, it is unlikely that the cause of the narrow peaks is the sinusoid-like waves, because their period is approximately 8 tokens or more. 2",
                    "tr t (QSK T ) = T \u2212t \u2211 i=1 (QSK T ) i,i+t(21)",
                    "= T \u2212t \u2211 i=1 d/n \u2211 j=1 s j q i,j k i+t,j(22)",
                    "= d/n \u2211 j=1 s j xcov j (t)(23)"
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_4",
                    "fig_4",
                    "fig_2"
                ],
                "table_ref": []
            },
            {
                "heading": "Phase Shift Width is the Same even if",
                "text": [
                    "Frequencies are Different",
                    "We saw in the previous subsection that the main factor of the concentration of attention is that the phases of multiple sinusoid-like waves are all shifted by the same number of tokens. In this subsection, we explain it based on the property of the eigenvalues and the eigenvectors of the matrix R that relates the query Q to the key K.",
                    "Let p i \u2208 C d and \u03bb i \u2208 C be an eigenvector and an eigenvalue of the matrix R, respectively. Since R is an orthogonal matrix, its eigenvalue can be expressed as \u03bb i = e j\u03b8 i where j is the imaginary unit. From Eq. ( 15), the following relation between the query and the key holds:",
                    "Kp i = QRp i = Q\u03bb i p i = Qp i \u2022 e j\u03b8 i .(24)",
                    "Let two conditions be assumed: (1) for each i = 1, . . . , d, the time series Qp i is sinusoidal with a single frequency f i and (2) the ratio of the argument \u03b8 i of the eigenvalue \u03bb i to the frequency f i is constant regardless of i. Then Eq. ( 24) implies that the phases of Qp i and Kp i differ by a constant number of tokens for any eigenvector p i :",
                    "(Qp i ) t = (Kp i ) t+\u2206(25)",
                    "where \u2206 = (T /2\u03c0) \u2022 (\u03b8 i /f i ). Furthermore, Q t = K t+\u2206 follows from Eq. ( 25). We provide the proofs in Appendix D. We verify whether the two conditions hold by analyzing the periodicity of Qp i and the ratio of the frequency to the argument \u03b8 i of the eigenvalue \u03bb i . To do so, we define the bivariate functions g for frequency and argument as follows:",
                    "g(f, \u03b8 i ) = abs(DFT(Qp i )) f (26)",
                    "This function g is shown in Figure 10 as a 2D histogram. Figure 10 shows that the spectrum of Qp i has peaks in different frequency bands according to \u03b8 i . It means that the component along each eigenvector p i is fairly band-limited, namely they are sinusoid-like. Furthermore, the spectral peaks 2 Figure 3a shows that the maximum frequency of the position embeddings is around 60. The minimum period is hence 512/60 (> 8) tokens. appear around a straight line. Specifically, the ratio \u2206(f, \u03b8) of frequency to phase defined as follows is nearly constant:",
                    "\u2206(f, \u03b8) = T 2\u03c0 \u2022 \u03b8 f . (27",
                    ")",
                    "Hence, the two conditions are in fact approximately hold. Thus, by multiplying the matrix R, the sinusoid-like components in the key are offset by a certain number of tokens relative to the query."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_7",
                    "fig_7",
                    "fig_2"
                ],
                "table_ref": []
            },
            {
                "heading": "Attention to the Adjacent Tokens",
                "text": [
                    "Figure 9 shows that, in head(8, 9), there are not only sinusoid-like waves but also spikes at the relative position t = \u22121. In this section, we dive deeper into the fact that, in some heads, the attention is focused only on the adjacent token. We analyze how the attention changes when we modify either the position embedding or the word embedding component. The following are the results on the modified inputs and insights from them.",
                    "Baseline The input is the sum of word embedding and position embedding as usual. This result is shown in Figure 8 and 9.",
                    "Only position embedding The word embeddings are replaced with zero vectors. Figure 11a shows that spikes of cross-correlation do not appear for this case. This suggests that position embedding is not the only cause of the spikes.",
                    "Only word embedding The position embeddings are replaced with zero vectors. Figure 11b shows that most of the cross-correlations are flat for this case. It suggests that word embedding contributes less to make the attention dependent on relative position. However, it is interesting that the cross-covariance at t = \u22121 (i.e., left neighbor) is relatively large even without position information.",
                    "Shuffling word embeddings The order of word embeddings is shuffled. Figure 11c shows that spikes appear at the relative position t = \u22121 even for this case. It suggests that the contribution of position embedding is significant in determining the direction of attention, since the attention is focused on the preceding word regardless of what it actually is.",
                    "As mentioned at the end of Section 4.3 and also suggested by Figure 11a, it is unlikely that position embedding is the only cause of the strong concentration of attention on the adjacent tokens. However, if the word embeddings identified the adjacent tokens (i.e., if the narrow peak of cross-correlation appeared due to an interaction of the word embeddings of a frequently occurring bigram), the attention would have been moved to non-neighboring positions by the shuffling of word embeddings, but this was not the case. It is thus suggested that the concept of adjacency in RoBERTa is built upon both word meaning and positional information."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_8",
                    "fig_8",
                    "fig_8",
                    "fig_8"
                ],
                "table_ref": []
            },
            {
                "heading": "Remark on the Learning Process of Position Embeddings",
                "text": [
                    "The training data of the masked language modeling is only word sequences without positional information. It suggests that the relative position dependence of attention is acquired by the combination of two factors: (1) the linguistic property that related words tend to appear nearby due to grammatical rules and collocations, and (2) the property that attention is focused on the word that is syntactically or semantically related and hence gives clue to fill the masked token. In appendix E, we demonstrate that the position representation can be acquired with a much smaller amount of training data than pre-training."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Related Works",
                "text": [
                    "Ravishankar and S\u00f8gaard (2021) observed that some columns of absolute position embedding were periodic and sinusoidal position embedding was more effective in multilingual models than other embedding methods. Chang et al. (2022) showed that position representation was periodic even in hidden representations by using Linear Discriminant Analysis, i.e., by identifying the axes separating the different position representations. We showed that sinusoid-like components could be extracted from the hidden states by applying SVD to the pre-trained parameters of the selfattention even though SVD does not have the objective of separating positional representations. Vaswani et al. (2017) stated that the sinusoidal position embedding allowed position offsets to be represented by a rotation transformation (Eq. ( 6)), and this could prompt learning of attention that depends on relative position. We showed that the query and the key in the self-attention included sinusoid-like components and the learned parameters in the self-attention shift the phase of the query and the key relatively. This means that the mechanism hypothesized by Vaswani et al. is in fact acquired through pre-training by masked language modeling. However, the frequencies acquired by the position embedding of RoBERTa are only in the specific frequency bands, whereas sinusoidal position embedding has d/2 frequencies (Eq. ( 4)-( 5)). RoBERTa thus seems to have acquired a more economical positon embedding than sinusoidal position embedding.",
                    "Recently, there are many variants of position embedding and Dufter et al. (2022) surveyed them exhaustively. In particular, Rotary Position Embedding (RoPE) (Su et al., 2022), a type of Relative Position Embedding (RPE) (Shaw et al., 2018), relates to the property that the self attetnion acquires the rotation matrix through pre-training.",
                    "To acquire relative positional dependence, RoPE widens the angle between query and key proportionally to the relative position, while pre-trained self-attention rotates the hidden states containing absolute positional bias by the same angle regardless of position. In other words, APE and selfattention, which are distant components, must acquire frequency and angle of rotation, respectively, to satisfy the relation Eq. ( 27). If translation invariance is essential to language understanding, the cost of discovering this relation is a possible reason why APEs are inefficient to learn compared to RPEs."
                ],
                "publication_ref": [
                    "b0",
                    "b16",
                    "b3",
                    "b15",
                    "b14"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Conclusion",
                "text": [
                    "We analyzed the concentration of attention based on relative position in the self-attention using the learnable absolute position embedding. As a result, we showed that it is due to relative phase shifts of the periodic components in the query and the key derived from position embeddings. Our results explain in part that absolute position embedding allows inference based on relative position."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Limitations",
                "text": [
                    "As mentioned in \u00a74.1.1, the positional representation of the GPT-2 differs significantly from ones of the encoder models. Thus, it is impossible to interpret the inferences of the decoder-only model in the same way as in this study.",
                    "In the tasks of predicting sentence structure (e.g., dependency parsing), the relative order of two tokens is important regardless of the distance between them. However, we analyzed the dependence of the output of each token only on the nearby tokens. Thus, it is unclear whether position embedding provides relative position information that helps determine which of the distant tokens precedes the other.",
                    "We obtained an interpretable representation by decomposing the attention scores before applying softmax function (Eq. ( 16)). When analyzing the contribution of the decomposed representations to downstream components (e.g., Value in self-attention), the non-linearity of softmax function should be taken into account."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A Cumulative Principal Component",
                "text": [
                    "Contribution Rate "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "B Amplitude Spectra of Various Models",
                "text": [
                    "We computed the amplitude spectra of the position embeddings of bert-base-uncased, cl-tohoku/bert-base-japanese-whole-word -masking, xlm-roberta-base, and gpt2 in the same way as Figure 3a. In Figure 13, the encoder models BERT and RoBERTa both have peaks in their amplitude spectra, and RoBERTa has a higher peaks. On the other hand, the GPT-2 decoder model has only low-frequency components. This suggests that the representation of absolute position embedding is similar between encoder models, regardless of language, but differs significantly between encoder models and decoder models. In fact, Irie et al. (2019) and Kazemnejad et al. (2023) showed that the position embeddings is unnecessary for the decoder models."
                ],
                "publication_ref": [
                    "b4"
                ],
                "figure_ref": [
                    "fig_2",
                    "fig_10"
                ],
                "table_ref": []
            },
            {
                "heading": "C Comparing Different Architectures",
                "text": [
                    "This paper analyzed an encoder-only model (RoBERTa). In this section, we apply our methods to other transformer-based architectures: decoderonly and encoder-decoder. The target pre-trained models are GPT-2 (gpt2) for decoder-only and BART (facebook/bart-base) (Lewis et al., 2020) for encoder-decoder, both of which use absolute position embedding and are available on huggingface. To reduce the gap between architectures, when analyzing the decoders, we use the attention scores, which is the matrix before causal masking and softmax function are applied, instead of the attention weights.",
                    "The attention matrices of GPT-2 show two main patterns: one related to position and the other not. Figure 14a shows that the attention head of GPT-2 pays stronger attention to the closer tokens by concentrating attention on the backward tokens, which are masked in the subsequent processing.",
                    "Figure 15 shows the result of clustering the attention scores of GPT-2 using k-means. The number of clusters was set to 2 and the inputs to k-means were t-offset traces (Eq.( 8)) from t = \u221230 to 30.",
                    "The heads that depend on position are found in the lower layers. Along \u00a74.4, we investigate the relationship between the frequency of the hidden state and the angle of the rotation matrix inherent in the parameters of attention head. Figure 16a differs from the case of RoBERTa (Figure 10) in that the peaks appear horizontally rather than holding a constant ratio between frequency and angle. Furthermore, according to Figure 13, the dominant components in position embedding of GPT-2 are those with frequencies below 10, i.e., with periods longer than 51.2 (= 512/10) tokens. These differences from RoBERTa imply that even when the attention is focused within a few tokens in a particular head, it cannot be attributed to the mechanism described in \u00a74.3.",
                    "In BART, the tendency in the positional dependence of attention differs between encoder and decoder. In encoder, the patterns of attention weights (Figure 17) and their trend (Figure 18), such as direction and strength, are similar to those of RoBERTa (Figure 1 and 2). On the other hand, comparing Figure 14 and Figure 20, the patterns of decoder is different from those of GPT-2. Such patterns in the BART decoder could not be clustered based on the strength or direction of attention using k-means. Like in GPT-2, Figure 21 shows that the peaks appear horizontally in the decoder.        Freezing parameters We freezed all parameters except position embeddings. This encourages the position embeddings to learn to focus attention only on position t = 1, 5, 9, 13, \u2022 \u2022 \u2022 and prevents positionindependent shortcut solutions (e.g., shortening the UNK embedding to ignore it)."
                ],
                "publication_ref": [
                    "b7"
                ],
                "figure_ref": [
                    "fig_11",
                    "fig_4",
                    "fig_5",
                    "fig_7",
                    "fig_10",
                    "fig_0",
                    "fig_0",
                    "fig_1",
                    "fig_11",
                    "fig_16",
                    "fig_1"
                ],
                "table_ref": []
            },
            {
                "heading": "Figures for GPT-",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Position embedding The position embeddings",
                "text": [
                    "were initialized with random values following a normal distribution N (0, 0.02 2 ) before training."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "E.2 Results",
                "text": [
                    "Table 1 shows that, before the additional training, RoBERTa cannot fill MASK with the appropriate tokens (in this case, nouns beginning with a vowel) when UNKs are inserted, but after the additional 3 Since Transformer is symmetric with respect to position, this process is similar to padding. However, the PAD token of RoBERTa published on hugging face is zero-vector, which is inconvenient for analyzing interactions between word embeddings. Thus, we choose UNK tokens. training, the models can predict them. The attention weights during inference are visualized in Figure 22. Since the attentions are concentrated every fourth token, the model with relearned position embeddings recognizes the relative positions of the non-UNK tokens. This result suggests that the attention is not focused on the tokens that cooccur frequently, but on the tokens that are informative to fill the MASK token. Thus, the relative position dependence of attention is simply caused by the fact that related words appear nearby.",
                    "In summary, this experiment indicates that the relative position dependence of attention is caused by the combination of two factors: (1) the linguistic property that related words tend to appear nearby due to grammatical rules and collocations, and (2) the property that attention is focused on words that are related in some sense."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_1"
                ],
                "table_ref": [
                    "tab_0"
                ]
            },
            {
                "heading": "D Theorems About the Phase Shift",
                "text": [
                    "Between the Query and the Key Theorem 1. The following two assumptions are given:",
                    "1. Qp i is sinusoidal with a single frequency f i .",
                    "2. The ratio of the argument \u03b8 i of an eigenvalue \u03bb i to the frequency f i is constant regardless of i.",
                    "In this case, Eq. ( 25) is derived from Eq. ( 24):",
                    "Proof. Since Qp i is sinusoidal, the t-th element in polar form is as follows:",
                    "where r i is the absolute value of (Qp i ) t . Then the t-th element of Kp i can be written as follows from Eq. ( 24):",
                    "where",
                    ". Now, since the ratio of the argument \u03b8 i to the frequency f i is constant, \u2206 i is independent of i, namely, \u2206 i can be replaced with a constant \u2206. Thus, (Qp i ) t = (Kp i ) t+\u2206 holds from Eq. ( 28) and Eq. (31).",
                    "Let the matrix P = [p 1 , p 2 , . . . , p d ], then the following equation holds:",
                    "Theorem 2. When, in a given basis, the position of each token in the key is offset by \u2206(\u2208 Z) tokens relative to the query, then in any basis, there is an Proof. Let B be an arbitrary matrix. Then,",
                    "(KP ) t+\u2206,k (P \u22121 B) ki (\u2235 Eq. ( 33))",
                    "(37)",
                    "In particular, when B = I, the equation Q t = K t+\u2206 is obtained."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "E How the Relative Position Dependence of Attention Emerges",
                "text": [
                    "How does a masked language model acquire the concept of \"neighborhood\" even though absolute position embedding learns without the information about the order of the tokens? In this section, we demonstrate the process of acquiring the ability to focus attention on nearby tokens by relearning the position embedding under the masked language modeling. Suppose that the following sentence is input into a pre-trained model: \"This <unk> is <unk> an <unk> <mask> .\"",
                    "Since this sentence is collapsed with many UNK tokens, the model cannot fill the MASK correctly. If we re-learn the position embedding, will the model be able to fill it?"
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            }
        ],
        "references": [
            {
                "ref_id": "b0",
                "title": "The geometry of multilingual language model representations",
                "journal": "",
                "year": "2022",
                "authors": "Tyler Chang; Zhuowen Tu; Benjamin Bergen"
            },
            {
                "ref_id": "b1",
                "title": "does BERT look at? an analysis of BERT's attention",
                "journal": "Association for Computational Linguistics",
                "year": "2019",
                "authors": "Kevin Clark; Urvashi Khandelwal; Omer Levy; Christopher D Manning"
            },
            {
                "ref_id": "b2",
                "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
                "journal": "Long and Short Papers",
                "year": "2019",
                "authors": "Jacob Devlin; Ming-Wei Chang; Kenton Lee; Kristina Toutanova"
            },
            {
                "ref_id": "b3",
                "title": "Position information in transformers: An overview",
                "journal": "Computational Linguistics",
                "year": "2022",
                "authors": "Philipp Dufter; Martin Schmitt; Hinrich Sch\u00fctze"
            },
            {
                "ref_id": "b4",
                "title": "Language Modeling with Deep Transformers",
                "journal": "",
                "year": "2019",
                "authors": "Kazuki Irie; Albert Zeyer; Ralf Schl\u00fcter; Hermann Ney"
            },
            {
                "ref_id": "b5",
                "title": "Karthikeyan Natesan Ramamurthy, Payel Das, and Siva Reddy. 2023. The impact of positional encoding on length generalization in transformers",
                "journal": "",
                "year": "",
                "authors": "Amirhossein Kazemnejad; Inkit Padhi"
            },
            {
                "ref_id": "b6",
                "title": "Revealing the dark secrets of BERT",
                "journal": "Association for Computational Linguistics",
                "year": "2019",
                "authors": "Olga Kovaleva; Alexey Romanov; Anna Rogers; Anna Rumshisky"
            },
            {
                "ref_id": "b7",
                "title": "BART: Denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension",
                "journal": "",
                "year": "2020",
                "authors": "Mike Lewis; Yinhan Liu; Naman Goyal ; Abdelrahman Mohamed; Omer Levy; Veselin Stoyanov; Luke Zettlemoyer"
            },
            {
                "ref_id": "b8",
                "title": "Open sesame: Getting inside BERT's linguistic knowledge",
                "journal": "",
                "year": "2019",
                "authors": "Yongjie Lin; Yi Chern Tan; Robert Frank"
            },
            {
                "ref_id": "b9",
                "title": "RoBERTa: A robustly optimized bert pretraining approach",
                "journal": "",
                "year": "2019",
                "authors": "Yinhan Liu; Myle Ott; Naman Goyal; Jingfei Du; Mandar Joshi; Danqi Chen; Omer Levy; Mike Lewis; Luke Zettlemoyer; Veselin Stoyanov"
            },
            {
                "ref_id": "b10",
                "title": "Pointer sentinel mixture models",
                "journal": "",
                "year": "2017",
                "authors": "Stephen Merity; Caiming Xiong; James Bradbury; Richard Socher"
            },
            {
                "ref_id": "b11",
                "title": "Language models are unsupervised multitask learners",
                "journal": "",
                "year": "2019",
                "authors": "Alec Radford; Jeff Wu; Rewon Child; David Luan; Dario Amodei; Ilya Sutskever"
            },
            {
                "ref_id": "b12",
                "title": "SVCCA: Singular vector canonical correlation analysis for deep learning dynamics and interpretability",
                "journal": "Curran Associates, Inc",
                "year": "2017",
                "authors": "Maithra Raghu; Justin Gilmer; Jason Yosinski; Jascha Sohl-Dickstein"
            },
            {
                "ref_id": "b13",
                "title": "The impact of positional encodings on multilingual compression",
                "journal": "Association for Computational Linguistics",
                "year": "2021",
                "authors": "Vinit Ravishankar; Anders S\u00f8gaard"
            },
            {
                "ref_id": "b14",
                "title": "Self-attention with relative position representations",
                "journal": "",
                "year": "2018",
                "authors": "Peter Shaw; Jakob Uszkoreit; Ashish Vaswani"
            },
            {
                "ref_id": "b15",
                "title": "Roformer: Enhanced transformer with rotary position embedding",
                "journal": "",
                "year": "2022",
                "authors": "Jianlin Su; Yu Lu; Shengfeng Pan; Ahmed Murtadha; Bo Wen; Yunfeng Liu"
            },
            {
                "ref_id": "b16",
                "title": "Attention is all you need",
                "journal": "Curran Associates, Inc",
                "year": "2017",
                "authors": "Ashish Vaswani; Noam Shazeer; Niki Parmar; Jakob Uszkoreit; Llion Jones; Aidan N Gomez; Illia Kaiser;  Polosukhin"
            },
            {
                "ref_id": "b17",
                "title": "On position embeddings in BERT",
                "journal": "",
                "year": "2021",
                "authors": "Benyou Wang; Lifeng Shang; Christina Lioma; Xin Jiang; Hao Yang; Qun Liu; Jakob Grue Simonsen"
            },
            {
                "ref_id": "b18",
                "title": "What do position embeddings learn? an empirical study of pre-trained language model positional encoding",
                "journal": "Online. Association for Computational Linguistics",
                "year": "2020",
                "authors": "Yu-An Wang; Yun-Nung Chen"
            }
        ],
        "figures": [
            {
                "figure_label": "1",
                "figure_type": "figure",
                "figure_id": "fig_0",
                "figure_caption": "Figure 1 :1Figure 1: Attention weights for the first 15 tokens of an input text.",
                "figure_data": ""
            },
            {
                "figure_label": "2",
                "figure_type": "figure",
                "figure_id": "fig_1",
                "figure_caption": "Figure 2 :2Figure2: For each head, a pie chart illustrates the percentage of labels assigned to 100 vectors a lh (Eq. (7)).",
                "figure_data": ""
            },
            {
                "figure_label": "3",
                "figure_type": "figure",
                "figure_id": "fig_2",
                "figure_caption": "Figure 3 :3Figure3: Amplitude spectra of position embeddings. Blue line is the mean of spec i and blue area is the quartile range. Orange line is the spectrum of word embeddings for an input before adding position embeddings.",
                "figure_data": ""
            },
            {
                "figure_label": "4",
                "figure_type": "figure",
                "figure_id": "fig_3",
                "figure_caption": "Figure 4 :4Figure 4: CCA coefficient for each layer compared to position embedding.",
                "figure_data": ""
            },
            {
                "figure_label": "5",
                "figure_type": "figure",
                "figure_id": "fig_4",
                "figure_caption": "Figure 5 :5Figure 5: Column i of the query and the key in head(1, 1).",
                "figure_data": ""
            },
            {
                "figure_label": "6",
                "figure_type": "figure",
                "figure_id": "fig_5",
                "figure_caption": "Figure 6 :6Figure 6: The frequency-wise maxima of the amplitude spectra. The l-th row of the heat map corresponds to max-spec l . The top figure is a reiteration of Figure 3a.",
                "figure_data": ""
            },
            {
                "figure_label": "789",
                "figure_type": "figure",
                "figure_id": "fig_6",
                "figure_caption": "Figure 7 :Figure 8 :Figure 9 :789Figure 7: The cross-correlation xcorr i (t) between the queries and the keys in Figure 5.",
                "figure_data": ""
            },
            {
                "figure_label": "10",
                "figure_type": "figure",
                "figure_id": "fig_7",
                "figure_caption": "Figure 10 :10Figure 10: 2D histogram of the function g(f, \u03b8). The section at \u03b8 = \u03b8 i is the amplitude spectrum of Qp i .",
                "figure_data": ""
            },
            {
                "figure_label": "11",
                "figure_type": "figure",
                "figure_id": "fig_8",
                "figure_caption": "Figure 11 :11Figure 11: The cross-correlations (left) and the weighted sum of cross-covariances (right) in head(8, 9) when we modify either the position embedding or the word embedding component of the input.",
                "figure_data": ""
            },
            {
                "figure_label": "12",
                "figure_type": "figure",
                "figure_id": "fig_9",
                "figure_caption": "Figure 12 :12Figure 12: Cumulative principal component contribution rate of RoBERTa position embedding.",
                "figure_data": ""
            },
            {
                "figure_label": "13",
                "figure_type": "figure",
                "figure_id": "fig_10",
                "figure_caption": "Figure 13 :13Figure 13: Amplitude spectra of position embedding of various models.",
                "figure_data": ""
            },
            {
                "figure_label": "14",
                "figure_type": "figure",
                "figure_id": "fig_11",
                "figure_caption": "Figure 14 :14Figures for GPT-2",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_12",
                "figure_caption": "Figure 16: 2D histogram of the function g(f, \u03b8) in GPT-2.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_13",
                "figure_caption": "FiguresFigures for BART encoder",
                "figure_data": ""
            },
            {
                "figure_label": "1719",
                "figure_type": "figure",
                "figure_id": "fig_14",
                "figure_caption": "Figure 17 :Figure 19 :1719Figure 17: Attention weights of BART encoder for the first 15 tokens of an input text.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_15",
                "figure_caption": "FiguresFigures for BART decoder",
                "figure_data": ""
            },
            {
                "figure_label": "20",
                "figure_type": "figure",
                "figure_id": "fig_16",
                "figure_caption": "Figure 20 :20Figure 20: Attention scores of BART decoder for the first 300 tokens of an input text.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_17",
                "figure_caption": "Figure 22: Attention weight with relearned position embedding PE predicted top-5 tokens relearned exercise essay experiment article adventure RoBERTa base and the , . to",
                "figure_data": ""
            },
            {
                "figure_label": "1",
                "figure_type": "table",
                "figure_id": "tab_0",
                "figure_caption": "Top 5 MASK candidates when 3 UNKs are put between each token in \"This is an MASK.\"E.1 ExperimentWe additionally train RoBERTa with the following configurations.Dataset We used 8645 samples consisting of more than 128 tokens from wikitext-2.Putting UNK token Three UNK tokens were inserted after each token in all sentences; the token sequence [t1 , t 2 , ..., t 128 ] was expanded to [t 1 , unk, unk, unk, t 2 , unk, unk, unk, . . . , t 128 , unk, unk, unk]. 3",
                "figure_data": ""
            }
        ],
        "formulas": [
            {
                "formula_id": "formula_0",
                "formula_text": "A lh = softmax ( X l W Q lh (X l W K lh ) T \u221a d/n ) (1) O lh = A lh X l W V lh (2) MultiHead l = concat(O l1 , . . . , O ln )W O l(3)",
                "formula_coordinates": [
                    2.0,
                    84.95,
                    326.45,
                    204.19,
                    77.42
                ]
            },
            {
                "formula_id": "formula_1",
                "formula_text": "W Q lh , W K lh , W V lh \u2208 R d\u00d7(d/n",
                "formula_coordinates": [
                    2.0,
                    101.39,
                    408.68,
                    127.86,
                    21.76
                ]
            },
            {
                "formula_id": "formula_2",
                "formula_text": "SP E (pos,2i) = sin(pos/10000 2i/d ) (4)",
                "formula_coordinates": [
                    2.0,
                    99.94,
                    629.57,
                    189.2,
                    14.7
                ]
            },
            {
                "formula_id": "formula_3",
                "formula_text": "[ sin x i cos x i ] [ cos \u03b8 \u2212 sin \u03b8 sin \u03b8 cos \u03b8 ] = [ sin(x i + \u03b8) cos(x i + \u03b8) ] .(6)",
                "formula_coordinates": [
                    2.0,
                    103.65,
                    718.86,
                    185.48,
                    51.73
                ]
            },
            {
                "formula_id": "formula_4",
                "formula_text": "tr t (A) = { \u2211 T \u2212t i=1 (A) i,i+t (t \u2265 0) \u2211 T +t i=1 (A) i\u2212t,i (t < 0)(7)",
                "formula_coordinates": [
                    2.0,
                    336.56,
                    553.04,
                    187.87,
                    40.95
                ]
            },
            {
                "formula_id": "formula_5",
                "formula_text": "a lh = [tr \u221210 (A lh ), . . . , tr 10 (A lh )] \u2208 R 21 . (8",
                "formula_coordinates": [
                    2.0,
                    318.84,
                    627.46,
                    201.34,
                    20.96
                ]
            },
            {
                "formula_id": "formula_6",
                "formula_text": ")",
                "formula_coordinates": [
                    2.0,
                    520.18,
                    627.87,
                    4.24,
                    13.15
                ]
            },
            {
                "formula_id": "formula_7",
                "formula_text": "spec i = abs(DFT(E pos e i ))(9)",
                "formula_coordinates": [
                    3.0,
                    354.08,
                    346.07,
                    170.34,
                    14.93
                ]
            },
            {
                "formula_id": "formula_8",
                "formula_text": "z l i = [ z l i (x 1 ), . . . , z l i (x m )",
                "formula_coordinates": [
                    4.0,
                    117.47,
                    719.79,
                    114.99,
                    25.22
                ]
            },
            {
                "formula_id": "formula_9",
                "formula_text": "Z l = [ z l 1 , . . . , z l n ](11)",
                "formula_coordinates": [
                    4.0,
                    115.76,
                    743.41,
                    173.37,
                    25.22
                ]
            },
            {
                "formula_id": "formula_10",
                "formula_text": "\u03c1 k = max a k ,b k Corr(Z l 1 a k , Z l 2 b k ) (12)",
                "formula_coordinates": [
                    4.0,
                    347.6,
                    344.91,
                    176.82,
                    20.74
                ]
            },
            {
                "formula_id": "formula_11",
                "formula_text": "W Q (W K ) T = U Q S(U K ) T (13) Q = XU Q , K = XU K (14)",
                "formula_coordinates": [
                    5.0,
                    118.15,
                    448.16,
                    170.98,
                    31.55
                ]
            },
            {
                "formula_id": "formula_12",
                "formula_text": "K = XU K = XU Q R = QR (15)",
                "formula_coordinates": [
                    5.0,
                    114.26,
                    725.99,
                    174.88,
                    13.55
                ]
            },
            {
                "formula_id": "formula_13",
                "formula_text": "XW Q (XW K ) T = QSK T = d/n \u2211 i=1 s i q i k T i (16)",
                "formula_coordinates": [
                    5.0,
                    314.03,
                    455.58,
                    210.39,
                    35.72
                ]
            },
            {
                "formula_id": "formula_14",
                "formula_text": "spec lhi = abs(DFT(Q lh e i )) (17) max-spec l = [max h,i (spec lhi ) f ] f =0,...,T /2 . (18",
                "formula_coordinates": [
                    5.0,
                    318.48,
                    673.44,
                    205.95,
                    35.97
                ]
            },
            {
                "formula_id": "formula_15",
                "formula_text": ")",
                "formula_coordinates": [
                    5.0,
                    519.88,
                    689.98,
                    4.54,
                    13.15
                ]
            },
            {
                "formula_id": "formula_16",
                "formula_text": "xcov j (t) = { \u2211 T \u2212t i=1 q i,j k i+t,j (t \u2265 0) \u2211 T +t i=1 q i\u2212t,j k i,j (t < 0) (19) xcorr j (t) = xcov j (t) \u2212 E t [xcov j (t)] \u2225q j \u2225\u2225k j \u2225(20)",
                "formula_coordinates": [
                    6.0,
                    82.55,
                    426.34,
                    206.58,
                    78.28
                ]
            },
            {
                "formula_id": "formula_17",
                "formula_text": "tr t (QSK T ) = T \u2212t \u2211 i=1 (QSK T ) i,i+t(21)",
                "formula_coordinates": [
                    6.0,
                    95.94,
                    654.13,
                    193.19,
                    34.93
                ]
            },
            {
                "formula_id": "formula_18",
                "formula_text": "= T \u2212t \u2211 i=1 d/n \u2211 j=1 s j q i,j k i+t,j(22)",
                "formula_coordinates": [
                    6.0,
                    150.27,
                    693.23,
                    138.86,
                    35.72
                ]
            },
            {
                "formula_id": "formula_19",
                "formula_text": "= d/n \u2211 j=1 s j xcov j (t)(23)",
                "formula_coordinates": [
                    6.0,
                    150.27,
                    734.67,
                    138.86,
                    35.72
                ]
            },
            {
                "formula_id": "formula_20",
                "formula_text": "Kp i = QRp i = Q\u03bb i p i = Qp i \u2022 e j\u03b8 i .(24)",
                "formula_coordinates": [
                    7.0,
                    88.45,
                    334.58,
                    200.68,
                    20.96
                ]
            },
            {
                "formula_id": "formula_21",
                "formula_text": "(Qp i ) t = (Kp i ) t+\u2206(25)",
                "formula_coordinates": [
                    7.0,
                    134.58,
                    472.1,
                    154.55,
                    13.76
                ]
            },
            {
                "formula_id": "formula_22",
                "formula_text": "g(f, \u03b8 i ) = abs(DFT(Qp i )) f (26)",
                "formula_coordinates": [
                    7.0,
                    117.99,
                    622.78,
                    171.15,
                    13.85
                ]
            },
            {
                "formula_id": "formula_23",
                "formula_text": "\u2206(f, \u03b8) = T 2\u03c0 \u2022 \u03b8 f . (27",
                "formula_coordinates": [
                    7.0,
                    372.63,
                    313.08,
                    147.25,
                    26.04
                ]
            },
            {
                "formula_id": "formula_24",
                "formula_text": ")",
                "formula_coordinates": [
                    7.0,
                    519.88,
                    318.56,
                    4.54,
                    13.15
                ]
            }
        ],
        "doi": ""
    },
    "Chinese Lexical Substitution: Dataset and Method": {
        "authors": "Jipeng Qiang; Kang Liu; Ying Li; Yun Li; Yi Zhu; Yunhao Yuan; Xiaocheng Hu; Xiaoye Ouyang",
        "pub_date": "",
        "abstract": "Existing lexical substitution (LS) benchmarks were collected by asking human annotators to think of substitutes from memory, resulting in benchmarks with limited coverage and relatively small scales. To overcome this problem, we propose a novel annotation method to construct an LS dataset based on human and machine collaboration. Based on our annotation method, we construct the first Chinese LS dataset CHNLS which consists of 33,695 instances and 144,708 substitutes, covering three text genres (News, Novel, and Wikipedia). Specifically, we first combine four unsupervised LS methods as an ensemble method to generate the candidate substitutes, and then let human annotators judge these candidates or add new ones. This collaborative process combines the diversity of machine-generated substitutes with the expertise of human annotators. Experimental results that the ensemble method outperforms other LS methods. To our best knowledge, this is the first study for the Chinese LS task.",
        "sections": [
            {
                "heading": "Introduction",
                "text": [
                    "Lexical substitution (LS) aims at finding appropriate substitutes for a target word in a sentence, which can be used as a backbone of various NLP applications such as writing assistance (Lee et al., 2021;Qiang et al., 2023a), word sense disambiguation (McCarthy, 2002), and lexical simplification (Paetzold and Specia, 2016;Qiang et al., 2021a,b). For instance, when presented with the sentence \"I read an amazing paper today\", we aim to select a more descriptive adjective to substitute the word \"amazing\". While options such as \"awesome\" and \"great\" may readily come to mind, it proves arduous for us to conceive of equally fitting alternatives such as \"incredible\" and \"fascinating\". Despite extensive research conducted on Lexical Substitution (LS) in various languages, including * Corresponding author.",
                    "English (Hassan et al., 2007;Yuret, 2007;Melamud et al., 2015b;Lee et al., 2021;Qiang et al., 2023b), German (Hintz andBiemann, 2015, 2016), Italian (Toral, 2009), and Croatian (Alagi\u0107 and \u0160najder, 2017), Chinese LS has received limited attention. In this paper, we address this gap by focusing on the Chinese LS task.",
                    "To enable the development and evaluation of effective Chinese LS methods, a large-scale dataset is intuitively important. Existing widely used English LS benchmarks, LS07 (McCarthy and Navigli, 2007), CoInCo (Kremer et al., 2014), and SwordS (Lee et al., 2021), were collected by asking human annotators to think of substitutes from memory. The annotation method has the following two problems.",
                    "(1) Limited Coverage: Human annotators may have limitations in recalling a comprehensive range of potential substitutes for a given target word, potentially overlooking less common or domainspecific substitutes (Liu et al., 2022). Much work (Lee et al., 2021;Qiang et al., 2023b) have also pointed out the lack of coverage of existing LS datasets. For example, the data collection strategy used in the existing benchmarks might contain words like \"awesome\" and \"great\", but miss words like \"incredible\" and \"fascinating\".",
                    "(2) High cost: Annotating lexical substitutes for target words in sentences is a time-consuming and labor-intensive task. It requires human annotators to carefully consider suitable substitutes, taking into account various linguistic and contextual factors. Due to the complexity of the task, annotating a large number of instances becomes challenging within a reasonable timeframe and budget. Consequently, widely used English LS datasets such as LS07, CoInCo, and SwordS comprise a mere 2,010, 2,474, and 1,250 instances, respectively.",
                    "To address these challenges, we propose a novel annotation method to construct an LS dataset based on human and machine collaboration. Firstly, we propose an ensemble method that leverages four different unsupervised LS methods to automatically generate substitutes. Automated methods can quickly generate a vast pool of potential substitutes, reducing the burden on human annotators. Secondly, we let human annotators assess the suitability of these alternatives as substitutes. Additionally, we request annotators to suggest new alternatives that are not present in the machine-generated options. This collaborative process harnesses the expertise of human annotators while leveraging the efficiency and scalability of machine-generated candidates. This efficiency allows for the creation of a larger dataset within a reasonable budget.",
                    "The annotation method is motivated by the following two findings:",
                    "(1) Machine-generated LS methods can introduce a greater diversity of substitutes. By leveraging computational techniques like word embeddings, language models, or paraphrasing models, a wide range of plausible substitutes can be generated. This diversity enriches the dataset by providing a variety of substitution options, capturing different semantic relationships and syntactic patterns.",
                    "(2) Assessing the suitability of these substitutes is much simpler for the annotator compared to generating a substitute from memory. Human annotators can focus on selecting the most appropriate substitutes from the machine-generated pool, ensuring high-quality and contextually relevant annotations.",
                    "In summary, our contributions are listed below:",
                    "(1) We provide a novel approach to construct an LS dataset based on human and machine collaboration. Our approach provides a good idea for constructing large-scale, high-coverage LS datasets. Based on our designing method, we construct the first large-scale Chinese LS dataset CHNLS that consists of 33,695 instances, which cover different text genres, namely News, Novel, and Wikipedia articles. Correspondingly, the latest English LS dataset only contains 1,250 instances.",
                    "(2) We present four Chinese LS methods (dictionary-based, embedding-based, BERT-based, and paraphraser-based) by adjusting current English LS methods, and give an ensemble method that combines the four methods. Experimental results on CHNLS show that the ensemble method can be served as a strong baseline for future studies.",
                    "The dataset and code is available at github 1 ."
                ],
                "publication_ref": [
                    "b11",
                    "b21",
                    "b14",
                    "b20",
                    "b5",
                    "b28",
                    "b18",
                    "b11",
                    "b23",
                    "b26",
                    "b0",
                    "b15",
                    "b8",
                    "b11",
                    "b13",
                    "b11",
                    "b23"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Related Work",
                "text": [
                    "Lexical Substitution Resources. Existing lexical substitution (LS) datasets are available for various languages, including English and other languages. Each instance in LS dataset is composed of a sentence, a target word, and corresponding substitutes.",
                    "In English, the first LS dataset from SemEval 2007 (LS07) (McCarthy and Navigli, 2007), consists of 300 development and 1,710 test instances for 201 polysemous words. For each target word, 10 sentences are provided. The annotators' task deployed by Amazon Mechanical Turk was to give up to 3 possible substitutes. Afterward, Biemnann (Biemann, 2012) created a large-scale dataset (TWSI) that annotates 25K sentences from Wikipedia, which, however, only covers noun targets. To alleviate this limitation, Kremer et al. (Kremer et al., 2014) proposed Concept In Context (ConInCo), a dataset of 2,474 sentences covering 3,874 distinct targets with different part-of-speech tags, which is the current largest LS benchmark. It consists of 15K target instances with a given 35% development and 65% test. Recently, Stanford Word Substitution Benchmark (SwordS) (Lee et al., 2021) is built on CoInCo by asking human annotators for higher coverage and higher quality. SwordS consists of 1250 instances with a given 417 development and 833 test. Considering the size of vocabulary in English, the size of the vocabulary covered by LS datasets is too small. Additionally, we found that many appropriate substitutes for many instances in SwordS are missing, since human annotators frequently utilize repetitive patterns to fabricate instances, leading to a lack of linguistic diversity (Liu et al., 2022).",
                    "The German LS dataset from GermEval 2015 consists of 2,040 instances from the German Wikipedia, which contains 153 unique target words. Italian LS dataset from EVALITA 2009 consists of 2,310 instances, which contains 231 unique target words. All the above LS datasets in all languages are constructed by human annotators. Due to their relatively small size, all of these datasets can only be used for evaluation and not for training. Unfortunately, research on Chinese LS is still scarce: to the best of our knowledge, there is currently no publicly available LS corpora for training, even lacking a dataset to evaluate the ability of LS models.",
                    "Figure 1: The overview of our approach for building Chinese LS corpus. Our approach is composed of two phrases: machine-generated substitution and manual annotation. The phase of machine-generated substitution combines four different LS methods as an ensemble method to generate the pseudo substitutes. The phase of manual annotation utilizes native Chinese annotators to judge the pseudo substitutes and add new substitutes.",
                    "Lexical Substitution. LS methods can be divided into four types: (1) dictionary-based method (Hassan et al., 2007;Yuret, 2007), (2) Embeddingbased method (Melamud et al., 2015a,b), (3) BERT-based method (Zhou et al., 2019;Lacerra et al., 2021a;Michalopoulos et al., 2022), and (4) Paraphraser-based method (Qiang et al., 2023c,b).",
                    "The early lexical substitution studies obtain synonyms by searching linguistic resources, such as WordNet. Embedding-based methods utilize word embedding modelings to obtain highly similar words as the substitutions. Since 2019, LS methods based on pretrained language models have attracted much attention (Zhou et al., 2019;Lacerra et al., 2021a;Michalopoulos et al., 2022), in which pretrained BERT is most used. Zhou et al. (Zhou et al., 2019) apply dropout to the embeddings of target words for partially obscuring the word, and obtain a probability distribution over the BERT output vocabulary. Arefyev et al. (Arefyev et al., 2020) present a comparative study of popular pretrained language models, such as ELMo, BERT, and XL-Net. Lacerra et al. (Lacerra et al., 2021b) first merge the development set of two LS datasets (Co-InCo and TWSI), and split it into training and development sets for fine-tuning the encoder-decoder framework. Michalopoulos et al. (Michalopoulos et al., 2022) propose a new mix-up embedding strategy by incorporating the knowledge of Word-Net into the prediction process of BERT. Recently, Qiang et al (Qiang et al., 2023b) propose a method ParaLS that utilizes a pretrained paraphraser to generate the substitutes. Compared to language modeling, paraphraser produces fluent, meaningpreserving paraphrases but contain variations in word choice. ParaLS achieves good results and is considered the state-out-of-art LS method."
                ],
                "publication_ref": [
                    "b15",
                    "b2",
                    "b8",
                    "b11",
                    "b13",
                    "b5",
                    "b28",
                    "b30",
                    "b9",
                    "b19",
                    "b30",
                    "b9",
                    "b19",
                    "b30",
                    "b10",
                    "b19",
                    "b23"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Creating CHNLS",
                "text": [
                    "In this section, we describe our method to build an LS dataset, and the overall architecture for constructing the Chinese LS corpus is illustrated in Figure 1."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Data Preparation",
                "text": [
                    "In this step, we extract the sentences and the corresponding target words. To ensure diversity and complexity in our dataset, we utilize three distinct text genres: News, Novel, and Wiki. The News category is sourced from the contents of People's Daily, Wiki consists of articles from Wikipedia (encyclopedia), and the Novel category comprises selected Chinese-published novels. By incorporating multiple sources, we aim to capture the richness and intricacy of the Chinese language.",
                    "To refine the dataset, we apply a filtering process to eliminate excessively short or long sentences based on their word count. For each sentence, we further segment it into words, considering nouns, verbs, adjectives, and adverbs as the target words for our analysis."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Machine-generated Substitution",
                "text": [
                    "Considering the sentence w 1 , w 2 , ..., tw, ..., w n containing the target word tw, we employ LS methods to generate a set of 15 pseudo substitutes for each target word. To foster a broader range of substitutes, we adopt an ensemble approach that combines four distinct LS methods: Dictionary-based, Embedding-based, BERT-based, and Paraphraserbased. By leveraging these diverse methods, each of which taps into different semantic knowledge, we aim to enhance the overall diversity of substitutes available for consideration.",
                    "Typically, LS methods encompass two essential steps: substitute generation and substitute ranking. The initial objective of substitute generation is to identify and produce potential alternatives that can effectively replace a target word within a given sentence. Once a set of substitute candidates is generated, the subsequent task of substitute ranking comes into play, aiming to ascertain the most appropriate substitute for the target word within the specific sentence.",
                    "Substitute Generation. We present four baseline approaches by adapting existing English LS methods:",
                    "(1) Dict-based: The dictionary-based method relies on a synonym thesaurus (HIT-Cilin (Mei et al., 1996)) to generate the candidate substitutes.",
                    "(2) Embedding-based: The embedding-based method selects substitutes with the highest similarities from word embedding models (Li et al., 2018). Substitutes are chosen based on their proximity, as determined by cosine similarity, to the target word.",
                    "(3) BERT-based: The BERT-based method (Qiang et al., 2021b) utilizes Chinese BERT modeling 2 and masks the target word for prediction.",
                    "(4) Paraphraser-based: The Paraphraser-based method (Qiang et al., 2023b) leverages a pretrained paraphrase model to generate substitutes. By inputting the sentence into the encoder of the para-phrase model, substitutes are generated using a special decoding strategy that focuses exclusively on the lexical variations of the target word.",
                    "Given the absence of a suitable Chinese paraphraser and a sufficiently large-scale paraphrase corpus, we take the initiative to construct a comprehensive Chinese paraphrase corpus. This corpus is then utilized to fine-tune a pretrained Chinese BART model 3 , enhancing its effectiveness for paraphrase generation.",
                    "To construct a paraphrase corpus, we leverage a large-scale bilingual English-Chinese translation corpus. The construction process entails the following steps:",
                    "(1) Gathering the machine translation corpus: We select a Chinese-English corpus consisting of 5.2 million sentence pairs 4 as our primary source.",
                    "(2) Aligning sentence pairs: We utilize a Chinese translator 5 to translate the English sentences into Chinese, thus creating aligned sentence pairs representing paraphrases.",
                    "(3) Identifying potential paraphrases: By comparing the aligned sentence pairs, we identify pairs that convey similar or identical meanings while being expressed differently. These pairs serve as potential paraphrases.",
                    "(4) Filtering and cleaning paraphrase pairs: We apply filters to remove unsuitable sentence pairs for paraphrase generation. For instance, we exclude pairs with significant length differences, pairs containing mistranslations, or pairs exhibiting inconsistencies.",
                    "Through these steps, we construct a high-quality paraphrase corpus that can be used for various natural language processing tasks, including paraphrase generation and LS.",
                    "Substitute Ranking. The effectiveness of text generation metrics for substitute ranking has been demonstrated in previous work (Qiang et al., 2023b). Therefore, we employ the BARTScore (Yuan et al., 2021) and BERTScore (Zhang et al., 2019) metrics for substitute ranking. To perform this ranking, we replace the target word in the original sentence with each substitute candidate, thereby creating an updated version of the sentence.",
                    "BARTScore leverages pre-trained BART models to calculate the similarity between the original sentence and the updated sentence. BARTScore considers various aspects of text quality, including fluency, grammaticality, and semantic similarity.",
                    "BERTScore utilizes pre-trained BERT models to measure the similarity between the original sentence and the updated sentence. BERTScore has shown a strong correlation with human judgments and has been widely used for evaluating text generation tasks.",
                    "Finally, our ranking method employs a linear combination of the scores of BARTScore and BERTScore to compute the final score for each candidate substitute. They consider different aspects of text quality and provide comprehensive measures to rank the substitutes based on their similarity to the reference word. By incorporating these metrics, the ranking process can be more robust and accurate, leading to an improved selection of suitable substitutes in lexical substitution tasks.",
                    "A ensemble Method. The aforementioned four LS methods utilize substitute generate and substitute ranking to generate 15 substitutes separately for each method. Specifically, the substitutes generated by Dictionary-based, Embeddingbased, BERT-based, and  Taking into consideration that each LS method generates 15 substitutes, the utilization of four LS methods results in a total of 60 candidate substitutes. To avoid overwhelming the annotators and incurring additional costs, as well as to prevent annotator fatigue, we need to limit the number of substitutes for annotation.",
                    "To achieve this, we propose a simple ensemble method that combines the above four methods. We assigned voting weights of 1 to Dict-based, Embedding-based, BERT-based, and paraphraserbased methods individually. We select the top 15 candidate substitutes with the highest votes, denoted as {c 1 , c 2 , ..., c 15 }, as pseudo substitutes. This selection process ensures that the substitutes generated by multiple methods are more likely to be chosen as potential substitutes."
                ],
                "publication_ref": [
                    "b16",
                    "b12",
                    "b24",
                    "b23",
                    "b23",
                    "b27",
                    "b29"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Manual Annotation",
                "text": [
                    "Given the sentence and target word pairs, as well as the corresponding 15 pseudo substitutes {c 1 , c 2 , ..., c 15 }, we engage multiple annotators for annotation. It is noteworthy that all the annotators involved in this process are native Chinese under- graduates.",
                    "We have created a specialized website for annotating data. On each page of the website, a sentence is presented with a highlighted target word, along with 15 pseudo substitutes for that target word. Additionally, there is an option to add new substitutes that are not included among the pseudo-substitutes.",
                    "For each pseudo substitute, there are two radio buttons labeled \"positive\" and \"negative.\" The annotators' task was to select \"positive\" if they considered the substitute to be a suitable replacement for the target word within the given sentence. Conversely, they were to choose \"negative\" if they determined that the substitute would not be appropriate.",
                    "To encourage annotators to contribute new substitutes, we offer higher compensation for providing new substitutes that are not included among the pseudo-substitutes. During the annotation process, each sentence and target word pair in the dataset is annotated three times. The final substitutes are selected from the newly added substitutes and the pseudo-substitutes that have been marked at least once.",
                    "We conducted a pilot test with one annotator, and they were able to annotate approximately 150 instances in one hour. The average time required per assignment was approximately 25 seconds, which may seem surprising. However, two factors contribute to this efficiency: (1) Native speakers can quickly make binary judgments regarding substitute words. (2) Annotators only need to read the target sentence once to provide judgments for all substitutes in an assignment. For more information on the interface, instructions, and filtering criteria, please refer to Appendix A.",
                    "The dataset consists of a total of 33,695 sentences and target word pairs, with a corresponding 144,708 labeled substitutes. On average, close to 10 words per sentence are selected as target words. We calucate named as High quality. The objective is to evaluate the accuracy of the substitutions made in the given sentence and target word pairs. A total of 300 instances were randomly selected, with 100 instances chosen from one of three text genres. A new annotator, proficient in the Chinese language, was assigned the task of assessing the precision of the substitutions within the selected instances.",
                    "This annotator compared each substitute against the original target word to determine if it accurately captured the intended meaning and maintained syntactic and semantic coherence within the sentence. He classified the substitutions as correct or incorrect. The precision of the substitutions was computed by dividing the number of correct substitutes by the total number of substitutes evaluated. The precision would be calculated as 1136/1254, which is equivalent to 90.5%. The high precision rate of above 90% indicates the high quality of the substitutions within the dataset.",
                    "High coverage. We show that CHNLS achieves high coverage. The same 300 instances in high quality are selected. Three new human evaluators, proficient in the Chinese language, were asked to independently think of substitutes for each sentence and target word pair in the selected instances.",
                    "The substitutes provided by the evaluators are compared against the set of substitutions present in the constructed dataset. Each substitute is evaluated to determine whether it matched any of the substitutions in the dataset. The coverage of the dataset is calculated by dividing the number of substitutions provided by the human annotators that belonged to the dataset's set of substitutions by the total number of substitutions provided.",
                    "The human annotators provide 742 substitutions and 723 substitutions belonged to the substitutions provided in the CHNLS. The coverage is calculated as 723/742, which is equivalent to 97%. This verification process demonstrates the extensive coverage of the dataset and its suitability for training and evaluating Chinese LS models. Additionally, it is worth noting that the three annotations only yielded a total of 742 substitutes, which is significantly smaller than the 1254 substitutes present in the dataset. This observation highlights the imprac- ticality of relying solely on manual annotation for generating language substitution word data, as it results in a substantial lack of coverage.",
                    "High agreement. We used common agreement metrics such as Cohen's Kappa (Cohen, 1960) and Fleiss' Kappa (Fleiss, 1971) to quantify the level of agreement among annotators. Cohen's Kappa measures agreement between two raters, and Fleiss' Kappa can be used for measuring agreement between multiple raters. The Kappa result be interpreted as follows: values \u2264 0 as indicating no agreement and 0.01-0.20 as none to slight, 0.21-0.40 as fair, 0.41-0.60 as moderate, 0.61-0.80 as substantial, and 0.81-1.00 as almost perfect agreement.",
                    "Table 2 lists the agreement scores for three annotators. Specifically, we calculated Fleiss' Kappa for our dataset, yielding a value of 0.594. This statistic underscores a substantial level of agreement among our human annotators, reaffirming the consistency and reliability of the annotations."
                ],
                "publication_ref": [
                    "b3",
                    "b4"
                ],
                "figure_ref": [],
                "table_ref": [
                    "tab_2"
                ]
            },
            {
                "heading": "Experiments",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Experimental Setup",
                "text": [
                    "Dataset. We split the whole dataset CHNLS into train (80%), valid (10%), test (10%) set. The train/valid/test sets in Wiki, News, and Novel have 8,425/1,065/888, 9,472/1,169/1,110, and 9,379/1,080/11,07 instances, respectively. The experimental results are computed on test sets.",
                    "Metrics. We employ the designated official metrics, namely \"best,\" \"best-m,\" \"oot,\" and \"oot-m,\" as outlined in the SemEval 2007 task. In addition, we incorporate Precision@1 (P@1) as an evaluation metric, adhering to the conventions established by previous LS methodologies (Zhang et al., 2019;Qiang et al., 2023b). Notably, \"best,\" \"best-m,\" and \"P@1\" gauge the quality of the most accurate predictions, while both \"oot\" (out-of-ten) and \"oot-m\" assess the extent to which the gold substitutes is encompassed within the top 10 predictions.",
                    "Implementation Details. Dict-based(Dict), Embedding-based (Embedding)  construct a large Chinese paraphrase dataset, containing 5,174,152 sentence pairs. Then we finetune Chinese BART on it to train a paraphraser. The initial learning rate is set to lr = 1 \u00d7 10 \u22125 and dropout is set to 0.1. We adopt the Adam optimizer with \u03b2 1 = 0.9, \u03b2 2 = 0.999, \u03f5 = 10 \u22128 . For the above methods, we set the max number of the generated candidates as 50. We use BARTscore and BERTscore to rank the candidates and select the top 10 words to calculate metrics. The weights are set as 1, 0.1 for BARTscore and BERTscore for all the above methods. To validate vLLM's ability on this dataset, we also tested two LLMs: ChatGLM 6 and ChatGPT 7 ,using their official API interfaces."
                ],
                "publication_ref": [
                    "b29",
                    "b23"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Evaluation Results",
                "text": [
                    "Table 3 displays the performance of all methods on the various metrics. To eliminate the impact of substitute ranking, we also provide the results without substitute ranking in parentheses.",
                    "Among the individual methods, we observed that BERT and ParaLS outperform the baselines Dict and Embedding. This is because both BERT and ParaLS utilize pretrained models that incorporate contextual information for better predictions. Without substitute ranking, ParaLS achieves better performance than BERT. It also means that ParaLS based on our constructed paraphrase corpus is the best individual LS method. When compared with vLLMs, we found BERT and ParaLS also outperform ChatGPT and ChatGLM.",
                    "Experimental results demonstrate that our proposed method Ensemble surpasses the individual LS methods on all metrics with statistical significance. Ensemble expands the coverage of possible substitutes by utilizing multiple LS methods. Each method has its own coverage limitations and biases. By combining them, Ensemble overcomes individual limitations and biases, leading to broader coverage of substitute candidates. This broader coverage increases the likelihood of finding suitable substitutes for a wide range of target words. Additionally, different LS methods may exhibit varying levels of sensitivity to different linguistic contexts, word senses, or syntactic structures. By combining multiple methods, the ensemble approach becomes ;\u770b\u4f5c(look upon as);\u770b\u505a(look upon as);\u770b\u6210(regard as);\u540c\u65e5\u800c\u8bed(talk in the same breath) Embedding \u5f53\u505a;\u5a92\u67d3\u5242(Mordant);\u9009\u4f5c(Selected Works);\u5217\u4f5c(Listed as);\u4e3b\u8981\u7528\u9014(main Uses);\u501f\u4f5c(borrow as);\u7528\u9014(Use);\u7528\u4e8e(For);\u79fb\u4f5c(shift to);\u7528\u6765 Bert \u4f5c\u4e3a;\u7528\u505a;\u4f5c;\u4ee5\u662f(so);\u6210\u4e3a(become);\u505a\u4e3a(act as);\u5f53\u4f5c;\u4e3a(for);\u7528\u4e3a(used as);\u5236\u6210(made to order) ParaLs \u4f5c\u4e3a;\u7528\u4e8e(for);\u7528\u505a;\u4ee5\u662f(so);\u4f5c;\u6210\u4e3a(become);\u4ee5\u4e3a(thought);\u505a\u4e3a(act as);\u5f53\u4f5c;\u4e3a(for) Ensemble \u4f5c\u4e3a;\u5f53\u4f5c;\u7528\u505a;\u4f5c;\u505a\u4e3a(act as);\u5f53\u505a;\u7528\u4e3a(used as);\u5f53;\u7528\u4e8e(for);\u4ee5\u662f(so)",
                    "Table 4: The top 10 substitutes of four instances in the Wiki subset of CHNLS using LS methods. The target word is marked in blue, and the substitutes in labels are marked in red.",
                    "more robust to such variations, as it can draw on the strengths of different methods to handle different linguistic scenarios effectively. This robustness contributes to the overall improved performance.",
                    "These reasons indicate that Ensemble benefits from the diversity, enhanced coverage, and robustness of individual LS methods. The combination of these factors contributes to the significant outperformance of the ensemble approach over the individual LS methods on all evaluation metrics, demonstrating its effectiveness in generating highquality substitutes for the Chinese LS task."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_4"
                ]
            },
            {
                "heading": "Qualitative evaluation",
                "text": [
                    "To qualitatively evaluate the effectiveness of the substitutes generated by LS methods, we present four instances of the Wiki subset of CHNLS for analysis. Table 4 displays the top 10 generated substitutes. More instances are shown in Appendix B.",
                    "It is evident that the substitutes we have annotated exhibit a considerable level of comprehensiveness, without any significant absence of suitable substitutes. This observation indicates the high cov-erage achieved by our constructed dataset. In comparison, even the latest English lexical substitution datasets, such as SwordS which is the improved version of CoInCo, still exhibit deficiencies in capturing a sufficient number of appropriate substitutes (Qiang et al., 2023b).",
                    "Consistent with the findings from the quantitative evaluation, the performance of the Dict-based and Embedding-based methods, which do not take contextual information into account during the substitution generation process, is relatively low compared to other methods.",
                    "BERT and ParaLS approaches demonstrate promising results in terms of capturing contextual information and generating semantically similar substitutes. By leveraging the strengths of different approaches, Ensemble has two advantages. Firstly, Ensemble yields a greater number of appropriate alternatives when compared to BERT and ParaLS. Across the five instances, BERT, ParaLS, and Ensemble produce 20, 19, and 24 correct substitutes, respectively. Secondly, certain well-suited alternatives that were initially ranked lower in the individual methods ascend to higher positions. For in-stance, the substitute \"\u8d70\u7ea2\" (meaning \"to famous\") in instance 2 exhibits a notable elevation, securing the second rank."
                ],
                "publication_ref": [
                    "b23"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Conclusions",
                "text": [
                    "This study presents the first comprehensive exploration of the Chinese Lexical Substitution (LS) task. We propose a novel annotation method to construct a large-scale Chinese LS dataset through a collaborative human-machine approach. The constructed dataset consists of 33,695 instances and 165,105 substitutes with high quality and high coverage. Our proposed ensemble method by leveraging the strengths of each method while mitigating their weaknesses, our ensemble approach significantly outperforms the individual LS methods across all evaluation metrics.",
                    "In conclusion, our study fills the research gap on how to construct a large-scale LS dataset with high coverage and low cost, providing a solid foundation for further research and development. The construction of a high-quality dataset and the development of an effective ensemble method showcase the potential for improved lexical substitution in the Chinese language."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Limitations",
                "text": [
                    "While our proposed collaborative approach successfully constructs a large-scale Chinese Lexical Substitution (LS) dataset, it is important to acknowledge some limitations to provide a balanced perspective.",
                    "Despite the large-scale nature of the dataset, it may not cover all possible lexical substitution scenarios in the Chinese language. The dataset's coverage might be limited to three genres (Wiki, News, Novel), which could affect its applicability in certain contexts. Researchers should be cautious when generalizing findings beyond the dataset's scope.",
                    "While efforts were made to ensure annotator agreement through guidelines and quality control measures, some level of inconsistency in judgments among human annotators is inevitable. The interannotator agreement might vary for different instances, which could introduce some noise or ambiguity in the dataset."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Ethics Statement",
                "text": [
                    "The dataset used in our research is constructed using publicly available data sources, ensuring that there are no privacy concerns or violations. We do not collect any personally identifiable information, and all data used in our research is obtained following legal and ethical standards.",
                    "An additional ethical concern revolves around the possibility of the Chinese LS method being exploited for malicious intents, including the generation of fabricated or deceptive content. It is imperative to contemplate the potential repercussions arising from the outputs of the LS method and to implement protective measures to deter its exploitation for nefarious objectives.",
                    "is selected as a potential target A total of 12,000 target words were selected from each of the three corpora. Subsequently, we employed four distinct lexical substitution methods to generate a set of 15 candidate words for each target word.",
                    "Consequently, every sentence, target word, and corresponding collection of 15 candidate words formed a single sample. Ultimately, we accumulated a comprehensive dataset comprising 36,000 samples. To ensure reliable annotations, each sample was presented to three annotators who were instructed to select appropriate alternatives from the provided word list for tagging. The final annotation results constituted the lexical substitution dataset."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.1 Selection of target words",
                "text": [
                    "We first divided each type of raw corpus into natural sentences. A natural sentence is a complete sentence that ends with a period, exclamation mark, question mark, or ellipsis and can express a complete meaning. Using a word segmenter, we segment and part-of-speech tag the natural sentences. For each verb, noun, adjective, and adverb in each natural sentence, we select them as potential target words. After removing proper nouns, fixed collocations, and other words that cannot be appropriately substituted, the remaining words are considered target words."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.2 Annotation Website",
                "text": [
                    "We have built a website based on JavaWeb+MySQL for annotators' labeling work. We provide a portion of the target words and a list of 15 substitute words to three annotators to collect suitable sets of substitute words from them.",
                    "To improve the quality of annotation, we have implemented the following three design strategies.",
                    "(1) To reduce costs and ensure annotation quality, we adopted a rotating approach to presenting the substitute word lists to annotators. In the annotation of each target word, not all 15 substitute words in the list were provided to a single annotator. Instead, a selective subset of 11 or 12 substitute words was presented. This approach aimed to maintain the quality of annotations by avoiding overwhelming annotators with too many words to annotate at once, while significantly reducing the time required for annotation.",
                    "For these 15 words, they were systematically rotated among the four annotators, ensuring equal opportunities for each word to be assigned to an annotator. This rotation strategy does not compromise the reliability of the annotation results, as each word has an equal chance of being assigned to any annotator. Thus, this approach ensures fairness and avoids potential bias in the annotation process.",
                    "(2) We modified the substitute word lists for a selected subset of target words and provided them as confusion sets to the annotators to ensure annotation quality. From the original set of 36,000 target words in three corpora, we randomly selected one-third of the target words. For each selected target word, we made modifications to two substitute words out of the 15-word list. One substitute word was changed to the original target word, which served as a required option for the annotators. The other substitute word was replaced with any Chinese word of the same length as the original target word, sourced from a dictionary, and served as a forbidden option for the annotators.",
                    "During the annotation process, we evaluated the quality of annotations by checking whether the annotators correctly labeled the confusion set options. This allowed us to assess the annotation quality based on the annotators' handling of the confusion sets.",
                    "(3) We have designed three annotation starting positions to ensure consistency in the annotation progress for the three corpora. Each target word has been assigned a unique identifier. Each annotator begins annotating from a designated starting position, which corresponds to the identifier of the target word. To maintain consistency in the an-progress across all corpora, we have established a starting position for annotation at the beginning of each corpus, evenly distributed among multiple annotators.",
                    "Once an annotator successfully annotates a target word, the current annotation identifier increments and the next annotatable content is automatically displayed. Only when an annotator reaches the maximum target word identifier, the annotation cycle restarts from the beginning. This approach offers the advantage of enabling consecutive annotations for target words within the same sentence in most cases, effectively reducing the workload of reading sentences, which is the most time-consuming task.",
                    "Finally, we eliminated instances that did not contain any meaningful substitute. The number of instances is 33,695."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.3 Annotation Manual",
                "text": [
                    "This manual is designed to facilitate the use of the Chinese lexical substitution dataset annotation system. It provides instructions on how to use the system effectively and serves as a reference for users, clarifying the purpose and functionality of the system. The manual includes an overview of the task, an explanation of the system's features, specific annotation examples, and a section addressing potential issues that may arise."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.4 The Work of Annotators",
                "text": [
                    "Annotators are initially instructed to carefully peruse the annotation manual in its entirety. The administrator provides each annotator with a username and password. The administrator also instructs the annotators to annotate the data carefully and explains the website's special features. The system's backend assigns corresponding data to annotators for annotation.",
                    "On the annotation website, for each instance, annotators need to determine whether suitable substitute words can be found for the target word in the instance. If an annotator believes that the target word in an instance is not suitable for replacement with any word other than the original word, they can select \"Not Replaceable\" for that sample and mark all substitute words as \"Not Suitable.\" If an annotator believes that suitable substitute words can be found for the target word in an instance, they need to evaluate and select the appropriate substitute words from the given list. Additionally, annotators can provide alternative suitable substitute words for each instance, different from the ones provided in the given substitute word list. The final collection consists of pairs of target words and the selected substitute word sets as annotated by the annotators.",
                    "Regarding the wage for each annotator, our principle is 15\u00a5 per hour. We conducted a pilot test with one annotator, and they were able to annotate approximately 150 instances in one hour. Based on this calculation, the average price for annotating one instance is 0.1\u00a5. To incentivize annotators to provide new words, an additional price of 0.1\u00a5 is offered for each new substitute word."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "B More Examples",
                "text": [
                    "Here, we randomly choose 5 instances from News and 5 instances from Novel for analysis in Table 5  and 6.",
                    "BERT, ParaLS, and Ensemble provide high coverage and high-quality substitutes compared to Dict and Embedding. These results indicate that Ensemble achieves a little better results.",
                    "Table 5: The top 10 substitutes of five instances in the News subset of CHNLS using LS methods. The target word is marked in blue, and the substitutes in labels are marked in red."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Acknowledgement",
                "text": [
                    "This research is partially supported by the National Natural Science Foundation of China under grants 62076217, U22B2037 and 61906060, and the Blue Project of Yangzhou University."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            }
        ],
        "references": [
            {
                "ref_id": "b0",
                "title": "A preliminary study of croatian lexical substitution",
                "journal": "",
                "year": "2017",
                "authors": "Domagoj Alagi\u0107"
            },
            {
                "ref_id": "b1",
                "title": "Alexander Podolskiy, and Alexander Panchenko. 2020. A comparative study of lexical substitution approaches based on neural language models",
                "journal": "",
                "year": "",
                "authors": "Nikolay Arefyev; Boris Sheludko"
            },
            {
                "ref_id": "b2",
                "title": "Turk bootstrap word sense inventory 2.0: A large-scale resource for lexical substitution",
                "journal": "",
                "year": "2012",
                "authors": "Chris Biemann"
            },
            {
                "ref_id": "b3",
                "title": "A coefficient of agreement for nominal scales. Educational and psychological measurement",
                "journal": "",
                "year": "1960",
                "authors": "Jacob Cohen"
            },
            {
                "ref_id": "b4",
                "title": "Measuring nominal scale agreement among many raters",
                "journal": "Psychological bulletin",
                "year": "1971",
                "authors": "L Joseph;  Fleiss"
            },
            {
                "ref_id": "b5",
                "title": "Unt: Subfinder: Combining knowledge sources for automatic lexical substitution",
                "journal": "",
                "year": "2007",
                "authors": "Samer Hassan; Andras Csomai; Carmen Banea; Ravi Sinha; Rada Mihalcea"
            },
            {
                "ref_id": "b6",
                "title": "Delexicalized supervised german lexical substitution",
                "journal": "Proceedings of GermEval",
                "year": "2015",
                "authors": "Gerold Hintz; Chris Biemann"
            },
            {
                "ref_id": "b7",
                "title": "Language transfer learning for supervised lexical substitution",
                "journal": "Long Papers",
                "year": "2016",
                "authors": "Gerold Hintz; Chris Biemann"
            },
            {
                "ref_id": "b8",
                "title": "What substitutes tell us-analysis of an \"all-words\" lexical substitution corpus",
                "journal": "",
                "year": "2014",
                "authors": "Katrin Kremer; Sebastian Erk; Stefan Pad\u00f3;  Thater"
            },
            {
                "ref_id": "b9",
                "title": "Alasca: an automated approach for large-scale lexical substitution",
                "journal": "",
                "year": "2021",
                "authors": "Caterina Lacerra; Tommaso Pasini; Rocco Tripodi; Roberto Navigli"
            },
            {
                "ref_id": "b10",
                "title": "Genesis: A generative approach to substitutes in context",
                "journal": "",
                "year": "2021",
                "authors": "Caterina Lacerra; Rocco Tripodi; Roberto Navigli"
            },
            {
                "ref_id": "b11",
                "title": "Swords: A benchmark for lexical substitution with improved data coverage and quality",
                "journal": "Online. Association for Computational Linguistics",
                "year": "2021",
                "authors": "Mina Lee; Chris Donahue; Robin Jia; Alexander Iyabor; Percy Liang"
            },
            {
                "ref_id": "b12",
                "title": "Analogical reasoning on chinese morphological and semantic relations",
                "journal": "Short Papers",
                "year": "2018",
                "authors": "Shen Li; Zhe Zhao; Renfen Hu; Wensi Li; Tao Liu; Xiaoyong Du"
            },
            {
                "ref_id": "b13",
                "title": "Wanli: Worker and ai collaboration for natural language inference dataset creation",
                "journal": "",
                "year": "2022",
                "authors": "Alisa Liu; Swabha Swayamdipta; A Noah; Yejin Smith;  Choi"
            },
            {
                "ref_id": "b14",
                "title": "Lexical substitution as a task for wsd evaluation",
                "journal": "",
                "year": "2002",
                "authors": "Diana Mccarthy"
            },
            {
                "ref_id": "b15",
                "title": "Semeval-2007 task 10: English lexical substitution task",
                "journal": "",
                "year": "2007",
                "authors": "Diana Mccarthy; Roberto Navigli"
            },
            {
                "ref_id": "b16",
                "title": "Tongyici cilin (extended)",
                "journal": "",
                "year": "1996",
                "authors": "J Mei; Y Zhu;  Gao"
            },
            {
                "ref_id": "b17",
                "title": "Modeling word meaning in context with substitute vectors",
                "journal": "",
                "year": "2015",
                "authors": "Oren Melamud; Ido Dagan; Jacob Goldberger"
            },
            {
                "ref_id": "b18",
                "title": "A simple word embedding model for lexical substitution",
                "journal": "",
                "year": "2015",
                "authors": "Oren Melamud; Omer Levy; Ido Dagan"
            },
            {
                "ref_id": "b19",
                "title": "Lexsubcon: Integrating knowledge from lexical resources into contextual embeddings for lexical substitution",
                "journal": "",
                "year": "2022",
                "authors": "George Michalopoulos; Ian Mckillop; Alexander Wong; Helen Chen"
            },
            {
                "ref_id": "b20",
                "title": "Unsupervised lexical simplification for non-native speakers",
                "journal": "",
                "year": "2016",
                "authors": "H Gustavo; Lucia Paetzold;  Specia"
            },
            {
                "ref_id": "b21",
                "title": "Chinese idiom paraphrasing",
                "journal": "Transactions of the Association for Computational Linguistics",
                "year": "2023",
                "authors": "Jipeng Qiang; Yang Li; Chaowei Zhang; Yun Li; Yi Zhu; Yunhao Yuan; Xindong Wu"
            },
            {
                "ref_id": "b22",
                "title": "Lsbert: Lexical simplification based on bert",
                "journal": "IEEE/ACM Transactions on Audio, Speech, and Language Processing",
                "year": "2021",
                "authors": "Jipeng Qiang; Yun Li; Yi Zhu; Yunhao Yuan; Yang Shi; Xindong Wu"
            },
            {
                "ref_id": "b23",
                "title": "Parals: Lexical substitution via pretrained paraphraser",
                "journal": "",
                "year": "2023",
                "authors": "Jipeng Qiang; Kang Liu; Yun Li; Yunhao Yuan; Yi Zhu"
            },
            {
                "ref_id": "b24",
                "title": "Chinese lexical simplification",
                "journal": "IEEE Transactions on Audio, Speech and Language Processing",
                "year": "2021",
                "authors": "Jipeng Qiang; Xinyu Lv; Yun Li; Yunhao Yuan; Xindong Wu"
            },
            {
                "ref_id": "b25",
                "title": "Natural language watermarking via paraphraser-based lexical substitution",
                "journal": "Artificial Intelligence",
                "year": "2023",
                "authors": "Jipeng Qiang; Shiyu Zhu; Yun Li; Yi Zhu; Yunhao Yuan; Xindong Wu"
            },
            {
                "ref_id": "b26",
                "title": "The lexical substitution task at evalita",
                "journal": "",
                "year": "2009",
                "authors": "Antonio Toral"
            },
            {
                "ref_id": "b27",
                "title": "Bartscore: Evaluating generated text as text generation",
                "journal": "Curran Associates, Inc",
                "year": "2021",
                "authors": "Weizhe Yuan; Graham Neubig; Pengfei Liu"
            },
            {
                "ref_id": "b28",
                "title": "Ku: Word sense disambiguation by substitution",
                "journal": "",
                "year": "2007",
                "authors": "Deniz Yuret"
            },
            {
                "ref_id": "b29",
                "title": "Bertscore: Evaluating text generation with bert",
                "journal": "",
                "year": "2019",
                "authors": "Tianyi Zhang; Varsha Kishore; Felix Wu; Q Kilian; Yoav Weinberger;  Artzi"
            },
            {
                "ref_id": "b30",
                "title": "Bert-based lexical substitution",
                "journal": "",
                "year": "2019",
                "authors": "Wangchunshu Zhou; Tao Ge; Ke Xu; Furu Wei; Ming Zhou"
            },
            {
                "ref_id": "b31",
                "title": "Each document is divided into sentences, and each verb, noun, adjective, and adverb in each sentence Inst. 1 \u6b21\u65e5\uff0c\u5979\u53c8\u53ec\u5f00\u804c\u5de5\u5927\u4f1a\uff0c\u4e0e\u804c\u5de5\u4eec\u4e00\u8d77\u8ba8\u8bba\u51fa\u73b0\u8d28\u91cf\u4e0d\u5408\u683c\u54c1\u7684\u539f\u56e0\u3002 English The next she held another staff meeting to discuss with the staff the reasons for the unqualified quality products",
                "journal": "Labels \u4e3e\u884c",
                "year": "",
                "authors": "\u4e3e\u884c \u53ec\u96c6;\u4e3e\u529e;\u5f00;\u7ec4\u7ec7;\u4e3b\u6301;\u5f00\u5c55 Dict"
            },
            {
                "ref_id": "b32",
                "title": "\u505a(make)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b33",
                "title": "",
                "journal": "Embedding \u5f00\u4f1a\u7814\u8ba8(Meeting discussion",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b34",
                "title": "",
                "journal": "\u5c40\u52a1(bureau affairs",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b35",
                "title": "",
                "journal": "\u515a\u7ec4\u4f1a",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b36",
                "title": "",
                "journal": "\u6269\u5927\u4f1a\u8bae(enlarged meeting",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b37",
                "title": "",
                "journal": "\u5ba1\u8bae(consider",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b38",
                "title": "\u5f00\u4f1a\u8ba8\u8bba(discussing in a Meeting);\u4e3e\u884c;\u73b0\u573a\u4f1a\u8bae(on site meetings",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b39",
                "title": "\u5f00\u5b8c(after driving) Bert \u53ec\u96c6;\u4e3e\u884c;\u5f00;\u7ec4\u7ec7;\u4e3e\u529e;\u53c2\u52a0",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b40",
                "title": "",
                "journal": "\u51fa\u5e2d(attend)",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b41",
                "title": "",
                "journal": "",
                "year": "",
                "authors": " \u8fdb\u884c"
            },
            {
                "ref_id": "b42",
                "title": "\u542f\u52a8(firing) ParaLS \u53ec\u96c6;\u4e3e\u884c;\u5f00;\u7ec4\u7ec7;\u4e3e\u529e;\u53c2\u52a0(participate in);\u5f00\u5c55;\u51fa\u5e2d(attend)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b43",
                "title": "\u5f00\u8d77(start);\u4e3b\u6301 Ensemble \u4e3e\u884c;\u53ec\u96c6;\u5f00;\u4e3e\u529e;\u51fa\u5e2d(attend);\u7ec4\u7ec7;\u5f00\u5c55;\u53c2\u52a0(participate in)",
                "journal": "\u4e3b\u6301",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b44",
                "title": "",
                "journal": "\u5f00\u5b8c",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b45",
                "title": "\u6b21\u65e5\uff0c\u5979\u53c8\u53ec\u5f00\u804c\u5de5\u5927\u4f1a\uff0c\u4e0e\u804c\u5de5\u4eec\u4e00\u8d77\u8ba8\u8bba\u51fa\u73b0\u8d28\u91cf\u4e0d\u5408\u683c\u54c1\u7684\u539f\u56e0\u3002 English The next day, she held another staff meeting to discuss with the staff the reasons for the unqualified quality products",
                "journal": "Labels \u63a2\u8ba8",
                "year": "",
                "authors": "\u63a2\u8ba8;\u8c08\u8bba;\u5546\u8bae;\u8bae\u8bba;\u7814\u8ba8;\u8c08\u8c08; \u8c08\u8bba;\u7814\u8ba8;\u8bae\u8bba;\u5546\u8ba8;\u5546\u8bae;\u7814\u7a76;\u534f\u5546;\u8c08\u8c08 Dict;  \u5ba1\u8bae"
            },
            {
                "ref_id": "b46",
                "title": "\u5ea7\u8c08(have an informal discussion)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b47",
                "title": "",
                "journal": "\u8bb2\u8bba(lectures",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b48",
                "title": "\u8bae\u4e8b(proceedings)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b49",
                "title": "Embedding \u5f00\u4f1a\u7814\u8ba8(meeting discussion)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b50",
                "title": "",
                "journal": "\u4e89\u8fa9(argue",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b51",
                "title": "",
                "journal": "",
                "year": "",
                "authors": "\u8bae "
            },
            {
                "ref_id": "b52",
                "title": "\u4e89\u8bba\u4e0d\u4f11(an endless debate)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b53",
                "title": "\u5f00\u4f1a\u8ba8\u8bba(discussing in a meeting)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b54",
                "title": "\u4e89\u8bba(debate)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b55",
                "title": "dispute);\u5546\u8ba8;\u8fa9\u8bba(debate) Bert \u63a2\u8ba8;\u5546\u8ba8;\u8c08\u8bba;\u5546\u8bae;\u7814\u7a76;\u5546\u91cf(discuss);\u8bae\u8bba;\u5206\u6790(analysis);\u7814\u8ba8;\u4e89\u8bba(debate) ParaLS \u63a2\u8ba8;\u5546\u8ba8;\u8c08\u8bba;\u5546\u8bae;\u7814\u7a76;\u5546\u91cf(discuss)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b56",
                "title": "",
                "journal": "\u5206\u6790(analysis)",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b57",
                "title": "3 \u5728\u5b9e\u8df5\u4e2d\uff0c\u6211\u4eec\u4f53\u4f1a\u5230\uff0c\u4f01\u4e1a\u53ea\u6709\u628a\u4ea7\u54c1\u8d28\u91cf\u770b\u4f5c\u81ea\u5df1\u7684 \u751f\u547d\uff0c\u624d\u80fd\u632f\u5174\u3002 English In practice, we have learned that a company can only be revitalized if it considers product quality to be its life",
                "journal": "Labels \u611f\u53d7",
                "year": "",
                "authors": "\u63a2\u8ba8;\u8c08\u8bba;\u5546\u8bae;\u8bae\u8bba;\u5546\u8ba8; \u5546\u8c08(negotiate);\u534f\u5546 Ensemble; );\u7814\u8ba8;\u7814\u7a76;\u5206\u6790;\u534f\u5546 \u5546\u91cf(discuss; ; \u4f53\u609f;\u4f53\u9a8c;\u9886\u609f;\u9886\u4f1a;\u8ba4\u8bc6;\u4f53\u5473;\u611f\u609f;\u610f\u8bc6 Inst; \u4f53\u9a8c Dict"
            },
            {
                "ref_id": "b58",
                "title": "",
                "journal": "\u8ba4\u77e5(cognition",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b59",
                "title": "",
                "journal": "",
                "year": "",
                "authors": " \u56de\u5473(aftertaste"
            },
            {
                "ref_id": "b60",
                "title": "",
                "journal": "\u5480\u56bc(chew",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b61",
                "title": "",
                "journal": "\u5fc3\u5f97(experience",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b62",
                "title": "\u541f\u5473(recite with relish)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b63",
                "title": "",
                "journal": "",
                "year": "",
                "authors": "\u7406\u89e3 Embedding"
            },
            {
                "ref_id": "b64",
                "title": "",
                "journal": "\u6df1\u5207\u4f53\u4f1a(deep experience",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b65",
                "title": "",
                "journal": "\u4f53\u4f1a\u51fa(experience",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b66",
                "title": "",
                "journal": "\u6df1\u6df1\u611f\u5230(deeply felt)",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b67",
                "title": "",
                "journal": "",
                "year": "",
                "authors": " \u9886\u4f1a\u5230"
            },
            {
                "ref_id": "b68",
                "title": "\u610f\u8bc6;\u4f53\u5473 Inst. 4 \u7531\u4e8e\u4eba\u6587\u5730\u7406\u7684\u539f\u56e0\uff0c\u767d\u6c9f\u4eba\u7ecf\u5546\u786e\u6709\u4f18\u52bf\u3002 English Due to cultural and geographical reasons, the people of Baigou do have advantages through negotiation. sewing machines, so the market boom concealed a potential quality crisis",
                "journal": "Labels \u7f18\u6545",
                "year": "",
                "authors": "\u4f53\u609f;\u8ba4\u8bc6;\u4f53\u9a8c;\u611f\u53d7; \u9886\u7565(appreciate);\u9886\u609f;\u611f\u609f Bert; );\u9886\u609f;\u611f\u609f;\u610f\u8bc6;\u9886\u4f1a; \u4e86\u89e3(understand; \u8ba4\u8bc6;\u4f53\u609f;\u4f53\u9a8c;\u610f\u8bc6;\u4e86\u89e3(\u4e86\u89e3);\u611f\u53d7;\u9886\u609f; \u5b66\u4e60(study) Parals; ) \u611f\u89c9(feelings; \u4f53\u9a8c;\u611f\u53d7;\u4f53\u609f;\u9886\u609f;\u611f\u609f;\u9886\u4f1a;\u8ba4\u8bc6;\u4e86\u89e3 ; \u56e0\u7d20;\u7f18\u7531;\u539f\u6545;\u4e3b\u56e0;\u539f\u7531;\u539f\u59d4 \u611f\u609f;\u9886\u4f1a Ensemble; \u7f18\u6545 Dict"
            },
            {
                "ref_id": "b69",
                "title": "",
                "journal": "",
                "year": "",
                "authors": " \u7531(cause"
            },
            {
                "ref_id": "b70",
                "title": "",
                "journal": "",
                "year": "",
                "authors": "\u6545 "
            },
            {
                "ref_id": "b71",
                "title": "\u56e0\u7531(cause)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b72",
                "title": "Embedding \u79cd\u79cd\u539f\u56e0(various reasons)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b73",
                "title": "",
                "journal": "\u7a76\u5176",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b74",
                "title": "",
                "journal": "",
                "year": "",
                "authors": " \u8bf1\u56e0"
            },
            {
                "ref_id": "b75",
                "title": "",
                "journal": "\u6839\u6e90(root)",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b76",
                "title": "",
                "journal": "\u8d77\u56e0(cause",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b77",
                "title": "",
                "journal": "\u95f4\u63a5\u539f\u56e0(indirect causes)",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b78",
                "title": "",
                "journal": "\u76f4\u63a5\u539f\u56e0",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b79",
                "title": "",
                "journal": "\u51b3\u5b9a\u56e0\u7d20(determinant) Bert \u7f18\u6545",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b80",
                "title": "",
                "journal": "\u4f18\u52bf(advantage",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b81",
                "title": "",
                "journal": "\u5173\u7cfb(relationship",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b82",
                "title": "",
                "journal": "\u7406\u7531(reason",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b83",
                "title": "\u539f\u6545;\u7279\u70b9(characteristic);\u7f18\u7531 ParaLS \u7f18\u6545;\u56e0\u7d20",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b84",
                "title": "",
                "journal": "",
                "year": "",
                "authors": " \u5f71\u54cd"
            },
            {
                "ref_id": "b85",
                "title": "",
                "journal": "\u4f18\u52bf(advantage",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b86",
                "title": "",
                "journal": "\u5173\u7cfb(relationship",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b87",
                "title": "",
                "journal": "\u7406\u7531(reason",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b88",
                "title": "",
                "journal": "\u7279\u6b8a(special",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b89",
                "title": "",
                "journal": "\u7279\u70b9(characteristic",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b90",
                "title": "\u8003\u8651(consider);\u539f\u6545 Ensemble \u7f18\u6545;\u539f\u6545;\u56e0\u7d20;\u7406\u7531(reason)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b91",
                "title": "",
                "journal": "",
                "year": "",
                "authors": " \u5f71\u54cd"
            },
            {
                "ref_id": "b92",
                "title": "",
                "journal": "\u4f18\u52bf(advantage",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b93",
                "title": "\u5173\u7cfb(relationship);\u7f18\u7531;\u7279\u6b8a(special)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b94",
                "title": "\u7279\u70b9(characteristic) Inst. 5 \u767d\u6c9f\u5e02\u573a\u4e00\u4e0b\u5c31\u51b7\u6e05\u4e0b\u6765\uff0c\u6211\u7684\u4e70\u5356\u4e5f\u8ddf\u7740\u8870\u4e86\u3002 English The Baigou market immediately cooled down, and my business also declined",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b95",
                "title": "",
                "journal": "\u7a7a\u8361\u8361(empty",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b96",
                "title": "\u8427\u7d22(desolate)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b97",
                "title": "\u95e8\u53ef\u7f57\u96c0(there are very few people)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b98",
                "title": "",
                "journal": "",
                "year": "",
                "authors": "\u6e05\u9759 Embedding"
            },
            {
                "ref_id": "b99",
                "title": "",
                "journal": "\u9759\u5bc2(silence)",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b100",
                "title": "",
                "journal": "",
                "year": "",
                "authors": " \u51c4\u51c9(dreariness"
            },
            {
                "ref_id": "b101",
                "title": "\u843d\u5bde(lonely);\u51b7\u6de1;\u7a7a\u7a7a\u8361\u8361;\u51b7\u6e05\u6e05;\u51c4\u51b7(cold) Bert \u51b7\u6de1;\u5bc2\u9759",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b102",
                "title": "",
                "journal": "",
                "year": "",
                "authors": "\u51b7 "
            },
            {
                "ref_id": "b103",
                "title": "\u51b7\u9759(calmness);\u6e05\u6de1;\u5e73\u9759(calmness);\u6c89\u5bc2;\u5bd2\u51b7(cold)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b104",
                "title": "",
                "journal": "",
                "year": "",
                "authors": " \u6e05\u9759"
            },
            {
                "ref_id": "b105",
                "title": "",
                "journal": "\u5b89\u9759(quiet) ParaLS \u51b7\u6de1",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b106",
                "title": "",
                "journal": "",
                "year": "",
                "authors": "\u51b7 "
            },
            {
                "ref_id": "b107",
                "title": "\u51b7\u9759(calmness);\u6e05\u6de1;\u51b7\u843d;\u6e05\u51b7(chilly)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b108",
                "title": "",
                "journal": "\u9eef\u6de1(dim",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b109",
                "title": "",
                "journal": "\u51b7\u5374(cooling",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b110",
                "title": "",
                "journal": "\u5e73\u9759(calmness) Ensemble \u51b7\u6de1",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b111",
                "title": "\u51b7\u9759(calmness);\u51b7\u843d;\u6e05\u51b7(chilly);\u6e05\u6de1;\u51b7(cold)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b112",
                "title": "\u9eef\u6de1(dim);\u6c89\u5bc2;\u5e73\u9759(calmness)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b113",
                "title": "He was naked and had a pair of leather pants on underneath, so he got the message in his sleep and came to plead for mercy",
                "journal": "Labels \u6d88\u606f",
                "year": "",
                "authors": "; \u4fe1;\u4fe1\u606f;\u4fe1\u53f7;\u60c5\u62a5;\u8baf\u53f7;\u8d44\u8baf \u4ed6\u4e0a\u8eab\u8d64\u88f8\uff0c\u4e0b\u8eab\u5957\u7740\u4e00\u6761\u76ae\u88e4\uff0c \u60f3\u662f\u7761\u68a6\u4e2d\u5f97\u5230\u8baf\u606f\uff0c\u8d76\u6765\u6c42\u60c5\u3002 English; \u6d88\u606f Dict;  \u8d44\u8baf"
            },
            {
                "ref_id": "b114",
                "title": "\u5feb\u8baf(news flash);\u60c5\u62a5;\u65b0\u95fb(news)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b115",
                "title": "",
                "journal": "",
                "year": "",
                "authors": "\u8baf "
            },
            {
                "ref_id": "b116",
                "title": "",
                "journal": "\u8c0d\u62a5",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b117",
                "title": "",
                "journal": "Embedding \u5c0f\u9053\u6d88\u606f(grapevine)",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b118",
                "title": "",
                "journal": "\u68c0\u5bdf\u4fe1\u606f(Inspection Information",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b119",
                "title": "",
                "journal": "\u65e0\u7528\u4fe1\u606f(Useless information",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b120",
                "title": "",
                "journal": "\u77ed\u6d88\u606f(Short Message",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b121",
                "title": "",
                "journal": "\u6b7b\u8baf(News of death",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b122",
                "title": "",
                "journal": "\u5546\u54c1\u4fe1\u606f(Product Information",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b123",
                "title": "",
                "journal": "\u75c5\u6bd2\u4fe1\u606f(Virus Information",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b124",
                "title": "",
                "journal": "\u4f20\u9001(Transmission)",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b125",
                "title": "\u4f20\u9012\u4fe1\u606f(Delivering information) Bert \u6d88\u606f;\u4fe1\u606f;\u8d44\u8baf;\u901a\u77e5(Notification);\u4fe1\u53f7;\u7ebf\u7d22(Clues);\u60c5\u62a5;\u97f3\u8baf(Audio)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b126",
                "title": "",
                "journal": "",
                "year": "",
                "authors": " \u77ed\u4fe1(sms"
            },
            {
                "ref_id": "b127",
                "title": "\u65b0\u95fb(News) ParaLS \u4fe1\u606f;\u6d88\u606f;\u8d44\u8baf;\u901a\u77e5(Notification);\u4fe1\u53f7;\u7ebf\u7d22(Clues)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b128",
                "title": "",
                "journal": "\u97f3\u8baf(Audio)",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b129",
                "title": "",
                "journal": "",
                "year": "",
                "authors": " \u77ed\u4fe1(sms"
            },
            {
                "ref_id": "b130",
                "title": "\u65b0\u95fb(news) Ensemble \u6d88\u606f;\u8d44\u8baf;\u4fe1\u606f;\u4fe1\u53f7;\u60c5\u62a5;\u901a\u77e5(Notification);\u8baf\u53f7;\u97f3\u8baf(Audio)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b131",
                "title": "",
                "journal": "",
                "year": "",
                "authors": " \u65b0\u95fb"
            },
            {
                "ref_id": "b132",
                "title": "",
                "journal": "\u547c\u5524",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b133",
                "title": "English Guo Jing rushed towards the back tent, grabbed it with his left hand and pulled it hard, pulling down half of the golden tent and covering it over the heads of the generals",
                "journal": "Labels \u4f7f\u52b2",
                "year": "",
                "authors": "\u5927\u529b \u7528\u52b2;\u5f3a\u529b;\u52a0\u529b;\u7aed\u529b;\u5927\u529b Dict"
            },
            {
                "ref_id": "b134",
                "title": "\u4f7f\u52b2;\u6781\u529b(Make an effort",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b135",
                "title": "\u7528\u52b2;\u5c3d\u529b(Try your best",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b136",
                "title": "",
                "journal": "\u4e00\u529b(One Power",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b137",
                "title": "",
                "journal": "\u5168\u529b(Full strength",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b138",
                "title": "\u62fc\u547d(do one's utmost)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b139",
                "title": "",
                "journal": "",
                "year": "",
                "authors": "\u64c2\u6253 Embedding"
            },
            {
                "ref_id": "b140",
                "title": "",
                "journal": "\u8981\u7528\u529b",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b141",
                "title": "",
                "journal": "\u63ff\u4f4f(Snap)",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b142",
                "title": "",
                "journal": "\u6b7b\u52b2(Dead weight",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b143",
                "title": "",
                "journal": "\u72e0\u547d(Tough life",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b144",
                "title": "\u6413\u64e6(Rubbing) Bert \u52aa\u529b(Effort);\u5927\u529b;\u4f7f\u52b2;\u5f3a\u529b;\u7528\u52b2;\u5c3d\u529b(Try your best",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b145",
                "title": "\u62fc\u547d(do one's utmost)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b146",
                "title": "",
                "journal": "\u8f7b\u8f7b(gently",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b147",
                "title": "",
                "journal": "",
                "year": "",
                "authors": " \u731b\u70c8"
            },
            {
                "ref_id": "b148",
                "title": "",
                "journal": "\u72e0\u72e0(Ruthlessly) ParaLS \u5927\u529b",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b149",
                "title": "\u4f7f\u52b2;\u5f3a\u529b;\u6781\u529b(Make an effort",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b150",
                "title": "\u7528\u52b2;\u52a0\u529b;\u5c3d\u529b(Try your best",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b151",
                "title": "\u6709\u529b(Powerful) Ensemble \u4f7f\u52b2;\u7528\u52b2;\u5927\u529b;\u6781\u529b(Make an effort",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b152",
                "title": "",
                "journal": "\u5c3d\u529b(Try your best",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b153",
                "title": "",
                "journal": "\u8f7b\u8f7b(gently",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b154",
                "title": "\u5f3a\u529b;\u594b\u529b(Endeavor)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b155",
                "title": "English Guo Jing rushed towards the back tent, grabbed it with his left hand and pulled it hard, pulling down half of the golden tent and covering it over the heads of the generals",
                "journal": "",
                "year": "",
                "authors": "\u626f;\u6495\u626f;\u62fd;\u62c9;\u62c9\u4f4f;\u7275\u626f Dict; \u62c9 "
            },
            {
                "ref_id": "b156",
                "title": "",
                "journal": "",
                "year": "",
                "authors": " \u62c9\u62c9(lara"
            },
            {
                "ref_id": "b157",
                "title": "\u626f;\u7275\u626f;\u62fd;\u62c9\u957f(Elongation)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b158",
                "title": "",
                "journal": "\u62c9\u6746(Tie Rod",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b159",
                "title": "",
                "journal": "\u6500\u626f(Climbing)",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b160",
                "title": "",
                "journal": "\u76f4\u62c9",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b161",
                "title": "",
                "journal": "Embedding \u626f\u4e0b\u53bb(Pull it down",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b162",
                "title": "",
                "journal": "\u53ae\u6253",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b163",
                "title": "",
                "journal": "",
                "year": "",
                "authors": " \u626f\u62c9(tug"
            },
            {
                "ref_id": "b164",
                "title": "",
                "journal": "\u63a8\u6253(push and beat",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b165",
                "title": "",
                "journal": "",
                "year": "",
                "authors": " \u626f\u4f4f(tug"
            },
            {
                "ref_id": "b166",
                "title": "",
                "journal": "\u63ea\u626f(tug at",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b167",
                "title": "",
                "journal": "\u626f\u65ad(Tear off",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b168",
                "title": "",
                "journal": "\u626d\u53bb(twist off) Bert \u62c9\u62fd",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b169",
                "title": "\u6495\u626f;\u62c9\u4f38(Stretching)",
                "journal": "",
                "year": "",
                "authors": " \u62c9\u62c9(lara"
            },
            {
                "ref_id": "b170",
                "title": "\u62c9\u4f4f;\u62c9\u5f00(Pull away",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b171",
                "title": "",
                "journal": "\u62c9\u62e2(rope in)",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b172",
                "title": "",
                "journal": "\u62c9\u7d27(Tensioning) ParaLS \u62c9\u62fd",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b173",
                "title": "",
                "journal": "",
                "year": "",
                "authors": " \u62c9\u62c9(lara"
            },
            {
                "ref_id": "b174",
                "title": "\u626f\u626f(tug at);\u6495\u626f;\u62c9\u4f38(Stretching)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b175",
                "title": "English After walking for more than ten miles, the two dismounted and worshipped each other, hugging each other for a while, and parting in tears",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b176",
                "title": "",
                "journal": "",
                "year": "",
                "authors": "\u6402\u6402 Embedding"
            },
            {
                "ref_id": "b177",
                "title": "",
                "journal": "\u72c2\u543b(Kissing furiously",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b178",
                "title": "",
                "journal": "",
                "year": "",
                "authors": " \u62e5\u543b(kissing"
            },
            {
                "ref_id": "b179",
                "title": "",
                "journal": "\u629a\u6478(Stroking)",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b180",
                "title": "",
                "journal": "\u6402\u7740(Cuddle up",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b181",
                "title": "",
                "journal": "\u62b1\u8170(lap",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b182",
                "title": "\u4eb2\u70ed(affectionate)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b183",
                "title": "",
                "journal": "\u8e2e\u7740(stand on tiptoe",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b184",
                "title": "\u7d27\u62b1(Hold tightly) Bert \u62e5\u62b1;\u6402;\u62b1;\u62b1\u62b1;\u6402\u4f4f(hold in one's arms",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b185",
                "title": "\u4eb2\u543b(kiss);\u504e\u62b1;\u543b(lips)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b186",
                "title": "",
                "journal": "",
                "year": "",
                "authors": "\u62e5\u62b1;\u6402;\u62b1;\u62b1\u62b1; \u62e5(embrace) Parals;  \u6402\u4f4f"
            },
            {
                "ref_id": "b187",
                "title": "\u4eb2\u543b(kiss)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b188",
                "title": "\u6000\u62b1(embrace);\u504e\u62b1;\u62e5\u543b(Smooch) Ensemble \u6402;\u62e5\u62b1;\u62b1\u62b1",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b189",
                "title": "\u504e\u62b1;\u4eb2\u543b(kiss)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b190",
                "title": "",
                "journal": "",
                "year": "",
                "authors": " \u62e5\u543b(smooch"
            },
            {
                "ref_id": "b191",
                "title": "",
                "journal": "",
                "year": "",
                "authors": " \u6402\u6402(snuggle"
            },
            {
                "ref_id": "b192",
                "title": "",
                "journal": "\u629a\u6478(Stroking)",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b193",
                "title": "\u6402\u4f4f(hold in one's arms) Inst. 5 \u4ed6\u6545\u610f\u66ff\u54f2\u522b\u63a9\u9970\uff0c\u4ee5\u514d\u6210\u5409\u601d\u6c57\u77e5\u6653\u5185\u60c5\u3002 English He deliberately covered up for Zhebei so that Genghis Khan would not know the inside story",
                "journal": "Labels \u6709\u610f",
                "year": "",
                "authors": "\u6709\u610f \u84c4\u610f;\u6210\u5fc3;\u5b58\u5fc3;\u7279\u610f;\u523b\u610f Dict;  \u84c4\u610f"
            },
            {
                "ref_id": "b194",
                "title": "\u5047\u610f(hypocrisy);\u5b58\u5fc3;\u6709\u5fc3",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b195",
                "title": "",
                "journal": "\u6709\u610f\u8bc6(consciously)",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b196",
                "title": "",
                "journal": "",
                "year": "",
                "authors": "\u6545 "
            },
            {
                "ref_id": "b197",
                "title": "Embedding \u5077\u5077(secretly)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b198",
                "title": "",
                "journal": "\u6545\u610f\u6740\u4eba\u7f6a(Intentional Homicide",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b199",
                "title": "",
                "journal": "",
                "year": "",
                "authors": " \u660e\u77e5(knowingly"
            },
            {
                "ref_id": "b200",
                "title": "",
                "journal": "",
                "year": "",
                "authors": " \u8bec\u8d56"
            },
            {
                "ref_id": "b201",
                "title": "",
                "journal": "",
                "year": "",
                "authors": " \u6545\u5f04(plague"
            },
            {
                "ref_id": "b202",
                "title": "\u5356\u5f04\u7384\u865a(make a mystery of something",
                "journal": "Bert \u523b\u610f",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b203",
                "title": "\u6697\u4e2d(secretly)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b204",
                "title": "",
                "journal": "",
                "year": "",
                "authors": " \u8bd5\u56fe"
            },
            {
                "ref_id": "b205",
                "title": "",
                "journal": "",
                "year": "",
                "authors": " \u6253\u7b97"
            },
            {
                "ref_id": "b206",
                "title": "\u6697\u6697(secretly) ParaLS \u523b\u610f",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b207",
                "title": "",
                "journal": "\u8bbe\u6cd5",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b208",
                "title": "\u6697\u4e2d(secretly);\u84c4\u610f;\u6253\u7b97(intend)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b209",
                "title": "",
                "journal": "",
                "year": "",
                "authors": " \u8bd5\u56fe"
            },
            {
                "ref_id": "b210",
                "title": "\u6697\u6697(secretly) Ensemble \u523b\u610f;\u7279\u610f;\u6709\u610f;\u84c4\u610f;\u5047\u610f",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b211",
                "title": "",
                "journal": "",
                "year": "",
                "authors": " \u5047\u88c5"
            },
            {
                "ref_id": "b212",
                "title": "\u51b3\u5b9a(decision)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b213",
                "title": "\u5077\u5077(secretly)",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b214",
                "title": "The top 10 substitutes of five instances in the Novel subset of CHNLS using LS methods. The target word is marked in blue, and the substitutes in labels are marked in red",
                "journal": "",
                "year": "",
                "authors": ""
            }
        ],
        "figures": [
            {
                "figure_label": "2",
                "figure_type": "figure",
                "figure_id": "fig_0",
                "figure_caption": "Figure 2 :2Figure 2: Screenshot of an annotation example on the annotation Website. The red text indicates added comments.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "",
                "figure_caption": "",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "table",
                "figure_id": "tab_0",
                "figure_caption": "paraphraser-based methods are denoted as {c 1",
                "figure_data": ""
            },
            {
                "figure_label": "2",
                "figure_type": "table",
                "figure_id": "tab_2",
                "figure_caption": "Cohen's kappa agreement scores for pairs of annotators and Fleiss' kappa agreement for three annotators",
                "figure_data": "Cohen's (A1-A2) Cohen's (A1-A3) Cohen's (A2-A3) Fleiss' kappahline 0.5980.6140.5720.594"
            },
            {
                "figure_label": "3",
                "figure_type": "table",
                "figure_id": "tab_4",
                "figure_caption": "Evaluation results of substitute generation and substitute ranking. The scores in parentheses are only calculated by the substitutes from the substitute generation step. The Best values are bolded and the second values are marked in blue.",
                "figure_data": ""
            }
        ],
        "formulas": [],
        "doi": ""
    },
    "One Cannot Stand for Everyone! Leveraging Multiple User Simulators to train Task-oriented Dialogue Systems": {
        "authors": "Yajiao Liu; Xin Jiang; Yichun Yin; Yasheng Wang; Fei Mi; Qun Liu; Xiang Wan; Benyou Wang",
        "pub_date": "",
        "abstract": "User simulators are agents designed to imitate human users; recent advances have found that Task-oriented Dialogue (ToD) systems optimized toward a user simulator could better satisfy the need of human users. However, this might result in a sub-optimal ToD system if it is tailored to only one ad hoc user simulator, since human users can behave differently. In this paper, we propose a framework called MUST 1 to optimize ToD systems via leveraging Multiple User SimulaTors. The main challenges of implementing the MUST are 1) how to adaptively determine which user simulator to interact with the ToD system at each optimization step, since the ToD system might be over-fitted to some specific user simulators, and simultaneously underfitted to some others; 2) how to avoid catastrophic forgetting of the adaption for a simulator that is not selected for several consecutive optimization steps. To tackle these challenges, we formulate MUST as a Multi-armed bandits (MAB) problem and provide a method called MUST adaptive that balances i) the boosting adaption for adaptive interactions between different user simulators and the ToD system and ii) the uniform adaption to avoid the catastrophic forgetting issue. With both automatic evaluations and human evaluations, our experimental results on MultiWOZ show that the dialogue system trained by MUST achieves a better performance than those trained by a single user simulator. It also has a better generalization ability when testing with unseen user simulators.",
        "sections": [
            {
                "heading": "Introduction",
                "text": [
                    "Task-oriented dialogue systems aim to help users accomplish their various tasks (e.g., restaurant reservations) through natural language conversations. Training task-oriented dialogue systems in supervised learning approaches often requires a large amount of expert-labeled dialogues, however collecting these dialogues is usually expensive and time-consuming. Moreover, even with a large amount of dialogue data, some dialogue states may not be explored sufficiently for dialogue systems 2 (Li et al., 2016b). To this end, many researchers try to build user simulators to mimic human users for generating reasonable and natural conversations. By using a user simulator and sampling user goals, we can train the dialogue system from scratch with reinforcement learning (RL) algorithms. Previous works tend to design better user simulator models (Schatzmann et al., 2007;Asri et al., 2016;Gur et al., 2018;Kreyssig et al., 2018;Lin et al., 2021). Especially, Shi et al. (2019) builds various user simulators and analyzes the behavior of each user simulator in the popular restaurant search task from MultiWOZ (Budzianowski et al., 2018).",
                    "In real scenarios, dialogue systems need to face various types of users. A single ad hoc user simulator can only represent one or a group of users, while other users might be under-represented. Instead of choosing the best-performing one from many dialogue systems trained by different single user simulators, we believe that it is worth trying to train a dialogue system by leveraging all user simulators simultaneously.",
                    "In this paper, we propose a framework called MUST to utilize Multiple User SimulaTors simultaneously to obtain a better system agent. There exist several simple ways to implement the MUST framework, including a merging strategy, a continual reinforcement learning (CRL) strategy, and a uniform adaption strategy, namely MUST merging , MUST CRL , and MUST uniform respectively (See \u00a73.2). However, none of them could effectively tackle the challenges: 1) how to efficiently leverage multiple user simulators to train the dialogue system since the system might be easily over-fitted to some specific user simulators and simultaneously under-fitted to some others, and 2) it should avoid a catastrophic forgetting issue. To tackle them effectively, we first formulate the problem as a Multi-armed bandits (MAB) problem (Auer et al., 2002); similar to the exploitation vs exploration trade-off, specifying multiple user simulators should trade off a boosting adaption (tackling challenge 1) and a uniform adaption (tackling challenge 2), see \u00a74.1 for more details. Then we implement a new method called MUST adaptive to utilize an adaptively-updated distribution among all user simulators to sample them when training the dialogue system in the RL training.",
                    "Our contributions are three-fold: (1) To the best of our knowledge, our proposed MUST is the first developed work to improve the dialogue system by using multiple user simulators simultaneously; (2) We design several ways to implement the MUST. Especially, we formulate MUST as a Multi-armed bandits (MAB) problem, based on which we provide a novel method MUST adaptive ; and (3) The results show that dialogue systems trained with MUST consistently outperform those trained with a single user simulator through automatic and human evaluations, showing its potential for robustness to the diversity of user simulators. Importantly, it significantly improves the performance of the dialogue system tested on out-of-domain evaluation. Moreover, our results show that our method MUST adaptive can efficiently leverage multiple user simulators to train the dialogue system in terms of convergence speed."
                ],
                "publication_ref": [
                    "b13",
                    "b24",
                    "b0",
                    "b5",
                    "b9",
                    "b14",
                    "b26",
                    "b1"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Background",
                "text": [
                    "Dialogue system. Task-oriented dialogue systems aim to help users accomplish various tasks such as restaurant reservations through natural language conversations. Researchers usually divide the task-oriented dialogue systems into four modules (Wen et al., 2017;Ham et al., 2020;Peng et al., 2021): Natural Language Understanding (NLU) (Liu and Lane, 2016) that first comprehends user's intents and extracts the slots-values pairs, Dialog State Tracker (DST) (Williams et al., 2013) that tracks the values of slots, Dialog Policy Learning (POL) (Peng et al., 2017(Peng et al., , 2018) ) that decides the dialog actions, and Natural Language Generation (NLG) (Wen et al., 2015;Peng et al., 2020) that translates the dialog actions into a natural-language form. The DST module and the POL module usually are collectively referred to as the dialogue manager (DM) (Chen et al., 2017). These different modules can be trained independently or jointly in an end-to-end manner (Wen et al., 2017;Liu and Lane, 2018;Ham et al., 2020;Peng et al., 2021).",
                    "User simulator. The user simulator is also an agent but plays a user role. Different from dialogue systems, the user agent has a goal describing a target entity (e.g., a restaurant at a specific location) and should express its goal completely in an organized way by interacting with the system agent (Takanobu et al., 2020). Therefore, besides the modules of NLU, DM, and NLG like dialogue systems, the user agent should have another module called Goal Generator (Kreyssig et al., 2018), which is responsible for generating the user's goal. Building a user simulator could usually use an agenda-based approach (Schatzmann et al., 2007;Schatzmann and Young, 2009) designing handcrafted rules to mimic user behaviors or a model-based approach such as neural networks (Asri et al., 2016;Kreyssig et al., 2018;Gur et al., 2018) learned on a corpus of dialogues.",
                    "Training dialogue systems with a user simulator. To start a dialogue, a user agent will have an initial goal from its Goal Generator and then expresses its goal in natural languages. However, users' goals are invisible to the system agent. Then the system agent tends to gradually understand the users' utterances, query the database to find entities, and provide useful information to accomplish users' task. When the database result returned by the system agent is empty, the user agent should learn to compromise and change its goal with the help of Goal Generator. When the dialogue ends, the user simulator will reward the system agent according to if it accomplishes the task. Then we could use the reward to update the system agent with RL algorithms (Tseng et al., 2021)."
                ],
                "publication_ref": [
                    "b30",
                    "b6",
                    "b17",
                    "b16",
                    "b19",
                    "b18",
                    "b29",
                    "b20",
                    "b3",
                    "b30",
                    "b15",
                    "b6",
                    "b17",
                    "b27",
                    "b9",
                    "b24",
                    "b25",
                    "b0",
                    "b9",
                    "b5",
                    "b28"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "MUST: a Framework to Leverage",
                "text": [
                    "Multiple User SimulaTors   agenda-based methods and neural networks-based methods on the popular restaurant search task from MultiWOZ (Budzianowski et al., 2018). From their experiments, we observed that the dialogue systems trained by different user simulators vary in their performances (i.e., the success rates tested by the same user simulators). For example, when interacting with the user simulator of AgenT, the success rates of the system agents trained by Agenda-based user simulators (i.e., AgenT, AgenR, AgenG) are much higher than those of the system agents trained by RNN-based user simulators (i.e., RNNT, RNNR, RNN), see Fig. 1(a). The reason might be that these user simulators (i.e., with either handcrafted rules or data-driven learning in their DM modules) have different user dialog act distributions 4 (see Fig. 1(b)) which determine the dialogue state space explored by the dialogue system.",
                    "One cannot stand for everyone. Users might behave differently, one could design different user simulators with specific user dialog act distributions, see Shi et al. (2019). A single user simulator learned on a task-oriented dialogue corpus can just represent one or a group of users, while the dialogue system needs to accomplish tasks from various human users in real scenarios. We argue that it is beneficial to utilize all different user simulators to train the dialogue system. By leveraging multiple user simulators that have different user dialog act distributions, the dialogue systems can explore a larger dialogue state space, which might 4 The dialogue policy learning module is essential in both dialogue systems and user simulators. A policy module corresponds to a dialog act distribution since it decides to take which dialog act to respond to the current dialogue state. The user dialog act distribution behind a user simulator determines the diversity of the dialogue state space explored by dialogue systems; therefore it might affect the system performances.",
                    "improve the ability of the learned dialogue system."
                ],
                "publication_ref": [
                    "b26"
                ],
                "figure_ref": [
                    "fig_1",
                    "fig_1"
                ],
                "table_ref": []
            },
            {
                "heading": "Some Preliminary Proposals for MUST",
                "text": [
                    "We propose a framework called MUST, the core idea of which is to train a better dialogue system by leveraging Multiple User SimulaTors simultaneously. There are several simple ways to implement our MUST, including a merging strategy (MUST merging ), a Continual Reinforcement Learning strategy (MUST CRL ), and a uniform adaption strategy (MUST uniform ).",
                    "(I) MUST merging first samples some dialogues from each user simulator and the corresponding dialogue system trained by this simulator. Then it combines the collected dialogues to train a new user simulator for ensembling different user dialog act distributions. Finally, it uses this new user simulator to train the dialogue system with RL.",
                    "(II) MUST CRL 5 treats each user simulator as an independent RL environment. It moves the trained system agent to another one (i.e., let the system agent interact with another user simulator) if the system has converged in the current environment.",
                    "(III) MUST uniform allows the system agent have chances to interact with all user simulators simultaneously. Different from MUST CRL , MUST uniform puts all user simulators in a single RL environment and adopts the simplest way to specify different user simulators to train the dialogue system, which is to pick a user simulator among all user simulators with a uniform distribution for each iteration in the RL training.  (Khetarpal et al., 2020) and would be sensitive to the order of different user agents interacting with the dialogue system, which might result in obtaining a sub-optimal dialogue system. As Shi et al. (2019) shows, the system agents trained by different user simulators have different convergence speeds and converged performances. Namely, the system agent might be easily fitted to some user simulators but might be hardly fitted to others. A uniform distribution for the simulator selection under MUST uniform will result in inefficient training, since it would be unnecessary to assign the many training costs for easily-adapted user simulators. Overall, the challenging problems under MUST are 1) how to efficiently leverage multiple user simulators to train the system agent, and 2) avoiding the catastrophic forgetting issue."
                ],
                "publication_ref": [
                    "b8",
                    "b26"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "MUST as a MAB Problem",
                "text": [
                    "To tackle the challenges in MUST, we first formulate MUST as a Multi-armed bandit (MAB) problem, see \u00a74.1. In \u00a74.2, we propose a method called MUST adaptive to use an adaptively-updated distribution to replace the uniform distribution under the MUST uniform for accelerating the MUST training. We briefly compare these different implementations of MUST in Tab. 1."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Formulating MUST as a MAB Problem",
                "text": [
                    "Adaptively specifying user simulators to train dialogue systems reminds us of a similar concept in machine learning, called boosting (Zhou, 2012). From a boosting point of view, one should increase the weights of weakly-performing data examples and decrease the weights for well-performing ones.",
                    "In MUST, we accordingly assume that it should reduce the interactions between the dialogue system and those user simulators that the system has performed well; and meanwhile increase the interactions between the system and other user simulators that the system performs poorly. We refer to this strategy as boosting adaption.",
                    "Meanwhile, we should also give some chances to all user simulators to relieve the catastrophic forgetting issue. We refer to this as uniform adaption. Such a trade-off between boosting adaption and uniform adaption is similar to the the exploitation vs exploration trade-off existing in the Multi-armed bandit (MAB) problem (Auer et al., 2002).",
                    "Here, we interpret MUST as a MAB problem. We treat each user simulator as an arm. Suppose there are K arms (simulators), and each arm i has a fixed but unknown reward distribution R i with an expectation \u00b5 i . At each time step t = 1, 2, ..., T , one must choose one of these K arms. We denote the arm pulled at time step t as i t \u2208 {1, ..., K}. After pulling an arm, it receives a reward x it drawn from the arm's underlying reward distribution. The decision maker's objective is to maximize the cumulative expected reward over the time horizon",
                    "T t=1 E[x it ] = T t=1 \u00b5 it .",
                    "(1)",
                    "In MUST, the reward received in each armpulling step refers to the possible performance gain of the dialogue system after it interacts with a selected user simulator. A significant difference between the standard MAB problem and MUST is that the reward expectation of a user simulator (arm) in MUST is not static; it changes over time. For example, by consecutively interacting with the same user simulator, the performance gain (reward) of the system will decay since the system might be in saturation or overfitting to this simulator. Moreover, the performance gain of the system after interacting with a simulator might increase if the simulator has not been selected for a period. To deal with this difference, we should tailor the solution of MAB to the MUST framework."
                ],
                "publication_ref": [
                    "b1"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Training with MUST adaptive",
                "text": [
                    "To solve this MAB problem in MUST, we implement a method called MUST adaptive with a two-phase procedure, as presented in Algorithm 1. MUST adaptive specifies user simulators in a Output: The learned dialogue system S.",
                    "uniform distribution, similar to the UCB1 6 algorithm, to train the dialogue system S in the first T warmup steps (i.e., in the warm-up phase). After that, the adaptive phase will balance the boosting adaption and the uniform adaption by introducing an adaptively-updated distribution p, which is used to specify different user simulators to train the system S in later RL training. To accelerate the RL training, intuitively, p is expected to assign lower weights to user simulators with which S already performs well and higher weights to those user simulators with which S performs poorly.",
                    "(1) Warm-up phase : in the first T warmup dialogues, we use a uniform distribution to sample all user simulators to train the system agent S (lines 4-7). This phase is mainly used to warm up the dialogue system S.",
                    "(2) Adaptive phase : the distribution p used to sample all user simulators will be adaptively updated. We call it as the adaptive phase. When this phase begins (i.e., t = 0), we will first evaluate the performance (i.e., the success rate xj , j \u2208 {1, \u2022 \u2022 \u2022 , K}) of the dialogue system S trained after the warm-up phase. The success rate xj is obtained by letting S interact d times with the simulator U j (e.g., j \u2208 {1, ..., K}) and calculating the 6 There exists an algorithm called UCB1 (Upper Confidence Bound 1 ) (Auer et al., 2002) that could solve the MAB problem. It first pulls each arm once in the first K steps, then will play the arm that could maximize the sum of two terms:",
                    "it = arg maxi xi + 2 ln t T i,t from t = K + 1 to T .",
                    "success rates.",
                    "Inspired by UCB1 (Auer et al., 2002), we design a calibrated performance expectation xj of the system agent S interacting with each user simulator U j taking exploration into consideration beyond pure exploitation:",
                    "xj = xj exploitation + 2 ln t Tj,t exploration , j \u2208 {1, ..., K}; (2)",
                    "where xj is the success rate of the system agent S tested with user simulator U j , and T j,t is the number of times user simulator U j has been selected with so far. Then we normalize xj into",
                    "zj = 1/ (xj \u2212 \u03c4 min({x1, \u2022 \u2022 \u2022 , xK })) ,(3)",
                    "Eq. 3 penalizes the user simulators with which the dialogue system already performs well in the expectation term. Where the hyperparameter \u03c4 is the smooth factor for distribution p = {p 1 , \u2022 \u2022 \u2022 , p K } -the larger \u03c4 is, the sharper p is. Each probability p j in p is calculated as",
                    "p j = z j K i=1 z i .(4)",
                    "In the following T \u2212 1 dialogues, we will specify all user simulators to train the system agent S with this distribution p (lines 15-18). We will also evaluate the RL model S for every e episodes (line 10-12) and update the distribution p with the new K success rates (line 13).",
                    "Difference with the original UCB1. The main differences between our modified UCB1 algorithm and the original UCB1 algorithm are twofold. First, we tailor the original UCB1 into our scenario by using Eq. 3 to penalize the user simulators with which the dialogue system has performed well. Secondly, we adopt a sampling schema based on a well-designed distribution (see Eq. 4) instead of taking the arm with the highest expectation. This is to increase the diversity and flexibility of arm selection."
                ],
                "publication_ref": [
                    "b1",
                    "b1"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Experiments",
                "text": [
                    "To verify the effectiveness of MUST, we benchmark the system agents trained either with a single user simulator or multiple user simulators (including MUST merging , MUST uniform , and MUST adaptive ). See MUST CRL in the App. C."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Experimental Setup",
                "text": [
                    "Available user simulators. There are six user simulators provided by Shi et al. (2019), which are Agenda-Template (AgenT), Agenda-Retrieval (AgenR), Agenda-Generation (AgenG), RNN-Template (RNNT), RNN-Retrieval (RNNR), RNN-End2End (RNN) trained with different dialog planning and generation methods. The NLU modules of all six user simulators are using the RNN model. The DM modules of AgenT, AgenR, and AgenG are rule-based methods. For the NLG module, these three simulators are using the template, retrieval, and generation methods respectively. The DM modules of RNNT, and RNNR are using Sequicity (Lei et al., 2018) as their backbones which is an RNN-based seq2seq model with copy mechanism. The NLG modules of these two simulators are using the template and retrieval methods respectively. The user simulator of RNN uses Sequicity as its backbone in an end-to-end manner.",
                    "Baselines. The baselines are the dialogue systems trained by each user simulator, including Sys-AgenT, Sys-AgenR, Sys-AgenG, Sys-RNNT, Sys-RNNR, and Sys-RNN. For a fair comparison, all system agents (including the systems trained by our MUST) have the same architecture described in Shi et al. (2019). See details in App. B.1.",
                    "MultiWOZ Restaurant Domain Dataset. The original task in MultiWOZ (Budzianowski et al., 2018) is to model the system response. Shi et al. (2019) annotate the user intents and the user-side dialog acts in the restaurant domain of MultiWOZ to build user simulators, which has a total of 1,310 dia-logues. Moreover, we randomly simulate 2,000 dialogues from each rule-based simulator (i.e., AgenT, AgenR, AgenG) and their corresponding system agents respectively, and processe these dialogues to have the same annotation format as the MultiWOZ restaurant domain dataset. We denote this dataset as Simulated Agenda Dataset, which has a total of 6,000 dialogues.",
                    "Evaluation Measures. A straightforward metric to evaluate dialogue systems is the success rate tested by each user simulator. We calculate the success rate between a user simulator and a system agent by sampling 200 dialogues. We exclude some user simulators in training MUST and test the systems with them as out-of-domain evaluation.",
                    "According to the previous study Gunasekara et al. ( 2020), there usually is a gap between automatic evaluations and human evaluations of dialogue systems. Therefore, we ask humans to converse with dialogue systems. Each dialogue system has conversed with 5 different users; each user has 10 dialogues. In total, we collect 50 dialogues for each dialogue system to calculate its success rate. See more details in App. B.5."
                ],
                "publication_ref": [
                    "b26",
                    "b11",
                    "b26",
                    "b26"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Implementations",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Two new User Simulators",
                "text": [
                    "We believe Pre-trained Language Models (PLMs) might improve the capacity of user simulators since they have recently shown remarkable success in building task-oriented dialogue systems (Ham et al., 2020;Peng et al., 2021;Hosseini-Asl et al., 2020).",
                    "Here we implement another two user simulators using GPT (Radford et al., 2018(Radford et al., , 2019)). Building a user simulator using GPT is similar to building a ToD system with GPT. See more details in App. G.",
                    "GPT Simulator. It is first fine-tuned on the simulated agenda dataset and then fine-tuned on the MultiWOZ restaurant domain dataset by leveraging GPT. This user simulator will be used to help implementing MUST.",
                    "GPT IL Simulator. To implement the MUST merging strategy, similar to Imitation Learning (IL), we first train a new user simulator with dialogue sessions collected from different user simulators and their corresponding dialogue systems. We also learn this new user simulator based on GPT model and denote it as GPT IL . GPT IL is first fine-tuned on the simulated agenda dataset. Then we sample 1,400 dialogues from the 97.5 90.0 94.7 3.3 92.9 5.3 [1] The underlined number represents the success rate between a user simulator and its corresponding dialogue system trained by this user simulator. The increasing and decreasing percentages (in red and green colors) use the underlined numbers as the base success rates.",
                    "[2] \u2193 (\u2191) indicates by what percentages the success rate has decreased (increased) compared with the base success rate by interacting with the same user simulator.",
                    "Table 2: The success rates of system agents testing on various user simulators. Each column represents a user simulator, each row represents a dialogue system trained with a specific simulator, e.g., Sys-AgenT means the system trained with AgenT. Each entry shows the success rate of a system agent when dealing with a user simulator. We use four simulators (AgenT, AgenR, RNNT, and GPT) to implement MUST uniform and MUST adaptive .",
                    "simulated agenda dataset and merge them with 1,310 MultiWOZ restaurant domain dialogues to continue fine-tuning GPT IL ."
                ],
                "publication_ref": [
                    "b6",
                    "b17",
                    "b7",
                    "b21",
                    "b22"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Dialogue Systems",
                "text": [
                    "Sys-GPT is trained with the single user simulator GPT. Sys-MUST merging is trained with GPT IL . Sys-MUST uniform is trained by the user simulators of AgenT, AgenR, RNNT, and GPT with a uniform sampling distribution. For training Sys-MUST adaptive 7 , the distribution p will be adaptively updated using our modified UCB1 algorithm. We also train the Sys-MUST uniform and Sys-MUST adaptive by using different subsets of the user simulators for ablation studies in App. D."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Experimental Results",
                "text": [
                    "Automatic Evaluation. As seen in Tab. 2, Sys-MUST uniform and Sys-MUST adaptive outperform the dialogue systems (Sys-AgenT, Sys-AgenR, Sys-RNNT, and Sys-GPT) trained by a single user simulator in the overall performance, demonstrating the superiority of leveraging multiple user simulators. Especially, Sys-MUST adaptive has a 1.2 absolute value improvement (92.9 vs. 91.7) averagely over the previous SOTA system Sys-AgenR. Observing that Sys-MUST merging is not as competitive as Sys-MUST uniform and Sys-MUST adaptive , this comparison shows that the merging strategy cannot effectively leverage multiple user simulators.",
                    "In in-domain evaluation, the performances of systems (Sys-AgenT, Sys-AgenR, Sys-RNNT, and Sys-GPT) trained by a single user simulator drop a lot when testing with a different simulator. It requires us to delicately select a suitable user simula- tor for obtaining a good dialogue system. However, users might be multi-facet or even unknown, making the selection even more difficult. Therefore, it is essential to leverage multiple user simulators when training dialogue systems. At least, the performance gap of dialogue systems trained with our MUST becomes smaller than without MUST, see the percentages labeled in green and red colors.",
                    "In out-of-domain evaluation where the user simulators used for testing the systems are unseen by our MUST, Sys-MUST uniform and Sys-MUST adaptive achieve at most 2.4 absolute value improvement over Sys-AgenR. This evidences that MUST has a better generalization ability for interacting with unseen user simulators. Moreover, the dialogue systems (Sys-MUST merging , Sys-MUST uniform , and Sys-MUST adaptive ) trained with the proposed MUST approaches have lower standard deviations, which indicates that they are more robust to the diversity of user simulators.",
                    "Human Evaluation. In Tab. 3, the human evaluation results show that our Sys-MUST uniform and Sys-MUST adaptive largely outperform the other dialogue systems when interacting with real users. The consistency between automatic evaluations and human evaluations evidences the effectiveness of our proposed MUST.   "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Analysis and Discussions",
                "text": [
                    "Convergences of MUST uniform and MUST adaptive . In Fig. 2, we show the learning curves of Sys-MUST uniform and Sys-MUST adaptive in 100,000 steps; the first 40,000 steps are in the warm-up phase for Sys-MUST adaptive . From Fig. 2(a), we can see that training the dialogue system with AgenT, AgenR, RNNT, and GPT by MUST adaptive converges faster than by MUST uniform . We do ablation studies on our modified UCB1 algorithm to help understanding the designed distribution p, see details in App. E. We further plot the performances of the dialogue system tested by each user simulator in the RL training in Fig. 2"
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_2",
                    "fig_2",
                    "fig_2"
                ],
                "table_ref": []
            },
            {
                "heading": "(b)-2(e).",
                "text": [
                    "Visualization on MUST adaptive . Let us define the adaptation difficulty of a user simulator using how many steps it must take to train the dialogue system with this user simulator until it converges. The adaptation difficulty of all user simulators could be ranked like AgenR > AgenT > GPT > RNNT according to Fig. 2(b)-2(e). To check whether MUST adaptive tends to sample harder-to-adapt user simulators more times in the adaptive phase, as assumed in \u00a74.2, we visualize the sampling proportions of all user simulators in Fig. 3(a). We could observe that AgenR was sampled with 45.1% (the biggest proportion) and it is indeed the hardest user simulator that can be adapted by the system; RNNT has the smallest sampling proportion and it is the easiest user simulator that can be adapted by the system. The consistency between the adaptation difficulty and sampling proportions for these four user simulators evidences our assumption in \u00a74.2. Fig. 3(b) visualizes the variations of the sampling distributions of user simulators. Interestingly, it shows that AgenR and AgenT are competitive with the GPT simulator; while RNNT and GPT are cooperative with each other. This might be because both RNNT and GPT simulators are learned from the dialogue corpus and might share some similar behaviors."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_2",
                    "fig_4",
                    "fig_4"
                ],
                "table_ref": []
            },
            {
                "heading": "Conclusion",
                "text": [
                    "In this paper, we propose a framework named MUST to improve dialogue systems by using multiple user simulators simultaneously. We discuss several simple methods to implement MUST, which is either inflexible or inefficient. Therefore, we formulate MUST as a Multi-armed bandits (MAB) problem, based on which we propose a novel implementation called MUST adaptive . The experimental results on the restaurant search task from MultiWOZ demonstrate that MUST can largely improve the system agent upon baselines, especially when tested with unseen user simulators. Moreover, MUST adaptive is more efficient than other implementations."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Limitation",
                "text": [
                    "The main limitation of this work is that we only conduct our experiments on the restaurant domain of the MultiWOZ since we can only find multiple user simulators from Shi et al. (2019) and they build these simulators only on the restaurant search task. In future work, we plan to apply our proposed methods to multi-domain scenarios."
                ],
                "publication_ref": [
                    "b26"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Ethics Statement",
                "text": [
                    "There "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A Multi-armed bandit problem",
                "text": [
                    "Reinforcement learning policies face the exploitation versus exploration trade-off, which can be described as the search for a balance between exploring the environment to find profitable actions while taking the empirically best action as often as possible. This exploitation vs exploration dilemma has been widely studied as a Multi-armed bandit (MAB) problem.",
                    "In the MAB problem, there are K arms, and each arm j has a fixed but unknown reward distribution R j with an expectation \u00b5 j . At each time step t = 1, 2, ..., T , the decision maker must choose one of these K arms. We denote the arm pulled at time step t as j t \u2208 {1, ..., K}. After pulling an arm, it will receive a reward X jt which is a realization drawn from the arm's underlying reward distribution. The decision masker's objective is to maximize the cumulative expected reward over the time horizon T t=1 E[X jt ] = T t=1 \u00b5 jt ."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "B More details about training dialogue systems B.1 The architectures of user simulators and dialogue systems",
                "text": [
                    "The basic modules of user simulators and dialogue systems are detailed in Tab. 4."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "B.2 The implementations of the dialogue systems",
                "text": [
                    "The NLU modules of all system agents are a 2-layer bidirectional-GRU with 200 hidden units. The NLG modules of them are using the template-based method. The DM modules of them are a simple MLP. The input of the DM module is a state representation, which consists of the traditional dialog state and word count vector of the current utterance same as Shi et al. (2019). We mainly use the policy gradient method to train the DM modules of dialogue systems from scratch."
                ],
                "publication_ref": [
                    "b26"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "B.3 The details of running policy gradient algorithm",
                "text": [
                    "For training the DM modules of dialogue systems with the policy gradient method, we also apply the \u03f5-greedy exploration strategy. We let \u03f5 be 0.5 in the beginning, and it will decrease to 0 linearly within the RL training. The dialogue ends either when the user simulators say \"goodbye\" or when the number of turns of the dialogue exceeds 10. The reward will be given +1 for task success, -1 for task failure, and -0.1 for each additional turn to encourage the RL-based policy module to finish the task fast. Also, a discounted factor of 0.9 is applied to all the experiences."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "B.4 The parameters of training Sys-MUST adaptive",
                "text": [
                    "The hyperparameters used to train the Sys-MUST adaptive are listed in the Tab. 5. Since some user simulators used for implementing our MUST framework are based on the GPT model, we train Sys-MUST adaptive on a V100 GPU and it will cost around 15 hours with the default hyperparameters above."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "B.5 Human Evaluation on dialogue systems",
                "text": [
                    "We find 5 volunteers to conduct the human evaluations on dialogue systems. They all have good English skills and are unpaid. Before the experiments, we introduced task-oriented dialogue systems and user simulators to them and tell them how to judge if the generated dialogue is successful. Then we prepare 50 user goals from MultiWOZ Restaurant Domain Dataset: 20 of them are simple, and 30 of them are a little bit complex. We specify 10 user goals for each volunteer and let the volunteer converse with all dialogue systems for each same user goal. In total, we collect 50 dialogues for each  dialogue system to calculate its success rate.",
                    "The criteria to judge whether a task-oriented dialogue is successful are based on two aspects: 1) the system agent correctly understands the user's goal (i.e., the predicted dialogue state tracking result is correct); and 2) the system agent provides all information (i.e., all slot values or a booking reference number) that the user requests. For human evaluations, we follow these standard criteria. Besides, we also see if the system act generated by the system agent is matched to the user act for each turn in the dialogue.",
                    "There have seven user acts, which are 'inform type\", \"inform type change\", \"ask info\", \"anything else\", \"make reservation\", \"make reservation change time\", and \"goodbye\". There have nine system acts, which are \"ask type\", \"present result\", \"nomatch result\", \"no other\", \"ask reservation info\", \"provide info\", \"booking success\", \"booking fail\" and \"goodbye\". The relationships between user acts and system acts are shown in Tab. 6."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "C Implement MUST with the MUST CRL strategy",
                "text": [
                    "Without losing any generality, we consider two representative sequential orders: 1) AgenT, AgenR, RNNT, GPT; and 2) AgenR, GPT, AgenT, RNNT.",
                    "For case 1, the first two user simulators are Agenda-based user simulators; the last two user simulators are Neural networks-based user simulators. For case 2, we interleave these two types of user simulators. When the system trained by a user simulator converges, we let it continue to interact with another user simulator following the order. As seen in Tab. 7, in case 1, the system agent achieves the best performance (i.e., 92.4 in terms of the average success rate) after training with AgenT and AgenR sequentially. However, its overall performance degrades to 83.0 after training with RNNT; especially, its performance decreases by 36.0% when testing with AgenR (93.0 \u2192 59.5). Moreover, after continuing to learn from GPT, the performance of the system agent becomes worse for AgenT (95.0 \u2192 75.5) and AgenR (59.5 \u2192 47.5). This indicates the catastrophic forgetting issue heavily happened when the system agent starts learning from AgenR. We also could observe a similar phenomenon from case 2. These results can confirm that implementing our proposed MUST with MUST CRL strategy indeed has the catastrophic forgetting issue."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "D Sensitivity on different subsets of user simulators",
                "text": [
                    "We also train the Sys-MUST uniform and Sys-MUST adaptive by using different groups of user simulators for ablation studies: 1) five user simulators of AgenT, AgenR, RNNT, RNNR, and GPT; and 2) three user simulators including AgenT, RNNT, and GPT.",
                    "Superiority of MUST. From Tab. 8 and Tab. 9, we can observe that Sys-MUST uniform and Sys-MUST adaptive largely outperform the dialogue systems trained by single user simulators. Especially, they gain an improvement of 4 absolute points (85.4 vs. 81.4) when trained with three user simulators of AgenT, RNNT, and GPT. In summary, MUST  could consistently improve the performance of the systems when using different numbers of user simulators. The ablation studies on different subsets of user simulators can demonstrate the robustness of MUST.",
                    "Out-of-domain evaluation. When testing our MUST with unseen user simulators, Sys-MUST uniform and Sys-MUST adaptive can also largely outperform the dialogue systems trained by a single user simulator. As seen in Tab. 8, Sys-MUST adaptive achieves a 2.7 absolute value improvement (92.5 vs 89.8) over Sys-AgenR. Sys-MUST uniform and Sys-MUST adaptive even improve at least 5.7 points (80.0 vs 74.3) over Sys-GPT (as shown in Tab. 9). These experimental results on different subsets of user simulators demonstrate that our MUST has a better generalization ability for interacting with unseen user simulators and is insensitive to the user simulator selection.",
                    "Comparison between MUST uniform and MUST adaptive . Fig. 4 shows the learning curves of Sys-MUST uniform and Sys-MUST adaptive on different subsets of user simulators. The first 40,000 steps are in the warm-up phase for Sys-MUST adaptive . We could conclude that training the dialogue system by MUST adaptive consistently converges faster than by MUST uniform , at least in the scenarios when using three, four, or five user simulators to implement MUST (see Fig. 4(a), From Tab. 8 where MUST is trained with five user simulators, we could observe that Sys-MUST adaptive outperforms Sys-MUST uniform with 0.5 absolute point. The performance gain becomes smaller when MUST is trained with three user simulators (see Tab. 9). This probably shows that Sys-MUST adaptive would be more beneficial when there exist more user simulators."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "E Ablation study for the modified UCB1 algorithm E.1 Necessity of the exploration term",
                "text": [
                    "Our modified UCB1 algorithm provides a distribution for guiding how to sample different user simulators to accelerate the entire MUST training. The exploration term in the proposed MUST adaptive exists mainly for uniform adaption (see the detailed explanation in Sec. 4.1). The original UCB1 algorithm (Auer et al., 2002) can tell us how to pull arms in bandits to maximize the cumulative expected reward. It is well-known that it cannot explore effectively without the exploration (UCB) term; consequently, it might not find the optimal action and lead to relatively poor performance. It is difficult to theoretically prove the usefulness of the exploration term in our scenario (like in the original UCB1 algorithm), which we leave as future work. However, we alternatively conduct some ablation studies to evidence the necessity of the exploration term.",
                    "MUST adaptive w/t exploration. If we omit the exploration term in our modified UCB1 algorithm, the simplest way to calculate the distribution p is to make the sample probability w.r.t a user simulator solely depend on the inversion of the system's performance. See the row called 'w/t exploration' in Tab. 10 for comparisons. In this situation, the obtained distribution p might be sharp due to the lack of the exploration term, which would be harmful for uniform adaption to some extent. As Fig. 5(a) shows, MUST adaptive performs worse and converges slower when omitting the exploration term, compared with when our modified UCB1 algorithm has the exploration term. This could demonstrate both the importance of uniform adaption and the usefulness of the exploration term."
                ],
                "publication_ref": [
                    "b1"
                ],
                "figure_ref": [
                    "fig_8"
                ],
                "table_ref": []
            },
            {
                "heading": "E.2 Ablation study on the designed distribution",
                "text": [
                    "Rationale of exploitation vs exploration tradeoff. Similar to the exploitation vs exploration trade-off, the distribution p under the MUST adaptive should trade off the boosting adaption and the uniform adaption when specifying multiple user simulators. Considering the boosting adaption, we make a exploitation assumption stated as follows: p is expected to assign lower weights to user simulators with which the system agent S already performs well and higher weights to those user simulators with which S performs poorly. Therefore, the sampling ratios for different user simulators should be inversely proportional to the system's performance on each user simulator.",
                    "Rationale of the modified UCB1 algorithm.",
                    "The modified UCB1 algorithm for implementing MUST adaptive is defined as",
                    "xj = xj exploitation + 2 ln t T j,t exploration , j \u2208 {1, ..., K}; z j = 1/ (x j \u2212 \u03c4 min({x 1 , \u2022 \u2022 \u2022 , xK })) , p i = z j K j=1 z j .(5)",
                    "MUST adaptive in Eq. 5 (which is the same as Eq. 2, Eq. 3, and Eq. 4) consists of three steps: exploitation-exploration term construction, postprocessing (re-scaling operation and the inversion operation), and the probability normalization, corresponding to each line in Eq. 5. Besides this way, we could have the following three variants that shuffle the order of these three key operations (i.e., the exploitation-exploration term construction, re-scaling operation, and the inversion operation). We name these variants as as MUST adaptive -I, MUST adaptive -II, and MUST adaptive -III.",
                    "MUST adaptive -I. For the exploitation assumption, we make the exploitation term inversely proportional to the system's performance xj on each user simulator U j , which is denoted as MUST adaptive -I. From Tab. 10, we can obverse that the difference between MUST adaptive -I and MUST adaptive is that MUST adaptive -I take the inversion of x before the exploitation-exploration term construction while MUST adaptive take the inversion operation after the exploitation-exploration term construction. Since each xj , j \u2208 {1, \u2022 \u2022 \u2022 , K} is smaller than 1, 1 xj will be larger than 1. Therefore, the term of 1 xj and the exploration term of 2 ln t T j,t (smaller than 1) are not with the same magnitude, which will lead to a consequence that the exploitation term becomes dominant while the exploration term is negligible. We have discussed a similar issue of ignoring the exploration term in Sec. E.1. Therefore, we adopt MUST adaptive in default if not specified rather than MUST adaptive -I since the latter might suffer from the different magnitudes of the exploitation term and the exploration term.  Results for ablation study on the variants. Experimental results of these different variants are shown in Fig. 5(b). The convergence speed of MUST adaptive -I is much slower compared to others, which demonstrates that the exploration term is useful once more. The convergence speeds of MUST adaptive -II and MUST adaptive -III is comparative to MUST adaptive . This probably shows that variants exploitation-exploration term post-processing distribution",
                    "MUST adaptive xj = xj + 2 ln t T j,t zj = 1 (xj\u2212\u03c4 min({x 1 ,\u2022\u2022\u2022 ,x K })) pj = z j K i=1 z i w/t exploration zj = 1 xj MUST adaptive -I xj = 1 xj + 2 ln t T j,t zj = xj \u2212 \u03c4 min({1/x1, \u2022 \u2022 \u2022 , 1/xK }) MUST adaptive -II xj = 1/x j K i=1 1/x i zj = \u1e91j \u2212 \u03c4 min({x1, \u2022 \u2022 \u2022 , xK }) \u1e91j = xj + 2 ln t T j,t MUST adaptive -III xj = 1 (x j \u2212\u03c4 min({x 1 ,\u2022\u2022\u2022 ,x K })) zj = xj K i=1 xi + 2 ln t T j,t",
                    "Table 10: The variants of MUST adaptive . The MUST adaptive implementation is an exploitation-exploration term followed by a post-processing for the re-scaling purpose and a sum-one normalization. Since we omit the exploration term for the second row, therefore, it does not need the post-processing. MUST adaptive -III moves the re-scaling and the inversion operations to the front of the constructed exploitation-exploration term.",
                    "our design with three operations (i.e., exploitationexploration term construction, re-scaling strategy, and the inversion of xj ) is not only reasonable but also robust to the order permutation of these three operations."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "F Implementing MUST with more user simulators",
                "text": [
                    "To implement our MUST with more user simulators, we use Simulated Agenda Dataset to train four extra user simulators 8 . Fig. 6(a) shows the learning curve of the system agent trained by MUST with eight simulators (AgenT, AgenR, RNNT, GPT, GPT AT , GPT AR , GPT AG , and GPT rand ). We could observe that the training of our proposed MUST can still succeed when we increase the number of user simulators to eight. Sys-MUST adaptive still converges faster than Sys-MUST uniform even though the difference between their convergence speeds is not too large in this case. It might be because some user simulators are similar (e.g., GPT AT is similar to AgenT, GPT AR is similar to AgenR), which might lead that the distribution p approaches a uniform distribution. Fig. 6(b) compares the learning curves of Sys-MUST adaptive and Sys-MUST uniform trained with different numbers of user simulators (i.e., four, five, and eight user simulators). It is a fair comparison because these combinations include the hardest 8 Simulated Agenda Dataset (See Sec. 5.1) is simulated from each rule-based user simulator (i.e., AgenT, AgenR, AgenG) and its corresponding system agent respectively. We use them to build three new user simulators denoted as GPTAT, GPTAR, and GPTAG based on the GPT model respectively. For example, we use the simulated dialogues from AgenT and Sys-AgenT to build the GPTAT. we also collect 3000 dialogues randomly from Simulated Agenda Dataset to train another new GPT user simulator denoted as GPT rand . user simulator AgenR that can be adapted by the system and the easiest user simulator RNNT that can be adapted by the system (See Sec. 5.4). We can observe that, with more user simulators, Sys-MUST adaptive not only performs better but also converges faster than with fewer user simulators. This probably shows that Sys-MUST adaptive has the potential to be generalized to a larger set of user simulators. Plus, we also could observe that Sys-MUST adaptive consistently converges faster than Sys-MUST uniform in different numbers of user simulators."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_10",
                    "fig_10"
                ],
                "table_ref": []
            },
            {
                "heading": "G Modeling User Simulator with GPT",
                "text": [
                    "We name the model of building a user simulator based on GPT as U-GPT. In this section, we will illustrate its details and conduct experiments to prove that it is a better model for building a user simulator."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "G.1 The architecture of U-GPT",
                "text": [
                    "As Fig. 7(a) shown, our U-GPT consists of four modules, which are Natural Language Understanding (NLU), Goal Generator, Dialog Policy Learning (POL), and Natural Language Generation (NLG). Dialogues consist of multiple turns. In the first turn t = 0, U-GPT (1) first outputs its NLU results N 0 by understanding the system input S 0 , and (3) decide its actions A 0 which is a list of pairs: (action_type, slot_name) based on (2) its initial goal G 0 and {S 0 , N 0 }. U-GPT then (4) conditions on {S 0 , N 0 , G 0 , A 0 } to generate the delexicalized utterance U 0 . The generated placeholders in U 0 will be filled using the corresponding slot values in the goal G 0 . When the conversation proceeds to turn t, U-GPT (1) generates the  NLU results N t based on all of previous dialogue history and generated outputs {C 0 , . . . , C t\u22121 , S t }, here",
                    "C i = [S i , N i , G i , A i , U i ].",
                    "If there has \"nooffer\" intent in N t representing that no entities could satisfy current constraints, then (2) Goal Generator should generate a new goal G t . Then U-GPT will continue to (3) generate the user acts A t and (4) generate delexicalized utterance U t conditioned on {C 0 , . . . , C t\u22121 , S t , N t , G t } sequentially. We should notice that the user utterances occurred in the history context should be lexicalized because they contain important information. [eos_pol], [eos_utt] to signal the ending of sequence representations of different modules. For the NLU results N t , we use five categories: \"inform\", \"request\", \"book inform\", \"select\", \"recommend\" same as Shi et al. (2019) to represent them. And we also introduce five tokens [eos_constraint], [eos_book], [eos_recommend],",
                    "[eos_select], [eos_request] to record different information. All of these tokens and the intents of user actions will be added to the vocabulary of GPT as additional special tokens. For training U-GPT, we use the same training objective as GPT which is to maximize the following likelihood:",
                    "L(U ) = i log P (u i |u i\u2212k , ..., u i\u22121 ; \u0398), \u2200 u i \u2208 {S 0 , N 0 , G 0 , A 0 , U 0 , ..., A t , U t },",
                    "where k is the size of the context window, and the conditional probability P is parameterized with \u0398."
                ],
                "publication_ref": [
                    "b26"
                ],
                "figure_ref": [
                    "fig_11"
                ],
                "table_ref": []
            },
            {
                "heading": "G.2 Evaluations on U-GPT",
                "text": [
                    "To evaluate our proposed U-GPT, we adopt both indirect evaluations and direct evaluations as in Shi et al. (2019). We evaluate a user simulator indirectly using the average success rate of the system agent trained by this simulator. It is called crossmodel evaluation (Schatzmann and Young, 2009) which assumes a strategy learned with a good user model still performs well when tested on poor user models. It can indirectly evaluate the goodness of a user simulator. For direct evaluations, we adopt six evaluation measures to evaluate the diversity of user simulators automatically: average utterance length, vocabulary size, Dist-1, Dist-2 (Li et al., 2016a) and Entropy (Zhang et al., 2018). We also ask human users to rate the simulated dialogues 9 to assess the user simulators directly. We use five same metrics as Shi et al. (2019) which are Fluency, Coherence, Goal Adherence, Diversity, and Overall quality to assess user simulators from multiple aspects."
                ],
                "publication_ref": [
                    "b26",
                    "b25",
                    "b12",
                    "b26"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "G.3 Training details of user simulators",
                "text": [
                    "We implement our GPT-based user simulators with DistilGPT2 (Sanh et al., 2020), a distilled version of GPT-2 by HuggingFace's Transformers (Wolf et al., 2020). We select the best performing models on the validation set through hyperparameters {\"info\":{\"food\": \"Venetian\", \"pricerange\": \"expensive\", \"area\": \"centre\"}, \"book\": {\"time\": \"12:00\", \"day\": \"Wednesday\", \"people\": \"4\"}} {\"info\":{\"food\": \"Chinese\", \"pricerange\": \"expensive\", \"area\": \"centre\"}, \"book\": {\"time\": \"12:00\", \"day\": \"Wednesday\", \"people\": \"4\"}}"
                ],
                "publication_ref": [
                    "b23",
                    "b23"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "System Agent User Simulator",
                "text": [
                    "(2) Goal Generator (1) NLU (2) Goal Generator   search of learning rate and batch size. The best models were fine-tuned with a batch size of 64 and a learning rate of 1e-3 over the corresponding dataset. We use the greedy decoding strategy for generating word-tokens in the inference phrase."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "G.4 Experiments",
                "text": [
                    "GPT-RNN. Because the implementation of user simulator RNN mainly consists of NLU and NLG, we remove the POL module from U-GPT and use the same annotated data as RNN to fine-tune it to compare our U-GPT with the RNN-based methods fairly and name it as GPT-RNN.",
                    "As Tab. 11, Tab. 12, Tab. 13 show, GPT-RNN outperforms the user simulator RNN. It proves the power of leveraging GPT.",
                    "Our GPT-RNN performs better than the user simulator RNNT, which can be seen from the crossmodel evaluation results in Tab. 11, the automatic evaluation results in Tab. 12, and the Hu.Div score in the human evaluation results in Tab. 13. However, as Tab. 13 shows, RNNT performs better than our GPT-RNN in the overall performance from the human evaluation. We think this might be because (1) the third-party system also has an impact on the generated dialogues and (2) the NLG module of RNNT is the template-based method which leads to the generated dialogues from RNNT being easy for the third-party system to understand and interact with.",
                    "The automatic evaluation results in Tab. 12 and the Hu.Div score in the human evaluation results in Tab. 13 show that RNNR can generate more diverse language than our GPT-RNN. We think it is because the user utterances generated by RNNR are retrieved from a corpus that is written by real humans and the sentences written by humans are usually more diverse than the sentences generated by generative models. Even though the dialogues generated by RNNR are more diverse, the dialogues generated by our GPT-RNN are more fluent and coherent. Also, the cross-model evaluation results in Tab. 11 show that GPT-RNN can help to learn a more robust system agent than RNNR, but the Hu.All score in the human evaluation in Tab. 13 gives the opposite result. "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Acknowledgements",
                "text": [
                    "Part of this work was done when the first author worked at Huawei Noah's Ark Lab. Besides, this work is supported by the Chinese Key-Area Research and Development Program of Guangdong Province (2020B0101350001), the Shenzhen Science and Technology Program (JCYJ20220818103001002), the Guangdong Provincial Key Laboratory of Big Data Computing, The Chinese University of Hong Kong, Shenzhen, Shenzhen Key Research Project (C10120230151) and Shenzhen Doctoral Startup Funding (RCBS20221008093330065). We would like to thank Zichao Li, Chen Zhang, and Dong Yang for their helpful discussions. Moreover, we thank anonymous reviewers for their valuable suggestions."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "",
                "text": [
                    "B3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided that it was specified? For the artifacts you create, do you specify intended use and whether that is compatible with the original access conditions (in particular, derivatives of data accessed for research purposes should not be used outside of research contexts)?",
                    "No response.",
                    "B4. Did you discuss the steps taken to check whether the data that was collected / used contains any information that names or uniquely identifies individual people or offensive content, and the steps taken to protect / anonymize it? No response.",
                    "B5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and linguistic phenomena, demographic groups represented, etc.? No response.",
                    "B6. Did you report relevant statistics like the number of examples, details of train / test / dev splits, etc. for the data that you used / created? Even for commonly-used benchmark datasets, include the number of examples in train / validation / test splits, as these provide necessary context for a reader to understand experimental results. For example, small differences in accuracy on large test sets may be significant, while on small test sets they may not be.",
                    "No response."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "C Did you run computational experiments?",
                "text": [
                    "Yes. Sec. 5",
                    "C1. Did you report the number of parameters in the models used, the total computational budget (e.g., GPU hours), and computing infrastructure used?"
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "See appendix",
                "text": [
                    "The Responsible NLP Checklist used at ACL 2023 is adopted from NAACL 2022, with the addition of a question on AI writing assistance."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            }
        ],
        "references": [
            {
                "ref_id": "b0",
                "title": "A sequence-to-sequence model for user simulation in spoken dialogue systems",
                "journal": "",
                "year": "2016",
                "authors": "Layla El Asri; Jing He; Kaheer Suleman"
            },
            {
                "ref_id": "b1",
                "title": "Finite-time analysis of the multiarmed bandit problem",
                "journal": "",
                "year": "2002",
                "authors": "Peter Auer; Nicol\u00f2 Cesa-Bianchi; Paul Fischer"
            },
            {
                "ref_id": "b2",
                "title": "MultiWOZ -a largescale multi-domain Wizard-of-Oz dataset for taskoriented dialogue modelling",
                "journal": "Association for Computational Linguistics",
                "year": "2018",
                "authors": "Pawe\u0142 Budzianowski; Tsung-Hsien Wen; Bo-Hsiang Tseng; I\u00f1igo Casanueva; Stefan Ultes; Milica Osman Ramadan;  Ga\u0161i\u0107"
            },
            {
                "ref_id": "b3",
                "title": "Deep learning for dialogue systems",
                "journal": "",
                "year": "2017",
                "authors": "Yun-Nung Chen; Asli Celikyilmaz; Dilek Hakkani-T\u00fcr"
            },
            {
                "ref_id": "b4",
                "title": "",
                "journal": "",
                "year": "",
                "authors": "R ; Chulaka Gunasekara; Seokhwan Kim; Luis Fernando; D' Haro; Abhinav Rastogi; Yun-Nung Chen; Mihail Eric; Behnam Hedayatnia; Karthik Gopalakrishnan; Yang Liu; Chao-Wei Huang; Dilek Hakkani-T\u00fcr; Jinchao Li; Qi Zhu; Lingxiao Luo; Lars Liden; Kaili Huang; Shahin Shayandeh; Runze Liang; Baolin Peng; Zheng Zhang; Swadheen Shukla; Minlie Huang; Jianfeng Gao; Shikib Mehri; Yulan Feng; Carla Gordon"
            },
            {
                "ref_id": "b5",
                "title": "User modeling for task oriented dialogues",
                "journal": "",
                "year": "2018",
                "authors": "Izzeddin Gur; Dilek Hakkani-Tur; Gokhan Tur; Pararth Shah"
            },
            {
                "ref_id": "b6",
                "title": "End-to-end neural pipeline for goal-oriented dialogue systems using GPT-2",
                "journal": "Online. Association for Computational Linguistics",
                "year": "2020",
                "authors": "Donghoon Ham; Jeong-Gwan Lee; Youngsoo Jang; Kee-Eung Kim"
            },
            {
                "ref_id": "b7",
                "title": "A simple language model for task-oriented dialogue",
                "journal": "Curran Associates, Inc",
                "year": "2020",
                "authors": "Ehsan Hosseini-Asl; Bryan Mccann; Chien-Sheng Wu; Semih Yavuz; Richard Socher"
            },
            {
                "ref_id": "b8",
                "title": "Towards continual reinforcement learning: A review and perspectives",
                "journal": "CoRR",
                "year": "2020",
                "authors": "Khimya Khetarpal; Matthew Riemer; Irina Rish; Doina Precup"
            },
            {
                "ref_id": "b9",
                "title": "Neural user simulation for corpus-based policy optimisation of spoken dialogue systems",
                "journal": "",
                "year": "2018",
                "authors": "Florian Kreyssig; I\u00f1igo Casanueva; Pawe\u0142 Budzianowski; Milica Ga\u0161i\u0107"
            },
            {
                "ref_id": "b10",
                "title": "Annual SIGdial Meeting on Discourse and Dialogue",
                "journal": "Association for Computational Linguistics",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b11",
                "title": "Sequicity: Simplifying task-oriented dialogue systems with single sequence-to-sequence architectures",
                "journal": "Association for Computational Linguistics",
                "year": "2018",
                "authors": "Wenqiang Lei; Xisen Jin; Min-Yen Kan; Zhaochun Ren; Xiangnan He; Dawei Yin"
            },
            {
                "ref_id": "b12",
                "title": "Deep reinforcement learning for dialogue generation",
                "journal": "Association for Computational Linguistics",
                "year": "2016",
                "authors": "Jiwei Li; Will Monroe; Alan Ritter; Dan Jurafsky; Michel Galley; Jianfeng Gao"
            },
            {
                "ref_id": "b13",
                "title": "A user simulator for task-completion dialogues",
                "journal": "",
                "year": "2016",
                "authors": "Xiujun Li; C Zachary; Bhuwan Lipton; Lihong Dhingra; Jianfeng Li; Yun-Nung Gao;  Chen"
            },
            {
                "ref_id": "b14",
                "title": "Domainindependent user simulation with transformers for task-oriented dialogue systems",
                "journal": "Association for Computational Linguistics",
                "year": "2021",
                "authors": "Nurul Hsien-Chin Lin; Songbo Lubis; Carel Hu; Christian Van Niekerk; Michael Geishauser; Shutong Heck; Milica Feng;  Gasic"
            },
            {
                "ref_id": "b15",
                "title": "End-to-end learning of task-oriented dialogs",
                "journal": "",
                "year": "2018",
                "authors": "Bing Liu; Ian Lane"
            },
            {
                "ref_id": "b16",
                "title": "Attention-based recurrent neural network models for joint intent detection and slot filling",
                "journal": "CoRR",
                "year": "2016",
                "authors": "Bing Liu; Ian R Lane"
            },
            {
                "ref_id": "b17",
                "title": "Shahin Shayandeh, Lars Liden, and Jianfeng Gao",
                "journal": "",
                "year": "2021",
                "authors": "Baolin Peng; Chunyuan Li; Jinchao Li"
            },
            {
                "ref_id": "b18",
                "title": "Deep Dyna-Q: Integrating planning for task-completion dialogue policy learning",
                "journal": "Association for Computational Linguistics",
                "year": "2018",
                "authors": "Baolin Peng; Xiujun Li; Jianfeng Gao; Jingjing Liu; Kam-Fai Wong"
            },
            {
                "ref_id": "b19",
                "title": "Composite task-completion dialogue policy learning via hierarchical deep reinforcement learning",
                "journal": "",
                "year": "2017",
                "authors": "Baolin Peng; Xiujun Li; Lihong Li; Jianfeng Gao; Asli Celikyilmaz; Sungjin Lee; Kam-Fai Wong"
            },
            {
                "ref_id": "b20",
                "title": "Few-shot natural language generation for taskoriented dialog",
                "journal": "",
                "year": "2002",
                "authors": "Baolin Peng; Chenguang Zhu; Chunyuan Li; Xiujun Li; Jinchao Li; Michael Zeng; Jianfeng Gao"
            },
            {
                "ref_id": "b21",
                "title": "Improving language understanding by generative pre-training",
                "journal": "",
                "year": "2018",
                "authors": "Alec Radford; Karthik Narasimhan"
            },
            {
                "ref_id": "b22",
                "title": "Language models are unsupervised multitask learners",
                "journal": "",
                "year": "2019",
                "authors": "Alec Radford; Jeff Wu; Rewon Child; David Luan; Dario Amodei; Ilya Sutskever"
            },
            {
                "ref_id": "b23",
                "title": "Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter",
                "journal": "",
                "year": "2020",
                "authors": "Victor Sanh; Lysandre Debut; Julien Chaumond; Thomas Wolf"
            },
            {
                "ref_id": "b24",
                "title": "Agenda-based user simulation for bootstrapping a POMDP dialogue system",
                "journal": "",
                "year": "2007",
                "authors": "Jost Schatzmann; Blaise Thomson; Karl Weilhammer; Hui Ye; Steve Young"
            },
            {
                "ref_id": "b25",
                "title": "The hidden agenda user simulation model",
                "journal": "IEEE Transactions on Audio, Speech, and Language Processing",
                "year": "2009",
                "authors": "Jost Schatzmann; Steve Young"
            },
            {
                "ref_id": "b26",
                "title": "How to build user simulators to train RL-based dialog systems",
                "journal": "Association for Computational Linguistics",
                "year": "1990",
                "authors": "Weiyan Shi; Kun Qian; Xuewei Wang; Zhou Yu"
            },
            {
                "ref_id": "b27",
                "title": "Multi-agent task-oriented dialog policy learning with role-aware reward decomposition",
                "journal": "Online. Association for Computational Linguistics",
                "year": "2020",
                "authors": "Ryuichi Takanobu; Runze Liang; Minlie Huang"
            },
            {
                "ref_id": "b28",
                "title": "Transferable dialogue systems and user simulators",
                "journal": "Online. Association for Computational Linguistics",
                "year": "2021",
                "authors": "Bo-Hsiang Tseng; Yinpei Dai; Florian Kreyssig; Bill Byrne"
            },
            {
                "ref_id": "b29",
                "title": "Semantically conditioned LSTM-based natural language generation for spoken dialogue systems",
                "journal": "",
                "year": "2015",
                "authors": "Milica Tsung-Hsien Wen; Nikola Ga\u0161i\u0107; Pei-Hao Mrk\u0161i\u0107; David Su; Steve Vandyke;  Young"
            },
            {
                "ref_id": "b30",
                "title": "A network-based end-to-end trainable task-oriented dialogue system",
                "journal": "Association for Computational Linguistics",
                "year": "2017",
                "authors": "David Tsung-Hsien Wen; Nikola Vandyke; Milica Mrk\u0161i\u0107; Lina M Ga\u0161i\u0107; Pei-Hao Rojas-Barahona; Stefan Su; Steve Ultes;  Young"
            },
            {
                "ref_id": "b31",
                "title": "",
                "journal": "",
                "year": "",
                "authors": " Sys-Agenr"
            },
            {
                "ref_id": "b32",
                "title": "",
                "journal": "System \\User AgenT AgenR AgenG RNNT RNNR RNN GPT GPTIL Avg.\u2191 Std.\u2193 Sys-RNNT",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b33",
                "title": "Did you discuss the experimental setup, including hyperparameter search and best-found hyperparameter values?",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b34",
                "title": "error bars around results, summary statistics from sets of experiments), and is it transparent whether you are reporting the max, mean, etc",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b35",
                "title": "for preprocessing, for normalization, or for evaluation",
                "journal": "",
                "year": "",
                "authors": " Nltk;  Spacy;  Rouge"
            },
            {
                "ref_id": "b36",
                "title": "crowdworkers) or research with human participants?",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b37",
                "title": "Did you report the full text of instructions given to participants, including e.g., screenshots, disclaimers of any risks to participants or annotators",
                "journal": "",
                "year": "",
                "authors": " D1"
            },
            {
                "ref_id": "b38",
                "title": "crowdsourcing platform, students) and paid participants, and discuss if such payment is adequate given the participants' demographic",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b39",
                "title": "Did you discuss whether and how consent was obtained from people whose data you're using/curating? For example, if you collected data via crowdsourcing, did your instructions to crowdworkers explain how the data would be used?",
                "journal": "",
                "year": "",
                "authors": " D3"
            },
            {
                "ref_id": "b40",
                "title": "Was the data collection protocol approved (or determined exempt) by an ethics review board?",
                "journal": "",
                "year": "",
                "authors": " D4"
            },
            {
                "ref_id": "b41",
                "title": "Did you report the basic demographic and geographic characteristics of the annotator population that is the source of the data?",
                "journal": "",
                "year": "",
                "authors": " D5"
            }
        ],
        "figures": [
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_0",
                "figure_caption": "(a) Success rates of different systems. (b) Dialog act distributions of different user simulators.",
                "figure_data": ""
            },
            {
                "figure_label": "1",
                "figure_type": "figure",
                "figure_id": "fig_1",
                "figure_caption": "Figure 1 :1Figure 1: (a) is the heat map on the success rates of system agents tested by different user simulators on 200 dialogues. (b) shows the dialog act distributions of Agenda-based User Simulators (ABUS) and Neural networksbased User Simulators (NUS) provided by Shi et al. (2019). There exist seven user dialog acts annotated in the restaurant search task from MultiWOZ, as shown on the Y-axis.",
                "figure_data": ""
            },
            {
                "figure_label": "2",
                "figure_type": "figure",
                "figure_id": "fig_2",
                "figure_caption": "Figure 2 :2Figure 2: The learning curves of Sys-MUST uniform and Sys-MUST adaptive . (a) shows their average success rates tested with all user simulators (AgenT, AgenR, RNNT, and GPT). The success rates of them tested with each user simulator are shown in (b)-(e).",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_3",
                "figure_caption": "(a) The sampling proportion of simulators. (b) Variations of the sampling proportions (in every 2000 steps) of simulators.",
                "figure_data": ""
            },
            {
                "figure_label": "3",
                "figure_type": "figure",
                "figure_id": "fig_4",
                "figure_caption": "Figure 3 :3Figure 3: The sampling proportions of user simulators in average (a) and in time horizon (b).",
                "figure_data": ""
            },
            {
                "figure_label": "2",
                "figure_type": "figure",
                "figure_id": "fig_5",
                "figure_caption": "Fig. 22Fig. 2(a), and Fig. 4(b), respectively).From Tab. 8 where MUST is trained with five user simulators, we could observe that Sys-MUST adaptive outperforms Sys-MUST uniform with 0.5 absolute point. The performance gain becomes smaller when MUST is trained with three user simulators (see Tab. 9). This probably shows that Sys-MUST adaptive would be more beneficial when there exist more user simulators.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_6",
                "figure_caption": "Figure 4: The learning curves of Sys-MUST uniform and Sys-MUST adaptive .",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_7",
                "figure_caption": "(a) Ablation study on the exploration term (b) Ablation study on the distribution p",
                "figure_data": ""
            },
            {
                "figure_label": "5",
                "figure_type": "figure",
                "figure_id": "fig_8",
                "figure_caption": "Figure 5 :5Figure 5: The learning curves of Sys-MUST uniform and Sys-MUST adaptive .",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_9",
                "figure_caption": "(a) The learning curves of the system trained with eight user simulators. (b) Comparison between different numbers of user simulators.",
                "figure_data": ""
            },
            {
                "figure_label": "6",
                "figure_type": "figure",
                "figure_id": "fig_10",
                "figure_caption": "Figure 6 :6Figure 6: The learning curves of Sys-MUST uniform and Sys-MUST adaptive .",
                "figure_data": ""
            },
            {
                "figure_label": "7",
                "figure_type": "figure",
                "figure_id": "fig_11",
                "figure_caption": "Fig. 77(b) shows an example of training sequence which consists of the concatenation x = [C 0 , C 1 ]. In order to leverage GPT, we need to convert the generated outputs {N i , G i , A i , U i } to sequences of tokens resembling a text. And we introduce delimiter tokens [eos_resp], [eos_nlu], [eos_goal],",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_12",
                "figure_caption": "The details of the first two-turn interactions between a system agent and our U-GPT. (b) An example of the model input for training U-GPT.",
                "figure_data": ""
            },
            {
                "figure_label": "7",
                "figure_type": "figure",
                "figure_id": "fig_14",
                "figure_caption": "Figure 7 :7Figure7: The overview of our U-GPT which consists of Natural Language Understanding (NLU), Goal Generator, Dialog Policy Learning (POL), and Natural Language Generation (NLG). It uses the auto-regressive language model GPT to understand the system inputs, generate the user actions and the user utterances given the dialogue context and the user goals sequentially in an end-to-end manner. (a) gives a detailed description of the first two-turn interactions between a system agent and our U-GPT. For training U-GPT, we need to convert the dialogue context and all annotations to sequences of tokens. (b) presents the training example of the first two-turn dialogues in (a).",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "table",
                "figure_id": "tab_2",
                "figure_caption": "Algorithm 1: Implement MUST adaptive with the modified UCB1 algorithm Input: K fixed User simulators U = {U1, U2, \u2022 \u2022 \u2022 UK } and the values of hyperparameters Twarmup, T, e, d, \u03c4 ; 1 Initialization: randomly initialize System agent S; 2 Initialization: initialize the simulator sampling distribution p as a uniform distribution. evaluate the performance i.e. the success rate xj of the agent S by letting it interact d times with the simulator Uj;",
                "figure_data": "3 (1) Warm-up phase: 4 for t = 0, ..., Twarmup \u2212 1 do 5 sample a simulator Uj in U w.r.t. the distribution p; 6 synthesize a new dialogue using the system agent S and the sampled Uj ; 7 use the reward obtained for the dialogue to update S with a RL algorithm;8 (2) Adaptive phase: 9 for t = 0, ..., T \u2212 1 do 10 if t%e == 0 then 11 for j = 1, ..., K do"
            },
            {
                "figure_label": "",
                "figure_type": "table",
                "figure_id": "tab_3",
                "figure_caption": "MUSTmerging 97.5 \u2191 0.0% 83.5 \u2193 7.2% 94.5 \u2193 4.6% 80.5\u2193 1.8% 97.5 94.0 82.5 91.3 6.4 90.0 6.9 Sys-MUST uniform 97.5 \u2191 0.0% 89.0 \u2193 1.0% 97.5\u2193 1.5% 82.5\u2191 0.5% 96.5 96.0 87.5 93.4 4.2 92.4 5.6 Sys-MUST adaptive 97.5 \u2191 0.0% 89.5 \u2193 0.5% 97.0\u2193 2.0% 82.5\u2191 0.5% 96.5",
                "figure_data": "Dialogue Systems single Sys-AgenT Sys-AgenR Sys-RNNT Sys-GPT MUST Sys-In-domain evaluation AgenR RNNT 54.0 \u2193 40.0% 98.5 \u2193 0.5% 78.0\u2193 4.9% 72.5 Out-of-domain evaluation GPT AgenG RNNR RNN Avg.\u2191 Std.\u2193 Avg.\u2191 Std.\u2193 All 92.5 77.0 80.7 8.6 81.4 14.8 96.0 \u2193 1.5% 90.0 AgenT 97.5 98.5\u2193 0.5% 80.5\u2193 1.8% 97.5 97.5 82.0 92.3 7.3 91.7 7.1 30.5 \u2193 68.7% 23.0 \u2193 74.4% 99.0 75.5\u2193 7.9% 35.5 97.5 84.0 72.3 26.6 63.6 30.5 60.5 \u2193 37.9% 51.5 \u2193 42.8% 97.0 \u2193 2.0% 82.0 59.5 94.0 92.0 81.8 15.8 76.6 17.6"
            },
            {
                "figure_label": "3",
                "figure_type": "table",
                "figure_id": "tab_4",
                "figure_caption": "Human evaluation.",
                "figure_data": "Dialogue Systems single Sys-AgenT Sys-AgenR Sys-RNNT Sys-GPT MUST Sys-MUSTmerging Sys-MUST uniform Sys-MUST adaptive 92.0 human evaluation 76.0 84.0 34.0 58.0 90.0 92.0"
            },
            {
                "figure_label": "",
                "figure_type": "table",
                "figure_id": "tab_5",
                "figure_caption": "are no ethics-related issues in this paper. The data and other related resources in this work are open-source and commonly-used by many existing work.",
                "figure_data": "Jason Williams, Antoine Raux, Deepak Ramachandran, and Alan Black. 2013. The dialog state tracking challenge. In Proceedings of the SIGDIAL 2013 Con-ference, pages 404-413, Metz, France. Association for Computational Linguistics.Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pier-ric Cistac, Tim Rault, Remi Louf, Morgan Funtow-icz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander Rush. 2020. Trans-formers: State-of-the-art natural language processing. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 38-45, Online. Association for Computational Linguistics.Yizhe Zhang, Michel Galley, Jianfeng Gao, Zhe Gan, Xiujun Li, Chris Brockett, and Bill Dolan. 2018. Generating informative and diverse conversational responses via adversarial information maximization. In NeurIPS."
            },
            {
                "figure_label": "4",
                "figure_type": "table",
                "figure_id": "tab_6",
                "figure_caption": "Shi et al., 2019) RNN \u2020 Agenda Template AgenR(Shi et al., 2019) RNN \u2020 Agenda Retrieval AgenG(Shi et al., 2019) RNN \u2020 Agenda RNN \u2020 (Generation) RNNT(Shi et al., 2019) The architectures of user simulators and dialogue systems. Modules with \u2020 are trainable.",
                "figure_data": "Agent TypesAgentsNLU DMNLGUser Simulators Dialogue Systems All AgenT (RNN  \u2020 RNNR (Shi et al., 2019) RNN  \u2020 RNN (Shi et al., 2019) RNN  \u2020 (NLU + NLG) Template Retrieval GPT (ours) Transformer  \u2020 (NLU + DM + NLG) GPTIL (ours) Transformer  \u2020 (NLU + DM + NLG) RNN  \u2020 RNN  \u2020 TemplateHyperparameterValueT100,000T 040,000e2,000d200\u03c40.75"
            },
            {
                "figure_label": "5",
                "figure_type": "table",
                "figure_id": "tab_7",
                "figure_caption": "The hyperparameters used for training the Sys-MUST adaptive .",
                "figure_data": ""
            },
            {
                "figure_label": "6",
                "figure_type": "table",
                "figure_id": "tab_9",
                "figure_caption": "The relationships between user acts and system acts.",
                "figure_data": "Dialogue Systems"
            },
            {
                "figure_label": "7",
                "figure_type": "table",
                "figure_id": "tab_10",
                "figure_caption": "The experimental results of implementing MUST with the MUST CRL strategy.",
                "figure_data": ""
            },
            {
                "figure_label": "8",
                "figure_type": "table",
                "figure_id": "tab_11",
                "figure_caption": "Ablation study on MUST. It uses five user simulators (AgenT, AgenR, RNNT, RNNR and GPT simulator) to implement MUST uniform and MUST adaptive .",
                "figure_data": "Dialogue Systems single Sys-AgenT Sys-RNNT Sys-GPT MUST Sys-MUST uniform 97.5\u2191 0.0% 96.0\u2193 3.0% 82.5\u2191 0.6% 55.0 In-domain evaluation AgenT RNNT GPT AgenR AgenG RNNR RNN Avg.\u2191 Std.\u2193 Avg.\u2191 Std.\u2193 Out-of-domain evaluation All 97.5 98.5\u2193 0.5% 78.0 \u2193 0.5% 54.0 72.5 92.5 77.0 74.0 13.7 81.4 14.8 30.5 \u2193 68.7% 99.0 75.5\u2193 7.9% 23.0 35.5 97.5 84.0 60.0 31.4 63.6 30.5 60.5 \u2193 37.9% 97.0 \u2193 2.0% 82.0 51.5 59.5 94.0 92.0 74.3 19.0 76.6 17.6 82.0 97.5 87.0 80.3 15.7 85.4 13.9 Sys-MUST adaptive 97.5\u2191 0.0% 97.5\u2193 1.5% 82.5\u2191 0.6% 55.5 80.5 97.0 87.0 80.0 15.3 85.4 13.9"
            },
            {
                "figure_label": "9",
                "figure_type": "table",
                "figure_id": "tab_12",
                "figure_caption": "Ablation study on MUST. It uses three user simulators (AgenT, RNNT, and GPT simulator) to implement MUST uniform and MUST adaptive .",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "table",
                "figure_id": "tab_13",
                "figure_caption": "hello! what can i help you? <eos_resp> [eos_constraint] [eos_book] [eos_recommend] [eos_select] [eos_request] <eos_nlu> [info] food venetian pricerange expensive area centre [request] [book] time 12:00 day wednesday people 4 <eos_goal> [inform_type] food area <eos_pol> i am looking at a place to eat that serves venetian food in the centre. <eos_utt> unfortunately, i do not see any restaurants that serve venetian in the centre of town. would you like to try a different area or type of cuisine? <eos_resp> nooffer [eos_constraint] [eos_book] [eos_recommend] [eos_select] [eos_request] <eos_nlu> [info] food chinese pricerange expensive area centre [request] [book] time 12:00 day wednesday people 4 <eos_goal> [inform_type_change] food <eos_pol> Do you have any [value_food] restaurants ? <eos_utt> Hello! What can I help you? constraint: [], book: [], recommend: [], select: [], request: [] inform_type: [food, area] I am looking at a place to eat that serves [value_food] food in the [value_area] . I am looking at a place to eat that serves Venetian food in the centre. Unfortunately, I don't see any restaurants that serve Venetian in the centre of town. Would you like to try a different area or type of cuisine?",
                "figure_data": "constraint: [nooffer], book: [],recommend: [], select: [], request: []inform_type_change: [food]Do you have any [value_food] restaurants ?Yes there are 10 in the centre of town. Any price preference?Do you have any Chinese restaurants?"
            },
            {
                "figure_label": "11",
                "figure_type": "table",
                "figure_id": "tab_14",
                "figure_caption": "Cross study results. Each entry shows the success rate obtained by having the user simulator interacting with the RL system for 200 times.",
                "figure_data": "User Simulators Utt \u2191 Vocab \u2191 DIST-1 \u2191 DIST-2 \u2191 ENT-4 \u2191 RNNT 9.83 192 0.77% 1.51% 4.24 RNNR 11.06 346 2.45% 9.59% 6.59 RNN 10.95 205 1.17% 3.14% 4.98 GPT-RNN 14.00 262 1.13% 3.53% 5.62"
            },
            {
                "figure_label": "12",
                "figure_type": "table",
                "figure_id": "tab_15",
                "figure_caption": "Automatic evaluation results of RNNT, RNNR and GPT-RNN. The metrics include average utterance length (Utt), vocabulary size (Vocab), distinct-n (DISTn) and entropy (ENT-n).",
                "figure_data": "RNNT RNNR RNN GPT-RNN4.60 3.92 2.80 4.104.68 3.88 2.30 4.044.96 4.72 2.86 4.303.34 3.94 2.74 3.704.70 4.16 2.30 4.00"
            },
            {
                "figure_label": "13",
                "figure_type": "table",
                "figure_id": "tab_16",
                "figure_caption": "Human evaluation results of RNNT, RNNR and GPT-RNN. The metrics include sentence fluency (Hu.Fl), coherence (Hu.Co), goal adherence (Hu.Go), language diversity (Hu.Div) and an overall score (Hu.All).",
                "figure_data": ""
            }
        ],
        "formulas": [
            {
                "formula_id": "formula_0",
                "formula_text": "T t=1 E[x it ] = T t=1 \u00b5 it .",
                "formula_coordinates": [
                    4.0,
                    370.06,
                    421.09,
                    91.39,
                    34.56
                ]
            },
            {
                "formula_id": "formula_1",
                "formula_text": "it = arg maxi xi + 2 ln t T i,t from t = K + 1 to T .",
                "formula_coordinates": [
                    5.0,
                    70.86,
                    761.87,
                    194.78,
                    13.83
                ]
            },
            {
                "formula_id": "formula_2",
                "formula_text": "xj = xj exploitation + 2 ln t Tj,t exploration , j \u2208 {1, ..., K}; (2)",
                "formula_coordinates": [
                    5.0,
                    318.68,
                    425.12,
                    206.47,
                    39.8
                ]
            },
            {
                "formula_id": "formula_3",
                "formula_text": "zj = 1/ (xj \u2212 \u03c4 min({x1, \u2022 \u2022 \u2022 , xK })) ,(3)",
                "formula_coordinates": [
                    5.0,
                    342.83,
                    528.48,
                    182.19,
                    16.88
                ]
            },
            {
                "formula_id": "formula_4",
                "formula_text": "p j = z j K i=1 z i .(4)",
                "formula_coordinates": [
                    5.0,
                    381.84,
                    630.97,
                    143.32,
                    30.12
                ]
            },
            {
                "formula_id": "formula_5",
                "formula_text": "xj = xj exploitation + 2 ln t T j,t exploration , j \u2208 {1, ..., K}; z j = 1/ (x j \u2212 \u03c4 min({x 1 , \u2022 \u2022 \u2022 , xK })) , p i = z j K j=1 z j .(5)",
                "formula_coordinates": [
                    14.0,
                    318.67,
                    448.15,
                    206.49,
                    94.24
                ]
            },
            {
                "formula_id": "formula_6",
                "formula_text": "MUST adaptive xj = xj + 2 ln t T j,t zj = 1 (xj\u2212\u03c4 min({x 1 ,\u2022\u2022\u2022 ,x K })) pj = z j K i=1 z i w/t exploration zj = 1 xj MUST adaptive -I xj = 1 xj + 2 ln t T j,t zj = xj \u2212 \u03c4 min({1/x1, \u2022 \u2022 \u2022 , 1/xK }) MUST adaptive -II xj = 1/x j K i=1 1/x i zj = \u1e91j \u2212 \u03c4 min({x1, \u2022 \u2022 \u2022 , xK }) \u1e91j = xj + 2 ln t T j,t MUST adaptive -III xj = 1 (x j \u2212\u03c4 min({x 1 ,\u2022\u2022\u2022 ,x K })) zj = xj K i=1 xi + 2 ln t T j,t",
                "formula_coordinates": [
                    16.0,
                    95.86,
                    92.44,
                    401.87,
                    107.56
                ]
            },
            {
                "formula_id": "formula_7",
                "formula_text": "C i = [S i , N i , G i , A i , U i ].",
                "formula_coordinates": [
                    17.0,
                    93.88,
                    557.03,
                    114.77,
                    11.81
                ]
            },
            {
                "formula_id": "formula_8",
                "formula_text": "L(U ) = i log P (u i |u i\u2212k , ..., u i\u22121 ; \u0398), \u2200 u i \u2208 {S 0 , N 0 , G 0 , A 0 , U 0 , ..., A t , U t },",
                "formula_coordinates": [
                    17.0,
                    315.07,
                    262.58,
                    180.5,
                    45.27
                ]
            }
        ],
        "doi": "10.18653/v1/D18-1547"
    },
    "Span-Selective Linear Attention Transformers for Effective and Robust Schema-Guided Dialogue State Tracking": {
        "authors": "Bj\u00f6rn Bebensee; Haejun Lee",
        "pub_date": "",
        "abstract": "In schema-guided dialogue state tracking models estimate the current state of a conversation using natural language descriptions of the service schema for generalization to unseen services. Prior generative approaches which decode slot values sequentially do not generalize well to variations in schema, while discriminative approaches separately encode history and schema and fail to account for inter-slot and intent-slot dependencies. We introduce SPLAT, a novel architecture which achieves better generalization and efficiency than prior approaches by constraining outputs to a limited prediction space. At the same time, our model allows for rich attention among descriptions and history while keeping computation costs constrained by incorporating linear-time attention. We demonstrate the effectiveness of our model on the Schema-Guided Dialogue (SGD) and Mul-tiWOZ datasets. Our approach significantly improves upon existing models achieving 85.3 JGA on the SGD dataset. Further, we show increased robustness on the SGD-X benchmark: our model outperforms the more than 30\u00d7 larger D3ST-XXL model by 5.0 points.",
        "sections": [
            {
                "heading": "Introduction",
                "text": [
                    "Dialogue State Tracking (DST) refers to the task of estimating and tracking the dialogue state consisting of the user's current intent and set of slotvalue pairs throughout the dialogue (Williams et al., 2013). Traditional approaches to DST assume a fixed ontology and learn a classifier for each slot (Chao and Lane, 2019). However, in real-world applications services can be added or removed requiring the model to be re-trained each time the ontology changes. Recently more flexible schemaguided approaches which take as input natural language descriptions of all available intents and slots and thus can be applied zero-shot to new services have been gaining popularity (Rastogi et al., 2020;Feng et al., 2021;Zhao et al., 2022;Gupta et al., 2022). Discriminative DST models are based on machine reading comprehension (MRC) methods, meaning they extract and fill in non-categorical slot values directly from the user utterances (Chao and Lane, 2019;Ruan et al., 2020;Zhang et al., 2021). We use the terms discriminative and extractive interchangeably when referring to these methods. Generative DST models leverage seq2seq language models which conditioned on the dialog history and a prompt learn to sequentially generate the appropriate slot values. Prior generative methods do not generalize well to variations in schema (Lee et al., 2021(Lee et al., , 2022;;Zhao et al., 2022) whereas discriminative methods separately encode history and schema and fail to account for inter-slot and intent-slot dependencies.",
                    "In this work we introduce the SPan-Selective Linear Attention Transformer, short SPLAT, a novel architecture designed to achieve better generalization, robustness and efficiency in DST than existing approaches. SPLAT is fully extractive and, unlike prior generative approaches, constrains the output space to only those values contained in the input sequence. Figure 1 shows an example i and intent representations h [INTENT]   k . A span encoder computes span representations h SPAN mn for all spans x m , . . . , x n . The target span is selected by matching the slot query h [SLOT]   q to the target span h SPAN ij .",
                    "of the key idea behind our approach. We jointly encode the natural language schema and full dialogue history allowing for a more expressive contextualization. Spans in the input are represented by aggregating semantics of each individual span into a single representation vector. Then we take a contrastive query-based pointer network approach (Vinyals et al., 2015) to match special query tokens to the target slot value's learned span representation in a single pass.",
                    "Our main contributions are as follows:",
                    "\u2022 We propose novel span-selective prediction layers for DST which provide better generalization and efficiency by limiting the prediction space and inferring all predictions in parallel. We achieve state-of-the-art performance on the SGD-X benchmark outperforming the 30\u00d7 larger D3ST by 5.0 points.",
                    "\u2022 We adopt a Linear Attention Transformer which allows more expressive contextualization of the dialogue schema and dialogue history with constrained prediction time. We show our model already outperforms other models with similar parameter budgets even without other modules we propose in Table 1 and 5.",
                    "\u2022 We pre-train SPLAT for better span representations with a recurrent span selection objective yielding significant further span prediction performance gains of up to 1.5 points."
                ],
                "publication_ref": [
                    "b24",
                    "b2",
                    "b5",
                    "b2",
                    "b11",
                    "b22"
                ],
                "figure_ref": [
                    "fig_0"
                ],
                "table_ref": [
                    "tab_0"
                ]
            },
            {
                "heading": "Approach",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Task Formulation",
                "text": [
                    "For a given dialog of T turns let U describe the set of utterances in the dialog history U = {u 1 , . . . , u T }. Each u i can represent either a user or a system utterance. The system is providing some service to the user defined by a service schema S. The service schema consists of a set of intents I = {i 1 , . . . , i K } and their intent descriptions D intent = {d intent 1 , . . . , d intent K } as well as a set of slots S = {s 1 , . . . , s L } and their slot descriptions D slot = {d slot 1 , . . . , d slot L }. In practice we prepend each u i with the speaker name (user or system) and a special utterance query token [UTT] which will serve as the encoding of the system-user utterance pair.",
                    "Each d slot i consists of the slot name, a natural language description of the semantics of the slot and for categorical values an enumeration of all possible values this slot can assume. We also append a special slot query embedding token [SLOT] which serves as the slot encoding. Some slot values are shared across all slots and their representation can be modeled jointly. Unless denoted otherwise these shared target values T are special tokens [NONE] and [DONTCARE] which correspond to the \"none\" and \"dontcare\" slot values in SGD and MultiWOZ."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Joint Encoding with Linear Attention",
                "text": [
                    "Linear Attention Transformers. In order to better capture the semantics of the input and to al-low for a longer context as well as all the relevant schema descriptions to be encoded jointly we use a Transformer (Vaswani et al., 2017) with linear-time attention. Instead of computing the full attention matrix as the original Transformer does, its linear attention variants compute either an approximation of it (Choromanski et al., 2021) or only compute full attention for a fixed context window of size w around the current token and additional n global global tokens, thus lowering the complexity of the attention computation from O(n 2 ) for a sequence of length n to O(w + n global ) (Beltagy et al., 2020;Zaheer et al., 2020).",
                    "We focus on the windowed variant and incorporate it to DST. We denote the Linear Attention Transformer with selective global attention parametrized by \u03b8 with input sequence I and its subset of global input tokens G \u2286 I, i.e. inputs corresponding to tokens at positions that are attended using the global attention mechanism, as LAT(I; G; \u03b8). While we choose the Longformer (Beltagy et al., 2020) for our implementation, in practice any variants with windowed and global attention can be used instead.",
                    "Joint encoding. The full input sequence of length N is given as the concatenation of its components. We define the set of globally-attended tokens as the union of sets of tokens corresponding to the intent descriptions D intent , the slot descriptions D slot , and the shared target values T . Then, the joint encoding of N hidden states is obtained as the output of the last Transformer layer as",
                    "I = [CLS] U [SEP] T D intent D slot [SEP] G = T \u222a D intent \u222a D slot E = LAT(I; G; \u03b8).",
                    "(1)"
                ],
                "publication_ref": [
                    "b21",
                    "b3",
                    "b0",
                    "b28",
                    "b0"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Intent Classification",
                "text": [
                    "Let x [UTT]   i denote the representation of the encoded [UTT] token corresponding to the i-th turn. Given the encoded sequence E, we obtain the final utterance representations by feeding x [UTT]   i into the utterance encoder. Similarly for each intent I = {i 1 , . . . , i t } and its respective [INTENT] token, we obtain final intent representations using the intent encoder:",
                    "h [UTT] i = LN(FFN(x [UTT] i )) h [INTENT] j = LN(FFN(x [INTENT] j ))(2)",
                    "Here LN refers to a LayerNorm and FFN to a feedforward network.",
                    "We maximize the dot product similarity between each utterance representation and the ground truth active intent's representation via cross-entropy:",
                    "score i\u2192j = sim(h [UTT] i , h [INTENT] j ) L intent = \u2212 1 T T i=1 log exp(score i\u2192j ) K k=1 exp(score i\u2192k ) \u2022 1 GT (3)",
                    "where K is the number of intents and 1 GT is an indicator function which equals 1 if and only if j is the ground truth matching i."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Span Pointer Module",
                "text": [
                    "We introduce a novel Span Pointer Module which computes span representations via a span encoder and extracts slot values by matching slot queries via a similarity-based span pointing mechanism (Vinyals et al., 2015). First, for any given span of token representations x i , . . . , x j in the joint encoding E we obtain the span representation h SPAN ij by concatenating the span's first and last token representation and feeding them into a 2-layer feed-forward span encoder (Joshi et al., 2020):",
                    "y ij = [x i ; x j ] h SPAN ij = LN(FFN GeLU (y ij )) \u00d7 n_layers (4)",
                    "Similarly, for each slot token representation x [SLOT] in E we compute a slot query representation h [SLOT] with a 2-layer feed-forward slot encoder:",
                    "h [SLOT] = LN(FFN GeLU (x [SLOT] )) \u00d7 n_layers",
                    "(5) Given slots S = {s 1 , . . . , s L } and corresponding slot query representations h [SLOT]  1 , . . . , h [SLOT]   L we score candidate target spans by dot product similarity of the slot queries with their span representations. That is, for each slot query q with ground truth target span x i , . . . , x j we maximize sim(h [SLOT]   q , h SPAN ij ) by cross-entropy. The loss function is given by",
                    "score q\u2192ij = sim(h [SLOT] q , h SPAN ij ) L slot = \u2212 1 L L q=1 log exp(score q\u2192ij ) K k=1 exp(score q\u2192k ) \u2022 1 GT (6)",
                    "where L is the number of slots and K is the number of spans. sim(h [SLOT]   q , h SPAN ij ) denotes the similarity between the q-th slot query representation and the span representation of its ground truth slot value.",
                    "It is computationally too expensive to compute span representations for all possible spans. In practice however the length of slot values rarely exceeds some L ans . Thus, we limit the maximum span length to L ans and do not compute scores for spans longer than this threshold. This gives us a total number of N \u2022 L ans candidate spans.",
                    "Joint optimization. We optimize the intent and slot losses jointly via the following objective:",
                    "L = L slot + L intent 2 (7)"
                ],
                "publication_ref": [
                    "b22",
                    "b8"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Pre-Training via Recurrent Span Selection",
                "text": [
                    "Since the span pointer module relies on span embedding similarity for slot classification we believe it is crucial to learn good and robust span representations. In order to improve span representations for down-stream applications to DST we pre-train SPLAT in a self-supervised manner using a modified recurrent span selection objective (Ram et al., 2021). Given an input text I let R = {R 1 , . . . , R a } be the clusters of identical spans that occur more than once. Following Ram et al. (2021) we randomly select a subset M \u2286 R of J recurring spans such that the number of their occurrences sums up to a maximum of 30 occurrences. Then, for each selected cluster of recurring spans M j we randomly replace all but one occurrence with the query token [SLOT].",
                    "The slot query tokens act as the queries while the respective unmasked span occurrences act as the targets. Unlike the original recurrent span selection objective we do not use separate start and end pointers for the target spans but instead use our Span Pointer Module to learn a single representation for each target span.",
                    "We pre-train SPLAT to maximize the dot product similarity between the query token and the unmasked target span representation. The loss for the j-th cluster of identical masked spans is given by Equation ( 6) and the total loss is given as the sum of losses of over all clusters.",
                    "Effectively each sentence containing a masked occurrence of the span acts as the span description while the target span acts as the span value. This can be seen as analogous to slot descriptions and slot values in DST."
                ],
                "publication_ref": [
                    "b17",
                    "b17"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Experimental Setup",
                "text": [
                    "We describe our experimental setup including datasets used for pre-training and evaluation, implementation details, baselines and evaluation metrics in detail below."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Benchmark Datasets",
                "text": [
                    "We conduct experiments on the Schema-Guided Dialogue (SGD) (Rastogi et al., 2020), SGD-X (Lee et al., 2022) and MultiWOZ 2.2 (Zang et al., 2020) datasets.",
                    "Schema-Guided Dialogue. Unlike other taskoriented dialogue datasets which assume a single, fixed ontology at training and test time the SGD dataset includes new and unseen slots and services in the test set. This allows us to not only measure DST performance but also zero-shot generalization to unseen services. The dataset includes natural language descriptions for all intents and slots in its schema. We follow the standard evaluation setting and data split suggested by the authors. SGD-X. The SGD-X benchmark is an extension of the SGD dataset which provides five additional schema variants of different linguistic styles which increasingly diverge in style from the original schema with v 1 being most similar and v 5 least similar. We can evaluate our model's robustness to variations in schema descriptions by training our model on SGD and comparing evaluation results using the different included schema variants.",
                    "MultiWOZ. The MultiWOZ dataset is set of human-human dialogues collected in the Wizardof-OZ setup. Unlike in SGD the ontology is fixed and there are no unseen services at test time. There are multiple updated versions of the original Mul-tiWOZ dataset (Budzianowski et al., 2018): Mul-tiWOZ 2.1 (Eric et al., 2020) and MultiWOZ 2.2 (Zang et al., 2020) fix annotation errors of previous versions, MultiWOZ 2.3 (Han et al., 2021) is based on version 2.1 and adds co-reference annotations, MultiWOZ 2.4 (Ye et al., 2022) is also based on version 2.1 and includes test set corrections. However, MultiWOZ 2.2 is the only version of the dataset which includes a fully defined schema matching the ontology. We therefore choose the MultiWOZ 2.2 dataset for our experiments. We follow the standard evaluation setting and data split."
                ],
                "publication_ref": [
                    "b1",
                    "b4",
                    "b7",
                    "b27"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Evaluation Metrics",
                "text": [
                    "In line with prior work (Rastogi et al., 2020) we evaluate our approach according to the following two metrics. Intent Accuracy: For intent detection the intent accuracy describes the fraction of turns for which the active intent has been correctly inferred. Joint Goal Accuracy (JGA): For slot prediction JGA describes the fraction of turns for which all slot values have been predicted correctly. Following the evaluation setting from each dataset we use a fuzzy matching score for slot values in SGD and exact match in MultiWOZ."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Implementation Details",
                "text": [
                    "We base our implementation on the Longformer code included in the HuggingFace Transformers library (Wolf et al., 2020) and continue training from the base model (110M parameters) and large model (340M parameters) checkpoints. We keep the default Longformer hyperparameters in place, in particular we keep the attention window size set to 512. The maximum sequence length is 4096. During pre-training we train the base model for a total of 850k training steps and the large model for 800k training steps. During fine-tuning we train all models for a single run of 10 epochs and choose the model with the highest joint goal accuracy on the development set. We use the Adam optimizer (Kingma and Ba, 2014) with a maximum learning rate of 10 \u22125 which is warmed up for the first 10% of steps and subsequently decays linearly. We set the batch size to 32 for base models and to 16 for large models. We pre-train SPLAT on English Wikipedia. Specifically we use the KILT Wikipedia snapshot 1 from 2019 (Petroni et al., 2021) as provided by the HuggingFace Datasets library (Lhoest et al., 2021).",
                    "For both SGD and MultiWOZ we set the shared target values T as the [NONE] and [DONTCARE] tokens and include a special intent with the name \"NONE\" for each service which is used as the target intent when no other intent is active. We set the maximum answer length L ans to 30 tokens.",
                    "All experiments are conducted on a machine with eight A100 80GB GPUs. A single training run takes around 12 hours for the base model and 1.5 days for the large model.",
                    "1 https://huggingface.co/datasets/kilt_ wikipedia"
                ],
                "publication_ref": [
                    "b25",
                    "b16",
                    "b13"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Evaluation",
                "text": [
                    "We evaluate the effectiveness of our model through a series of experiments designed to answer the following questions: 1) How effective is the proposed model architecture at DST in general? 2) Does the model generalize well to unseen services? 3) Is the model robust to changes in schema such as different slot names and descriptions? 4) Which parts of the model contribute most to its performance?"
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Baselines",
                "text": [
                    "We compare our model to various discriminative and generative baseline approaches. Note that not all of them are directly comparable due to differences in their experimental setups.",
                    "Extractive baselines. SGD baseline (Rastogi et al., 2020) is a simple extractive BERT-based model which encodes the schema and last utterance separately and uses the embeddings in downstream classifiers to predict relative slot updates for the current turn. SGP-DST (Ruan et al., 2020) and DS-DST (Zhang et al., 2020) are similar but jointly encode utterance and slot schema. Multi-Task BERT (Kapelonis et al., 2022) is also similar but uses system action annotations which include annotations of slots offered or requested by the system (e.g."
                ],
                "publication_ref": [
                    "b9"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "\"[ACTION] Offer [SLOT] location [VALUE]",
                "text": [
                    "Fremont\"). paDST (Ma et al., 2019) combines an extractive component for non-categorical slots with a classifier that uses 83 hand-crafted features (including system action annotations) for categorical slots. Additionally it augments training data via back-translation achieving strong results but making a direct comparison difficult. LUNA (Wang et al., 2022) separately encodes dialogue history, slots and slot values and learns to first predict the correct utterance to condition the slot value prediction on.",
                    "Generative baselines. Seq2Seq-DU (Feng et al., 2021) first separately encodes utterance and schema and then conditions the decoder on the cross-attended utterance and schema embeddings. The decoder generates a state representation consisting of pointers to schema elements and utterance tokens. AG-DST (Tian et al., 2021) (Feng et al., 2021) BERT-base (110M) \u2713 90.9 54.4 LUNA (Wang et al., 2022) BERT-base (110M) \u2717 -56.1 AG-DST (Tian et al., 2021) GPT-2 (117M) \u2717 \u2021 -56.1 AG-DST (Tian et al., 2021) PLATO-2 (310M) \u2717 \u2021 -57.3 DaP (seq) (Lee et al., 2021) T5-base (220M) \u2713 -51.2 DaP (ind) (Lee et al., 2021) T5-base (220M) \u2717 -57.5 D3ST (Base) (Zhao et al., 2022) T5-base (220M) \u2713 -56.1 D3ST (Large) (Zhao et al., 2022) T5-large (770M) \u2713 -54.2 D3ST (XXL) (Zhao et al., 2022) T5-XXL (  (Zang et al., 2020). \u2021: AG-DST uses a fixed two-pass generation procedure.",
                    "itly so it is unclear how well AG-DST transfers to new services. DaP (Lee et al., 2021) comes in two variants which we denote as DaP (seq) and DaP (ind). DaP (ind) takes as input the entire dialogue history and an individual slot description and decodes the inferred slot value directly but requires one inference pass for each slot in the schema. DaP (seq) instead takes as input the dialogue history and the sequence of all slot descriptions and decodes all inferred slot values in a single pass. D3ST (Zhao et al., 2022) takes a similar approach and decodes the entire dialogue state including the active intent in a single pass. Categorical slot values are predicted via an index-picking mechanism."
                ],
                "publication_ref": [
                    "b15",
                    "b23",
                    "b5",
                    "b20",
                    "b5",
                    "b23",
                    "b20",
                    "b20",
                    "b11",
                    "b11",
                    "b11"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Main Results",
                "text": [
                    "Schema-Guided Dialogue. more than 30\u00d7 larger D3ST XXL model. We note that although paDST achieves the best performance of all baseline models in terms of JGA, it is not directly comparable because it is trained with hand-crafted features and additional back-translation data for training which has been shown to significantly improve robustness and generalization to unseen descriptions in schema-guided DST (Lee et al., 2022). Similarly, although Multi-Task BERT achieves good performance this can mostly be attributed to the use of system action annotation as Kapelonis et al. (2022) themselves demonstrate. Without system action annotations its performance drops to 71.9 JGA.",
                    "In terms of intent accuracy SPLAT base slightly underperforms D3ST base and D3ST large by 0.5 and 0.4 JGA while SPLAT large achieves better performance and slightly improves upon the D3ST large performance. Overall, SPLAT achieves strong performance on SGD.",
                    "MultiWOZ. Table 2 shows results on the Multi-WOZ 2.2 test set. As the majority of papers does not report intent accuracy on MultiWOZ 2.2 we focus our analysis on JGA. We find that SPLAT base outperforms most similarly-sized models including D3ST base and large and that SPLAT large performs better than all models aside from the more than 30\u00d7 larger D3ST XXL. The notable exceptions to this are AG-DST and DaP (ind). AG-DST large achieves performance that is similar to SPLAT large using a generative approach but it performs two decoding passes, employs a negative sampling strategy to focus on more difficult examples and is trained for a fixed schema. DaP (ind) also achieves similar performance but needs one inference pass for every slot at every turn of the dialogue. This is much slower and simply not realistic in real-world scenarios with a large number of available services and slots. The sequential variant DaP (seq) which instead outputs the full state in a single pass performs much worse.",
                    "Comparison. While DaP (ind) shows strong performance that matches SPLAT on MultiWOZ, SPLAT fares much better than DaP (ind) on the SGD dataset. This can be seen to be indicative of a stronger generalization ability as MultiWOZ uses the same schema at training and test time whereas SGD includes new, unseen services at test time and thus requires the model to generalize and understand the natural language schema descriptions."
                ],
                "publication_ref": [
                    "b9"
                ],
                "figure_ref": [],
                "table_ref": [
                    "tab_1"
                ]
            },
            {
                "heading": "Robustness",
                "text": [
                    "DST models which take natural language descriptions of intents and slots as input naturally may be sensitive to changes in these descriptions. In order to evaluate the robustness of our model to such linguistic variations we perform experiments on the SGD-X benchmark. The SGD-X benchmark comes with five crowd-sourced schema variants v 1 to v 5 which increasingly diverge in style from the original schema. We train SPLAT on SGD and evaluate it on the test set using all five different schema variants.",
                    "As shown in baseline models. On average SPLAT base loses around 4.1 points and SPLAT large loses around 2.5 points joint goal accuracy when compared to the results on the original schema. When considering the mean performance across all unseen schema variants SPLAT large significantly outperforms the more than 30\u00d7 larger D3ST XXL by 5.0 points. These observations also hold for the base model: the 110M parameter SPLAT base even outperforms the 11B parameter D3ST XXL on the least similar schema variant v 5 further highlighting the superior robustness of our model."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Generalization to unseen domains",
                "text": [
                    "In real-world scenarios virtual assistants cover a wide range of services that can change over time as new services get added or removed requiring dialogue models to be re-trained. One of our goals is to improve generalization to unseen services thus minimizing the need for expensive data collection and frequent re-training. As the MultiWOZ dataset does not include any new and unseen services in its test set our analysis primarily focuses on the SGD dataset. Table 4 shows results on SGD with a separate evaluation for dialogues in seen and unseen domains. We find that SPLAT achieves better generalization and improves upon the baselines with a particularly large margin on unseen domains where SPLAT base outperforms D3ST base by 8.8 points and SPLAT base outperforms D3ST large by 6.8 points."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_4"
                ]
            },
            {
                "heading": "Ablation Study",
                "text": [
                    "We conduct an ablation study to identify the contribution of the different components to model performance. Results can be seen in "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Related Work",
                "text": [
                    "Extractive DST. Following the traditional extractive setting Chao and Lane (2019) propose a machine reading comprehension (MRC) approach which decodes slot values turn-by-turn using a different learned classifier for each slot. As a classifier has to be learned for each new slot this approach cannot easily be transferred to new slots. Schema-guided approaches address this by explicitly conditioning predictions on a variable schema which describes intents and slots in natural language (Rastogi et al., 2020). Both Ruan et al. (2020) and Zhang et al. (2021) introduce schema-guided models but predict slots independently from one another requiring multiple encoder passes for each turn and failing to model intent-slot and inter-slot dependencies. Ma et al. (2019) use MRC for non-categorical and handcrafted features for categorical slots.",
                    "Generative DST. In an attempt to address the lack of ability to generalize to new domains and ontologies, Wu et al. (2019) propose incorporating a generative component into DST. Based on the dialog history and a domain-slot pair a state generator decodes a value for each slot. However as each slot is decoded independently the approach cannot model slot interdependencies. Feng et al. (2021) instead generate the entire state as a single sequence of pointers to the dialogue history and input schema but separately encode history and schema. Zhao et al. (2021) model DST fully as a text-to-text problem and directly generate the entire current state as a string. Lin et al. (2021) transfer a language model fine-tuned for seq2seq question answering to DST zero-shot using the dialog history as context and simply asking the model for the slot values. By also including a natural language schema in the input, Zhao et al. (2022) show that full joint modeling and rich attention between history and schema lead to better results in DST. Furthermore, they demonstrate the flexibility of this fully language driven paradigm by leveraging strong pre-trained language models for cross-domain zero-shot transfer to unseen domains. Gupta et al. (2022) show the effectiveness of using demonstrations of slots being used in practice instead of a natural language descriptions in the prompt."
                ],
                "publication_ref": [
                    "b2",
                    "b15",
                    "b26",
                    "b5",
                    "b33"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Conclusion",
                "text": [
                    "In this work we introduced SPLAT, a novel architecture for schema-guided dialogue state tracking which learns to infer slots by learning to select target spans based on natural language descriptions of slot semantics, and further showed how to pretrain SPLAT via a recurrent span selection objective for better span representations and a stronger slot prediction performance. We find that our proposed architecture yields significant improvements over existing models and achieving 85.3 JGA on the SGD dataset and 57.4 JGA on the MultiWOZ dataset. In schema-guided DST the ability to generalize to new schemas and robustness to changes in schema descriptions is of particular interest. We demonstrated that our model is much more robust to such changes in experiments on the SGD-X benchmark where SPLAT outperforms the more than 30\u00d7 larger D3ST-XXL model by 5.0 points."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Limitations",
                "text": [
                    "One trade-off of limiting the prediction space using an extractive pointer module is that it does not support prediction of multiple slot values which is necessary for some dialogues in the MultiWOZ 2.3 and 2.4 datasets. To keep the architecture simple we do not consider cases in which slots take multiple values in this work, but we can effectively adapt our model for this setting by introducing sequential query tokens for each slot. Another limitation is that the span representation requires a computation of O(N \u2022 L ans ) complexity where N and L ans represent the length of context and answer span, respectively. For very long answers this might occur significant computational costs compared to exist-ing span prediction approaches which have O(N ) complexity. However, this can be alleviated by adding a simple sampling and filtering step during training and prediction. We plan to further study and address these limitations in future work."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Ethics Statement",
                "text": [
                    "We introduced a novel model architecture for schema-guided dialogue state tracking which leverages a natural language schema and a span pointer module to achieve higher accuracy in dialogue state tracking. All experiments were conducted on publicly available datasets which are commonly used in research on dialogue systems."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": " [INTENT] ",
                "text": [
                    "Intent embedding h [SLOT]  Slot embedding h [UTT]  Utterance embedding h SPAN ij Span embedding from position i to j x i Token representation at position i \u03b8 Model parameters We discussed the limitations of our work in the unnumbered limitations section.",
                    "A2. Did you discuss any potential risks of your work?",
                    "We only used publically available datasets that are commonly used in research on dialogue systems. We believe there are no significant risks associated with our work.",
                    "A3. Do the abstract and introduction summarize the paper's main claims?",
                    "Abstract and section 1 A4. Have you used AI writing assistants when working on this paper?",
                    "Left blank.",
                    "B Did you use or create scientific artifacts?",
                    "Discussed in section 3.1 and 3.3 B1. Did you cite the creators of artifacts you used?",
                    "Section 3.1 and 3.3 B2. Did you discuss the license or terms for use and / or distribution of any artifacts?",
                    "We only used publically available data and adhere to the creator's license terms. The SGD dataset is freely available under the CC-BY-SA 4.0 and the MultiWOZ dataset is freely available under the MIT license.",
                    "B3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided that it was specified? For the artifacts you create, do you specify intended use and whether that is compatible with the original access conditions (in particular, derivatives of data accessed for research purposes should not be used outside of research contexts)?",
                    "We only used publically available data and adhere to the creator's license terms and their intended use. The SGD dataset is freely available under the CC-BY-SA 4.0 and the MultiWOZ dataset is freely available under the MIT license.",
                    "B4. Did you discuss the steps taken to check whether the data that was collected / used contains any information that names or uniquely identifies individual people or offensive content, and the steps taken to protect / anonymize it?",
                    "We only used publically available data that is commonly used in dialogue systems research and which does not uniquely identify people and which does not contain any personal data or offensive content.",
                    "B5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and linguistic phenomena, demographic groups represented, etc.?",
                    "We did not create artifacts. Documentation of the artifacts used is provided in section 3.1 and 3.3.",
                    "B6. Did you report relevant statistics like the number of examples, details of train / test / dev splits, etc. for the data that you used / created? Even for commonly-used benchmark datasets, include the number of examples in train / validation / test splits, as these provide necessary context for a reader to understand experimental results. For example, small differences in accuracy on large test sets may be significant, while on small test sets they may not be. Section 3.1",
                    "The Responsible NLP Checklist used at ACL 2023 is adopted from NAACL 2022, with the addition of a question on AI writing assistance."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "C Did you run computational experiments?",
                "text": [
                    "Section 3 and Section 4",
                    "C1. Did you report the number of parameters in the models used, the total computational budget (e.g., GPU hours), and computing infrastructure used? D3. Did you discuss whether and how consent was obtained from people whose data you're using/curating? For example, if you collected data via crowdsourcing, did your instructions to crowdworkers explain how the data would be used? Not applicable. Left blank.",
                    "D4. Was the data collection protocol approved (or determined exempt) by an ethics review board? Not applicable. Left blank.",
                    "D5. Did you report the basic demographic and geographic characteristics of the annotator population that is the source of the data? Not applicable. Left blank."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            }
        ],
        "references": [
            {
                "ref_id": "b0",
                "title": "Longformer: The long-document transformer",
                "journal": "",
                "year": "2020",
                "authors": "Iz Beltagy; E Matthew; Arman Peters;  Cohan"
            },
            {
                "ref_id": "b1",
                "title": "MultiWOZ -a largescale multi-domain Wizard-of-Oz dataset for taskoriented dialogue modelling",
                "journal": "Association for Computational Linguistics",
                "year": "2018",
                "authors": "Pawe\u0142 Budzianowski; Tsung-Hsien Wen; Bo-Hsiang Tseng; I\u00f1igo Casanueva; Stefan Ultes; Milica Osman Ramadan;  Ga\u0161i\u0107"
            },
            {
                "ref_id": "b2",
                "title": "BERT-DST: Scalable End-to-End Dialogue State Tracking with Bidirectional Encoder Representations from Transformer",
                "journal": "",
                "year": "2019",
                "authors": "Guan-Lin Chao; Ian Lane"
            },
            {
                "ref_id": "b3",
                "title": "Rethinking attention with performers",
                "journal": "",
                "year": "2021",
                "authors": "Valerii Krzysztof Marcin Choromanski; David Likhosherstov; Xingyou Dohan; Andreea Song; Tamas Gane; Peter Sarlos; Jared Quincy Hawkins; Afroz Davis; Lukasz Mohiuddin; David Benjamin Kaiser; Lucy J Belanger; Adrian Colwell;  Weller"
            },
            {
                "ref_id": "b4",
                "title": "Mul-tiWOZ 2.1: A consolidated multi-domain dialogue dataset with state corrections and state tracking baselines",
                "journal": "",
                "year": "2020",
                "authors": "Mihail Eric; Rahul Goel; Shachi Paul; Abhishek Sethi; Sanchit Agarwal; Shuyang Gao; Adarsh Kumar; Anuj Goyal; Peter Ku; Dilek Hakkani-Tur"
            },
            {
                "ref_id": "b5",
                "title": "A sequenceto-sequence approach to dialogue state tracking",
                "journal": "Long Papers",
                "year": "2021",
                "authors": "Yue Feng; Yang Wang; Hang Li"
            },
            {
                "ref_id": "b6",
                "title": "Show, don't tell: Demonstrations outperform descriptions for schema-guided task-oriented dialogue",
                "journal": "Association for Computational Linguistics",
                "year": "2022",
                "authors": "Raghav Gupta; Harrison Lee; Jeffrey Zhao; Yuan Cao; Abhinav Rastogi; Yonghui Wu"
            },
            {
                "ref_id": "b7",
                "title": "Multiwoz 2.3: A multi-domain task-oriented dialogue dataset enhanced with annotation corrections and co-reference annotation",
                "journal": "Springer",
                "year": "2021",
                "authors": "Ting Han; Ximing Liu; Ryuichi Takanabu; Yixin Lian; Chongxuan Huang; Dazhen Wan; Wei Peng; Minlie Huang"
            },
            {
                "ref_id": "b8",
                "title": "Spanbert: Improving pre-training by representing and predicting spans",
                "journal": "Transactions of the Association for Computational Linguistics",
                "year": "2020",
                "authors": "Mandar Joshi; Danqi Chen; Yinhan Liu; S Daniel; Luke Weld; Omer Zettlemoyer;  Levy"
            },
            {
                "ref_id": "b9",
                "title": "A multi-task bert model for schema-guided dialogue state tracking",
                "journal": "",
                "year": "2022",
                "authors": "Eleftherios Kapelonis; Efthymios Georgiou; Alexandros Potamianos"
            },
            {
                "ref_id": "b10",
                "title": "Adam: A method for stochastic optimization",
                "journal": "",
                "year": "2014",
                "authors": "P Diederik; Jimmy Kingma;  Ba"
            },
            {
                "ref_id": "b11",
                "title": "Dialogue state tracking with a language model using schema-driven prompting",
                "journal": "Association for Computational Linguistics",
                "year": "2021",
                "authors": "Chia-Hsuan Lee; Hao Cheng; Mari Ostendorf"
            },
            {
                "ref_id": "b12",
                "title": "Sgd-x: A benchmark for robust generalization in schemaguided dialogue systems",
                "journal": "",
                "year": "2022",
                "authors": "Harrison Lee; Raghav Gupta; Abhinav Rastogi; Yuan Cao; Bin Zhang; Yonghui Wu"
            },
            {
                "ref_id": "b13",
                "title": "Datasets: A community library for natural language processing",
                "journal": "Association for Computational Linguistics",
                "year": "2021",
                "authors": "Quentin Lhoest; Albert Villanova Del Moral; Yacine Jernite; Abhishek Thakur; Suraj Patrick Von Platen; Julien Patil; Mariama Chaumond; Julien Drame; Lewis Plu; Joe Tunstall; Mario Davison; Gunjan \u0160a\u0161ko; Bhavitvya Chhablani; Simon Malik; Teven Le Brandeis; Victor Scao; Canwen Sanh; Nicolas Xu; Angelina Patry; Philipp Mcmillan-Major; Sylvain Schmid;  Gugger"
            },
            {
                "ref_id": "b14",
                "title": "Zero-shot dialogue state tracking via cross-task transfer",
                "journal": "",
                "year": "2021",
                "authors": "Zhaojiang Lin; Bing Liu; Andrea Madotto; Seungwhan Moon; Paul Crook; Zhenpeng Zhou; Zhiguang Wang; Zhou Yu; Eunjoon Cho; Rajen Subba"
            },
            {
                "ref_id": "b15",
                "title": "An end-to-end dialogue state tracking system with machine reading comprehension and wide & deep classification",
                "journal": "",
                "year": "2019",
                "authors": "Yue Ma; Zengfeng Zeng; Dawei Zhu; Xuan Li; Yiying Yang; Xiaoyuan Yao; Kaijie Zhou; Jianping Shen"
            },
            {
                "ref_id": "b16",
                "title": "KILT: a benchmark for knowledge intensive language tasks",
                "journal": "",
                "year": "2021",
                "authors": "Fabio Petroni; Aleksandra Piktus; Angela Fan; Patrick Lewis; Majid Yazdani; Nicola De Cao; James Thorne; Yacine Jernite; Vladimir Karpukhin; Jean Maillard; Vassilis Plachouras; Tim Rockt\u00e4schel; Sebastian Riedel"
            },
            {
                "ref_id": "b17",
                "title": "Few-shot question answering by pretraining span selection",
                "journal": "Long Papers",
                "year": "2021",
                "authors": "Ori Ram; Yuval Kirstain; Jonathan Berant; Amir Globerson; Omer Levy"
            },
            {
                "ref_id": "b18",
                "title": "Towards scalable multi-domain conversational agents: The schema-guided dialogue dataset",
                "journal": "",
                "year": "2020",
                "authors": "Abhinav Rastogi; Xiaoxue Zang; Srinivas Sunkara; Raghav Gupta; Pranav Khaitan"
            },
            {
                "ref_id": "b19",
                "title": "2020. Fine-tuning bert for schema-guided zero-shot dialogue state tracking",
                "journal": "",
                "year": "",
                "authors": "Yu-Ping Ruan; Zhen-Hua Ling; Jia-Chen Gu; Quan Liu"
            },
            {
                "ref_id": "b20",
                "title": "Amendable generation for dialogue state tracking",
                "journal": "Online. Association for Computational Linguistics",
                "year": "2021",
                "authors": "Xin Tian; Liankai Huang; Yingzhan Lin; Siqi Bao; Huang He; Yunyi Yang; Hua Wu; Fan Wang; Shuqi Sun"
            },
            {
                "ref_id": "b21",
                "title": "Attention is all you need",
                "journal": "",
                "year": "2017",
                "authors": "Ashish Vaswani; Noam Shazeer; Niki Parmar; Jakob Uszkoreit; Llion Jones; Aidan N Gomez; \u0141ukasz Kaiser; Illia Polosukhin"
            },
            {
                "ref_id": "b22",
                "title": "Pointer networks. Advances in neural information processing systems",
                "journal": "",
                "year": "2015",
                "authors": "Oriol Vinyals; Meire Fortunato; Navdeep Jaitly"
            },
            {
                "ref_id": "b23",
                "title": "LUNA: Learning slot-turn alignment for dialogue state tracking",
                "journal": "",
                "year": "2022",
                "authors": "Yifan Wang; Jing Zhao; Junwei Bao; Chaoqun Duan; Youzheng Wu; Xiaodong He"
            },
            {
                "ref_id": "b24",
                "title": "The dialog state tracking challenge",
                "journal": "Association for Computational Linguistics",
                "year": "2013",
                "authors": "Jason Williams; Antoine Raux; Deepak Ramachandran; Alan Black"
            },
            {
                "ref_id": "b25",
                "title": "Transformers: State-of-the-art natural language processing",
                "journal": "Association for Computational Linguistics",
                "year": "2020",
                "authors": "Thomas Wolf; Lysandre Debut; Victor Sanh; Julien Chaumond; Clement Delangue; Anthony Moi; Pierric Cistac; Tim Rault; R\u00e9mi Louf; Morgan Funtowicz; Joe Davison; Sam Shleifer; Clara Patrick Von Platen; Yacine Ma; Julien Jernite; Canwen Plu; Teven Le Xu; Sylvain Scao; Mariama Gugger; Quentin Drame; Alexander M Lhoest;  Rush"
            },
            {
                "ref_id": "b26",
                "title": "Transferable multi-domain state generator for task-oriented dialogue systems",
                "journal": "Association for Computational Linguistics",
                "year": "2019",
                "authors": "Chien-Sheng Wu; Andrea Madotto; Ehsan Hosseini-Asl; Caiming Xiong; Richard Socher; Pascale Fung"
            },
            {
                "ref_id": "b27",
                "title": "MultiWOZ 2.4: A multi-domain task-oriented dialogue dataset with essential annotation corrections to improve state tracking evaluation",
                "journal": "",
                "year": "2022",
                "authors": "Fanghua Ye; Jarana Manotumruksa; Emine Yilmaz"
            },
            {
                "ref_id": "b28",
                "title": "Big bird: Transformers for longer sequences",
                "journal": "Advances in Neural Information Processing Systems",
                "year": "2020",
                "authors": "Manzil Zaheer; Guru Guruganesh; Joshua Kumar Avinava Dubey; Chris Ainslie; Santiago Alberti; Philip Ontanon; Anirudh Pham; Qifan Ravula; Li Wang;  Yang"
            },
            {
                "ref_id": "b29",
                "title": "MultiWOZ 2.2 : A dialogue dataset with additional annotation corrections and state tracking baselines",
                "journal": "",
                "year": "2020",
                "authors": "Xiaoxue Zang; Abhinav Rastogi; Srinivas Sunkara; Raghav Gupta; Jianguo Zhang; Jindong Chen"
            },
            {
                "ref_id": "b30",
                "title": "Find or classify? dual strategy for slot-value predictions on multi-domain dialog state tracking",
                "journal": "Association for Computational Linguistics",
                "year": "2020",
                "authors": "Jianguo Zhang; Kazuma Hashimoto; Chien-Sheng Wu; Yao Wang; Philip Yu; Richard Socher; Caiming Xiong"
            },
            {
                "ref_id": "b31",
                "title": "Sgd-qa: Fast schema-guided dialogue state tracking for unseen services",
                "journal": "",
                "year": "2021",
                "authors": "Yang Zhang; Vahid Noroozi; Evelina Bakhturina; Boris Ginsburg"
            },
            {
                "ref_id": "b32",
                "title": "Izhak Shafran, and Yonghui Wu. 2022. Descriptiondriven task-oriented dialog modeling",
                "journal": "",
                "year": "",
                "authors": "Jeffrey Zhao; Raghav Gupta; Yuan Cao; Dian Yu; Mingqiu Wang; Harrison Lee; Abhinav Rastogi"
            },
            {
                "ref_id": "b33",
                "title": "Effective sequence-tosequence dialogue state tracking",
                "journal": "Association for Computational Linguistics",
                "year": "2021",
                "authors": "Jeffrey Zhao; Mahdis Mahdieh; Ye Zhang; Yuan Cao; Yonghui Wu"
            }
        ],
        "figures": [
            {
                "figure_label": "1",
                "figure_type": "figure",
                "figure_id": "fig_0",
                "figure_caption": "Figure 1 :1Figure 1: Span selection for schema-guided dialogue in practice. [SLOT] encodes the semantics of the natural language description of \"to_location\" and is matched with the span representation of \"Long Beach, CA\". Similarly [UTT] encodes the semantics of the current utterance and is matched with the target [INTENT] encoding.",
                "figure_data": ""
            },
            {
                "figure_label": "2",
                "figure_type": "figure",
                "figure_id": "fig_1",
                "figure_caption": "Figure 2 :2Figure 2: An overview over the SPLAT model architecture. Intent scores are computed using the utterance representation h [UTT]",
                "figure_data": ""
            },
            {
                "figure_label": "1",
                "figure_type": "table",
                "figure_id": "tab_0",
                "figure_caption": "takes as input the previous state and the current turn and learns to generate the new state in a first pass and correcting mistakes in a second generation pass. AG-DST does not condition generation on the schema and slot semantics are learned implic-Results on the SGD test set.",
                "figure_data": "ModelPretrained ModelSingle-Pass Intent JGAWith system action annotationsMT-BERT (Kapelonis et al., 2022)BERT-base (110M)\u271794.7 82.7paDST (Ma et al., 2019)XLNet-large (340M)\u271794.8 86.5No additional dataSGD baseline (Rastogi et al., 2020)BERT-base (110M)\u271790.6 25.4MT-BERT (Kapelonis et al., 2022)BERT-base (110M)\u2717-71.9DaP (ind) (Lee et al., 2021)T5-base (220M)\u271790.2 71.8SGP-DST (Ruan et al., 2020)T5-base (220M)\u271791.8 72.2D3ST (Base) (Zhao et al., 2022)T5-base (220M)\u271397.2 72.9D3ST (Large) (Zhao et al., 2022)T5-large (770M)\u271397.1 80.0D3ST (XXL) (Zhao et al., 2022)T5-XXL (11B)\u271398.8 86.4SPLAT (Base)Longformer-base (110M)\u271396.7 80.1SPLAT (Large)Longformer-large (340M)\u271397.6 85.3ModelPretrained ModelSingle-Pass Intent JGADS-DST  \u2020 (Zhang et al., 2020) Seq2Seq-DUBERT-base (110M)\u2717-51.7"
            },
            {
                "figure_label": "2",
                "figure_type": "table",
                "figure_id": "tab_1",
                "figure_caption": "Results on the MultiWOZ 2.2 test set. Results denoted by \u2020 were reported in the original MultiWOZ 2.2 paper",
                "figure_data": "11B)\u2713-58.7"
            },
            {
                "figure_label": "1",
                "figure_type": "table",
                "figure_id": "tab_2",
                "figure_caption": "",
                "figure_data": "shows re-"
            },
            {
                "figure_label": "3",
                "figure_type": "table",
                "figure_id": "tab_3",
                "figure_caption": "Joint goal accuracy on the five different SGD-X schema variants. Results denoted by * are based on a reimplementation in the SGD-X paper which could not reproduce the original results.",
                "figure_data": "ModelParams. Seen Unseen OverallSGP-DST 1220M88.067.072.2D3ST (Base) 2220M92.566.472.9D3ST (Large) 2770M93.875.480.0D3ST (XXL) 211B95.883.386.4SPLAT (Base)110M94.575.280.1SPLAT (Large) 340M94.682.285.3"
            },
            {
                "figure_label": "4",
                "figure_type": "table",
                "figure_id": "tab_4",
                "figure_caption": "Joint goal accuracy on the SGD test set on seen and unseen services. Baseline results are reported by 1 Ruan et al. (2020) and 2 Zhao et al. (2022) respectively.",
                "figure_data": ""
            },
            {
                "figure_label": "5",
                "figure_type": "table",
                "figure_id": "tab_5",
                "figure_caption": "Table 3, our model is considerably more robust to linguistic variations than all of the Ablation results on the SGD and MultiWOZ test sets. Longformer (extr.) refers to an extractive model with no span representations and simple start and end pointers for answer prediction, SPM refers to the Span Pointer Module and RSS-PT to pre-training with the Recurrent Span Selection objective.",
                "figure_data": "SGDMultiWOZModelParams. Intent JGA Intent JGALongformer (extr.) 110M + SPM 110M + SPM + RSS-PT 110M95.9 78.5 91.4 55.5 97.0 79.0 91.4 56.1 96.7 80.1 91.4 56.6Longformer (extr.) 340M97.5 83.5 91.4 56.3+ SPM + SPM + RSS-PT340M 340M98.2 83.8 91.4 57.8 97.6 85.3 91.5 57.4"
            },
            {
                "figure_label": "5",
                "figure_type": "table",
                "figure_id": "tab_6",
                "figure_caption": "We compare a variant of our model which does not use span representations (referred to as \"Longformer (extractive)\") but instead has two pointers [SLOT] and [/SLOT] which are used to select the start and end of the answer span. We find that using the Span Pointer Module to directly select the span improves performance across both model sizes and datasets.",
                "figure_data": "Furthermore, we find pre-training our model forbetter span representations via the recurrent spanselection task to be crucial giving further signifi-cant performance gains for all sizes and datasets ex-cept the 340M parameter model on the MultiWOZdataset where JGA slightly deteriorates. Acrossboth model sizes gains from RSS pre-training arelarger on the SGD dataset. We hypothesize thatthis may be attributed to better span representa-tions learned through RSS pre-training which inturn generalize better to unseen domains."
            }
        ],
        "formulas": [
            {
                "formula_id": "formula_0",
                "formula_text": "I = [CLS] U [SEP] T D intent D slot [SEP] G = T \u222a D intent \u222a D slot E = LAT(I; G; \u03b8).",
                "formula_coordinates": [
                    3.0,
                    86.35,
                    517.83,
                    187.28,
                    56.84
                ]
            },
            {
                "formula_id": "formula_1",
                "formula_text": "h [UTT] i = LN(FFN(x [UTT] i )) h [INTENT] j = LN(FFN(x [INTENT] j ))(2)",
                "formula_coordinates": [
                    3.0,
                    106.35,
                    707.48,
                    183.52,
                    34.17
                ]
            },
            {
                "formula_id": "formula_2",
                "formula_text": "score i\u2192j = sim(h [UTT] i , h [INTENT] j ) L intent = \u2212 1 T T i=1 log exp(score i\u2192j ) K k=1 exp(score i\u2192k ) \u2022 1 GT (3)",
                "formula_coordinates": [
                    3.0,
                    306.59,
                    120.63,
                    218.57,
                    67.81
                ]
            },
            {
                "formula_id": "formula_3",
                "formula_text": "y ij = [x i ; x j ] h SPAN ij = LN(FFN GeLU (y ij )) \u00d7 n_layers (4)",
                "formula_coordinates": [
                    3.0,
                    316.59,
                    424.14,
                    208.56,
                    36.23
                ]
            },
            {
                "formula_id": "formula_4",
                "formula_text": "h [SLOT] = LN(FFN GeLU (x [SLOT] )) \u00d7 n_layers",
                "formula_coordinates": [
                    3.0,
                    309.85,
                    525.16,
                    210.86,
                    21.63
                ]
            },
            {
                "formula_id": "formula_5",
                "formula_text": "score q\u2192ij = sim(h [SLOT] q , h SPAN ij ) L slot = \u2212 1 L L q=1 log exp(score q\u2192ij ) K k=1 exp(score q\u2192k ) \u2022 1 GT (6)",
                "formula_coordinates": [
                    3.0,
                    309.55,
                    669.99,
                    215.61,
                    68.71
                ]
            },
            {
                "formula_id": "formula_6",
                "formula_text": "L = L slot + L intent 2 (7)",
                "formula_coordinates": [
                    4.0,
                    138.24,
                    251.97,
                    151.63,
                    26.31
                ]
            }
        ],
        "doi": "10.18653/v1/D18-1547"
    },
    "EM Pre-training for Multi-party Dialogue Response Generation": {
        "authors": "Yiyang Li; Hai Zhao",
        "pub_date": "",
        "abstract": "Dialogue response generation requires an agent to generate a response according to the current dialogue history, in terms of which twoparty dialogues have been well studied, but leaving a great gap for multi-party dialogues at the same time. Different from two-party dialogues where each response is a direct reply to its previous utterance, the addressee of a response utterance should be specified before it is generated in the multi-party scenario. Thanks to the huge amount of two-party conversational data, various pre-trained language models for two-party dialogue response generation have been proposed. However, due to the lack of annotated addressee labels in multi-party dialogue datasets, it is hard to use them to pre-train a response generation model for multi-party dialogues. To tackle this obstacle, we propose an Expectation-Maximization (EM) approach that iteratively performs the expectation steps to generate addressee labels, and the maximization steps to optimize a response generation model. Theoretical analyses and extensive experiments have justified the feasibility and effectiveness of our proposed method. The official implementation of this paper is available at https://github.com/EricLee8/MPDRG.",
        "sections": [
            {
                "heading": "Introduction",
                "text": [
                    "Inspired by the tremendous success in pre-training large language models (PLMs) in general domains (Devlin et al., 2019;Clark et al., 2020;Radford et al., 2018), efforts have been made to train PLMs for dialogue response generation (Zhang et al., 2020;Bao et al., 2020;Chen et al., 2022). However, they constrain the dialogues to be either two-party, or sequential structured (i.e. each utterance replies directly to its previous utterance). Different from them, a multi-party dialogue can involve multiple interlocutors, where each interlocutor can reply to any preceding utterances, making the response relations of the dialogue tree-structured and much more complicated (Zhang et al., 2018;Le et al., 2019;Shi and Huang, 2019;Wang et al., 2020). Besides, the speaker and addressee of a response utterance should be specified before it is generated in multi-party scenario, making the annotated data for multi-party dialogue response generation (MP-DRG) less available. Figure 1 illustrates an example of MPDRG task taken from the Ubuntu IRC benchmark (Hu et al., 2019). The upper part shows the tree-structured addressee relations of the dialogue, where the arrows point from addressees to speakers, and different colors represent different interlocutors. The middle part displays the content of the dialogue history, where U 7 is the response to be generated. The addressee (U 6 ) and the speaker (#4) of it are given, and the content of this response is the target of our model. The lower part gives the human response, which is also called the ground truth reference.",
                    "Previous works on MPDRG fine-tune generative PLMs on small multi-party dialogue datasets with explicit addressee annotations. They utilize the response annotations to form a tree-structured response graph, then encode the dialogue history using either homogeneous or heterogeneous Graph Neural Networks (GNNs) (Hu et al., 2019;Gu et al., 2022). Nevertheless, none of them make attempts to pre-train a response generation model for multiparty dialogues due to the lack of large-scale corpora with annotated addressee labels.",
                    "To solve the aforementioned problem of data scarcity, we propose an EM approach that iteratively performs the expectation steps to generate addressee labels, and the maximization steps to optimize a response generation model. Specifically, we treat the addressee of each utterance in the dialogue history as a discrete latent variable z. During the E-steps, given the current dialogue history c t and the the response utterance r t , we model the distribution of the current addressee z t as p(z t |c t , r t ; \u03b8), where \u03b8 is the current model parameters. During the M-steps, we sample (c t , r t , z t ) triplets from distribution p(z t |c t , r t ; \u03b8) and optimize the generative model p(r t |c t , z t ; \u03b8) on these samples. With the iteration number increasing, the accuracy of latent variable prediction and the quality of generated responses will grow together. It is worth noting that during these iterations, annotated addressee labels are not required, which makes it possible to leverage the huge amount of multi-party dialogue corpora without addressee labels. We provide theoretical analyses to prove the feasibility of our EM method, and conduct experiments on the Ubuntu IRC benchmark, which is used in previous works (Hu et al., 2019;Gu et al., 2022).",
                    "The contributions of our work can be summarized as the following three folds: \u2022 To the best of our knowledge, we are the first to study the pre-training of multi-party dialogue response generation, which is much more challenging and complicated than two-party dialogues. \u2022 We put forward an EM approach to alleviate the scarcity of multi-party dialogue data with addressee labels, making it possible to pre-train a model with huge amount of unlabeled corpora. \u2022 We provide theoretical analyses to prove the feasibility of our EM pre-training method, and experimental results on the Ubuntu IRC benchmark show our pre-trained model achieves state-of-theart performance compared with previous works.",
                    "2 Related Works"
                ],
                "publication_ref": [
                    "b3",
                    "b2",
                    "b16",
                    "b21",
                    "b0",
                    "b20",
                    "b7",
                    "b17",
                    "b4",
                    "b4"
                ],
                "figure_ref": [
                    "fig_0"
                ],
                "table_ref": []
            },
            {
                "heading": "Pre-training for Response Generation",
                "text": [
                    "In recent years, researchers have gradually drawn their attention from retrieval-based dialogue systems to generation-based ones. Thanks to the huge amount of two-party dialogue corpora, various PLMs for two-party dialogue response generation have been proposed. Zhang et al. (2020) propose DialoGPT, which utilizes the sequential response chains in the Reddit Corpus to pre-train an auto-regressive response generation model based on the architecture of GPT (Radford et al., 2018). Different from their work, which focuses on sequential dialogue history, our work aims to solve the case where the agent can respond to any previous utterance in a tree-structured dialogue history. Bao et al. (2020) propose PLATO, which models the conversational intents as K discrete latent  variables, then utilizes response selection, bag-ofwords prediction, and language modeling objectives to train the model. DialogVED (Chen et al., 2022) further extends the discrete latent variables to continuous ones, and models them with a multivariable Gaussian distribution. It utilizes KL divergence reduction to optimize the parameters of the latent distribution and applies masked language modeling, response generation, and bag-of-words prediction to train the whole model. PLATO and DialogVED focus on two-party conversations, and the conversational intents they put forward have no corresponding concepts of actual entities (e.g., intent to argue, intent to end a conversation, and so on). Distinct from their works, we lay emphasis on multi-party dialogues, and the latent variables of our method have actual meanings: variable z t = j indicates that the addressee of the response at the t th turn is the j th utterance."
                ],
                "publication_ref": [
                    "b21",
                    "b16",
                    "b0"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Human Response:",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Multi-party Dialog Response Generation",
                "text": [
                    "Several previous works have studied the MPDRG task. Hu et al. (2019) extract a subset of the Ubuntu Dialogue Corpus (Lowe et al., 2015)  of a dialogue as a node, and the addressee relations as edges to construct a dialogue graph, then make use of GNNs to encode the dialogue history. Finally, they adopt a Gated Recurrent Unit (GRU) with cross attention as the decoder to generate responses. Gu et al. (2022) put forward Het-erMPC, which models the dialogue history as a heterogeneous graph. In detail, they first design six types of edges: reply and replied-by, address and addressed-by, speak and spoken-by, among two kinds of nodes: interlocutor nodes and utterance nodes, and then encode the dialogue history using Transformers (Vaswani et al., 2017) together with heterogeneous GNNs. Finally, they utilize a Transformer Decoder to generate responses. Instead of fine-tuning models on a small dataset with annotated addressee labels as these existing work did, our work focuses on the utilization of large unlabeled corpora to pre-train a response generation model for multi-party dialogues."
                ],
                "publication_ref": [
                    "b13",
                    "b4",
                    "b18"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Methodology",
                "text": [
                    "To design a model for multi-party dialogue response generation and make it compatible with the EM training algorithm, there are two important things to consider: how to model p(r t |c t , z t ; \u03b8) in the maximization step, and how to compute p(z t |c t , r t ; \u03b8) in the expectation step. In this section, we will first address these two problems, then mathematically derive the feasibility of our EM pre-training algorithm."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Task Formulation",
                "text": [
                    "Given an input sequence of the dialogue history and the speaker of the response at time step t,",
                    "X = {S 1 : U 1 [SEP]S 2 : U 2 [SEP] . . . S t-1 : U t-1 [SEP]S t :},",
                    "together with the addressee of the response z t = j, our goal is to train a model that can generate an response Y = U t . Here each S i is the name of the speaker at time step i, which is represented as Speaker #S i like those in Figure 1. U i = {w i1 , w i2 , . . . , w in i } is the content of the i th utterance with n i words. z t = j represents that S t speaks to S j , who utters U j , and [SEP] is a special token that indicates the end of a dialogue turn."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_0"
                ],
                "table_ref": []
            },
            {
                "heading": "Addressee Modeling",
                "text": [
                    "In this section, we answer the first question: how to model p(r t |c t , z t ; \u03b8), or in other words, how to incorporate the addressee information z t = j into the process of generating a response r t . We design a straightforward method that adds addressee embeddings to the positional encodings and word embeddings, before they are further encoded by a PLM. The left part of Figure 2 illustrates this method, where we use an embedding look-up table with 2 entries to indicate whether a word belongs to the addressee utterance or not. Specifically, if a word is in the addressee utterance, it will get its addressee embedding from entry 1, otherwise from entry 0. Since addressee modeling is not the key contribution of this work, we just adopt the most straightforward and effective way. In our experiments, we use BART (Lewis et al., 2020) as the backbone PLM, following previous works (Gu et al., 2022). Due to the page limit, the proverbial architecture of Transformer and BART are omitted here."
                ],
                "publication_ref": [
                    "b8",
                    "b4"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Latent Variable Prediction",
                "text": [
                    "In this section, we answer the second question: how to compute p(z t |c t , r t ; \u03b8) in the expectation step, or in other words, how to predict the distribution of the unlabeled addressee z t , given the current dialogue context c t , response r t , under parameters \u03b8. The solution to this question is essentially the most important part of our method since it delicately solves the problem of data scarcity in MPDRG.",
                    "Let's consider what humans will do to participate in a multi-party conversation. First, we will read the dialogue history c t , then choose an addressee z t to reply. Once c t and z t are determined, we will utter a response according to the content of the whole dialogue and the addressee utterance. The right part of Figure 2 gives the Bayesian Network of the above process, where the joint distribution of (c t , z t , r t ) can be factorized as:",
                    "p(c, z, r) = p(c) \u2022 p(z|c) \u2022 p(r|c, z)(1)",
                    "Here we omit the subscript t and model parameters \u03b8 for simplicity. Given Eq. ( 1), p(z|c, r; \u03b8) can be derived as:",
                    "p(z|c, r) = p(c, z, r) p(c, r) = p(c) \u2022 p(z|c) \u2022 p(r|c, z) p(c) \u2022 p(r|c) = p(z|c) \u2022 p(r|c, z) p(r|c)(2)",
                    "We assume that the probability of choosing any previous utterance as the addressee is the same given the current dialogue history, which means p(z|c) obeys a uniform distribution. Meanwhile, the denominator p(r|c) is independent of z, leaving only the term p(r|c, z). Now, we can induce that:",
                    "p(z|c, r) \u221d p(r|c, z)(3)",
                    "Therefore, for each z i , i = 1, 2, . . . , t \u2212 1, we have:",
                    "p(z i |c, r) = p(r|c, z i ) t\u22121 j=1 p(r|c, z j )(4)",
                    "In practice, we can use the generative model p(r t |c t , z t ; \u03b8) to compute the probability distribution of p(z t |c t , r t ; \u03b8) by Eq. (4). parameters \u03b8, where Eq. ( 4) gives a reasonable approximation of this value. Specifically, for a sample (c t , r t ), with the model parameters \u03b8 fixed, we first calculate the un-normalized probability of each of the i th (i < t) utterance being the addressee: p(r t |c t , z i t ; \u03b8) using Eq. ( 3), then normalize them to get the conditional distribution of z t using Eq. ( 4). Once P (z t |c t , r t ; \u03b8) is obtained, we sample (c t , r t , z t ) triplets from this distribution, which is further used in the maximization step. The Maximization Step is analogical to the normal training process. Given the sampled"
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Expectation-Maximization Process",
                "text": [
                    "{(c k t , r k t , z k t )} N k=1",
                    "triplets, where N is the total number of samples, our goal is to minimize the auto-regressive language modeling loss:",
                    "L G = \u2212 N k=1 n k i=1 log p w k i | w k <i , c k t , z k t ; \u03b8 (5)",
                    "where w k i is the i th word in the response of the k th sample:",
                    "r k t = {w k i } n i i=1",
                    ", and n i is the length of this response.",
                    "Compared with the vanilla EM algorithm, there are several differences in our implementations. First of all, we do not use the initial model to generate the training data for the first round of the maximization step. Instead, we utilize the discourse parser provided by Shi and Huang (2019) to predict the addressee of each utterance in the unlabeled corpus to get a coarse initial training dataset. The reason for this initialization method is that the initialization of training data (or model parameters) is vital to the EM method, which helps it converge to a better point. Second, rather than sampling z t from its conditional distribution, we adopt a hard EM approach which takes the value z i t with highest probability as the predicted label, where i = arg max i p(z i t |c t , r t ; \u03b8). This hard EM approach is proved as more effective to boost the performance (Min et al., 2019). Finally, to ensure the quality of the generated training data in the maximization step, we set a hyper-parameter \u03b1 \u2208 [0, 1] to control the proportion of training data that is actually used. Specifically, we first rank the prediction confidence of each z k t according to the value of p(z k t |c k t , r k t ; \u03b8), then pick the top \u03b1 \u00d7 N samples with the highest confidence scores. In our experiments, \u03b1 is dynamically set to ensure the addressee prediction accuracy of the selected samples is over 80% in an annotated validation set."
                ],
                "publication_ref": [
                    "b17",
                    "b15"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Proof of Feasibility",
                "text": [
                    "In a multi-party dialogue corpus without annotated addressee labels, a usual solution to train a response generation model is to maximize the marginal loglikelihood (or incomplete log-likelihood) over all possible addressees:",
                    "\u2113(c, r; \u03b8) = log p(r|c; \u03b8) = log i p(r, z i |c; \u03b8) (6)",
                    "However, this objective is hard to optimize since the distribution of z is hard to obtain. Here, we define an expected complete log-likelihood where our estimation of p(z t |c t , r t ; \u03b8) can come to rescue:",
                    "l(c, r; \u03b8) = q(z i ) i log p(r, z i |c; \u03b8) q(z) = p(z t |c t , r t ; \u03b8) (7)",
                    "Our new objective now becomes maximizing the expected complete log-likelihood. The relation between \u2113 and l can be derived as follows:",
                    "\u2113(c, r; \u03b8) = log i p(r, z i |c; \u03b8) = log i q(z i ) \u2022 p(r, z i |c; \u03b8) q(z i ) \u2265 i q(z i ) \u2022 log p(r, z i |c; \u03b8) q(z i ) = i q(z i ) \u2022 log p(r, z i |c; \u03b8) \u2212 i q(z i ) \u2022 log q(z i ) = l(c, r; \u03b8) + H q(z)(8)",
                    "where the third line is derived from the Jensen Inequality, and H q(z) is the entropy of the distribution of z. Since H q(z) \u2265 0, we can derive that l(c, r; \u03b8) \u2264 \u2113(c, r; \u03b8), which means l is the lower bound of \u2113. By maximizing the lower bound l, we can indirectly maximize \u2113, which is originally hard to optimize. Another important observation is hat l = \u2113 if and only if q(z) = p(z t |c t , r t ; \u03b8), which is exactly what we calculate during the E-steps in Eq. ( 7). Though the derivation of the posterior distribution of z is not exact since we assume uniform prior in Eq. ( 2), it is still much closer to the real distribution compared to random q(z).",
                    "It is worth noting that the global optimal point is not guaranteed to be reached by this algorithm, and it depends heavily on the initialization of model parameters or the training data for the first round of the maximization step. This explains the reason why we utilize a discourse parser to get a coarse initial training dataset instead of using the expectation step at the first iteration in Section 3.4."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Experiments",
                "text": [
                    "In this section, we first introduce the datasets to pre-train and evaluate our model, then present the experimental results and comparisons with previous methods."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Datasets and Experimental Setups",
                "text": [
                    "For pre-training, we adopt the second version of Ubuntu Dialogue Corpus (Lowe et al., 2015), which contains no annotated addressee labels. The original dataset contains 1M dialogues for training, and 0.5M dialogues for validation and testing, respectively. Dialogues that contain less than 4 turns, or have overlap with the dataset for the downstream task (the Ubuntu IRC benchmark, Hu et al. 2019), are excluded from the pre-training data. After filtering, we eventually get a pre-training dataset that contains 764,373 dialogues.",
                    "For fine-tuning, we follow previous works (Hu et al., 2019;Gu et al., 2022) to adopt the Ubuntu IRC benchmark, which is constructed by extracting all utterances with response addressees indicated by the \"@\" symbol in the Ubuntu Dialogue Corpus. In total, this dataset consists of 311,725 dialogues for training, and 5,000 dialogues for validation and testing, respectively. It is worth noting that this dataset contains addressee labels for every single utterance in the dialogue history, which are utilized by previous methods, yet not by ours.",
                    "For both pre-training and fine-tuning, BART (Lewis et al., 2020)  pre-training, we evaluate our model on the validation set of the Ubuntu IRC benchmark, and the best checkpoint is saved for the fine-tuning process."
                ],
                "publication_ref": [
                    "b13",
                    "b4",
                    "b8"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Baseline Models and Evaluation Metrics",
                "text": [
                    "Table 1 shows the results of our method and previous models, where GPT-2, GSN, and HeterMPC (Radford et al., 2018;Hu et al., 2019;Gu et al., 2022) are introduced in section 2.1 and 2.2, respectively. BART is a sequence-to-sequence model with encoder-decoder Transformer architecture and is trained using denoising objectives. Following Hu et al. (2019), we also adopt BLEU-1 to BLEU-4, METEOR, and ROUGE-L as the automatic evaluation metrics, which can be calculated using the pycocoevalcap package. Besides automatic evaluation, human evaluation is also conducted and will be introduced in Section 4.4."
                ],
                "publication_ref": [
                    "b16",
                    "b4"
                ],
                "figure_ref": [],
                "table_ref": [
                    "tab_2"
                ]
            },
            {
                "heading": "Automatic Evaluation Results",
                "text": [
                    "Let's firstly focus on the upper and middle part of Table 1, where we present the results of previous models and our methods. able to achieve comparable results with the previous state-of-the-art (SOTA) models. It is surprising since the pre-training requires no annotated addressee labels, while previous models not merely utilize the addressee information of the response utterance, but also make use of the addressee labels of the dialogue history to form a response graph. Second, fine-tuning our model on the downstream dataset with the ground truth addressee labels yields better results compared with pre-training only. Since it uses the ground truth addressee labels of responses, the results of it can be regarded as an upper bound of what the EM training can achieve. Besides, FO outperforms the previous SOTA model by large margins with even simpler architecture and fewer annotations (without addressee labels in the dialogue history), demonstrating the effectiveness of our proposed addressee embeddings. Finally, by further fine-tuning the pre-trained checkpoint with the ground truth addressee labels, we achieve the best performance on all metrics, which shows the transferability of our pre-trained model."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_2"
                ]
            },
            {
                "heading": "Human Evaluation Results",
                "text": [
                    "For human evaluation, we recruit a team with 8 members who have at least a Bachelor's degree in Computer Science and are familiar with Ubuntu and Linux. We randomly sample 100 examples from the testing set, then ask the team members to score each prediction and select the best one. The quality scores are considered in terms of three independent aspects: 1) relevance, 2) fluency and 3) informativeness. They are scored from 0-3 and the average values were reported. The evaluation results are shown in Table 2, where our model (Pre-training + Fine-tuning) constantly outperforms vanilla BART and the previous SOTA model HeterMPC BART . We also report the Fleiss's Kappa to indicate the agreement between annotators. Besides, the ratio of our predictions being the best response is the same as that of human responses, demonstrating the high quality of the generated responses of our model."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_3"
                ]
            },
            {
                "heading": "Analysis",
                "text": [
                    "In order to get more insights into the proposed EM pre-training method, we dive deeper into it by conducting extensive analyses."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Ablation Study",
                "text": [
                    "We conduct ablation studies to investigate the contribution of our different designs, whose results are tabulated in the lower part of Table 1. Firstly, let's focus on the first line of the lower part. To study whether other utterances that are not in the reply chain of the current addressee can help to generate a better response, we extract the reply train by traversing from the current leave utterance (the response) up to the root node (the first utterance), then train a model by inputting this chain only. We see a large performance drop on all metrics in this setting, demonstrating the significance of the side information provided by the whole context.",
                    "Second, let's pay attention to the second and third lines of the lower part. In order to study the effect of the EM pre-training process, which is the key contribution of our work, we remove this process and pre-train a model using only the addressee labels obtained from the discourse parser (i.e. the initial training data used in the first iteration of our EM approach). A sharp performance drop is observed compared with PO and PF with our proposed EM pre-training strategy, demonstrating the significance of our design. Without the iterative EM procedure, the noisy addressee labels obtained from the discourse parser can cause error propaga- tion, which makes the model learn noisy features to predict a response, and hurts the performance.",
                    "Finally, aiming at investigating whether the performance gains come from seeing more in-domain data in the pre-training process, we use the same pre-training data to train another model with the denoising objectives proposed in BART (Lewis et al., 2020), then also fine-tune it on the Ubuntu IRC benchmark. The last line of the lower part presents the results, where we observe nearly the same performance compared with FO. This observation indicates that simply performing domain adaptation using the general pre-training objectives is insufficient to benefit the MPDRG task."
                ],
                "publication_ref": [
                    "b8"
                ],
                "figure_ref": [],
                "table_ref": [
                    "tab_2"
                ]
            },
            {
                "heading": "Response Generation vs. Addressee Prediction",
                "text": [
                    "In Section 3.3, we prove that p(z|c, r) \u221d p(r|c, z).",
                    "To verify the correctness of this equation and also to investigate the training process of our EM strategy, we draw the line chart of the BLEU-4 score and addressee prediction accuracy of the top-30% confidence samples on the validation set with the increasing of pre-training iterations. The addressees are predicted using Eq. ( 4), where we take the z i with the highest conditional probability as the predicted addressee. Figure 4 illustrates the trending of the BLEU-4 score and addressee prediction accuracy. On the one hand, we see that the trending of both metrics is consistent, which means with a more powerful response generation model comes a higher addressee prediction accuracy. This observation verifies the correctness of Eq. ( 3). On the other hand, with the increasing of iterations, both metrics grow mutually, then reach their tops at around the 6 th iteration, demonstrating the effectiveness of the EM process.  "
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_2"
                ],
                "table_ref": []
            },
            {
                "heading": "Case Studies",
                "text": [
                    "To understand the effect of our method intuitively, we sample two cases from the testing set and present them in this section. Figure 5 illustrates an example whose addressee relations and dialogue history are shown in Figure 1. This conversation is about how to run the compiz or beryl in a comp with 256MB RAM. Speaker #2 points that it's the graphic card that is important, but Speaker #4 seems unsatisfied by saying that didn't tell me much. After that, Speaker #5 suggests using the rdesktop and Speaker #4 replies him/her. Our model is able to capture the key information rdesktop and terminal in the addressee utterance U 6 , and generate a proper response Well, how do I install rdesktop from the terminal, which is very close to the human answer and even better with more information from the terminal. On the contrary, the baseline model (BART) fails to capture the addressee information and just replies with a safe response I tried but it didn't work. This case shows the great significance of modeling the addressee information, and also demonstrates the effectiveness of our model design. Figure 6 presents another example sampled from the testing set, where we investigate how different addressee labels affect the generated responses. In the figure, different colors represent different utterances in the Dialogue History part, and different responses generated by giving the corresponding utterances as addressees in the Generated Responses part. This conversation is about discussing the file system in Ubuntu that can share on a network with windows machines. When the addressee is given as U 1 , our model suggests using samba, which is a solution to the question of U 1 . Responses to U 2 and U 3 are like safe responses, but they make sense in their contexts: the former expresses its confusion about a confusing utterance (U 2 ), and the latter expresses its gratitude to the suggestion in  U 3 . Response to U 4 states his/her understanding towards U 4 , and questions if his/her understanding is right. Response to U 5 acknowledges the solution gentoo in U 5 by saying using gentoo on my computer too. In general, this case demonstrates the ability of our model to generate diverse responses according to the specified addressees and contexts of the dialogue history."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_4",
                    "fig_0",
                    "fig_5"
                ],
                "table_ref": []
            },
            {
                "heading": "Response Parser: A Byproduct for Free",
                "text": [
                    "Another contribution of our EM pre-training is that a response parser can be freely obtained. This byproduct comes from Eq. ( 4), where given a response generation model with addressee modeling, we can predict the addressee for each utterance in the dialogue. Previous literature has studied and proved that explicitly modeling the structural information is beneficial to understanding specific structured data. (Li et al., 2020(Li et al., , 2022a,b),b). In this context, the response parser can be used to infer the discourse structures, which contributes to boosting the performance of some multi-party dialogue comprehension tasks like response selection and question answering. (Jia et al., 2020;Li and Zhao, 2021;Ma et al., 2022) 6 Conclusion",
                    "Most multi-party dialogue corpora are not annotated with addressee labels, making them unable to support the pre-training of response generation models. To solve this problem, we design a simple yet effective way to model the addressee of a response as a latent variable and propose an EM pre-training approach that iteratively performs the expectation steps to generate addressee labels, and the maximization steps to optimize a response generation model. Mathematical derivation, experimental results on the Ubuntu IRC benchmark, and extensive analyses have justified the theoretical feasibility and actual effectiveness of our method."
                ],
                "publication_ref": [
                    "b9",
                    "b6",
                    "b11",
                    "b14"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Limitations",
                "text": [
                    "First, Due to the lack of datasets to evaluate the MP-DRG task, we perform our experiments only on the Ubuntu IRC benchmark and pre-train our model only on the domain of Ubuntu chats. However, the potential of our approach goes far beyond that since it is applicable to any open-domain multi-party dialogue dataset. In the future work, we will consider applying our method in more open-domain conversational datasets, such as the transcripts of TV series or movies. Additionally, the pre-training process solely relies on the addressee information of individual turns, disregarding the reply-to relations within the dialogue history. This oversight prevents the model from benefiting from valuable contextual cues necessary for a comprehensive understanding of the multi-party dialogue. In our future work, we will explore the integration of discourse-level reply-to relations into the pre-training process to further enrich the capabilities of the model."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "",
                "text": [
                    "B2. Did you discuss the license or terms for use and / or distribution of any artifacts?",
                    "They are publicly available and can be found on github.",
                    "B3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided that it was specified? For the artifacts you create, do you specify intended use and whether that is compatible with the original access conditions (in particular, derivatives of data accessed for research purposes should not be used outside of research contexts)? Not applicable. Left blank.",
                    "B4. Did you discuss the steps taken to check whether the data that was collected / used contains any information that names or uniquely identifies individual people or offensive content, and the steps taken to protect / anonymize it? Not applicable. Left blank.",
                    "B5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and linguistic phenomena, demographic groups represented, etc.? Section 4. B6. Did you report relevant statistics like the number of examples, details of train / test / dev splits, etc. for the data that you used / created? Even for commonly-used benchmark datasets, include the number of examples in train / validation / test splits, as these provide necessary context for a reader to understand experimental results. For example, small differences in accuracy on large test sets may be significant, while on small test sets they may not be. Left blank."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "C Did you run computational experiments?",
                "text": [
                    "Section 4.",
                    "C1. Did you report the number of parameters in the models used, the total computational budget (e.g., GPU hours), and computing infrastructure used? They can be found on our code.",
                    "The Responsible NLP Checklist used at ACL 2023 is adopted from NAACL 2022, with the addition of a question on AI writing assistance."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            }
        ],
        "references": [
            {
                "ref_id": "b0",
                "title": "PLATO: Pre-trained dialogue generation model with discrete latent variable",
                "journal": "Online. Association for Computational Linguistics",
                "year": "2020",
                "authors": "Siqi Bao; Huang He; Fan Wang; Hua Wu; Haifeng Wang"
            },
            {
                "ref_id": "b1",
                "title": "DialogVED: A pre-trained latent variable encoder-decoder model for dialog response generation",
                "journal": "Association for Computational Linguistics",
                "year": "2022",
                "authors": "Wei Chen; Yeyun Gong; Song Wang; Bolun Yao; Weizhen Qi; Zhongyu Wei; Xiaowu Hu; Bartuer Zhou; Yi Mao; Weizhu Chen; Biao Cheng; Nan Duan"
            },
            {
                "ref_id": "b2",
                "title": "ELECTRA: pretraining text encoders as discriminators rather than generators",
                "journal": "",
                "year": "2020-04-26",
                "authors": "Kevin Clark; Minh-Thang Luong; Quoc V Le; Christopher D Manning"
            },
            {
                "ref_id": "b3",
                "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
                "journal": "Association for Computational Linguistics",
                "year": "2019",
                "authors": "Jacob Devlin; Ming-Wei Chang; Kenton Lee; Kristina Toutanova"
            },
            {
                "ref_id": "b4",
                "title": "HeterMPC: A heterogeneous graph neural network for response generation in multi-party conversations",
                "journal": "Association for Computational Linguistics",
                "year": "2022",
                "authors": "Jia-Chen Gu; Chao-Hong Tan; Chongyang Tao; Zhen-Hua Ling; Huang Hu; Xiubo Geng; Daxin Jiang"
            },
            {
                "ref_id": "b5",
                "title": "GSN: A graph-structured network for multi-party dialogues",
                "journal": "",
                "year": "2019-08-10",
                "authors": "Wenpeng Hu; Zhangming Chan; Bing Liu; Dongyan Zhao; Jinwen Ma; Rui Yan"
            },
            {
                "ref_id": "b6",
                "title": "Multi-turn response selection using dialogue dependency relations",
                "journal": "Online. Association for Computational Linguistics",
                "year": "2020",
                "authors": "Qi Jia; Yizhu Liu; Siyu Ren; Kenny Zhu; Haifeng Tang"
            },
            {
                "ref_id": "b7",
                "title": "Who is speaking to whom? learning to identify utterance addressee in multi-party conversations",
                "journal": "",
                "year": "2019",
                "authors": "Ran Le; Wenpeng Hu; Mingyue Shang; Zhenjun You; Lidong Bing; Dongyan Zhao; Rui Yan"
            },
            {
                "ref_id": "b8",
                "title": "BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
                "journal": "",
                "year": "2020",
                "authors": "Mike Lewis; Yinhan Liu; Naman Goyal; Marjan Ghazvininejad; Abdelrahman Mohamed; Omer Levy; Veselin Stoyanov; Luke Zettlemoyer"
            },
            {
                "ref_id": "b9",
                "title": "Molweni: A challenge multiparty dialogues-based machine reading comprehension dataset with discourse structure",
                "journal": "",
                "year": "2020",
                "authors": "Jiaqi Li; Ming Liu; Min-Yen Kan; Zihao Zheng; Zekun Wang; Wenqiang Lei; Ting Liu; Bing Qin"
            },
            {
                "ref_id": "b10",
                "title": "Semantic-preserving adversarial code comprehension",
                "journal": "",
                "year": "2022",
                "authors": "Yiyang Li; Hongqiu Wu; Hai Zhao"
            },
            {
                "ref_id": "b11",
                "title": "Self-and pseudo-selfsupervised prediction of speaker and key-utterance for multi-party dialogue reading comprehension",
                "journal": "",
                "year": "2021",
                "authors": "Yiyang Li; Hai Zhao"
            },
            {
                "ref_id": "b12",
                "title": "Back to the future: Bidirectional information decoupling network for multi-turn dialogue modeling",
                "journal": "",
                "year": "2022",
                "authors": "Yiyang Li; Hai Zhao; Zhuosheng Zhang"
            },
            {
                "ref_id": "b13",
                "title": "The Ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems",
                "journal": "Association for Computational Linguistics",
                "year": "2015",
                "authors": "Ryan Lowe; Nissan Pow; Iulian Serban; Joelle Pineau"
            },
            {
                "ref_id": "b14",
                "title": "Structural characterization for dialogue disentanglement",
                "journal": "Association for Computational Linguistics",
                "year": "2022",
                "authors": "Xinbei Ma; Zhuosheng Zhang; Hai Zhao"
            },
            {
                "ref_id": "b15",
                "title": "A discrete hard EM approach for weakly supervised question answering",
                "journal": "",
                "year": "2019",
                "authors": "Sewon Min; Danqi Chen; Hannaneh Hajishirzi; Luke Zettlemoyer"
            },
            {
                "ref_id": "b16",
                "title": "Improving language understanding by generative pre-training",
                "journal": "OpenAI Technical Report",
                "year": "2018",
                "authors": "Alec Radford; Karthik Narasimhan; Tim Salimans; Ilya Sutskever"
            },
            {
                "ref_id": "b17",
                "title": "The Thirty-First Innovative Applications of Artificial Intelligence Conference",
                "journal": "AAAI Press",
                "year": "2019-01-27",
                "authors": "Zhouxing Shi; Minlie Huang"
            },
            {
                "ref_id": "b18",
                "title": "Attention is all you need",
                "journal": "",
                "year": "2017-12-04",
                "authors": "Ashish Vaswani; Noam Shazeer; Niki Parmar; Jakob Uszkoreit; Llion Jones; Aidan N Gomez; Lukasz Kaiser; Illia Polosukhin"
            },
            {
                "ref_id": "b19",
                "title": "Response selection for multi-party conversations with dynamic topic tracking",
                "journal": "Online. Association for Computational Linguistics",
                "year": "2020",
                "authors": "Weishi Wang; C H Steven; Shafiq Hoi;  Joty"
            },
            {
                "ref_id": "b20",
                "title": "Addressee and response selection in multi-party conversations with speaker interaction rnns",
                "journal": "AAAI Press",
                "year": "2018-02-02",
                "authors": "Rui Zhang; Honglak Lee; Lazaros Polymenakos; Dragomir R Radev"
            },
            {
                "ref_id": "b21",
                "title": "DIALOGPT : Large-scale generative pre-training for conversational response generation",
                "journal": "",
                "year": "2020",
                "authors": "Yizhe Zhang; Siqi Sun; Michel Galley; Yen-Chun Chen; Chris Brockett; Xiang Gao; Jianfeng Gao; Jingjing Liu; Bill Dolan"
            },
            {
                "ref_id": "b22",
                "title": "Did you discuss the experimental setup, including hyperparameter search and best-found hyperparameter values? Section 4",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b23",
                "title": "error bars around results, summary statistics from sets of experiments), and is it transparent whether you are reporting the max, mean, etc",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b24",
                "title": "If you used existing packages (e.g., for preprocessing, for normalization, or for evaluation), did you report the implementation, model, and parameter settings used",
                "journal": "",
                "year": "",
                "authors": " Nltk;  Spacy;  Rouge"
            },
            {
                "ref_id": "b25",
                "title": "crowdworkers) or research with human participants? Section 4",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b26",
                "title": "Did you report the full text of instructions given to participants, including e.g., screenshots, disclaimers of any risks to participants or annotators",
                "journal": "",
                "year": "",
                "authors": " D1"
            },
            {
                "ref_id": "b27",
                "title": "crowdsourcing platform, students) and paid participants, and discuss if such payment is adequate given the participants' demographic",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b28",
                "title": "Did you discuss whether and how consent was obtained from people whose data you're using/curating? For example, if you collected data via crowdsourcing, did your instructions to crowdworkers explain how the data would be used?",
                "journal": "",
                "year": "",
                "authors": " D3"
            },
            {
                "ref_id": "b29",
                "title": "Was the data collection protocol approved (or determined exempt) by an ethics review board? Not applicable",
                "journal": "",
                "year": "",
                "authors": " D4"
            },
            {
                "ref_id": "b30",
                "title": "Did you report the basic demographic and geographic characteristics of the annotator population that is the source of the data?",
                "journal": "",
                "year": "",
                "authors": " D5"
            }
        ],
        "figures": [
            {
                "figure_label": "1",
                "figure_type": "figure",
                "figure_id": "fig_0",
                "figure_caption": "Figure 1 :1Figure 1: An example of multi-party dialogue response generation task, better view in color.",
                "figure_data": ""
            },
            {
                "figure_label": "33",
                "figure_type": "figure",
                "figure_id": "fig_1",
                "figure_caption": "Figure 3 Figure 3 :33Figure 3 illustrates the overview of our EM training process. During the E-steps, we compute the probability distribution of the latent variable (the addressee z). During the M-steps, we sample (c, r, z) triplets from this distribution and optimize the generative model by standard training algorithms.The ExpectationStep is to compute the conditional distribution of the latent variable z t , given the observed data (c t , r t ) and the current model",
                "figure_data": ""
            },
            {
                "figure_label": "4",
                "figure_type": "figure",
                "figure_id": "fig_2",
                "figure_caption": "Figure 4 :4Figure 4: Line chart of the BLEU-4 score and addressee prediction accuracy with the increase of EM iterations.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_3",
                "figure_caption": "[Speaker #4: Well, how do I install rdesktop from the terminal?] Baseline Model: [Speaker #4: I tried but it didn't work.]",
                "figure_data": ""
            },
            {
                "figure_label": "5",
                "figure_type": "figure",
                "figure_id": "fig_4",
                "figure_caption": "Figure 5 :5Figure 5: The first example of Case Studies, which shows the generated responses of our model and the baseline model.",
                "figure_data": ""
            },
            {
                "figure_label": "6",
                "figure_type": "figure",
                "figure_id": "fig_5",
                "figure_caption": "Figure 6 :6Figure 6: The second example of Case Studies, which illustrates the generated response of our model given different addressee labels. Better view in color.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "table",
                "figure_id": "tab_1",
                "figure_caption": "",
                "figure_data": "Generative Pre-trained Language Models (BART)U tBayesian Networkc tz t\u2026 \u2026\u2026 \u2026\u2026\u2026r tFigure 2: The overview of our model architecture. The left part shows how we incorporate the addressee information into response generation by adding addressee embeddings. The right part illustrates a Bayesian Network of how a response is generated given the current dialogue history c t and the addressee z t .withexplicit addressee labels to construct the UbuntuIRC benchmark, where they propose a Graph Struc-tured Neural Network (GSN) for dialogue model-ing. Specifically, they first treat each utterance"
            },
            {
                "figure_label": "1",
                "figure_type": "table",
                "figure_id": "tab_2",
                "figure_caption": "is used as the backbone model. Before pre-training, we initialize the pre-trained weights from BART-base. During the process of Results on the Ubuntu IRC benchmark, where the upper part presents models of previous works, the middle part shows our backbone model BART together with our method under different settings, and the lower part shows the ablation studies.",
                "figure_data": "ModelBLEU-1 BLEU-2 BLEU-3 BLEU-4 METEOR ROUGE-LGPT-2 (Radford et al., 2018) GSN (Hu et al., 2019) HeterMPCBART (Gu et al., 2022)10.37 10.23 12.263.60 3.57 4.801.66 1.70 2.420.93 0.97 1.494.01 4.10 4.949.53 9.91 11.20BART (Lewis et al., 2020) Pre-training Only (PO) Fine-tuning Only (FO) Pre-training + Fine-tuning (PF)11.25 11.78 11.47 12.314.02 4.67 5.11 5.391.78 2.38 2.98 3.340.95 1.41 2.11 2.454.46 4.98 5.23 5.529.90 11.19 11.31 11.71FO + Reply-Chain PO w/o EM PF w/o EM Denoising + Fine-tuning9.11 10.03 11.39 11.493.52 3.90 5.04 5.081.99 2.03 3.02 3.021.35 1.18 2.15 2.134.32 4.56 5.27 5.259.36 9.66 11.20 11.28"
            },
            {
                "figure_label": "2",
                "figure_type": "table",
                "figure_id": "tab_3",
                "figure_caption": "Human evaluation results, where Score is the average score and Best means the ratio of each system being the best response.",
                "figure_data": "Three settings of ourmethod based on BART are experimented with:pre-training only (PO), fine-tuning only (FO), andpre-training-fine-tuning (PF). Results of PO areobtained by directly using the pre-trained modelto generate the response for each dialogue. FOmeans the checkpoint of BART is directly fine-tuned on the Ubuntu IRC benchmark without pre-training. PF follows a pre-training-fine-tuningparadigm, where the best checkpoint of the pre-training process is further fine-tuned on the down-stream dataset.Three observations can be seen from the ta-ble. First of all, solely pre-training with our pro-posed EM method with unlabeled corpus is already"
            }
        ],
        "formulas": [
            {
                "formula_id": "formula_0",
                "formula_text": "X = {S 1 : U 1 [SEP]S 2 : U 2 [SEP] . . . S t-1 : U t-1 [SEP]S t :},",
                "formula_coordinates": [
                    3.0,
                    70.86,
                    720.35,
                    221.65,
                    34.06
                ]
            },
            {
                "formula_id": "formula_1",
                "formula_text": "p(c, z, r) = p(c) \u2022 p(z|c) \u2022 p(r|c, z)(1)",
                "formula_coordinates": [
                    4.0,
                    103.59,
                    232.39,
                    186.27,
                    20.55
                ]
            },
            {
                "formula_id": "formula_2",
                "formula_text": "p(z|c, r) = p(c, z, r) p(c, r) = p(c) \u2022 p(z|c) \u2022 p(r|c, z) p(c) \u2022 p(r|c) = p(z|c) \u2022 p(r|c, z) p(r|c)(2)",
                "formula_coordinates": [
                    4.0,
                    103.31,
                    307.13,
                    186.56,
                    85.29
                ]
            },
            {
                "formula_id": "formula_3",
                "formula_text": "p(z|c, r) \u221d p(r|c, z)(3)",
                "formula_coordinates": [
                    4.0,
                    135.37,
                    494.94,
                    154.5,
                    20.55
                ]
            },
            {
                "formula_id": "formula_4",
                "formula_text": "p(z i |c, r) = p(r|c, z i ) t\u22121 j=1 p(r|c, z j )(4)",
                "formula_coordinates": [
                    4.0,
                    116.02,
                    543.88,
                    173.84,
                    31.5
                ]
            },
            {
                "formula_id": "formula_5",
                "formula_text": "{(c k t , r k t , z k t )} N k=1",
                "formula_coordinates": [
                    4.0,
                    306.14,
                    412.98,
                    75.39,
                    20.41
                ]
            },
            {
                "formula_id": "formula_6",
                "formula_text": "L G = \u2212 N k=1 n k i=1 log p w k i | w k <i , c k t , z k t ; \u03b8 (5)",
                "formula_coordinates": [
                    4.0,
                    313.22,
                    465.42,
                    211.94,
                    35.4
                ]
            },
            {
                "formula_id": "formula_7",
                "formula_text": "r k t = {w k i } n i i=1",
                "formula_coordinates": [
                    4.0,
                    342.79,
                    524.92,
                    62.73,
                    21.42
                ]
            },
            {
                "formula_id": "formula_8",
                "formula_text": "\u2113(c, r; \u03b8) = log p(r|c; \u03b8) = log i p(r, z i |c; \u03b8) (6)",
                "formula_coordinates": [
                    5.0,
                    76.42,
                    340.86,
                    213.44,
                    34.17
                ]
            },
            {
                "formula_id": "formula_9",
                "formula_text": "l(c, r; \u03b8) = q(z i ) i log p(r, z i |c; \u03b8) q(z) = p(z t |c t , r t ; \u03b8) (7)",
                "formula_coordinates": [
                    5.0,
                    99.41,
                    440.05,
                    190.46,
                    49.18
                ]
            },
            {
                "formula_id": "formula_10",
                "formula_text": "\u2113(c, r; \u03b8) = log i p(r, z i |c; \u03b8) = log i q(z i ) \u2022 p(r, z i |c; \u03b8) q(z i ) \u2265 i q(z i ) \u2022 log p(r, z i |c; \u03b8) q(z i ) = i q(z i ) \u2022 log p(r, z i |c; \u03b8) \u2212 i q(z i ) \u2022 log q(z i ) = l(c, r; \u03b8) + H q(z)(8)",
                "formula_coordinates": [
                    5.0,
                    95.01,
                    541.98,
                    194.85,
                    174.39
                ]
            }
        ],
        "doi": "10.18653/v1/2020.acl-main.9"
    },
    "Explainable Recommendation with Personalized Review Retrieval and Aspect Learning": {
        "authors": "Hao Cheng; Shuo Wang; Wensheng Lu; Wei Zhang; Mingyang Zhou; Kezhong Lu; Hao Liao",
        "pub_date": "",
        "abstract": "Explainable recommendation is a technique that combines prediction and generation tasks to produce more persuasive results. Among these tasks, textual generation demands large amounts of data to achieve satisfactory accuracy. However, historical user reviews of items are often insufficient, making it challenging to ensure the precision of generated explanation text. To address this issue, we propose a novel model, ERRA (Explainable Recommendation by personalized Review retrieval and Aspect learning). With retrieval enhancement, ERRA can obtain additional information from the training sets. With this additional information, we can generate more accurate and informative explanations. Furthermore, to better capture users' preferences, we incorporate an aspect enhancement component into our model. By selecting the top-n aspects that users are most concerned about for different items, we can model user representation with more relevant details, making the explanation more persuasive. To verify the effectiveness of our model, extensive experiments on three datasets show that our model outperforms state-of-theart baselines (for example, 3.4% improvement in prediction and 15.8% improvement in explanation for TripAdvisor).",
        "sections": [
            {
                "heading": "Introduction",
                "text": [
                    "Recent years have witnessed a growing interest in the development of explainable recommendation models (Ai et al., 2018;Chen et al., 2021). In general, there are three different kinds of frameworks for explainable recommendation models, which are post-hoc (Peake and Wang, 2018), embedded (Chen et al., 2018) and multi-task learning methods (Chen et al., 2019b). Post-hoc methods generate explanations for a pre-trained model after the fact, leading to limited diversity in explanations. * Corresponding author Embedded methods, on the other hand, demonstrate efficacy in acquiring general features from samples and mapping data to a high-dimensional vector space. However, since embedded methods rely on historical interactions or features to learn representations, they may struggle to provide accurate recommendations for users or items with insufficient data.",
                    "In addition to the two frameworks mentioned above, there has been a utilization of multi-task learning frameworks in explainable recommendation systems, where the latent representation shared between user and item embeddings is employed (Chen et al., 2019b;Ai et al., 2018). These frameworks often employ the Transformer (Vaswani et al., 2017;Li et al., 2021b), a powerful text encoder and decoder structure widely used for textual processing tasks. While efficient for prediction tasks, they encounter challenges in generation tasks due to limited review content, leading to a significant decline in performance. Furthermore, these previous transformer-based frameworks do not incorporate personalized information and treat heterogeneous textual data indiscriminately. To address these issues, we make adaptations to the existing multi-task learning framework by incorporating two main components: retrieval enhancement, which alleviates the problem of data scarcity, and aspect enhancement, which facilitates the generation of specific and relevant explanations.",
                    "Real-world datasets usually contain redundant reviews generated by similar users, making the selected reviews uninformative and meaningless, which is illustrated in Figure 1. To address this issue, a model-agnostic retrieval enhancement method has been employed to identify and select the most relevant reviews. Retrieval is typically implemented using established techniques, such as TF-IDF (Term Frequency-Inverse Document Frequency) or BM25 (Best Match 25) (Lewis et al., 2020), which efficiently match keywords with an Figure 1: A user's reviews of different items and selected reviews by different models. Specifically, (a) a CNN-based method, by which the review selected is too general, (b) a user-id attention-based query method (Papineni et al., 2002), by which the review selected is not specific, (c) a Co-attention based method (Chen et al., 2019b), by which the review selected contain some details, (d) our model: retrieval-based method generates informative and personalized reviews that are relevant to the hotel. inverted index and represent the question and context using high-dimensional sparse vectors. This approach facilitates the generation of sufficient specific text, thereby attaining enhanced textual quality for the user. Generally, Wikipedia is utilized as a retrieval corpus for the purpose of aiding statement verification (Karpukhin et al., 2020;Yamada et al., 2021). Here, we adopt a novel approach wherein the training set of each dataset is utilized as the retrieval corpus. By integrating this component into our framework, we are able to generate sentences with more specific and relevant details. Consequently, this enhancement facilitates the generation of explanations that are more accurate, comprehensive, and informative at a finer granularity.",
                    "Moreover, users rarely share a common preference (Papineni et al., 2002). Therefore, aspects (Zhang et al., 2014), extracted from corresponding reviews, can be utilized to assist in the modeling of user representation. The incorporation of aspect enhancement has resulted in not only improved prediction accuracy, but also more personalized and user-specific text during the text generation process. By incorporating retrieval enhancement and aspect enhancement into our model, we adjust the transformer architecture to meet our needs, achieving better performance in both prediction and generation tasks.",
                    "The main contributions of our framework are as follows:",
                    "\u2022 In response to the problem of insufficient historical reviews for users and items in explainable recommendation systems, we propose a retrieval enhancement technique to supplement the available information with knowledge bases obtained from a corpus. To the best of our knowledge, this study represents the first application of retrievalenhanced techniques to review-based explainable recommendations.",
                    "\u2022 We propose a novel approach wherein different aspects are selected for individual users when interacting with different items, and are subsequently utilized to facilitate the modeling of user representation, thereby leading to the generation of more personalized explanations.",
                    "\u2022 Experimental results on real-world datasets demonstrate the effectiveness of our proposed approach, achieving superior performance compared to state-of-the-art baselines 2 .",
                    "2 Related Work"
                ],
                "publication_ref": [
                    "b0",
                    "b2",
                    "b26",
                    "b5",
                    "b5",
                    "b0",
                    "b32",
                    "b21",
                    "b16",
                    "b25",
                    "b5",
                    "b34",
                    "b25"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Explainable Recommendation with Generation",
                "text": [
                    "Explainable recommendation systems (Zhang et al., 2020) have been extensively studied using two primary methodologies: machine learning and human-computer interaction. The former (Gedikli et al., 2014;Chen and Wang, 2017) investigates how humans perceive different styles of explanations, whereas the latter generates explanations through the application of explainable recommendation algorithms, which is more relevant to our research. Numerous approaches exist for explaining recommendations, including the use of definition templates (Li et al., 2021a), image visualization (Chen et al., 2019a), knowledge graphs (Xian et al., 2019), and rule justifications (Shi et al., 2020). Among these methods, natural language explanations (Chen et al., 2019b;Li et al., 2021b) are gaining popularity due to their user accessibility, advancements in natural language processing techniques, and the availability of vast amounts of text data on recommendation platforms. Several studies have employed Recurrent Neural Network (RNN) networks (Li et al., 2017), coupled with Long Short-Term Memory (LSTM) (Graves and Graves, 2012), for generating explanatory texts, while others have utilized co-attention and Gated",
                    "Recurrent Unit (GRU) (Cho et al., 2014) in conjunction with Convolutional Attentional Memory Networks (CAML) (Chen et al., 2019b) for text generation. More recently, transformer-based networks have seen increased utilization for score prediction and interpretation generation. (Li et al., 2021b) 2.2 Pre-trained Models",
                    "The pre-trained model has gained significant traction in the field of NLP recently. These models, such as (Devlin et al., 2019;Reimers and Gurevych, 2019) are trained on large-scale opendomain datasets utilizing self-supervised learning tasks, which enables them to encode common language knowledge. The ability to fine-tune these models with a small amount of labeled data has further increased their utility for NLP tasks (Qiu et al., 2020;Ren et al., 2021). For example, a pre-trained model is Sentence-BERT (Reimers and Gurevych, 2019), which utilizes a multi-layer bidirectional transformer encoder and incorporates Masked Language Model and Next Sentence Prediction to capture word and sentence-level representations. Another example is UniLM (Dong et al., 2019), which builds upon the architecture of BERT and has achieved outstanding performance in a variety of NLP tasks including unidirectional, bidirectional, and sequence-to-sequence prediction. Furthermore, research has demonstrated that pre-trained models possess the capability to capture hierarchysensitive and syntactic dependencies (Qiu et al., 2020), which is highly beneficial for downstream NLP tasks. The utilization of pre-trained models has proven to be a powerful approach in NLP field, with the potential to further improve performance on a wide range of tasks."
                ],
                "publication_ref": [
                    "b9",
                    "b3",
                    "b19",
                    "b4",
                    "b33",
                    "b31",
                    "b5",
                    "b21",
                    "b3",
                    "b12",
                    "b6",
                    "b5",
                    "b21",
                    "b7",
                    "b28",
                    "b27",
                    "b29",
                    "b28",
                    "b8",
                    "b27"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Retrieval Enhancement",
                "text": [
                    "Retrieval-enhanced text generation has recently received increased attention due to its capacity to enhance model performance in a variety of natural language processing (NLP) tasks (Ren et al., 2021;Qiu et al., 2020). For instance, in open-domain question answering, retrieval-enhanced text generation models can generate the most up-to-date answers by incorporating the latest information during the generation process (Li and Gaussier, 2021;Li et al., 2020a). This is not possible for traditional text generation models, which store knowledge through large parameters, and the stored information is immutable. Retrieval-based methods also have an advantage in scalability, as they require fewer additional parameters compared to traditional text generation models (Ren et al., 2021). Moreover, by utilizing relevant information retrieved from external sources as the initial generation condition (Ren et al., 2021), retrieval-enhanced text generation can generate more diverse and accurate text compared to text generation without any external information."
                ],
                "publication_ref": [
                    "b29",
                    "b27",
                    "b22",
                    "b17",
                    "b29",
                    "b29"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Problem Statement",
                "text": [
                    "Our task is to develop a model that can accurately predict ratings for a specific product and provide a reasonable explanation for the corresponding prediction. The model's input is composed of various elements, namely the user ID, item ID, aspects, reviews, and retrieval sentences, whereas the resulting output of the model encompasses both a prediction and its explanation. We offer a detailed description of our models' input and output data in this section."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Input Data",
                "text": [
                    "\u2022 Heterogeneous information: The variables included in the framework encompass user ID u, item ID v, aspects A, retrieval sentences S and review R. Aspects A are captured in the form of a vector representing user's attention, denoted as (A u,1 , . . . , A u,n ), where A u,j represents the j-th aspect extracted from the reviews provided by user u. As an illustration, the review The screen of this phone is too small encompasses the aspect (screen, small). Regarding users, we extract the most important sentence S u,j from the set (S u,1 , ..., S u,n ). Similar operations are performed for items, where S v,j is employed. Ultimately, the user's review for the item R u,v is fed into the training process to enhance the ability to generate sentences."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Output Data",
                "text": [
                    "\u2022 Prediction and explaination: Given a user u and an item v, we can obtain a rating prediction ru,v , representing user u's preference towards item v and a generated explanatory text L = (l 1 , l 2 , . . . , l T ), providing a rationale for the prediction outcome. In this context, l i denotes the i-th word within the explanation text, while T represents the maximum length of the generated text."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Methodology",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Overview of Model",
                "text": [
                    "Here we present a brief overview of ERRA model. As shown in Figure 2, our model mainly consists of three components, each corresponding to a subprocess of the information processing model:",
                    "\u2022 Retrieval Enhancement aims to retrieve external knowledge from the training sets.",
                    "\u2022 Aspect Enhancement aims to identify the most important aspects that users are concerned about in their reviews.",
                    "\u2022 Joint Enhancement Transformers is responsible for the integration of the retrieved sentences and aspects with a transformer structure for simultaneously performing the prediction and explanation tasks.",
                    "Next, we will provide an in-depth description of each component and how they are integrated into a unified framework."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_0"
                ],
                "table_ref": []
            },
            {
                "heading": "Retrieval Enhancement",
                "text": [
                    "A major challenge in generating rich and accurate explanations for users is the lack of sufficient review data. However, this problem can be alleviated via retrieval-enhanced technology, which introduces external semantic information."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Retrieval Encode",
                "text": [
                    "The retrieval corpus is constructed using the training set. To obtain fine-grained information, lengthy reviews are divided into individual sentences with varied semantics. Using these sentences as searching unit allows the model to generate more fine-grained text. Sentence-BERT (Reimers and Gurevych, 2019) is utilized to encode each sentence in the corpus, which introduces no additional model parameters. We did not use other LLMs (Large Language Models) for retrieval encoding because it is optimized for dense retrieval and efficient for extensive experiments. Sentence-BERT is considerably faster than BERT-large or RoBERTa when encoding large-scale sentences and possesses an enhanced capacity for capturing semantic meaning, making it particularly well-suited for the retrieval task. The encoded corpus is saved as an embedding file, denoted as C. During the retrieval process, the most relevant information is directly searched from the saved vector C, which greatly improves the efficiency of retrieval."
                ],
                "publication_ref": [
                    "b28"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Retrieval Method",
                "text": [
                    "We adopt a searching model commonly used in the field of question answering (QA) and utilize cosine similarity for querying as a simple and efficient retrieval method. Here, we use the average of the review embedding U avg of each user as the query. This representation is in the same semantic space and also captures user preferential information to a certain extent. The average embedding U avg of all the reviews for a user is used as a query to retrieve the most similar n sentences (S u,1 , ..., S u,n ) in the previous corpus C. Our approach incorporates the Approximate Nearest Neighbor (ANN) search technique, with an instantiation based on the Faiss 3 library to improve retrieval speed through index creation. This optimization substantially decreases the total retrieval search duration. Then, in our implementation, we set n as 3 and stitch these sentences together to form a final sentence. Sentence-BERT is then used to encode this final sentence to obtain a vector S u,v , which represents the user for the item retrieval. Similarly, S v,u is used for items to retrieve users."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Aspect Enhancement",
                "text": [
                    "Users' preferences are often reflected in their reviews. To better represent users, we need to select the most important aspects of their reviews. Specifically, we first extract aspects from each user and item review using extraction tools. The extracted aspects from user reviews represent the style of the users in their reviews, while the extracted aspects from item reviews represent the most important features of the item. We aim to identify the most important aspects that users are concerned about in their reviews. It is worth noting that users' interests may vary in different situations. For example, when choosing a hotel, a user may care more about the environment. Whereas, price is a key factor to consider when buying a mobile phone. To address this, we use the average vector A v i ,avg , v i \u2208 V , representing all aspects under the item reviews, as the query. This vector is encoded using Sentence-BERT. For each user, we construct a local corpus of their aspects collection (A u i ,1 , ..., A u i ,l ), u i \u2208 U and use cosine similarity as the measurement indicator. We search for the top-n aspects from the local corpus by A v i ,avg . These retrieved aspects represent the top-n aspects that the user is concerned about this item. "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Joint Enhancement Transformers",
                "text": [
                    "In our proposed model, we adopt the transformer structure in the prediction and explanation tasks.",
                    "The transformer consists of multiple identical layers with each layer comprising two sub-layers: the multi-head self-attention and the position-wise feed feedback network. Previous research has made various modifications to the transformer architecture (Li et al., 2021b;Geng et al., 2022). Here we integrate the retrieved aspects with the encoding of multiple sentences in various ways. The retrieved sentences S U,j , S V,j are encoded uniformly as the input hidden vector s uv , s vu and are introduced into the first layer of the transformer.",
                    "Below, we use one layer as an example to introduce our calculation steps.",
                    "A i,h = softmax Q i,h K \u22a4 i,h \u221a d V i,h(1)",
                    "Q i,h = S i\u22121 W Q i,h , K i,h = S i\u22121 W K i,h ,(2)",
                    "V i,h = S i W V i,h(3)",
                    "where S i\u22121 \u2208 R |S|\u00d7d is the i-th layer's output,",
                    "W Q i,h , W K i,h , W V i,h \u2208 R d\u00d7 d",
                    "H are projection matrices, d denotes the dimension of embeddings and is set to 384. |S| denotes the length of the input sequence.",
                    "Subsequently, we incorporate aspect information into the model. As aspects are closely related to both users and items, we modify the internal mask structure of the model and combine the user's aspects and ID information through a selfattention mechanism. Not only does this strategy account for the uniqueness of the ID when modeling users, but also increase the personalization of the user's interactions with the item. Specifically, the same user may have different points of attention when interacting with different items. As illustrated in Figure 2, we make the information of the first four positions attend to each other, because the first two positions encode the unique user identifier, while the third and fourth positions encapsulate the personalized aspects of the user's preferences. The underlying rationale for selecting these positions is to facilitate the attention mechanism in capturing the interactions between users and products, ultimately enhancing the model's accuracy. At this point, our final input is as follows: For the two different information of ID and aspects, we use them jointly to represent the user and item. We use the self-attention mechanism to combine these two different semantic information, however, we found that it causes the final ID embedding matrix to be very close to the word embedding matrix, resulting in the loss of unique ID information and high duplication in generated sentences. To address this problem, we adopt the strategy from previous research (Geng et al., 2022) that only uses an ID to generate texts, and compares the generated text with the real text to compute the loss L c . To a certain extent, this method preserves the unique ID information in the process of combining aspects, thereby reducing the problem of repetitive sentences.",
                    "[U id , V id , A u 1 , A u 2 , s uv , s vu ,",
                    "L c = (u,v)\u2208T 1 |t len | |t len | t=1 \u2212 log H g ti v (4)",
                    "where T denotes the training set. g ti denotes that only use the hidden vector of the position H v to generate the i-th word, i \u2208 1, 2..., t len ."
                ],
                "publication_ref": [
                    "b21",
                    "b10",
                    "b10"
                ],
                "figure_ref": [
                    "fig_0"
                ],
                "table_ref": []
            },
            {
                "heading": "Rating Prediction",
                "text": [
                    "We utilized the two positions of the final layer (denoted as H v ) as the input. To combine the infor-mation of the ID and the hidden vector H v , we employed a multi-layer perceptron (MLP) to map the input into a scalar. The loss function used in this model is the Root Mean Square Error (RMSE) function.",
                    "r u,v = ReLU ([H v , u id , v id ]W l,1 ) W l,2(5)",
                    "L r = 1 |T | (u,v)\u2208T (r u,v \u2212 ru,v ) 2 (6)",
                    "where where W 1 \u2208 R 3d\u00d7d , W 2 \u2208 R d\u00d71 are weight parameters, r u,v is the ground-truth rating."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Explanation Generation",
                "text": [
                    "We adopt an auto-regressive methodology for word generation, whereby words are produced sequentially to form a coherent interpretation text. Specifically, we employ a greedy decoding strategy, wherein the model selects the word with the highest likelihood to sample at each time step. The model predicts the subsequent hidden vector based on the previously generated one, thereby ensuring the preservation of context throughout the entire generation process.",
                    "e t = softmax (W v H L,t + b v )(7)",
                    "where W v \u2208 R |V|\u00d7d and b v \u2208 R |V| are weight parameters. The vector e t represents the probability distribution over the vocabulary V."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Aspect Discriminator",
                "text": [
                    "To increase the probability that the selected aspects appear in explanation generation. We use the previous method (Chen et al., 2019b) and adapt it to our task. We represent \u03c4 as the aspects that interest this user, \u03c4 \u2208 R |V| . If the generated word at time t is an aspect, then \u03c4 a is 1. Otherwise, it is 0. The loss function is as follows:",
                    "L a = 1 |T | (u,v)\u2208T 1 |t len | |t len | t=1 (\u2212\u03c4 a log e t,a ) (8)"
                ],
                "publication_ref": [
                    "b5"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Text Generation",
                "text": [
                    "We propose a mask mechanism that allows for the efficient integration of ID, aspects, and retrieved sentence information into the hidden vector of the Beginning of Sentence (BOS) position. At each time step, the word hidden vector is transformed into a vocabulary probability through a matrix, and the word with the highest probability is selected via the Greedy algorithm. The generation process terminates when the predicted word is the End of Sentence (EOS) marker. To ensure that the generated text adheres to a specific length, we employ a padding and truncation strategy. When the number of generated words falls short of the set length, we fill in the remaining positions with a padding token (PAD). Conversely, when the number of generated words exceeds the set length, we truncate the later words. Here we use the Negative log-likelihood loss as a generated text L g . This loss function ensures the similarity between the generated words and the ground truth ones.",
                    "L g = 1 |T | (u,v)\u2208T 1 |t len | |t len | t=1 \u2212 log e gt 6+t (9)",
                    "where T denotes the training set. g t denotes the utilization of the 6+t position hidden vector to generate the t-th word, t \u2208 1, 2..., t len . 6 represents the initial first six positions vector information before the BOS, and t represents the current moment."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Multi-Task Learning",
                "text": [
                    "We aggregate losses to form the final objective function of our multi-task learning framework. The objective function is defined as:",
                    "L = plL r + \u03bb c L c + glL g + alL a + \u03bb l \u2225\u0398\u2225 2 2 (10)",
                    "where L g represents the loss function of text generation and L c is the loss function for context prediction, with pl and gl as their weights, respectively. L a is the loss function for aspect discriminator and al is its weights. \u0398 contains all the neural parameters."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Experiments",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Datasets",
                "text": [
                    "We performed experiments on three datasets, namely Amazon (cell phones), Yelp (restaurants), and TripAdvisor (hotels) (Li et al., 2020b). We  (Zhang et al., 2014) to extract the aspects in each review and correspond it to the respective review."
                ],
                "publication_ref": [
                    "b20"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Evaluation Metrics",
                "text": [
                    "For rating prediction, in order to evaluate the recommendation performance, we employ two commonly used indicators: Root Mean Square Error (RMSE) and Mean Absolute Error (MAE), which measure the deviation between the predicted ratings r and the ground truth ratings r * . For generated text, we adopt a variety of indicators that consider the quality of the generated text from different levels. BLEU (Papineni et al., 2002), ROUGE (Lin, 2004) and BERTscore (Reimers and Gurevych, 2019) are commonly used metrics in natural language generation tasks. BLEU-N (N=1,4) mainly counts on the N-grams. R2-P, R2-R, R2-F, RL-P, RL-R and RL-F denote Precision, Recall and F1 of ROUGE-2 and ROUGE-L. BERT-S represents similarity scores using contextual embeddings to calculate. They are employed to objectively evaluate the similarity between the generated text and the targeted content."
                ],
                "publication_ref": [
                    "b25",
                    "b24",
                    "b28"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Baseline Methods",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Prediction",
                "text": [
                    "The performance in terms of accuracy of rating prediction is compared with two types of methods: Machine Learning and Deep Learning:",
                    "\u2022 Deep learning models: NARRE (Chen et al., 2018) is a popular type of neural network for textbased tasks. PETER (Li et al., 2021b) and NRT (Li et al., 2017) are deep learning models that use review text for prediction and explanation at the same time.",
                    "\u2022 Factorization methods: PMF (Salakhutdinov and Mnih, 2007) is a matrix factorization method that uses latent factors to represent users and SVD++ (Koren, 2008) leverages a user's interacted items to enhance the latent factors."
                ],
                "publication_ref": [
                    "b21",
                    "b3",
                    "b30",
                    "b15"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Explainability",
                "text": [
                    "To evaluate the performance of explainability, we compare against three explanation methods, namely CAML (Chen et al., 2019b) and ReXPlug (Hada et al., 2021) and NRT and PETER.",
                    "\u2022 ReXPlug uses GPT-2 to generate texts and is capable of rating prediction.",
                    "\u2022 CAML uses users' historical reviews to represent users and uses co-attention mechanisms to pick the most relevant reviews and concepts and combine these concepts to generate text.",
                    "\u2022 NRT is an advanced deep learning method for explanation tasks. As a generative method, NRT mainly generates explanations based on predicted ratings and the distribution of words in tips.",
                    "\u2022 PETER is a powerful model improved by a transformer. This model effectively integrates the ID in the transformer and combines this ID information as the starting vector to generate text."
                ],
                "publication_ref": [
                    "b5",
                    "b13"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Reproducibility",
                "text": [
                    "We conduct experiments by randomly splitting the dataset into a training set (80%), validation set (10%), and test set (10%). The baselines are tuned by following the corresponding papers to ensure the best results. The embedded vector dimension is 384 and the value yielded superior performance after conducting a grid search within the range of [128,256,384,512,768,1024]. The maximum length of the generated sentence is set to 15-20. The weight of the rating prediction (pl) is set to 0.2, and the weight of the \u03bb c and al is set to either 0.8 or 0.05. For the explanation task, the parameter gl is adjusted to 1.0 and is initialized using the Xavier method (Glorot and Bengio, 2010). The models are optimized using the Adam optimizer with a learning rate of 10 \u22121 and L2 regularization of 10 \u22124 . When the model reaches the minimum loss in a certain epoch, the learning rate will be changed at that time and multiplied by 0.25. When the total loss of continuous three epochs has not decreased, the training process will terminate. More implementation details can be found on github 4 . "
                ],
                "publication_ref": [
                    "b11"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Explainability Study",
                "text": [
                    "Explainability results: Table 3 shows that our proposed ERRA method consistently outperforms the baselines in terms of BLEU and ROUGE on different datasets. For instance, take BLEU as an example, our method demonstrates the largest improvement on the TripAdvisor dataset. It is likely due to the smaller size of the dataset and the relatively short length of the reviews, which allows for additional information from the retrieved sentences and aspects to supplement the generated sentences, leading to an enhancement in their richness and accuracy. In contrast, the increase in BLEU on the Yelp dataset is relatively small. It is due to the large size of the Yelp dataset, which allows the model to be trained on a vast amount of data. The GPT (Brown et al., 2020) series also prove this case, large amounts of data can train the model well, resulting in our retrieval not having as obvious an improvement compared to other datasets. Similarly, when compared with NRT and PE-TER, our model consistently outperforms them in all metrics. Whether it is in terms of the fluency of the sentence, the richness of the text, or the consistency with the real label, our model has achieved excellent results.",
                    "Case study: We take three cases generated from three datasets by NRT, PETER, and ERRA method as examples. Table 4 shows that ERRA model can predict keywords, which are both closer to the original text and match the consumers' opinions, generating better explanations compared to the baseline. While the baseline model always generates statements and explanations that are not specific and detailed enough, our model can generate personalized, targeted text, such as the battery doesn't last long in Case 2 and excellent! The food here is very delicious! in Case 3. This either is the same as or similar to the ground truth.",
                    "Human evaluation: We also evaluate the model's usefulness in generated sentences via the fluency evaluation experiment, which is done by human judgment. We randomly selected 1000 samples and invited 10 annotators to assign scores. Five "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_3",
                    "tab_5"
                ]
            },
            {
                "heading": "Accuracy of Prediction",
                "text": [
                    "The evaluation result of prediction accuracy is shown in "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Ablation Analysis",
                "text": [
                    "In order to investigate the contribution of individual modules in our proposed model, we performed ablation studies by removing the retrieval enhancement and aspect module denoted as \"ERRA-R\" and \"ERRA-A\", From Figure 3(a), we can see that the retrieval module plays a crucial role in enhancing the performance of the explanation generation task. Specifically, for the Amazon and TripAdvisor datasets, the difference between \"ERRA-R\" and ERRA is the largest for explanation generation, while showing mediocrity in the prediction task. Additionally, we also evaluated the impact of  the aspect enhancement module on performance. Without this key module, discernible degradation can be observed in both the prediction and explanation tasks, which is shown in Figure 3(b). This can be attributed to the diverse attention points of individual users. The aspects can more accurately represent the user's preference, thus making the prediction more accurate and the generated text more personalized."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_1",
                    "fig_1"
                ],
                "table_ref": []
            },
            {
                "heading": "Conclusion",
                "text": [
                    "In this paper, we propose a novel model, called ERRA, that integrates personalized aspect selection and retrieval enhancement for prediction and explanation tasks. To address the issue of incorrect embedding induced by data sparsity, we incorporate personalized aspect information and rich review knowledge corpus into our model. Experimental results demonstrate that our approach is highly effective compared with state-of-the-art baselines on both the accuracy of recommendations and the quality of corresponding explanations."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Limitation",
                "text": [
                    "Despite the promising results obtained in our model, there are still several areas for improvement. Firstly, when dealing with a large corpus, the online retrieval function becomes challenging as it requires a significant amount of computational resources and time. Additionally, creating a vectorized corpus dynamically every time becomes difficult. Secondly, the process of collecting a large number of reviews from users raises privacy concerns. The collection of data, especially from private and non-public sources, may pose difficulties. "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Acknowledgments",
                "text": [
                    "The authors thank all the anonymous reviewers for their valuable comments and constructive feedback. The authors acknowledge financial support from the National Natural Science Foundation of China (Grant Nos. 62276171 and 62072311), Shenzhen Fundamental Research-General Project (Grant Nos. JCYJ20190808162601658, 20220811155803001, 20210324094402008 and 20200814105901001), CCF-Baidu Open Fund (Grant No. OF2022028), and Swiftlet Fund Fintech funding. Hao Liao is the corresponding author."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "",
                "text": [
                    "B2. Did you discuss the license or terms for use and / or distribution of any artifacts? Not applicable. Left blank.",
                    "B3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided that it was specified? For the artifacts you create, do you specify intended use and whether that is compatible with the original access conditions (in particular, derivatives of data accessed for research purposes should not be used outside of research contexts)? Not applicable. Left blank.",
                    "B4. Did you discuss the steps taken to check whether the data that was collected / used contains any information that names or uniquely identifies individual people or offensive content, and the steps taken to protect / anonymize it? Not applicable. Left blank.",
                    "B5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and linguistic phenomena, demographic groups represented, etc.? Not applicable. Left blank.",
                    "B6. Did you report relevant statistics like the number of examples, details of train / test / dev splits, etc. for the data that you used / created? Even for commonly-used benchmark datasets, include the number of examples in train / validation / test splits, as these provide necessary context for a reader to understand experimental results. For example, small differences in accuracy on large test sets may be significant, while on small test sets they may not be. Not applicable. Left blank.",
                    "C Did you run computational experiments? 5 C1. Did you report the number of parameters in the models used, the total computational budget (e.g., GPU hours), and computing infrastructure used? 5",
                    "The Responsible NLP Checklist used at ACL 2023 is adopted from NAACL 2022, with the addition of a question on AI writing assistance."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            }
        ],
        "references": [
            {
                "ref_id": "b0",
                "title": "Learning heterogeneous knowledge base embeddings for explainable recommendation",
                "journal": "",
                "year": "2018",
                "authors": "Qingyao Ai; Vahid Azizi; Xu Chen; Yongfeng Zhang; ; Jared D Kaplan; Prafulla Dhariwal; Amanda "
            },
            {
                "ref_id": "b1",
                "title": "Neural attentional rating regression with review-level explanations",
                "journal": "",
                "year": "2018",
                "authors": "Chong Chen; Min Zhang; Yiqun Liu; Shaoping Ma"
            },
            {
                "ref_id": "b2",
                "title": "Generate natural language explanations for recommendation",
                "journal": "",
                "year": "2021",
                "authors": "Hanxiong Chen; Xu Chen; Shaoyun Shi; Yongfeng Zhang"
            },
            {
                "ref_id": "b3",
                "title": "Explaining recommendations based on feature sentiments in product reviews",
                "journal": "",
                "year": "2017",
                "authors": "Li Chen; Feng Wang"
            },
            {
                "ref_id": "b4",
                "title": "Personalized fashion recommendation with visual explanations based on multimodal attention network: Towards visually explainable recommendation",
                "journal": "",
                "year": "2019",
                "authors": "Xu Chen; Hanxiong Chen; Hongteng Xu; Yongfeng Zhang"
            },
            {
                "ref_id": "b5",
                "title": "Co-attentive multi-task learning for explainable recommendation",
                "journal": "",
                "year": "2019",
                "authors": "Zhongxia Chen; Xiting Wang; Xing Xie; Tong Wu; Guoqing Bu; Yining Wang; Enhong Chen"
            },
            {
                "ref_id": "b6",
                "title": "Learning phrase representations using RNN encoder-decoder for statistical machine translation",
                "journal": "",
                "year": "2014",
                "authors": "Kyunghyun Cho; Bart Van Merri\u00ebnboer; Caglar Gulcehre; Dzmitry Bahdanau; Fethi Bougares; Holger Schwenk; Yoshua Bengio"
            },
            {
                "ref_id": "b7",
                "title": "BERT: pre-training of deep bidirectional transformers for language understanding",
                "journal": "",
                "year": "2019",
                "authors": "Jacob Devlin; Ming-Wei Chang; Kenton Lee; Kristina Toutanova"
            },
            {
                "ref_id": "b8",
                "title": "Unified language model pre-training for natural language understanding and generation",
                "journal": "",
                "year": "2019",
                "authors": "Li Dong; Nan Yang; Wenhui Wang; Furu Wei; Xiaodong Liu; Yu Wang; Jianfeng Gao; Ming Zhou; Hsiao-Wuen Hon"
            },
            {
                "ref_id": "b9",
                "title": "How should i explain? a comparison of different explanation types for recommender systems",
                "journal": "International Journal of Human-Computer Studies",
                "year": "2014",
                "authors": "Fatih Gedikli; Dietmar Jannach; Mouzhi Ge"
            },
            {
                "ref_id": "b10",
                "title": "Improving personalized explanation generation through visualization",
                "journal": "",
                "year": "2022",
                "authors": "Shijie Geng; Zuohui Fu; Yingqiang Ge; Lei Li; Gerard De Melo; Yongfeng Zhang"
            },
            {
                "ref_id": "b11",
                "title": "Understanding the difficulty of training deep feedforward neural networks",
                "journal": "",
                "year": "2010",
                "authors": "Xavier Glorot; Yoshua Bengio"
            },
            {
                "ref_id": "b12",
                "title": "Long short-term memory. Supervised sequence labelling with recurrent neural networks",
                "journal": "",
                "year": "2012",
                "authors": "Alex Graves; Alex Graves"
            },
            {
                "ref_id": "b13",
                "title": "Rexplug: Explainable recommendation using plug-and-play language model",
                "journal": "",
                "year": "2021",
                "authors": "V Deepesh;  Hada; M Vijaikumar; Shirish K Shevade"
            },
            {
                "ref_id": "b14",
                "title": "Dense passage retrieval for open-domain question answering",
                "journal": "",
                "year": "2020-11-16",
                "authors": "Vladimir Karpukhin; Barlas Oguz; Wen-Tau Yih"
            },
            {
                "ref_id": "b15",
                "title": "Factorization meets the neighborhood: a multifaceted collaborative filtering model",
                "journal": "",
                "year": "2008",
                "authors": "Yehuda Koren"
            },
            {
                "ref_id": "b16",
                "title": "Retrieval-augmented generation for knowledge-intensive nlp tasks",
                "journal": "",
                "year": "2020",
                "authors": "Patrick Lewis; Ethan Perez; Aleksandra Piktus; Fabio Petroni; Vladimir Karpukhin; Naman Goyal; Heinrich K\u00fcttler; Mike Wen-Tau Yih; Tim Rockt\u00e4schel"
            },
            {
                "ref_id": "b17",
                "title": "Parade: Passage representation aggregation for document reranking",
                "journal": "",
                "year": "2020",
                "authors": "Canjia Li; Andrew Yates; Sean Macavaney; Ben He; Yingfei Sun"
            },
            {
                "ref_id": "b18",
                "title": "Generating long and informative reviews with aspect-aware coarse-to-fine decoding",
                "journal": "",
                "year": "2019",
                "authors": "Junyi Li; Wayne Xin Zhao; Ji-Rong Wen; Yang Song"
            },
            {
                "ref_id": "b19",
                "title": "Caesar: context-aware explanation based on supervised attention for service recommendations",
                "journal": "Journal of Intelligent Information Systems",
                "year": "2021",
                "authors": "Lei Li; Li Chen; Ruihai Dong"
            },
            {
                "ref_id": "b20",
                "title": "Generate neural template explanations for recommendation",
                "journal": "",
                "year": "2020",
                "authors": "Lei Li; Yongfeng Zhang; Li Chen"
            },
            {
                "ref_id": "b21",
                "title": "Personalized transformer for explainable recommendation",
                "journal": "",
                "year": "2021",
                "authors": "Lei Li; Yongfeng Zhang; Li Chen"
            },
            {
                "ref_id": "b22",
                "title": "Keybld: Selecting key blocks with local pre-ranking for long document information retrieval",
                "journal": "",
                "year": "2021",
                "authors": "Minghan Li; Eric Gaussier"
            },
            {
                "ref_id": "b23",
                "title": "Neural rating regression with abstractive tips generation for recommendation",
                "journal": "",
                "year": "2017",
                "authors": "Piji Li; Zihao Wang; Zhaochun Ren; Lidong Bing; Wai Lam"
            },
            {
                "ref_id": "b24",
                "title": "Rouge: A package for automatic evaluation of summaries",
                "journal": "",
                "year": "2004",
                "authors": "Chin-Yew Lin"
            },
            {
                "ref_id": "b25",
                "title": "Bleu: a method for automatic evaluation of machine translation",
                "journal": "",
                "year": "2002",
                "authors": "Kishore Papineni; Salim Roukos; Todd Ward; Wei-Jing Zhu"
            },
            {
                "ref_id": "b26",
                "title": "Explanation mining: Post hoc interpretability of latent factor models for recommendation systems",
                "journal": "",
                "year": "2018",
                "authors": "Georgina Peake; Jun Wang"
            },
            {
                "ref_id": "b27",
                "title": "Pre-trained models for natural language processing: A survey",
                "journal": "Science China Technological Sciences",
                "year": "2020",
                "authors": "Xipeng Qiu; Tianxiang Sun; Yige Xu; Yunfan Shao; Ning Dai; Xuanjing Huang"
            },
            {
                "ref_id": "b28",
                "title": "Sentence-bert: Sentence embeddings using siamese bert-networks",
                "journal": "",
                "year": "2019",
                "authors": "Nils Reimers; Iryna Gurevych"
            },
            {
                "ref_id": "b29",
                "title": "Rocketqav2: A joint training method for dense passage retrieval and passage re-ranking",
                "journal": "",
                "year": "2021",
                "authors": "Ruiyang Ren; Yingqi Qu; Jing Liu; Wayne Xin Zhao; Qiaoqiao She; Hua Wu; Haifeng Wang; Ji-Rong Wen"
            },
            {
                "ref_id": "b30",
                "title": "Probabilistic matrix factorization",
                "journal": "",
                "year": "2007",
                "authors": "Ruslan Salakhutdinov; Andriy Mnih"
            },
            {
                "ref_id": "b31",
                "title": "Neural logic reasoning",
                "journal": "",
                "year": "2020",
                "authors": "Shaoyun Shi; Hanxiong Chen; Weizhi Ma; Jiaxin Mao; Min Zhang; Yongfeng Zhang"
            },
            {
                "ref_id": "b32",
                "title": "Attention is all you need",
                "journal": "",
                "year": "2017",
                "authors": "Ashish Vaswani; Noam Shazeer; Niki Parmar; Jakob Uszkoreit; Llion Jones; Aidan N Gomez; Lukasz Kaiser; Illia Polosukhin"
            },
            {
                "ref_id": "b33",
                "title": "Reinforcement knowledge graph reasoning for explainable recommendation",
                "journal": "",
                "year": "2019",
                "authors": "Yikun Xian; Zuohui Fu; S Muthukrishnan; Gerard De Melo; Yongfeng Zhang"
            },
            {
                "ref_id": "b34",
                "title": "Efficient passage retrieval with hashing for open-domain question answering",
                "journal": "",
                "year": "2021",
                "authors": "Ikuya Yamada; Akari Asai; Hannaneh Hajishirzi"
            },
            {
                "ref_id": "b35",
                "title": "error bars around results, summary statistics from sets of experiments), and is it transparent whether you are reporting the max, mean, etc",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b36",
                "title": "If you used existing packages (e.g., for preprocessing, for normalization, or for evaluation), did you report the implementation, model, and parameter settings used",
                "journal": "",
                "year": "",
                "authors": " Nltk;  Spacy;  Rouge"
            },
            {
                "ref_id": "b37",
                "title": "crowdworkers) or research with human participants? 5.5",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b38",
                "title": "Did you report the full text of instructions given to participants, including e.g., screenshots, disclaimers of any risks to participants or annotators",
                "journal": "",
                "year": "",
                "authors": " D1"
            },
            {
                "ref_id": "b39",
                "title": "crowdsourcing platform, students) and paid participants, and discuss if such payment is adequate given the participants' demographic (e.g., country of residence)? Not applicable",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b40",
                "title": "Did you discuss whether and how consent was obtained from people whose data you're using/curating? For example, if you collected data via crowdsourcing, did your instructions to crowdworkers explain how the data would be used?",
                "journal": "",
                "year": "",
                "authors": " D3"
            },
            {
                "ref_id": "b41",
                "title": "Was the data collection protocol approved (or determined exempt) by an ethics review board? Not applicable",
                "journal": "",
                "year": "",
                "authors": " D4"
            },
            {
                "ref_id": "b42",
                "title": "Did you report the basic demographic and geographic characteristics of the annotator population that is the source of the data? Not applicable",
                "journal": "",
                "year": "",
                "authors": " D5"
            }
        ],
        "figures": [
            {
                "figure_label": "2",
                "figure_type": "figure",
                "figure_id": "fig_0",
                "figure_caption": "Figure 2 :2Figure 2: An overview of the ERRA framework.",
                "figure_data": ""
            },
            {
                "figure_label": "3",
                "figure_type": "figure",
                "figure_id": "fig_1",
                "figure_caption": "Figure 3 :3Figure 3: Ablation analysis of prediction and explanation tasks",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "table",
                "figure_id": "tab_0",
                "figure_caption": "t 1 , . . . , t |t len | ]. After including the location [P 1 , P 2 , P 3 , . . . , P |s| ], where |s| is the length of the input, the final input becomes [H 1 , H 2 , H 3 , . . . , H |s| ].",
                "figure_data": ""
            },
            {
                "figure_label": "1",
                "figure_type": "table",
                "figure_id": "tab_1",
                "figure_caption": "Statistics of the datasets",
                "figure_data": "DatasetsYelpAmazon TripAdvisorNumber of users27,147157,2129,765Number of items20,26648,1866,280Number of reviews 1,293,247 1,128,437320,023Records per user47.647.1832.77Records per item63.8123.4150.96"
            },
            {
                "figure_label": "2",
                "figure_type": "table",
                "figure_id": "tab_2",
                "figure_caption": "Results of prediction",
                "figure_data": "YelpAmazonTripAdvisorPMFR \u2193 1.097 0.883 1.235 0.913 0.870 0.704 M \u2193 R \u2193 M \u2193 R \u2193 M \u2193SVD++ 1.022 0.793 1.196 0.871 0.811 0.623NARRE 1.028 0.791 1.176 0.865 0.796 0.612DAML1.014 0.784 1.173 0.858 0.793 0.617NRT1.016 0.796 1.188 0.853 0.797 0.611CAML1.026 0.798 1.191 0.878 0.818 0.622PETER 1.017 0.793 1.181 0.863 0.814 0.635ERRA1.008 0.781 1.158 0.832 0.787 0.603filtered out users with fewer than 5 comments andre-divided the dataset into three sub-datasets inthe ratio of 8:1:1. The details of the datasets areshown in Table 1. We use an aspects extraction tool"
            },
            {
                "figure_label": "3",
                "figure_type": "table",
                "figure_id": "tab_3",
                "figure_caption": "Results of explanation",
                "figure_data": "DatasetsMetricsBaselines NRT CAML ReXPlug PETER ERRA-A ERRA-R ERRA OursImprovementAmazon Yelp TripAdvisorBLEU1 13.37 11.19 BLEU4 1.44 1.12 R2-P 2.06 1.48 R2-R 2.08 1.23 R2-F 1.97 1.24 RL-P 12.52 9.32 RL-R 12.20 10.11 RL-F 10.77 8.11 BERT-S 75.4 74.9 BLEU1 10.5 9.91 BLEU4 0.67 0.56 R2-P 1.95 1.78 R2-R 1.29 1.05 R2-F 1.35 1.25 RL-P 15.88 14.25 RL-R 10.72 14.26 RL-F 9.53 9.16 BERT-S 83.6 83.2 BLEU1 15.78 14.43 BLEU4 0.85 0.86 R2-P 1.98 1.49 R2-R 1.92 1.91 R2-F 1.9 1.92 RL-P 14.85 13.36 RL-R 14.03 12.38 RL-F 12.25 12.39 BERT-S 82.7 84.810.8 1.29 2.17 1.12 1.22 9.20 10.58 8.73 75.3 8.59 0.57 1.49 1.07 1.11 13.32 9.56 8.70 82.2 12.64 0.71 1.61 1.49 1.61 11.38 10.22 9.97 83.213.78 1.68 2.21 2.02 1.97 12.62 12.06 11.07 76.2 10.29 0.69 1.91 1.31 1.43 16.07 10.14 10.26 83.3 15.33 0.89 1.92 2.01 1.94 13.54 14.75 12.61 86.414.07 1.76 2.67 2.86 2.34 15.85 14.11 12.49 78.1 10.62 0.71 1.95 1.34 1.46 16.45 10.83 10.62 84.7 15.93 1.02 2.03 2.1 2.02 15.3 14.93 13.08 87.613.28 1.64 2.37 2.33 2.18 13.49 12.67 11.97 77.3 10.59 0.71 1.90 1.29 1.41 15.95 10.21 10.14 83.1 15.43 0.95 1.97 1.98 1.99 14.84 14.77 12.79 86.914.38 1.88 2.71 2.93 2.57 16.13 14.41 13.87 79.8 10.71 0.73 2.03 1.36 1.48 16.60 11.23 10.82 85.2 16.13 1.06 2.09 2.15 2.05 15.40 15.02 13.17 88.14.17% 10.6% 14.8% 17.6% 21.2% 19.7% 16.3% 18.1% 4.5% 3.92% 5.43% 5.91% 3.6% 2.36% 3.19% 9.7% 5.1% 2.2% 5.9% 15.8% 8.1% 9.7% 5.3% 8.6% 1.81% 4.50% 1.96%"
            },
            {
                "figure_label": "2",
                "figure_type": "table",
                "figure_id": "tab_4",
                "figure_caption": "",
                "figure_data": ". As we can see, it shows that ourmethod consistently outperforms baseline methodsincluding PMF, NRT, and PETER in RMSE andMSE for all datasets. We mainly compare the per-formance of our model with the PETER model,which is a state-of-the-art method. Our modeldemonstrates a significant improvement over thebaseline methods on the TripAdvisor dataset. Weattribute this improvement to the way we modelusers. By taking aspects into consideration, ourmodel is capable of accurately modeling users.And this in turn can generate more accurate pre-dictions. As shown in Table 2, ERRA's predictiveindicator is the best result on each dataset."
            },
            {
                "figure_label": "4",
                "figure_type": "table",
                "figure_id": "tab_5",
                "figure_caption": "Explanations generated by ERRA and Baseline. PETER The hotel service is pretty good! looks very nice! ERRA The room environment is pretty comfortable! The traffic here is very convenient. Case 2 -Truth The screen of this phone is too small and his battery drains fast so I can't stand it. Aspects:(screen, too small) (battery, fast) NRT The phone is bad. PETER The phone is bad, It works poorly and I don't like it. ERRA I really hate this phone, the battery doesn't last long, the screen is faulty. Case 3 -Truth Delicious! The customer service is pretty good and the open all the way to 3 am in the morning. The prime foods are excellent! Aspects:(service, good) (foods, excellent) NRT The service is pretty good. PETER he tastes delicious! The service is pretty good! ERRA excellent! The service here is pretty good. The food here is very delicious! There are many unique foods in it and open till dawn.",
                "figure_data": "Case 1 -Truth NRTThe environment of this hotel is comfortable and the trans-portation is very convenient and the sound insulation effect is great. Aspects:(environment, comfortable) (hotel, insula-tion) The environment of this hotel is best!"
            },
            {
                "figure_label": "5",
                "figure_type": "table",
                "figure_id": "tab_6",
                "figure_caption": "Results of the fluency evaluation.",
                "figure_data": "Measures Fluency KappaNRT 2.73 (0.67)CAML ReXPlug ERRA 2.92 3.11 3.45 (0.63) (0.74) (0.79)"
            },
            {
                "figure_label": "",
                "figure_type": "table",
                "figure_id": "tab_7",
                "figure_caption": "Joint Conference on Natural Language Processing, pages 979-986. Yongfeng Zhang, Xu Chen, et al. 2020. Explainable recommendation: A survey and new perspectives. Foundations and Trends in Information Retrieval, 14(1):1-101. Yongfeng Zhang, Guokun Lai, and Shaoping Ma. 2014. Explicit factor models for explainable recommendation based on phrase-level sentiment analysis. In The 37th International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 83-92.",
                "figure_data": ""
            }
        ],
        "formulas": [
            {
                "formula_id": "formula_0",
                "formula_text": "A i,h = softmax Q i,h K \u22a4 i,h \u221a d V i,h(1)",
                "formula_coordinates": [
                    5.0,
                    101.91,
                    609.74,
                    187.96,
                    30.99
                ]
            },
            {
                "formula_id": "formula_1",
                "formula_text": "Q i,h = S i\u22121 W Q i,h , K i,h = S i\u22121 W K i,h ,(2)",
                "formula_coordinates": [
                    5.0,
                    96.51,
                    656.07,
                    193.36,
                    16.8
                ]
            },
            {
                "formula_id": "formula_2",
                "formula_text": "V i,h = S i W V i,h(3)",
                "formula_coordinates": [
                    5.0,
                    145.71,
                    681.51,
                    144.16,
                    15.25
                ]
            },
            {
                "formula_id": "formula_3",
                "formula_text": "W Q i,h , W K i,h , W V i,h \u2208 R d\u00d7 d",
                "formula_coordinates": [
                    5.0,
                    70.2,
                    718.35,
                    121.55,
                    22.52
                ]
            },
            {
                "formula_id": "formula_4",
                "formula_text": "[U id , V id , A u 1 , A u 2 , s uv , s vu ,",
                "formula_coordinates": [
                    5.0,
                    306.14,
                    356.27,
                    126.07,
                    14.32
                ]
            },
            {
                "formula_id": "formula_5",
                "formula_text": "L c = (u,v)\u2208T 1 |t len | |t len | t=1 \u2212 log H g ti v (4)",
                "formula_coordinates": [
                    5.0,
                    339.08,
                    639.21,
                    186.07,
                    38.83
                ]
            },
            {
                "formula_id": "formula_6",
                "formula_text": "r u,v = ReLU ([H v , u id , v id ]W l,1 ) W l,2(5)",
                "formula_coordinates": [
                    6.0,
                    87.64,
                    164.13,
                    202.23,
                    13.85
                ]
            },
            {
                "formula_id": "formula_7",
                "formula_text": "L r = 1 |T | (u,v)\u2208T (r u,v \u2212 ru,v ) 2 (6)",
                "formula_coordinates": [
                    6.0,
                    110.6,
                    198.81,
                    179.27,
                    33.52
                ]
            },
            {
                "formula_id": "formula_8",
                "formula_text": "e t = softmax (W v H L,t + b v )(7)",
                "formula_coordinates": [
                    6.0,
                    111.72,
                    440.67,
                    178.14,
                    14.16
                ]
            },
            {
                "formula_id": "formula_9",
                "formula_text": "L a = 1 |T | (u,v)\u2208T 1 |t len | |t len | t=1 (\u2212\u03c4 a log e t,a ) (8)",
                "formula_coordinates": [
                    6.0,
                    81.45,
                    629.85,
                    208.41,
                    38.83
                ]
            },
            {
                "formula_id": "formula_10",
                "formula_text": "L g = 1 |T | (u,v)\u2208T 1 |t len | |t len | t=1 \u2212 log e gt 6+t (9)",
                "formula_coordinates": [
                    6.0,
                    329.78,
                    384.18,
                    195.37,
                    38.83
                ]
            },
            {
                "formula_id": "formula_11",
                "formula_text": "L = plL r + \u03bb c L c + glL g + alL a + \u03bb l \u2225\u0398\u2225 2 2 (10)",
                "formula_coordinates": [
                    6.0,
                    311.6,
                    577.76,
                    213.56,
                    20.96
                ]
            }
        ],
        "doi": ""
    },
    "ACLM: A Selective-Denoising based Generative Data Augmentation Approach for Low-Resource Complex NER": {
        "authors": "Sreyan Ghosh; Utkarsh Tyagi; Manan Suri; \u2663 Sonal",
        "pub_date": "",
        "abstract": "Complex Named Entity Recognition (NER) is the task of detecting linguistically complex named entities in low-context text. In this paper, we present ACLM (Attention-map aware keyword selection for Conditional Language Model fine-tuning), a novel data augmentation approach, based on conditional generation, to address the data scarcity problem in lowresource complex NER. ACLM alleviates the context-entity mismatch issue, a problem existing NER data augmentation techniques suffer from and often generates incoherent augmentations by placing complex named entities in the wrong context. ACLM builds on BART and is optimized on a novel text reconstruction or denoising task -we use selective masking (aided by attention maps) to retain the named entities and certain keywords in the input sentence that provide contextually relevant additional knowledge or hints about the named entities. Compared with other data augmentation strategies, ACLM can generate more diverse and coherent augmentations preserving the true word sense of complex entities in the sentence. We demonstrate the effectiveness of ACLM both qualitatively and quantitatively on monolingual, crosslingual, and multilingual complex NER across various low-resource settings. ACLM outperforms all our neural baselines by a significant margin (1%-36%). In addition, we demonstrate the application of ACLM to other domains that suffer from data scarcity (e.g., biomedical). In practice, ACLM generates more effective and factual augmentations for these domains than prior methods.",
        "sections": [
            {
                "heading": "Introduction",
                "text": [
                    "Named Entity Recognition (NER) is a fundamental task in Natural Language Processing (NLP) that aims to detect various types of named entities (NEs) from text. Recently, there has been 1 Code: https://github.com/Sreyan88/ACLM * These authors contributed equally to this work.",
                    "considerable progress in NER using neural learning methods that achieve state-of-the-art (SOTA) performance (Wang et al., 2021;Zhou and Chen, 2021) on well-known benchmark datasets, including CoNLL 2003 (Tjong Kim Sang and De Meulder, 2003) and OntoNotes (Schwartz et al., 2012). However, these datasets are designed to evaluate the performance on detecting \"relatively easy\" NEs like proper names (e.g., people such as \"Barack Obama,\" locations such as \"New York,\" or organizations such as \"IBM\") in well-formed, contextrich text that comes from news articles (Augenstein et al., 2017). On the other hand, complex NER benchmarks like MultiCoNER (Malmasi et al., 2022) present several contemporary challenges in NER, including short low-context texts with emerging and semantically ambiguous complex entities (e.g., movie names in online comments) that reduce the performance of SOTA methods previously evaluated only on the existing NER benchmark datasets. Our experiments reveal that the performance of the current SOTA NER method (Zhou and Chen, 2021) (previously evaluated only on the CoNLL 2003 dataset) drops by 23% when evaluated on MultiCoNER and 31.8% when evaluated on a low-resource setting with just 500 training samples (more details in Table 8). Thus, we emphasize that research on building systems that can effectively detect complex NEs in the text is currently understudied in the field of NLP.",
                    "In the past, researchers have made several attempts at building supervised approaches to detect complex and compositional noun phrase entities in sentences (Doddington et al., 2004;Biggio et al., 2010;Magnolini et al., 2019). However, the scarcity of annotated training data for building effective systems has always been a challenge. Data augmentation has been shown to be an effective solution for low-resource NER (Ding et al., 2020;Liu et al., 2021;Zhou et al., 2022). In practice, though these systems perform well and generate coherent augmentations on common NER benchmark datasets with easy proper noun NEs, they fail to be effective for complex NER, often generating incoherent augmentations. We first argue that certain types of complex NEs follow specific linguistic patterns and appear only in specific contexts (examples in Appendix 4), and augmentations that do not follow these patterns impede a NER model from learning such patterns effectively. This sometimes also leads to augmentations with context-entity mismatch, further hurting the learning process. For e.g., unlike proper names, substituting complex NEs from other sentences in the corpus or replacing them with synonyms (Dai and Adel, 2020a) often leads to augmentations where the NE does not fit into the new context (e.g., swapping proper names across sentences might still keep the sentence coherent but swapping the name of a book with a movie (both creative work entity) or the name of a football team with a political party (both group entity) makes it incoherent). Fine-tuning pretrained language models (PLMs), similar to priorwork (Ding et al., 2020;Liu et al., 2021;Zhou et al., 2022), fail to generate new context around complex NEs or completely new NEs with the desired linguistic patterns due to low-context sentences and the lack of existing knowledge of such linguistically complex NEs (examples in Fig. 3). This leads to in-coherent augmentations and poses a severe problem in knowledge-intensive tasks like biomedical NER, where non-factual augmentations severely hurt learning. Our experiments also reveal that introducing new context patterns around NEs proves to be a more effective data augmentation technique for complex NER than diversifying NEs (ACLM vs. MELM in Table 1).",
                    "Main Results: To overcome the aforesaid problems, we formulate data augmentation as a conditional generation task and propose ACLM, a conditional text generation model that generates augmentation samples by introducing new and diverse context patterns around a NE. ACLM builds on BART (Lewis et al., 2020) and is fine-tuned on a modification of the text reconstruction from corrupted text task, a common denoising-based PLM pre-training objective. In contrast to other PLM pretraining strategies, which randomly mask a portion of the text for corruption, our modified objective is based on selective masking, wherein we mask all other words in the sentence except the NEs and a small percentage of keywords related to the NEs.",
                    "We refer to this corrupted sentence as a template, and it serves as input to the model for both the training and generation phases. These keywords are other non-NE tokens in the sentence that provide contextually relevant additional knowledge or hints to BART about the complex NEs without the need of retrieving knowledge from any external sources. We select these keywords using attention maps obtained from a transformer model fine-tuned on the NER task, and they help the PLM overcome the problem where it might not possess enough knowledge about a semantically ambiguous complex NE (example in Fig. 3). Training ACLM on this modified objective allows us to generate diverse, coherent, factual, and high-quality augmentations given templates. We also propose mixner, a novel algorithm that mixes two templates during the augmentation generation phase and boosts the diversity of augmentations. Our primary contributions are as follows:",
                    "\u2022 We propose ACLM, a novel data augmentation framework specially designed for lowresource complex NER. Compared with previous methods in the literature, ACLM effectively alleviates the context-entity mismatch problem by preserving the true sense of semantically ambiguous NEs in augmentations.",
                    "Additionally, to accompany ACLM, we propose mixner, which boosts the diversity of ACLM generations.",
                    "\u2022 We qualitatively and quantitively show the benefits of ACLM for monolingual, crosslingual, and multilingual complex NER across various low-resource settings on the Multi-CoNER dataset. Our proposed ACLM outperforms all other baselines in literature by a significant margin (1%-36%) and generates more diverse, coherent, and high-quality augmentations compared to them.",
                    "\u2022 We perform extensive experiments to study the application of ACLM in three other domains, including science and medicine. ACLM outperforms all our baselines in these domains (absolute gains in the range of 1%-11%) and generates more factual augmentations."
                ],
                "publication_ref": [
                    "b37",
                    "b42",
                    "b36",
                    "b33",
                    "b42",
                    "b12",
                    "b4",
                    "b26",
                    "b11",
                    "b25",
                    "b41",
                    "b9",
                    "b11",
                    "b25",
                    "b41",
                    "b23"
                ],
                "figure_ref": [],
                "table_ref": [
                    "tab_9",
                    "tab_0"
                ]
            },
            {
                "heading": "Background and Related Work",
                "text": [
                    "Complex NER Background: Complex NER is a relatively understudied task in the field of NLP.",
                    "Building on insights from Augenstein et al. ( 2017), we discuss key reasons behind high performance on common NER benchmark datasets and try to understand why modern SOTA NER algorithms do not work well on complex NER benchmarks:",
                    "(1) Context: Most of the common benchmark datasets are curated from articles in the news domain. This gives them several advantages, including rich context and surface features like proper punctuation and capitalized nouns, all of which are major drivers of success in these datasets (Mayhew et al., 2019). In contrast, for entity recognition beyond news text, like search queries or voice commands, the context is less informative and lacks surface features (Guo et al., 2009;Carmel et al., 2014); (2) Entity Complexity: Data from news articles contain proper names or \"easy\" entities with simple syntactic structures, thus allowing pretrained models to perform well due to their existing knowledge of such entities. On the other hand, complex NEs like movie names are syntactically ambiguous and linguistically complex and which makes Complex NER a difficult task (Ashwini and Choi, 2014). Examples of such entities include noun phrases (e.g., Eternal Sunshine of the Spotless Mind), gerunds (e.g., Saving Private Ryan), infinitives (e.g., To Kill a Mockingbird), or full clauses (e.g., Mr. Smith Goes to Washington); (3) Entity Overlap: Models trained on these common benchmark datasets suffer from memorization effects due to the large overlap of entities between the train and test sets. Unseen and emerging entities pose a huge challenge to complex NER (Bernier-Colborne and Langlais, 2020).",
                    "Complex NER: Prior work has mostly focused on solving the entity complexity problem by learning to detect complex nominal entities in sentences (Magnolini et al., 2019;Meng et al., 2021;Fetahu et al., 2022;Chen et al., 2022). Researchers have often explored integrating external knowledge in the form of gazetteers for this task. Gazetteers have also proven to be effective for low-resource NER (Rijhwani et al., 2020). GemNet (Meng et al., 2021), the current SOTA system for complex NER, conditionally combines the contextual and gazetteer features using a Mixture-of-Experts (MoE) gating mechanism. However, gazetteers are difficult to build and maintain and prove to be ineffective for complex NER due to their limited entity coverage and the nature of unseen and emerging entities in complex NER.",
                    "Data Augmentation for Low-Resource NER: Data Augmentation to handle data scarcity for lowresource NLP is a well-studied problem in the literature and is built on word-level modifications, including simple synonym replacement strategies (Wei and Zou, 2019), or more sophisticated learning techniques like LSTM-based language models (Kobayashi, 2018), Masked Language Modeling (MLM) using PLMs (Kumar et al., 2020), auto-regressive PLMs (Kumar et al., 2020), or constituent-based tagging schemes (Zhou et al., 2019). However, most of these methods, though effective for classification tasks, suffer from tokenlabel misalignment when applied to token-level tasks such as NER and might require complex preprocessing steps (Bari et al., 2020;Zhong and Cambria, 2021). One of the first works to explore effective data augmentation for NER replaces NEs with existing NEs of the same type or replaces tokens in the sentence with one of their synonyms retrieved from WordNet (Dai and Adel, 2020b). Following this, many neural learning systems were proposed that either modify the Masked Language Modelling (MLM) training objective using PLMs (Zhou et al., 2022;Liu et al.) or use generative language modeling with LSTM LMs (Ding et al., 2020) or mBART (Liu et al., 2021), to produce entirely new sentences from scratch. However, all these systems were designed for low-resource NER on common benchmark datasets and failed to generate effective augmentations for low-resource complex NER with semantically ambiguous and complex entities."
                ],
                "publication_ref": [
                    "b28",
                    "b15",
                    "b5",
                    "b1",
                    "b26",
                    "b29",
                    "b6",
                    "b32",
                    "b29",
                    "b38",
                    "b21",
                    "b22",
                    "b22",
                    "b40",
                    "b2",
                    "b39",
                    "b10",
                    "b41",
                    "b11",
                    "b25"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Methodology",
                "text": [
                    "In this section, we give an overview of our approach. Fig. 1 represents the entire workflow of our ACLM data augmentation framework. A sentence is first passed through a fine-tuned XLM-RoBERTa fine-tuned on only gold data to generate the attention map for each token in the sentence. This attention map is then used to selectively mask the sentence and create a template. This template is then used as an input to optimize the model on the text reconstruction objective for fine-tuning ACLM: the model is asked to reconstruct the entire original sentence from only the content in the template. While generating augmentations, ACLM follows the same template generation process in addition to adding two templates through mixner, which we discuss in detail in Section 3.3."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_2"
                ],
                "table_ref": []
            },
            {
                "heading": "Keyword Selection",
                "text": [
                    "he advanced, attacked the enemy 's infantry with the lance, and then retired while the enemy swarmed out of hidden ground where royal artillery GRP guns could attack them. Semantically similar sentence the enemy's infantry was swarmed to the ground with royal artilleryGRP guns.",
                    "ashby was wounded on the foot while a regiment member of the kentuckyLOC regiment was sent to the war.",
                    "ashby conducted raids across the line from kentucky LOC and the enemy were attacked and later retired by hidden ground royal artilleryGRP guns."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Generated Samples:",
                "text": [
                    "he advanced, attacked the enemy's infantry with the lance, and then retired while the enemy swarmed out of hidden ground where <b-grp> royal <b-grp> <i-grp> artillery <i-grp> guns could attack them.",
                    "Text Reconstruction:  \u20dd Labeled Sequence Linearization: Label tokens are added before and after each entity in the sentence. 4",
                    "\u20dd Dynamic Masking: The template goes through further masking where a small portion of the keywords are dynamically masked at each training iteration. While generation we also apply mixner, which randomly joins two templates after 3 \u20dd and before 4 \u20dd. Post generating augmentations with ACLM, the generated augmentations are concatenated with the gold data and used to fine-tune our final NER model."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Template Creation",
                "text": [
                    "To corrupt a sentence and create a template, we follow a 4-step process described below:",
                    "1. Keyword Selection: For each sentence in our training corpus, we first obtain a set of non-NE tokens in the sentence that are most attended to by its NEs. We call these tokens keywords. For our research, we consider a non-NE token as a keyword if the NEs in the sentence contextually depend on them the most. We measure contextual dependency between NE and non-NE tokens using attention scores from attention maps extracted from a transformer-based NER model fine-tuned only on gold data. We hypothesize that attention heads in a transformer when fine-tuned for NER, formulated as a token-level tagging task, tend to pay the highest attention to the most contextually relevant tokens around it. Thus, formally put, consider a sentence with a total of T tokens comprised of t other non-NE and t entity NE tokens. Our primary aim is to find the top p% of t other tokens, which we call keywords. To calculate the total attention score that each token in the sentence assigns to each other token, we sum up the attention scores across each of the heads in the transformer network and across the last a layers (a = 4 in our case). Different heads in different layers tend to capture different properties of language, and taking the average attention scores across the last 4 layers ensures that diverse linguistic relations are taken into account while choosing the keywords (e.g., syntactic, semantic, etc.). This also makes the keyword selection process more robust, as in low-resource conditions the attention maps may be noisy, and the NEs might not be focusing on the right context always. Additionally, the choice of just the last four layers is inspired by the fact that the lower layers have very broad attention and spend at most 10% of their attention mass on a single token (Clark et al., 2019). Note t entity might be comprised of (1) multiple contiguous tokens forming an individual NE and (2) multiple such individual NEs. To handle the first case, inspired from Clark et al. (2019), we sum up the attention scores over all the individual tokens in the NE. For the second case, we find t attn for each individual NE and take a set union of tokens in these t attn . Thus, as an extra pre-processing step, to improve robustness, we also ignore punctuations, stop words, and other NEs from the top p% of t other tokens to obtain our final keywords. We provide examples of templates in Appendix C.",
                    "2. Selective Masking: After selecting the top p% of t other tokens in the sentence as keywords, we now have K non-NE keyword tokens and E entity tokens. To create the template, we now substitute each non-NE token not belonging to the K with the mask token and remove contiguous mask tokens.",
                    "3. Labeled Sequence Linearization: After we have our initial template, inspired by Zhou et al. (2022), we perform labeled sequence linearization to explicitly take label information into consideration during fine-tuning and augmentation generation. Similar to Zhou et al. (2022), as shown in Figure 1, we add label tokens before and after each entity token and treat them as the normal context in the sentence. Additionally, these label tokens before and after each NE provide boundary supervision for NEs with multiple tokens.",
                    "4. Dynamic Masking: Post labeled sequence linearization, our template goes through further masking wherein we dynamically mask a small portion of the K keywords during each iteration of training and generation. To be precise, we first sample a dynamic masking rate \u03b5 from a Gaussian distribution N (\u00b5, \u03c3 2 ), where the Gaussian variance \u03c3 is set to 1/K. Next, we randomly sample tokens from the K keywords in the sentence according to the masking rate \u03b5 and replace this with mask tokens, followed by removing consecutive mask tokens. At every round of generation, dynamic masking helps boost 1) context diversity by conditioning ACLM generation on different templates with a different set of keywords and 2) length diversity by asking ACLM to infill a different number of mask tokens."
                ],
                "publication_ref": [
                    "b7",
                    "b7",
                    "b41",
                    "b41"
                ],
                "figure_ref": [
                    "fig_2"
                ],
                "table_ref": []
            },
            {
                "heading": "Fine-tuning ACLM",
                "text": [
                    "As discussed earlier, ACLM is fine-tuned on a novel text reconstruction from corrupted text task wherein the created templates serve as our corrupted text and ACLM learns to recover the original text from the template. Text reconstruction from the corrupted text is a common denoising objective that PLMs like BART and BERT are pre-trained on. For this work, we use it as our fine-tuning objective and differ from other existing pre-training objectives by our selective masking strategy for creating templates."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Data Generation",
                "text": [
                    "Post fine-tuning on the text reconstruction task, we utilize ACLM to generate synthetic data for data augmentation. For each sentence in the training dataset, we apply steps 1-4 in the Template Creation pipeline for R rounds to randomly corrupt the sentence and obtain a template which is then passed through the fine-tuned ACLM model to generate a total of R\u00d7 augmented training samples. Additionally, to boost diversity, during auto-regressive the 1988 elections were also held on a non party basis, although around 30 candidates sympathetic to the muslim brotherhood GRP were elected.",
                    "a nonpartisan candidate, george washington PER , carried the state twice ( in 1789 and 1792 ). generation, we randomly sample the next word from the top-k most probable words and choose the most probable sequence with beam search. mixner: During the R rounds of augmentation on our training dataset, we propose the use of mixner, a novel template mixing algorithm that helps ACLM generate diverse sentences with new context and multiple NEs in the sentence. More specifically, given the template for any arbitrary sentence a in the training set in step 3 of the template creation process, we retrieve the template for another sentence b that is semantically similar to a and join both the templates before passing on the template to step 4. We show examples of sentences generated with mixner in Fig. 3 and Section D.1. Note that we apply mixner only in the generation step and not during fine-tuning.",
                    "As mentioned earlier, to retrieve b from the training set, we randomly sample a sentence from the top-k sentences with the highest semantic similarity to a. To calculate semantic similarity between each sentence in the training set, we first take the embedding e for each sentence from a multi-lingual Sentence-BERT (Reimers and Gurevych, 2019) and then calculate semantic similarity by: sim(e i , e j ) = e i \u22c5 e j \u2225e i \u2225 \u2225e j \u2225",
                    "(1)",
                    "where sim(. ) is the cosine similarity between two embeddings , and i, j \u2208 N where i \u2260 j, and N is the size if the training set. Additionally, we don't apply mixner on all rounds R but sample a probability \u03b3 from a Gaussian distribution N (\u00b5, \u03c3 2 ) and only apply mixner if \u03b3 crosses a set threshold \u03b2."
                ],
                "publication_ref": [
                    "b31"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Post-Processing",
                "text": [
                    "As a post-processing step, we remove augmentations similar to the original sentence and also the extra label tokens added in the labeled sequence linearization step. Finally, we concatenate the augmented data with the original data to fine-tune our NER model."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Experiments and Results",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Dataset",
                "text": [
                    "All our experiments were conducted on the Multi-CoNER dataset (Malmasi et al., 2022), a large multilingual dataset for complex NER. MultiCoNER covers 3 domains, including Wiki sentences, questions, and search queries, across 11 distinct languages. The dataset represents contemporary challenges in NER discussed in Section 2 and is labeled with six distinct types of entities: person, location, corporation, groups (political party names such as indian national congress), product (consumer products such as apple iPhone 6), and creative work (movie/song/book titles such as on the beach). We conduct experiments on a set of 10 languages L where L = {English (En), Bengali (Bn, Hindi (Hi), German (De), Spanish (Es), Korean (Ko), Dutch (Nl), Russian (Ru), Turkish (Tr), Chinese (Zh)}. Language-wise dataset statistics can be found in Table 12. We would also like to highlight that the number of sentences in MultiCoNER test sets ranges from 133,119 -217,887, which is much higher than test sets of other existing NER datasets. For more details on the dataset, we refer our readers to Malmasi et al. (2022). For monolingual and cross-lingual low-resource experiments, we perform iterative stratified sampling over all the sentences by using the entity classes in a sample as its target label across four low-resource settings (100, 200, 500, and 1000). We downsample the development set accordingly. For multi-lingual experiments, we combine all the data sampled for our monolingual settings. We evaluate all our systems and baselines on the original MultiCoNER test sets. We report micro-averaged F1 scores averaged across 3 runs for 3 different random seeds."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_2"
                ]
            },
            {
                "heading": "Algorithm 1 ACLM: Our proposed augmentation framework",
                "text": [
                    "Given training set D train , and PLM L",
                    "D masked \u2190 \u2205, D aug \u2190 \u2205 for {X, Y } \u2208 D train do \u25b7 Training Loop t other , t entity \u2190 X K \u2190 T op p% of ATTNMAP(t other ) \u25b7 Keyword Selection X \u2190 GENTEMPLATE(X, {t other } \u2212 {K}) \u25b7 Selective Masking X \u2190 LINEARIZE( X, Y ) \u25b7 Labeled Sequence Linearization D masked \u2190 D masked \u222a { X} end for for {X, Y } \u2208 D masked do X \u2190 DYNAMICMASK(X, \u03b7) \u25b7 Dynamic Masking L f inetune \u2190 FINETUNE(L, X) \u25b7 Fine-tune ACLM end for for {X, Y } \u2208 D train do \u25b7 Generation Loop repeat R times: X \u2190 GENTEMPLATE(X, {t other } \u2212 {K}) \u25b7 Selective masking X \u2190 LINEARIZE( X, Y ) \u25b7 Labeled Sequence Linearization X \u2190 DYNAMICMASK( X, \u00b5) \u25b7 Dynamic Masking X aug \u2190 GENAUG(L f inetune ( X)), if \u03b3 < \u03b2 X augmix \u2190 MIXNER(L f inetune ( X)), if \u03b3 > \u03b2 D aug \u2190 D aug \u222a {X aug } \u222a {X augmix } end for D aug \u2190 POSTPROCESS(D aug ) \u25b7 Post-processing return D train \u222a D aug 4.2 Experimental Setup",
                    "ACLM. We use mBart-50-large (Tang et al., 2020) with a condition generation head to fine-tune ACLM. We fine-tune ACLM for 10 epochs using Adam optimizer (Kingma and Ba, 2014) with a learning rate of 1e",
                    "\u22125 and a batch size of 32.",
                    "NER. We use XLM-RoBERTa-large with a linear head as our NER model. Though the field of NER has grown enormously, in this paper, we adhere to the simplest formulation and treat the task as a token-level classification task with a BIO tagging scheme. We use the Adam optimizer to optimize our model, set the learning rate to 1e \u22122 , and train with a batch size of 16. The NER model is trained for 100 epochs, and the model with the best performance on the dev set is used for testing.",
                    "Hyper-parameter Tuning. For template creation during fine-tuning and generation, we set the selection rate p and the Gaussian \u00b5 to be 0.3 and 0.5, respectively. The number of augmentation rounds R is set as 5. For mixner we set Gaussian \u00b5 and \u03b2 to be 0.5 and 0.7, respectively. All hyper-parameters are tuned on the development set with grid search. More details can be found in Appendix A."
                ],
                "publication_ref": [
                    "b35"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Baselines",
                "text": [
                    "To prove the effectiveness of our proposed ACLM, we compare it with several strong NER augmentation baselines in the literature. In this sub-section, we briefly describe each of these baselines. All baselines were run for R rounds.",
                    "Gold-Only. The NER model is trained using only gold data from the MultiCoNER dataset without any augmentation. ACLM random. We train and infer ACLM with templates created with randomly sampled keywords instead of taking keywords with high attention scores. This baseline proves the effectiveness of our keyword selection algorithm which provides NEs in the template with rich context. ACLM only entity. We train and infer ACLM with templates created with only linearized entities and no keywords. This baseline proves the effectiveness of additional context in our templates."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Experimental Results",
                "text": [
                    "Monolingual Complex NER. and 500) which we acknowledge is a reasonable size in real-world conditions.",
                    "Cross-lingual Complex NER. We also study the cross-lingual transferability of a NER model trained on a combination of gold and generated augmentations. Thus, we evaluated a model, trained on En, on 4 other languages, including Hi, Bn, De, and Zh in a zero-shot setting. ACLM outperforms our neural baselines by a significant margin (absolute gains in the range of 1% -21%). None of these systems perform well in cross-lingual transfer to Zh which was also observed by (Hu et al., 2021).",
                    "Multi-lingual Complex NER. Table 2 compares the performance of all our baselines with ACLM on the MultiCoNER test sets under various multilingual low-resource settings. As clearly evident, ACLM outperforms all our baselines by a significant margin (absolute gains in the range of 1%-21% across individual languages). All our baselines, including our Gold-Only baseline, also perform better than their monolingual counterparts which demonstrates the effectiveness of multi-lingual finetuning for low-resource complex NER.",
                    "5 Further Analysis 5.1 Generation Quality Quantitative Analysis. Table 3 compares augmentations from various systems on the quantitative measures of perplexity and diversity. Perplexity (Jelinek et al., 1977) is a common measure of text fluency, and we measure it using GPT2 (Radford et al., 2019). We calculate 3 types of diversity metrics: for Diversity-E and Diversity-N, we calculate the average percentage of new NE and non-NE words in the generated samples compared with the original samples, respectively. For Diversity-L, we  "
                ],
                "publication_ref": [
                    "b17",
                    "b18",
                    "b30"
                ],
                "figure_ref": [],
                "table_ref": [
                    "tab_2",
                    "tab_4"
                ]
            },
            {
                "heading": "Original",
                "text": [
                    "The control group consisted of 40 consecutive [FMF]DISEASE patients, who arrived at the [FMF]DISEASE clinic for their regular follow-up visit and were 40 years of age or older at the time of the examination.",
                    "\uf0fc The original sentence describes an occasion where a group of 40 patients diagnosed with a certain kind of disease visited a clinic, and the sentence provides us with information on the age statistics of the patients."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "LwTR",
                "text": [
                    "The control, consisted of 40 consecutive [fragile]DISEASE patients, who arrived at the [FMF]DISEASE status for their regular follow -up and were 40 years of age or older at the time of the examination analyzed \u274c LwTR replaces \"FMF\" in the sentence with \"fragile\" and the phrase \"fragile patients\" does not make sense. It also adds an extra word, \"analyzed\", at the end of the sentence."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "MELM",
                "text": [
                    "The control group consisted of 40 consecutive [FMR]DISEASE patients, who arrived at the [PDA]DISEASE clinic for their regular follow-up visit and were 40 years of age or older at the time of the examination.",
                    "\u274c MELM replaces the 1st occurrence of \"FMF\" in the sentence with \"FMR\" and the second occurrence with \"PDA\". \"FMR\" is not the name of a disease and is closest to \"FMR1\", which is the name of a gene. \"PDA\" stands for \"Patent ductus arteriosus.\" Thus, the entire sentence does not make much sense."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "ACLM w/o mixner",
                "text": [
                    "The data-sensitive domains. We show samples of generated augmentations in Fig. 3 and Appendix D.1."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Conclusion",
                "text": [
                    "In this paper, we propose ACLM, a novel data augmentation framework for low-resource complex NER. ACLM is fine-tuned on a novel text reconstruction task and is able to generate diverse augmentations while preserving the NEs in the sentence and their original word sense. ACLM effectively alleviates the context-entity mismatch problem and generates diverse, coherent, and highquality augmentations that prove to be extremely effective for low-resource complex NER. Additionally, we also show that ACLM can be used as an effective data augmentation technique for low-resource NER in the domains of medicine and science due to its ability to generate extremely reliable augmentations."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Limitations",
                "text": [
                    "We list down some potential limitations of ACLM: 1) PLMs are restricted by their knowledge to generate entirely new complex entities due to their syntactically ambiguous nature. Adding to this, substituting complex NEs in existing sentences leads to context-entity mismatch. Thus, as part of future work, we would like to explore if integrating external knowledge into ACLM can help generate sentences with new complex entities in diverse contexts. 2) We do not conduct experiments in the language Farsi from the MultiCoNER dataset as neither mBart-50-large nor XLM-RoBERTa-large was pre-trained on this language.",
                    "3) The use of mBart-50-large for generation also restricts ACLM from being transferred to code-switched settings, and we would like to explore this as part of future work."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A Hyperparameter Tuning",
                "text": [
                    "All hyperparameters were originally tuned with grid search on the development set. Augmentation rounds R: Augmenting the training dataset with several augmentation rounds R proves effective until a saturation point is reached. Continuing to add more augmented data to the gold dataset starts introducing noise to the combined data. Additionally, with an increase in R, the chances of auto-regressive generation with top-k sampling generating similar sentences increase. To determine the optimal value of R, we experiment on 2 low-resource settings on the English sub-set of MultCoNER and report the micro F1 results on the test-set for R ranging from 1 to 7. All other hyperparameters are kept constant. As shown in Table 5, R = 5 gives us the best test-set performance, and the performance decreases after 5 rounds. Attention layers a for Keyword Selection: Selecting the right keywords for creating a template is integral to the success of ACLM. A clear example of this can be seen in Table 1, where ACLM outperforms ACLM random (which chooses random tokens as keywords for template creation) by a significant margin. Transformer encoders consist of multiple layers, and each layer consists of multiple attention heads. While all heads in the same layer tend to behave similarly, different layers generally encode different semantic and syntactic information (Clark et al., 2019). Thus we experiment with different values of \u03b1, or different combinations of transformer encoder layers which are used for calculating the attention scores for keyword selection. As mentioned in Section 3.1, by default, we average attention scores across all tokens, all heads, and the last \u03b1 layers. For all our low-resource experiments, we use attention maps from a 24-layer XLMRoBERTa-large fine-tuned on the low-resource gold dataset for that particular setting. Table 7 compares the performance of 3 settings of \u03b1 on 2 low-resource settings on the English sub-set of MultCoNER: 1. Only last layer 2. Last 4 layers. 3. All 24 layers. As clearly evident, though setting 2 achieves the best performance, the difference in performance among different values of \u03b1 is not too high. As part of future work, we would like to explore better ways to search for the optimal \u03b1. Training on the entire dataset: Beyond just evaluating ACLM performance on low-resource settings, we also compare ACLM with all our baselines on the entire MultiCoNER dataset (each language split contains \u2248 15300 sentences). Similar to low-resource settings, ACLM outperforms all our baselines across all languages and achieves an absolute average gain of 1.58% over our best baseline. Entity-wise Performance Analysis: Previous to MultiCoNER, common benchmark datasets like CoNLL 2003 had only \"easy entities\" like names of Persons, Locations, and Organizations. The Mul-tiCoNER dataset has 3 additional types of NEs, namely Products (PROD), Groups (GRP), and Creative Work (CW). These entities are syntactically ambiguous, which makes it challenging to recognize them based on their context. The top system from WNUT 2017 achieved 8% recall for creative work entities. Length-wise Performance Analysis: As mentioned in Section 2, low-context is a major problem in complex NER, and an effective complex NER system should be able to detect NEs in sentences with both low and high context (by context we refer to the number of words around the NEs in the sentence). By the nature of its fine-tuning pipeline, ACLM is able to generate augmentations of variable length, and our dynamic masking step further boosts the length diversity of generated augmentations. Adding to this, we acknowledge that effective augmentations for syntactically complex entity types should enable a model to learn to detect these entities in even low-context. Table 11 compares the entity-wise performance of ACLM with our various baselines on two low-resource settings on the MultiCoNER dataset. All results are averaged across all 10 languages. ACLM outperforms all our baselines across all length settings, which re-affirms ACLM's ability to generate effective augmentation for complex NER. To be specific, ACLM improves over our best baseline by 8.8% and 7.4% for 200 and 3.2% and 6.7% for 500 for low-and high-context sentences, respectively.  Context entity mismatch occurs when the generated NEs do not fit the surrounding context. Linguistic incoherence refers to cases where a generated NE does not follow the linguistic pattern for that particular type of NE or context."
                ],
                "publication_ref": [
                    "b7"
                ],
                "figure_ref": [],
                "table_ref": [
                    "tab_0",
                    "tab_8",
                    "tab_1"
                ]
            },
            {
                "heading": "C Templates and Attention Maps",
                "text": [
                    "Creating templates with keywords that effectively provides the PLM with additional knowledge about the NEs in the sentence is an integral part of ACLM. Fig. 11,12,13,14,15 shows examples of templates created for our sentences in MultiCoNER English subset, Spanish subset, Hindi subset NCBI Disease and TDMSci datasets, respectively. Additionally, we provide examples of attention maps used to create templates in Fig. 16f."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_18"
                ],
                "table_ref": []
            },
            {
                "heading": "D Qualitative Analysis of Augmentations D.1 Augmentation Examples",
                "text": [
                    "MultiCoNER Dataset: We provide additional examples of augmentations generated by ACLM and all our baselines in Fig. 9 and Fig. 10 "
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_9"
                ],
                "table_ref": []
            },
            {
                "heading": "Original",
                "text": [
                    "To determine the genetic basis for the differences between the cardiac and [brain AE3 variants] GENE , we isolated and characterized the rat gene."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "LwTR",
                "text": [
                    "To determine the genetic basis for the differences between the cardiac and [IgA AE3 related] GENE , we isolated and characterized the rat immunodeficiency increased"
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "MELM",
                "text": [
                    "To determine the genetic basis for the differences between the cardiac and [mouse EFR varianter] GENE , we isolated and characterized the rat gene."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "ACLM w/o mixner",
                "text": [
                    "The genetic basis for the cardiac [brain AE3 variants] GENE in the rat population is unknown."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "ACLM w/ mixner",
                "text": [
                    "On basis of the differences in both [brain AE3 variants] GENE and [estrogen receptors] GENE we isolated the mechanisms that govern the variations in mouse and human genes.  "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Original",
                "text": [
                    "These data show that if we are ever to fully master [natural language generation] TASK , especially for the genres of news and narrative, researchers will need to devote more attention to understanding how to generate descriptive, and not just distinctive, referring expressions."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "LwTR",
                "text": [
                    "These data show that if we are ever to runs focus [Urdu/generation] TASK , proposed for the genres of + and narrative, researchers will need to devote more attention to understanding how to Fixed descriptive, and not just raw transformed morphological supervised corpora."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "MELM",
                "text": [
                    "These data show that if we are ever to fully master [the text interpretation] TASK , especially for the genres of news and narrative, researchers will need to devote more attention to understanding how to generate descriptive, and not just distinctive, referring expressions."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "ACLM w/o mixner",
                "text": [
                    "These results show that in the [natural language generation] TASK of news text, researchers are able to generate descriptive text with distinctive language expressions."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "ACLM w/ mixner",
                "text": [
                    "These data show that if we are ever to fully master [natural language generation] TASK for genres other than narrative, researchers will be able to generate descriptive and distinctive meaning by referring to them. We propose a holistic approach to [image description generation] TASK that is noisy and challenging.     Original Template The goal of fully unsupervised [word segmentation] TASK , then, is to recover the correct boundaries for arbitrary natural language corpora without explicit human parameterization. In particular , for [question classification] TASK , no labeled question corpus is available for French, so this paper studies the to use existing English corpora and transfer a classification by translating the question and their labels .      ",
                    "\u0906\u093f\u0927\u0915\u093e \u0930\u0915 \u0924\u094c\u0930 \u092a\u0930 \u092c \u0921 \u0938\u092e\u093e \u0939\u094b \u0917\u092f\u093e, \u0932\u0947 \u093f\u0915\u0928 \u0968\u0966\u0966\u0967 \u092e \u0905\u092a\u0928\u0947 \u090f \u092e [\u091c\u0940\u0935\u0928 \u0915\u0940 \u0938\u093e\u0901 \u0938\u0947 ] CW \u0915 \u0947 \u0938\u093e\u0925 \u0935\u093e\u092a\u0938\u0940 \u0915\u0940\u0964 [M] \u0906\u093f\u0927\u0915\u093e \u0930\u0915 [M] \u092c \u0921 [M] \u0968\u0966\u0966\u0967 [M] \u090f \u092e [M] <B-CW> \u091c\u0940\u0935\u0928 <B-CW> <I-CW> \u0915\u0940 <I-CW> <I-CW> \u0938\u093e\u0901 \u0938\u0947 <I-CW> [M] \u0935\u093e\u092a\u0938\u0940 \u0915\u0940 [M] \u0905\u0917\u0932\u0947 \u0938\u092b\u0932 \u0935\u0937 \u092e \u0907\u0938\u0915\u093e \u093f\u0935 \u093e\u0930 \u0906 \u0914\u0930 [\u092e\u0947 \u091f \u094b \u092e\u093f\u0928\u0932\u093e] LOC \u0947 \u092e \u0928\u090f \u092a \u0930\u0938\u0930\u094b\u0902 \u0915\u0940 \u093e\u092a\u0928\u093e \u0908 | [M] <B-LOC> \u092e\u0947 \u091f \u094b <B-LOC> <I-LOC> \u092e\u093f\u0928\u0932\u093e <I-LOC> \u0947 [M] \u0928\u090f \u092a \u0930\u0938\u0930\u094b\u0902 [M] \u093e\u092a\u0928\u093e \u0908 [M] \u092a\u093e \u093e \u0915\u094b [\u092e\u0947 \u095b] PROD \u0941 \u0927\u093e\u0935\u0927 \u0915 \u0915 \u0947 \u092a \u092e \u092d\u0940 \u092a\u0930\u094b\u0938\u093e \u091c\u093e \u0938\u0915\u0924\u093e \u0939\u0948 \u0964 [M] \u092a\u093e \u093e [M] <B-PROD> \u092e\u0947 \u095b <B-PROD> [M] \u092a\u0930\u094b\u0938\u093e [M]"
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "",
                "text": [
                    "Limitations Section (After conclusion and before citations).",
                    "A2. Did you discuss any potential risks of your work?",
                    "Section E.",
                    "A3. Do the abstract and introduction summarize the paper's main claims?",
                    "Section 1 and Abstract.",
                    "A4. Have you used AI writing assistants when working on this paper?",
                    "Left blank.",
                    "B Did you use or create scientific artifacts?",
                    "Section 4.1.",
                    "B1. Did you cite the creators of artifacts you used?",
                    "Citations.",
                    "B2. Did you discuss the license or terms for use and / or distribution of any artifacts?",
                    "Section E.",
                    "B3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided that it was specified? For the artifacts you create, do you specify intended use and whether that is compatible with the original access conditions (in particular, derivatives of data accessed for research purposes should not be used outside of research contexts)? Section E.",
                    "B4. Did you discuss the steps taken to check whether the data that was collected / used contains any information that names or uniquely identifies individual people or offensive content, and the steps taken to protect / anonymize it? Section E.",
                    "B5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and linguistic phenomena, demographic groups represented, etc.? Section E.",
                    "B6. Did you report relevant statistics like the number of examples, details of train / test / dev splits, etc. for the data that you used / created? Even for commonly-used benchmark datasets, include the number of examples in train / validation / test splits, as these provide necessary context for a reader to understand experimental results. For example, small differences in accuracy on large test sets may be significant, while on small test sets they may not be. Section E.",
                    "C Did you run computational experiments?",
                    "Section E.",
                    "C1. Did you report the number of parameters in the models used, the total computational budget (e.g., GPU hours), and computing infrastructure used? Section E.",
                    "The Responsible NLP Checklist used at ACL 2023 is adopted from NAACL 2022, with the addition of a question on AI writing assistance."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            }
        ],
        "references": [
            {
                "ref_id": "b0",
                "title": "FLAIR: An easy-to-use framework for state-of-theart NLP",
                "journal": "",
                "year": "2019",
                "authors": "Alan Akbik; Tanja Bergmann; Duncan Blythe; Kashif Rasul; Stefan Schweter; Roland Vollgraf"
            },
            {
                "ref_id": "b1",
                "title": "recognition: A quantitative analysis",
                "journal": "",
                "year": "2014",
                "authors": "Sandeep Ashwini; D Jinho;  Choi"
            },
            {
                "ref_id": "b2",
                "title": "Uxla: A robust unsupervised data augmentation framework for zero-resource cross-lingual nlp",
                "journal": "",
                "year": "2020",
                "authors": "Tasnim Bari; Shafiq Mohiuddin;  Joty"
            },
            {
                "ref_id": "b3",
                "title": "Hardeval: Focusing on challenging tokens to assess robustness of ner",
                "journal": "",
                "year": "2020",
                "authors": "Gabriel Bernier-Colborne; Philippe Langlais"
            },
            {
                "ref_id": "b4",
                "title": "Entity mention detection using a combination of redundancy-driven classifiers",
                "journal": "",
                "year": "2010",
                "authors": "Silvana Marianela Bernaola Biggio; Manuela Speranza; Roberto Zanoli"
            },
            {
                "ref_id": "b5",
                "title": "Erd'14: entity recognition and disambiguation challenge",
                "journal": "Acm",
                "year": "2014",
                "authors": "David Carmel; Ming-Wei Chang; Evgeniy Gabrilovich; Bo-June Hsu; Kuansan Wang"
            },
            {
                "ref_id": "b6",
                "title": "Ustc-nelslip at semeval-2022 task 11: Gazetteer-adapted integration network for multilingual complex named entity recognition",
                "journal": "",
                "year": "2022",
                "authors": "Beiduo Chen; Jun-Yu Ma; Jiajun Qi; Wu Guo; Zhen-Hua Ling; Quan Liu"
            },
            {
                "ref_id": "b7",
                "title": "What does bert look at? an analysis of bert's attention",
                "journal": "",
                "year": "2019",
                "authors": "Kevin Clark; Urvashi Khandelwal; Omer Levy; Christopher D Manning"
            },
            {
                "ref_id": "b8",
                "title": "Unsupervised cross-lingual representation learning at scale",
                "journal": "",
                "year": "2019",
                "authors": "Alexis Conneau; Kartikay Khandelwal; Naman Goyal; Vishrav Chaudhary; Guillaume Wenzek; Francisco Guzm\u00e1n; Edouard Grave; Myle Ott; Luke Zettlemoyer; Veselin Stoyanov"
            },
            {
                "ref_id": "b9",
                "title": "An analysis of simple data augmentation for named entity recognition",
                "journal": "",
                "year": "2020",
                "authors": "Xiang Dai; Heike Adel"
            },
            {
                "ref_id": "b10",
                "title": "An analysis of simple data augmentation for named entity recognition",
                "journal": "",
                "year": "2020",
                "authors": "Xiang Dai; Heike Adel"
            },
            {
                "ref_id": "b11",
                "title": "Daga: Data augmentation with a generation approach for low-resource tagging tasks",
                "journal": "",
                "year": "2020",
                "authors": "Bosheng Ding; Linlin Liu; Lidong Bing; Canasai Kruengkrai; Hai Thien; Shafiq Nguyen; Luo Joty; Chunyan Si;  Miao"
            },
            {
                "ref_id": "b12",
                "title": "The automatic content extraction (ace) program-tasks, data, and evaluation",
                "journal": "",
                "year": "2004",
                "authors": "Alexis George R Doddington;  Mitchell; A Mark;  Przybocki; A Lance; Stephanie M Ramshaw; Ralph M Strassel;  Weischedel"
            },
            {
                "ref_id": "b13",
                "title": "Ncbi disease corpus: a resource for disease name recognition and concept normalization",
                "journal": "Journal of biomedical informatics",
                "year": "2014",
                "authors": "Robert Rezarta Islamaj Dogan; Zhiyong Leaman;  Lu"
            },
            {
                "ref_id": "b14",
                "title": "Dynamic gazetteer integration in multilingual models for cross-lingual and cross-domain named entity recognition",
                "journal": "Association for Computational Linguistics",
                "year": "2022",
                "authors": "Besnik Fetahu; Anjie Fang; Oleg Rokhlenko; Shervin Malmasi"
            },
            {
                "ref_id": "b15",
                "title": "Named entity recognition in query",
                "journal": "",
                "year": "2009",
                "authors": "Jiafeng Guo; Gu Xu; Xueqi Cheng; Hang Li"
            },
            {
                "ref_id": "b16",
                "title": "Tdmsci: A specialized corpus for scientific literature entity tagging of tasks datasets and metrics",
                "journal": "Association for Computational Linguistics",
                "year": "2021-04",
                "authors": "Yufang Hou; Charles Jochim; Martin Gleize; Francesca Bonin; Debasis Ganguly"
            },
            {
                "ref_id": "b17",
                "title": "Investigating transfer learning in multilingual pretrained language models through chinese natural language inference",
                "journal": "",
                "year": "2021",
                "authors": "Hai Hu; He Zhou; Zuoyu Tian; Yiwen Zhang; Yina Ma; Yanting Li; Yixin Nie; Kyle Richardson"
            },
            {
                "ref_id": "b18",
                "title": "Perplexity-a measure of the difficulty of speech recognition tasks",
                "journal": "The Journal of the Acoustical Society of America",
                "year": "1977",
                "authors": "Fred Jelinek; L Robert;  Mercer; R Lalit; James K Bahl;  Baker"
            },
            {
                "ref_id": "b19",
                "title": "Yejin Bang, Andrea Madotto, and Pascale Fung. 2022. Survey of hallucination in natural language generation",
                "journal": "ACM Computing Surveys",
                "year": "",
                "authors": "Ziwei Ji; Nayeon Lee; Rita Frieske; Tiezheng Yu; Dan Su; Yan Xu; Etsuko Ishii"
            },
            {
                "ref_id": "b20",
                "title": "Adam: A method for stochastic optimization",
                "journal": "",
                "year": "2014",
                "authors": "P Diederik; Jimmy Kingma;  Ba"
            },
            {
                "ref_id": "b21",
                "title": "Contextual augmentation: Data augmentation by words with paradigmatic relations",
                "journal": "",
                "year": "2018",
                "authors": "Sosuke Kobayashi"
            },
            {
                "ref_id": "b22",
                "title": "Data augmentation using pre-trained transformer models",
                "journal": "",
                "year": "2020",
                "authors": "Varun Kumar; Ashutosh Choudhary; Eunah Cho"
            },
            {
                "ref_id": "b23",
                "title": "BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
                "journal": "",
                "year": "2020",
                "authors": "Mike Lewis; Yinhan Liu; Naman Goyal; Marjan Ghazvininejad; Abdelrahman Mohamed; Omer Levy; Veselin Stoyanov; Luke Zettlemoyer"
            },
            {
                "ref_id": "b24",
                "title": "Low-resource ner by data augmentation with prompting",
                "journal": "",
                "year": "",
                "authors": "Jian Liu; Yufeng Chen; Jinan Xu"
            },
            {
                "ref_id": "b25",
                "title": "Mulda: A multilingual data augmentation framework for low-resource cross-lingual ner",
                "journal": "Long Papers",
                "year": "2021",
                "authors": "Linlin Liu; Bosheng Ding; Lidong Bing; Shafiq Joty; Luo Si; Chunyan Miao"
            },
            {
                "ref_id": "b26",
                "title": "How to use gazetteers for entity recognition with neural models",
                "journal": "",
                "year": "2019",
                "authors": "Simone Magnolini; Vevake Valerio Piccioni; Marco Balaraman; Bernardo Guerini;  Magnini"
            },
            {
                "ref_id": "b27",
                "title": "Multiconer: a largescale multilingual dataset for complex named entity recognition",
                "journal": "",
                "year": "2022",
                "authors": "Shervin Malmasi; Anjie Fang; Besnik Fetahu; Sudipta Kar; Oleg Rokhlenko"
            },
            {
                "ref_id": "b28",
                "title": "ner and pos when nothing is capitalized",
                "journal": "",
                "year": "2019",
                "authors": "Stephen Mayhew; Tatiana Tsygankova; Dan Roth"
            },
            {
                "ref_id": "b29",
                "title": "Gemnet: Effective gated gazetteer representations for recognizing complex entities in low-context input",
                "journal": "",
                "year": "2021",
                "authors": "Tao Meng; Anjie Fang; Oleg Rokhlenko; Shervin Malmasi"
            },
            {
                "ref_id": "b30",
                "title": "Language models are unsupervised multitask learners",
                "journal": "",
                "year": "2019",
                "authors": "Alec Radford; Jeff Wu; Rewon Child; David Luan; Dario Amodei; Ilya Sutskever"
            },
            {
                "ref_id": "b31",
                "title": "Sentence-bert: Sentence embeddings using siamese bert-networks",
                "journal": "",
                "year": "2019",
                "authors": "Nils Reimers; Iryna Gurevych"
            },
            {
                "ref_id": "b32",
                "title": "Soft gazetteers for lowresource named entity recognition",
                "journal": "",
                "year": "2020",
                "authors": "Shruti Rijhwani; Shuyan Zhou; Graham Neubig; Jaime Carbonell"
            },
            {
                "ref_id": "b33",
                "title": "Improving supervised sense disambiguation with web-scale selectors",
                "journal": "",
                "year": "2012",
                "authors": "Andrew Schwartz; Fernando Gomez; Lyle Ungar"
            },
            {
                "ref_id": "b34",
                "title": "Overview of biocreative ii gene mention recognition",
                "journal": "Genome biology",
                "year": "2008",
                "authors": "Larry Smith; K Lorraine; Cheng-Ju Tanabe;  Kuo; Chun-Nan Chung; Yu-Shi Hsu; Roman Lin; Christoph M Klinger; Kuzman Friedrich; Manabu Ganchev;  Torii"
            },
            {
                "ref_id": "b35",
                "title": "Multilingual translation with extensible multilingual pretraining and finetuning",
                "journal": "",
                "year": "2020",
                "authors": "Yuqing Tang; Chau Tran; Xian Li; Peng-Jen Chen; Naman Goyal; Vishrav Chaudhary; Jiatao Gu; Angela Fan"
            },
            {
                "ref_id": "b36",
                "title": "Introduction to the conll-2003 shared task: Languageindependent named entity recognition",
                "journal": "",
                "year": "2003",
                "authors": "Erik F Tjong; Kim Sang; Fien De Meulder"
            },
            {
                "ref_id": "b37",
                "title": "Automated Concatenation of Embeddings for Structured Prediction",
                "journal": "",
                "year": "2021",
                "authors": "Xinyu Wang; Yong Jiang; Nguyen Bach; Tao Wang; Zhongqiang Huang; Fei Huang; Kewei Tu"
            },
            {
                "ref_id": "b38",
                "title": "EDA: Easy data augmentation techniques for boosting performance on text classification tasks",
                "journal": "",
                "year": "2019",
                "authors": "Jason Wei; Kai Zou"
            },
            {
                "ref_id": "b39",
                "title": "Time Expression and Named Entity Recognition",
                "journal": "Springer",
                "year": "2021",
                "authors": "Xiaoshi Zhong; Erik Cambria"
            },
            {
                "ref_id": "b40",
                "title": "Dual adversarial neural transfer for lowresource named entity recognition",
                "journal": "Association for Computational Linguistics",
                "year": "2019",
                "authors": "Joey Tianyi Zhou; Hao Zhang; Di Jin; Hongyuan Zhu; Meng Fang; Rick Siow Mong Goh; Kenneth Kwok"
            },
            {
                "ref_id": "b41",
                "title": "Melm: Data augmentation with masked entity language modeling for low-resource ner",
                "journal": "Long Papers",
                "year": "2022",
                "authors": "Ran Zhou; Xin Li; Ruidan He; Lidong Bing; Erik Cambria; Luo Si; Chunyan Miao"
            },
            {
                "ref_id": "b42",
                "title": "Learning from noisy labels for entity-centric information extraction",
                "journal": "",
                "year": "2021",
                "authors": "Wenxuan Zhou; Muhao Chen"
            },
            {
                "ref_id": "b43",
                "title": "Did you discuss the experimental setup, including hyperparameter search and best-found hyperparameter values?",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b44",
                "title": "error bars around results, summary statistics from sets of experiments), and is it transparent whether you are reporting the max, mean, etc",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b45",
                "title": "for preprocessing, for normalization, or for evaluation",
                "journal": "",
                "year": "",
                "authors": " Nltk;  Spacy;  Rouge"
            },
            {
                "ref_id": "b46",
                "title": "crowdworkers) or research with human participants? Left blank",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b47",
                "title": "Did you report the full text of instructions given to participants, including e.g., screenshots, disclaimers of any risks to participants or annotators",
                "journal": "",
                "year": "",
                "authors": " D1"
            },
            {
                "ref_id": "b48",
                "title": "crowdsourcing platform, students) and paid participants, and discuss if such payment is adequate given the participants' demographic",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b49",
                "title": "Did you discuss whether and how consent was obtained from people whose data you're using/curating? For example, if you collected data via crowdsourcing, did your instructions to crowdworkers explain how the data would be used?",
                "journal": "",
                "year": "",
                "authors": " D3"
            },
            {
                "ref_id": "b50",
                "title": "Was the data collection protocol approved (or determined exempt) by an ethics review board? No response",
                "journal": "",
                "year": "",
                "authors": " D4"
            },
            {
                "ref_id": "b51",
                "title": "Did you report the basic demographic and geographic characteristics of the annotator population that is the source of the data? No response",
                "journal": "",
                "year": "",
                "authors": " D5"
            }
        ],
        "figures": [
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_0",
                "figure_caption": "[M] enemy [M] infantry [M] retired [M] enemy swarmed [M] hidden ground [M] ground [M] royal artillery guns [M] attack [enemy [M] infantry [M] retired [M] enemy swarmed [M] hidden ground [M] <b-grp> royal <b-grp> <i-grp> artillery <i-grp> guns [M] attack [M] [M] enemy [M] infantry [M] swarmed [M] hidden ground [M] <b-grp> royal <b-grp> <i-grp> artillery <i-grp> guns [M] ashby was wounded in the right foot during one of three raids into kentuckyLOC made by his regiment during 1862 . ashby [M] wounded [M] foot [M] raids [M] allegiance [M] rejoin <b-loc> kentucky <b-loc> [",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_1",
                "figure_caption": "attacked the enemy 's infantry with the lance , and then retired while the enemy swarmed out of hidden ground where royal artillery guns could attack them .",
                "figure_data": ""
            },
            {
                "figure_label": "1",
                "figure_type": "figure",
                "figure_id": "fig_2",
                "figure_caption": "Figure 1 :1Figure 1: Overview of ACLM: ACLM follows a 4-step template creation process, which serves as an input to the model during fine-tuning and generation. 1 \u20dd Keyword Selection: The most important keywords (in red) associated with the NEs (in bold) in the sentence is first extracted using attention maps obtained from a fine-tuned NER model. 2 \u20dd Selective Masking: All words except the NEs and the keywords obtained from the previous step is replaced with mask tokens [M]. 3\u20dd Labeled Sequence Linearization: Label tokens are added before and after each entity in the sentence. 4\u20dd Dynamic Masking: The template goes through further masking where a small portion of the keywords are dynamically masked at each training iteration. While generation we also apply mixner, which randomly joins two templates after 3 \u20dd and before 4 \u20dd. Post generating augmentations with ACLM, the generated augmentations are concatenated with the gold data and used to fine-tune our final NER model.",
                "figure_data": ""
            },
            {
                "figure_label": "42",
                "figure_type": "figure",
                "figure_id": "fig_3",
                "figure_caption": "4 Figure 2 :42Figure 2: Overview of mixner: During the augmentation generation process, for a particular sentence in the training dataset, we retrieve another semantically similar sentence and concatenate them before step 4\u20dd of the template creation process. This merged template is then passed through ACLM to generate diverse augmentations that incorporate semantics and NEs from both sentences.",
                "figure_data": ""
            },
            {
                "figure_label": "4",
                "figure_type": "figure",
                "figure_id": "fig_4",
                "figure_caption": "OriginalFigure 4 :4Figure 4: Analysis and comparison of augmentations generated by our baselines with ACLM. Words underlined are the NEs.",
                "figure_data": ""
            },
            {
                "figure_label": "5",
                "figure_type": "figure",
                "figure_id": "fig_5",
                "figure_caption": "Figure 5 :5Figure 5: Augmentation examples of the CoNLL 2003 dataset from the news domain. All generations are produced in a low-resource setting (500 training examples).",
                "figure_data": ""
            },
            {
                "figure_label": "6",
                "figure_type": "figure",
                "figure_id": "fig_6",
                "figure_caption": "Figure 6 :6Figure 6: Augmentation examples of BC2GM from the bio-medical domain. All generations are produced in a low-resource setting (500 training examples).",
                "figure_data": ""
            },
            {
                "figure_label": "7",
                "figure_type": "figure",
                "figure_id": "fig_7",
                "figure_caption": "Figure 7 :7Figure 7: Augmentation examples of NCBI dataset from the bio-medical domain. All generations are produced in a low-resource setting (500 training examples).",
                "figure_data": ""
            },
            {
                "figure_label": "8",
                "figure_type": "figure",
                "figure_id": "fig_8",
                "figure_caption": "Figure 8 :8Figure 8: Augmentation examples of TDMSci from the science domain. All generations are produced in a low-resource setting (500 training examples).",
                "figure_data": ""
            },
            {
                "figure_label": "10",
                "figure_type": "figure",
                "figure_id": "fig_9",
                "figure_caption": "Figure 10 :10Figure 10: Augmentation examples on the English subset of the MultiCoNER dataset. All generations are produced in a low-resource setting (500 training examples).",
                "figure_data": ""
            },
            {
                "figure_label": "11",
                "figure_type": "figure",
                "figure_id": "fig_10",
                "figure_caption": "Figure 11 :11Figure 11: Examples of templates created for sentences taken from the English subset of the MultiCoNER dataset. All templates shown are created in a low-resource setting (500 training examples). Words underlined are identified keywords.",
                "figure_data": ""
            },
            {
                "figure_label": "12",
                "figure_type": "figure",
                "figure_id": "fig_11",
                "figure_caption": "Figure 12 :12Figure 12: Examples of templates created for sentences taken from the Spanish subset of the MultiCoNER dataset. All templates shown are created in a low-resource setting (500 training examples). Words underlined are identified keywords.",
                "figure_data": ""
            },
            {
                "figure_label": "13",
                "figure_type": "figure",
                "figure_id": "fig_12",
                "figure_caption": "Figure 13 :13Figure 13: Examples of templates created for sentences taken from the Hindi subset of the MultiCoNER dataset. All templates shown are created in a low-resource setting (500 training examples). Words underlined are identified keywords.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_13",
                "figure_caption": "[M] goal [M] unsupervised <B-TASK> word <B-TASK> <I-TASK> segmentation <I-TASK> [M] correct boundaries [M] language corpora [M] human parameterization [M]",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_14",
                "figure_caption": "[M] <B-TASK> question <I-TASK>classification <I-TASK> [M] labeled question corpus [M] French [M] paper [M] existing English corpora [M] classification [M] translating [M] question [M] labels [M]",
                "figure_data": ""
            },
            {
                "figure_label": "15",
                "figure_type": "figure",
                "figure_id": "fig_15",
                "figure_caption": "Figure 15 :15Figure 15: Examples of templates created for sentences taken from the TDMSci dataset. All templates shown are created in a low-resource setting (500 training examples). Words underlined are identified keywords.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_16",
                "figure_caption": "Sentence: bamboo, like [wood] PROD is a natural [composite material] PROD with a high strength to weight ratio useful for structures. Sentence: [michael sanchez] PER , who was member of the band [deep forest] GRP , co wrote the lyrics.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_17",
                "figure_caption": "Sentence: his last theatrical composition was music for [joan the woman] CW starring [geraldine farrar] PER . Sentence: while auditioning for television and film roles, she worked on [theatre] GRP productions of [romeo and juliet] CW and [arsenic and old lace] CW . CORP purchased the intellectual property in 2012 and provided funding for the project again,reimagining it as an [actionadventure game] CW for release on multiple platforms. Sentence: the bulk of the locality is used for growing [sugarcane] PROD and tropical fruit, while some of the locality, particularly surrounding the creeks is left as swampy wetlands.",
                "figure_data": ""
            },
            {
                "figure_label": "16",
                "figure_type": "figure",
                "figure_id": "fig_18",
                "figure_caption": "Figure 16 :16Figure 16: Attention maps for different sentences from the MULTICONER dataset. All the sentences are picked from a low-resource setting (1000 training examples).",
                "figure_data": ""
            },
            {
                "figure_label": "1",
                "figure_type": "table",
                "figure_id": "tab_0",
                "figure_caption": "Results",
                "figure_data": "MONOLINGUALCROSS-LINGUAL#Gold MethodEnBnHiDeEsKoNlRuTrZhAvgEn \u2192 Hi En \u2192 Bn En \u2192 De En \u2192 Zh AvgGold-only29.36 14.49 18.80 37.04 36.30 12.76 38.78 23.89 24.13 14.18 24.9716.3612.1529.710.3114.63LwTR48.60 20.25 29.95 48.38 44.08 35.09 43.00 39.22 30.58 27.70 36.6832.3624.5946.052.1126.28DAGA16.24 5.87 10.40 32.44 27.78 19.28 15.44 11.14 16.17 10.33 16.514.543.2814.210.135.54100 MELM40.12 6.22 27.84 43.94 37.45 34.10 37.82 32.38 20.13 25.11 30.5126.3720.3334.322.7120.93ACLM only entity 14.06 17.55 19.60 29.72 38.10 31.57 38.47 27.40 35.62 26.34 27.8421.7216.5530.931.5817.69ACLM random43.59 20.13 28.04 45.83 42.27 33.64 41.82 38.20 36.79 25.99 35.6329.6821.6445.273.0524.91ACLM (ours)48.76 23.09 33.53 48.80 44.14 38.35 46.22 39.48 37.20 35.12 39.4732.5223.9146.483.5826.62Gold-only51.83 19.31 33.68 49.62 45.16 42.51 47.83 31.55 26.76 32.34 38.0636.9027.4448.703.7629.20LwTR52.88 23.85 34.27 50.31 47.01 42.77 52.01 40.18 35.92 30.57 40.9840.0732.3648.956.0431.85DAGA33.30 17.12 19.58 35.10 33.56 26.50 38.04 29.83 23.35 25.66 28.2018.9214.3729.321.7916.10200 MELM47.83 5.47 29.67 45.85 42.08 36.62 49.47 41.84 31.25 32.27 36.2427.5518.8041.106.2123.41ACLM only entity 50.06 25.58 37.78 50.95 48.21 43.39 48.46 34.87 34.92 28.20 40.2430.7622.5344.176.5025.99ACLM random52.69 35.26 39.83 51.14 48.70 42.19 48.71 39.68 37.26 34.22 42.9636.5227.1947.737.1229.64ACLM (ours)54.99 38.39 40.55 53.36 49.57 44.32 53.19 43.97 39.71 39.31 45.7445.2236.6454.518.5536.23Gold-only55.51 34.6 38.66 55.95 51.52 48.57 50.97 45.14 38.83 38.84 45.8635.9325.6450.137.2329.73LwTR56.97 35.42 37.83 55.91 54.74 49.36 56.10 46.82 39.00 38.55 47.0743.1434.6051.6111.4035.19DAGA44.62 22.36 24.30 43.02 42.77 36.23 47.11 30.94 30.84 33.79 35.6026.5021.5237.894.8222.68500 MELM52.57 9.46 31.57 53.57 46.40 45.01 51.90 46.73 38.26 39.64 41.5134.9727.1744.317.3128.44ACLM only entity 57.55 35.69 35.82 56.15 53.64 50.20 53.07 46.40 41.58 38.65 46.8735.4829.3749.107.9930.48ACLM random57.92 38.24 39.33 57.14 53.24 49.81 55.06 48.27 42.22 40.55 48.1841.7232.1652.2713.6334.95ACLM (ours)58.31 40.26 41.48 59.35 55.69 51.56 56.31 49.40 43.57 41.23 49.7244.3635.5954.0416.2737.57Gold-only57.22 30.20 39.55 60.18 55.86 53.39 60.91 49.93 43.67 43.05 44.4043.4433.2754.615.3434.17LwTR59.10 39.65 43.90 61.28 57.29 51.37 59.25 52.04 44.33 43.71 51.1943.3233.7453.327.3834.44DAGA50.24 32.09 35.02 51.45 49.47 42.41 51.88 41.56 33.18 39.51 42.6833.1226.2242.135.1526.651000 MELM53.48 6.88 37.02 58.69 52.43 50.50 56.25 48.99 36.83 38.88 44.0035.2325.6446.508.2228.90ACLM only entity 55.46 38.13 41.84 60.05 56.99 53.32 58.22 50.17 45.11 39.62 49.8937.3829.7741.106.4928.69ACLM random58.87 41.00 46.27 61.19 57.29 53.61 59.52 52.77 45.01 43.60 51.9143.9634.1453.377.2534.68ACLM (ours)60.14 42.42 48.20 63.80 58.33 55.55 61.22 54.31 48.23 45.19 53.7444.5935.7056.748.9436.49"
            },
            {
                "figure_label": "1",
                "figure_type": "table",
                "figure_id": "tab_1",
                "figure_caption": ".66 42.16 55.71 54.98 45.14 57.48 46.13 44.40 30.72 46.86  LwTR  55.65 38.47 43.44 54.71 53.95 44.78 56.50 46.93 45.41 31.56  47.14 MulDA 46.87 29.25 34.52 45.92 45.55 33.91 48.21 38.65 35.56 27.33 38.58 MELM 53.27 23.43 41.55 48.17 51.28 39.23 51.37 45.73 41.97 30.67 42.67 ACLM (ours) 58.74 41.00 46.22 59.13 56.93 51.22 60.30 50.26 49.32 40.93 51.40 200 \u00d710 Gold-Only 58.67 39.84 46.34 59.65 58.50 50.70 60.79 51.66 47.12 40.98 51.42 LwTR 51.78 35.93 38.87 52.73 51.59 42.55 54.49 43.99 41.23 35.19 44.83 MulDA 48.89 31.45 36.76 48.41 48.30 39.78 51.09 42.01 35.98 31.65 41.43 MELM 52.53 24.27 40.10 49.69 52.42 43.56 47.28 44.35 40.62 34.28 47.45 ACLM (ours) 59.75 42.61 48.52 61.49 59.05 53.46 61.59 53.34 49.96 44.72 53.45    ",
                "figure_data": "compares"
            },
            {
                "figure_label": "2",
                "figure_type": "table",
                "figure_id": "tab_2",
                "figure_caption": "Results of multi-lingual low-resource complex NER.ACLM obtains absolute gains in the range of 1% -21%.",
                "figure_data": ""
            },
            {
                "figure_label": "3",
                "figure_type": "table",
                "figure_id": "tab_4",
                "figure_caption": "Quantitative evaluation of generation quality from various systems on the measures of perplexity and diversity. Diversity-E, N, and L stand for Entity, Non-Entity, and Length, respectively.calculate the average absolute difference between the number of tokens in generated samples and the original samples. ACLM achieves the lowest perplexity and highest non-NE and length diversity compared with other baselines. NE diversity in ACLM is achieved with mixner where ACLM fairs well compared to MELM which just replaces NEs. LwTR achieves the highest perplexity, thereby reaffirming that it generates incoherent augmentations.Original it was developed by a team led by former [blizzard entertainment]CORP employees, some of whom had overseen the creation of the [diablo]CW series.LwTRit was developed by a makers led by, [blizzard entertainment]CORP ., some of whom had elevation the serving of the [diablo]CW 12th. \u274c LwTR replaces random words in the sentence, which makes it incoherent.MELMit was developed by a team led by former [blizzago games]CORP employees, some of whom had overseen the creation of the [hablo]CW series.\u274c MELM keeps the sentence coherent but generates new NEs that do not correspond to real-world entities.ACLM w/o mixner [blizzard entertainment]CORP employees have overseen the production of the animated films, including the production of the [diablo]CW series.",
                "figure_data": "Qualtitative Analysis. Fig. 3 illustrates the superi-ority of augmentations generated by ACLM whencompared with our other baselines. As clearly evi-dent, while MELM generates just minor changesin NEs, augmentations produced by LwTR oftentend to be nonsensical and incoherent. On the otherhand, ACLM generates meaningful and diverse sen-tences around NEs, which is further boosted withmixner. We provide examples in Appendix D.1.5.2 Application to other domainsTo evaluate the transferability of ACLM to otherdomains, we evaluate ACLM on 4 more datasets be-yond MultiCoNER. These datasets include CoNLL2003 (Tjong Kim Sang and De Meulder, 2003)(news), BC2GM (Smith et al., 2008) (bio-medical),NCBI Disease (Dogan et al., 2014) (bio-medical)and TDMSci (Hou et al., 2021) (science). Table 4compares our baselines with ACLM across 2 low-resource settings on all 4 datasets. ACLM outper-forms all our baselines on all settings except LwTRon CoNLL 2003. This occurs because LwTR gen-erates a large variety of effective augmentationswith NE replacement on easy entities in CoNLL2003. The results demonstrate the effectiveness ofACLM over diverse domains, including domainswith an acute scarcity of data (bio-medical). Addi-tionally, we also emphasize that ACLM producesmore factual augmentations and, unlike our otherbaselines, avoids context-entity mismatch, whichmakes the NER model store wrong knowledge in"
            },
            {
                "figure_label": "4",
                "figure_type": "table",
                "figure_id": "tab_5",
                "figure_caption": "sample consisted of four consecutive [FMF]DISEASE patients who arrived at the [FMF]DISEASE clinic for a visit of examination. Only one of the 4 remaining patients had [FMF]DISEASE . Comparison",
                "figure_data": "\uf0fc ACLM introduces a new context pattern around the sentence. The entire sentenceis coherent."
            },
            {
                "figure_label": "5",
                "figure_type": "table",
                "figure_id": "tab_6",
                "figure_caption": "In this section, we show performance on the test set for better analysis. Too less context, like our ACLM only entity baseline with only linearized NEs in the template, might make it difficult for the model to know the appropriate context of the syntactically ambiguous complex NE and thus might lead to sentences generated with a context-entity mismatch (for e.g. sam is reading on the Beach where on the beach might be a name of a movie). On the contrary, retaining too many words from the original sentence in our template might lead to a drop in the diversity of generated sentences the model needs to infill only a small portion of the words. To determine the optimal value of p we experiment on 2 low-resource settings on the English sub-set of MultiCoNER and report the micro F1 results on the test-set for p \u2208 Test set F1 for various Keyword Selection rates.",
                "figure_data": "Keyword Selection rate p: The keywords in our template provide the model with contextually rel-evant additional knowledge about the NEs duringtraining and generation. However, we are facedwith the question: How much context is good con-text?. {0, 0.1, 0.2, 0.3. 0.4, 0.5, 0.6, 0.7}. All other hyper-parameters are kept constant. As shown in Table 5,p = 0.3 gives us the best test-set performance, andthe performance decreases after 0.4.#Gold 200 50.06 51.82 53.99 54.99 51.05 54.28 52.16 54.34 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 500 57.55 56.12 57.93 58.31 57.55 56.88 56.60 58.10"
            },
            {
                "figure_label": "6",
                "figure_type": "table",
                "figure_id": "tab_7",
                "figure_caption": ".96 52.40 50.05 54.99 53.46 53.75  500 58.24 58.17 57.90 58.11 58.31 57.20 57.40    Test set F1 for the number of augmentation rounds.",
                "figure_data": "#Gold1234567200 52.37 53"
            },
            {
                "figure_label": "7",
                "figure_type": "table",
                "figure_id": "tab_8",
                "figure_caption": "Test set F1 for various settings of \u03b1",
                "figure_data": "#Gold 200 5001 52.43 54.99 54.13 2 3 58.09 58.31 58.15B Additional ResultsCurrent state of state-of-the-art: Most current state-of-the-art systems are built and evaluated oncommon NER benchmarks like CoNLL 2003 andOntoNotes v5.0. As discussed in Section 2, thesebenchmarks do not represent contemporary chal-lenges in NER and contain sentences with easyentities and rich context. Table 8 compares theperformance of a simple XLM-R (Conneau et al.,2019), and Co-regularized LUKE (Zhou and Chen,"
            },
            {
                "figure_label": "8",
                "figure_type": "table",
                "figure_id": "tab_9",
                "figure_caption": "Performance comparison of XLM-RoBERTa(Conneau et al., 2019) and Co-regularized LUKE(Zhou and Chen, 2021) on two common benchmark NER datasets and Multi-CoNER(Malmasi et al., 2022)  (complex NER benchmark) in both high-and low-resource settings. Co-regularized LUKE is the current SOTA NER system on both CoNLL 2003 and OntoNotes v5.0. Complex NER remains a difficult NLP task in both low-and high-resource labeled data settings.",
                "figure_data": ""
            },
            {
                "figure_label": "9",
                "figure_type": "table",
                "figure_id": "tab_10",
                "figure_caption": "Result comparison Complex NER. Avg is the average result across all languages. ACLM outperforms all our baselines.",
                "figure_data": "MethodEnBnHiDeEsKoNlRuTrZhAvgGold-only71.25 59.10 61.59 75.33 67.71 65.29 71.55 68.76 62.44 60.56 66.36LwTR71.22 58.86 60.72 75.50 70.06 65.80 72.94 68.26 62.70 58.74 66.48DAGA64.30 47.93 53.03 67.70 62.07 59.84 65.37 60.72 52.45 55.32 58.87MELM ACLM (ours) 72.69 60.13 62.58 77.26 70.89 67.01 73.28 69.90 65.24 61.63 68.06 66.27 56.27 61.04 71.25 65.56 63.71 70.43 66.28 60.74 57.72 63.93"
            },
            {
                "figure_label": "10",
                "figure_type": "table",
                "figure_id": "tab_11",
                "figure_caption": "Table 10 compares the entity-wise performance of ACLM with our various baselines on two low-resource settings on the MultiCoNER dataset. All results are averaged across all 10 lan-guages. ACLM outperforms all our baselines on all individual entities, including PROD, GRP, and CW, which re-affirms ACLM's ability to generate effective augmentation for complex NER. Entity-wise performance comparison of different augmentation methods. Results are averaged across all languages.",
                "figure_data": "#Gold Method 200 Gold-Only LwTR DAGA MELM ACLM (ours) 64.42 48.92 PER LOC PROD GRP CORP 56.35 42.32 30.10 31.36 33.83 56.13 41.78 34.87 36.52 39.30 45.19 35.40 19.96 21.92 19.60 52.16 41.16 30.24 28.61 34.13 41.76 37.31 44.08 500 Gold-Only 63.05 48.48 42.75 37.55 45.10 LwTR 64.80 54.17 45.70 44.06 50.80 DAGA 51.82 41.11 28.58 30.50 34.10 MELM 58.41 45.64 37.04 34.11 40.42 ACLM (ours) 66.49 51.24 48.87 42.00 51.55CW 23.30 27.46 14.33 22.77 30.61 31.34 35.10 21.61 28.33 35.18"
            },
            {
                "figure_label": "",
                "figure_type": "table",
                "figure_id": "tab_13",
                "figure_caption": "-medical as it may make the model store wrongful knowledge. Our detailed analysis of generated augmentations shows that: (1) LwTR is prone to generating such incoherent sentences because it randomly samples entities from the corpus with the same tag for replacement. (2) MELM on the other hand, fine-tuned on a transformerencoder-based PLM, gets to see the entire context of the sentence for generating a new NE. However, it does not learn to focus on particular keywords and tends to generate a new NE based on the broader context of the sentence (e.g., it does not learn to differentiate between human and cow diseases and generates a new NE based on the broader context of the sentence). (3) ACLM generates highly reliable samples by conditioning on templates with keywords related to the NE. We illustrate examples of such templates in Fig.14 and 15.OriginalThe [European Commission] ORG said on Thursday it disagreed with [German] MISC advice to consumers to shun [British] MISC lamb until scientists determine whether mad cow disease can be transmitted to sheep.LwTRThe [European Sox] ORG seed on Thursday it disagreed with [German] MISC advice to consumers to shun [British] MISC regarding until scientists determine whether mad 70 disease can be --to sheep 1MELM[France] LOC 's [Aquaculture Committee] ORG suggested on Wednesday that consumers avoid eating meat from [German] MISC sheep until scientists determine whether mad cow disease can be transmitted to the animals. ORG said on Thursday that consumers should shun [British] MISC lamb until scientists determine whether the disease can be transmitted to humans. ORG has a scientific and multidisciplinary group of veterinary scientists who disagreed with the consumers on Thursday and decided to shun them out until scientists determine whether the [Bovine Spongiform Encephalopathy] MISC ( BSE ) --mad cow disease can be transmitted.",
                "figure_data": "ACLM w/o mixner The [European Commission] ACLM w/ mixner The [European Commission]for Hindi and English subsets of MultiCoNER dataset respec-tively. Extra Datasets: Fig 5, 6, 7 and 8 illustrate augmetation examples for CoNLL 2003 (Tjongdomains like bioE Additional DetailsKim Sang and De Meulder, 2003) (news), BC2GM (Smith et al., 2008) (bio-medical), NCBI Disease (Dogan et al., 2014) (bio-medical) and TDMSci (Hou et al., 2021) (science) datasets respectively. Except for on CoNLL 2003 datasets, both our base-lines, LwTR and MELM, generate incoherent and unreliable training samples for the other 2 datasets. We only compare ACLM with LwTR and MELM as these methods don't generate augmentations from scratch and modify existing sentences. WeModel Parameters: XLM-RoBERTa-large has \u2248 355M parameters with 24-layers of encoder, 1027-hidden-state, 4096 feed-forward hidden-state and 16-heads. mBART-50-large \u2248 has 680M parame-ters with 12 layers of encoder, 12 layers of decoder, 1024-hidden-state, and 16-heads. Compute Infrastructure: All our experiments are conducted on a single NVIDIA A100 GPU. An entire ACLM training pipeline takes \u2248 40 minutes.define unreliable sentences as sentences generatedwith an entity-context mismatch (eg. a NE de-scribing a disease prone to cows is placed in the context of humans or vice-versa). Generating unre-Dataset Details: We use 5 datasets in total for our experiments: MultiCoNER 2 (Malmasi et al.,liable augmentations prove fatal in data-sensitive"
            },
            {
                "figure_label": "",
                "figure_type": "table",
                "figure_id": "tab_14",
                "figure_caption": "Original [\u0939\u0901 \u0938\u0947 \u0932 \u0914\u0930 \u0947 \u091f\u0932] CW , \u090f\u0915 \u092a\u0930\u0940 \u0915\u0925\u093e \u093f\u091c\u0938\u092e \u0928\u093e\u092e\u093e\u0902 \u093f\u0915\u0924 \u092a\u093e \u0947 \u0921 \u0902 \u092c \u0915\u093e \u093f\u0928\u0936\u093e\u0928 \u091b\u094b\u095c\u0924\u0947 \u0939 LwTR [\u0913\u092a\u0928\u0911\u093f\u092b\u0938 \u0914\u0930 \u0947 \u091f\u0932] CW , \u090f\u0915 \u093f\u0915\u092f\u093e \u0924\u0915 \u093f\u091c\u0938\u092e \u0930\u0947 \u093f\u091f\u0902 \u0917 \u092a\u093e \u0947 \u0921 \u0902 \u092c \u0915\u093e \u092e \u093f\u0915\u092f\u093e\u0964 \u0939 MELM [\u25cc\u0940 \u0915 \u0947 \u091c\u0942 \u0930\u093e] CW , \u090f\u0915 \u092a\u0930\u0940 \u0915\u0925\u093e \u093f\u091c\u0938\u092e \u0928\u093e\u092e\u093e\u0902 \u093f\u0915\u0924 \u092a\u093e \u0947 \u0921 \u0902 \u092c \u0915\u093e \u093f\u0928\u0936\u093e\u0928 \u091b\u094b\u095c\u0924\u0947 \u0939 ACLM w/o mixner [\u0939\u0901 \u0938\u0947 \u0932 \u0914\u0930 \u0947 \u091f\u0932] CW \u0915\u0940 \u0915\u0925\u093e \u0915\u094b \u0967\u096f\u096f\u096f \u092e \u0928\u093e\u092e\u093e\u0902 \u093f\u0915\u0924 \u093f\u0915\u092f\u093e \u0917\u092f\u093e \u0925\u093e\u0964 ACLM w/ mixner [\u0939\u0901 \u0938\u0947 \u0932 \u0914\u0930 \u0947 \u091f\u0932] CW \u0915\u0940 \u092a\u0930\u0940 \u0915\u0925\u093e \u0915\u094b \u0928\u093e\u092e\u093e\u0902 \u093f\u0915\u0924 \u093f\u0915\u092f\u093e \u0917\u092f\u093e \u0925\u093e , \u093f\u091c\u0938\u0947 [\u093f\u0928\u0932\u0947 \u0938\u093e\u0924\u094b] GRP \u0938\u0948 \u091f\u0947 \u0932\u093e\u0907\u091f \u0928\u0947 \u091f\u0935\u0915 \u093e\u0930\u093e \u0938\u093e \u0930\u0924 \u093f\u0915\u092f\u093e \u091c\u093e\u0924\u093e \u0939\u0948 \u0964 [\u0939\u093e\u0935 \u0921 \u093f\u0935 \u093f\u0935 \u093e\u0932\u092f] GRP \u0938\u0947 \u0906\u093f\u0915 \u091f\u0947 \u0930 \u0915\u0940 \u093f\u0921 \u0940 \u093e \u0915\u0940\u0964 ACLM w/ mixner \u0935\u0939 [\u0939\u093e\u0935 \u0921 \u093f\u0935 \u093f\u0935 \u093e\u0932\u092f] GRP \u0938\u0947 \u093e\u0924\u0915 \u0915\u0940 \u093f\u0921 \u0940 \u093e \u0915\u0930\u0928\u0947 \u0915 \u0947 \u092c\u093e\u0926 \u0921\u0949 \u0930\u0947 \u091f \u0915\u0940 \u0909\u092a\u093e\u093f\u0927 \u093e \u0915\u0930\u0928\u0947 \u0915 \u0947 \u093f\u0932\u090f [\u093f\u0921\u091c\u093e\u0907\u0928 \u0915 \u0947 \u0939\u093e\u0935 \u0921 \u0947 \u091c\u0941 \u090f\u091f \u0942 \u0932] GRP \u092e \u0906\u093f\u0915 \u091f\u0947 \u0930 \u0907\u0902 \u091c\u0940\u093f\u0928\u092f\u0930 \u092c\u0928 \u0917\u090f\u0964 Figure 9: Augmentation examples on the Hindi subset of the MultiCoNER dataset. All generations are produced in a low-resource setting (500 training examples). gibson was educated at [harrow school] GRP , where he played in the cricket team, and at [trinity college] LOC . PER on the soundtracks of his films [du, the ware] CW and walkaway in 1986 and 1987. PER wrote the soundtracks for his films [sid and nancy walker] CW in 1987 . PER wrote the soundtracks for his film [sid and nancy and walker] CW and appeared in many of his films, including [powder] CW , [simply irresistible] CW and [dtox] CW .",
                "figure_data": "Original\u0909 \u094b\u0902 \u0928\u0947 \u0967\u096f\u0966\u0966 \u092e [\u0939\u093e\u0935 \u0921 \u093f\u0935 \u093f\u0935 \u093e\u0932\u092f] GRP \u0938\u0947 \u092e\u093e \u0930 \u093f\u0921 \u0940 \u0914\u0930 \u0967\u096f\u0966\u096a \u092e \u0921\u0949 \u0930\u0947 \u091f \u0915\u0940 \u0909\u092a\u093e\u093f\u0927 \u093e \u0915\u0940\u0964LwTR\u0909 \u094b\u0902 \u0928\u0947 \u0967\u096f\u0966\u0966 \u0939\u0948 \u0964 [\u0939\u093e\u0935 \u0921 \u093f\u0935 \u093f\u0935 \u093e\u0932\u092f] GRP \u0938\u0947 \u0967\u096f\u096f\u0969 \u093f\u0921 \u0940 \u0914\u0930 \u0967\u096f\u0966\u096a \u092e \u0921\u0949 \u0930\u0947 \u091f \u0915\u0940 \u0909\u092a\u093e\u093f\u0927 \u093e \u0915\u0940\u0964MELM\u0909 \u094b\u0902 \u0928\u0947 \u0967\u096f\u0966\u0966 \u092e [\u092c\u0949 \u0921 \u0915\u0949\u0932\u0947 \u091c] GRP \u0938\u0947 \u092e\u093e \u0930 \u093f\u0921 \u0940 \u0914\u0930 \u0967\u096f\u0966\u096a \u092e \u0921\u0949 \u0930\u0947 \u091f \u0915\u0940 \u0909\u092a\u093e\u093f\u0927 \u093e \u0915\u0940\u0964ACLM w/o mixner \u0909 \u094b\u0902 \u0928\u0947 \u0967\u096f\u0966\u0966 \u092e OriginalACLM w/o mixner [alex cox] ACLM w/ mixner [alex cox]"
            }
        ],
        "formulas": [
            {
                "formula_id": "formula_0",
                "formula_text": "D masked \u2190 \u2205, D aug \u2190 \u2205 for {X, Y } \u2208 D train do \u25b7 Training Loop t other , t entity \u2190 X K \u2190 T op p% of ATTNMAP(t other ) \u25b7 Keyword Selection X \u2190 GENTEMPLATE(X, {t other } \u2212 {K}) \u25b7 Selective Masking X \u2190 LINEARIZE( X, Y ) \u25b7 Labeled Sequence Linearization D masked \u2190 D masked \u222a { X} end for for {X, Y } \u2208 D masked do X \u2190 DYNAMICMASK(X, \u03b7) \u25b7 Dynamic Masking L f inetune \u2190 FINETUNE(L, X) \u25b7 Fine-tune ACLM end for for {X, Y } \u2208 D train do \u25b7 Generation Loop repeat R times: X \u2190 GENTEMPLATE(X, {t other } \u2212 {K}) \u25b7 Selective masking X \u2190 LINEARIZE( X, Y ) \u25b7 Labeled Sequence Linearization X \u2190 DYNAMICMASK( X, \u00b5) \u25b7 Dynamic Masking X aug \u2190 GENAUG(L f inetune ( X)), if \u03b3 < \u03b2 X augmix \u2190 MIXNER(L f inetune ( X)), if \u03b3 > \u03b2 D aug \u2190 D aug \u222a {X aug } \u222a {X augmix } end for D aug \u2190 POSTPROCESS(D aug ) \u25b7 Post-processing return D train \u222a D aug 4.2 Experimental Setup",
                "formula_coordinates": [
                    6.0,
                    306.14,
                    93.31,
                    218.28,
                    224.19
                ]
            },
            {
                "formula_id": "formula_1",
                "formula_text": "\u0906\u093f\u0927\u0915\u093e \u0930\u0915 \u0924\u094c\u0930 \u092a\u0930 \u092c \u0921 \u0938\u092e\u093e \u0939\u094b \u0917\u092f\u093e, \u0932\u0947 \u093f\u0915\u0928 \u0968\u0966\u0966\u0967 \u092e \u0905\u092a\u0928\u0947 \u090f \u092e [\u091c\u0940\u0935\u0928 \u0915\u0940 \u0938\u093e\u0901 \u0938\u0947 ] CW \u0915 \u0947 \u0938\u093e\u0925 \u0935\u093e\u092a\u0938\u0940 \u0915\u0940\u0964 [M] \u0906\u093f\u0927\u0915\u093e \u0930\u0915 [M] \u092c \u0921 [M] \u0968\u0966\u0966\u0967 [M] \u090f \u092e [M] <B-CW> \u091c\u0940\u0935\u0928 <B-CW> <I-CW> \u0915\u0940 <I-CW> <I-CW> \u0938\u093e\u0901 \u0938\u0947 <I-CW> [M] \u0935\u093e\u092a\u0938\u0940 \u0915\u0940 [M] \u0905\u0917\u0932\u0947 \u0938\u092b\u0932 \u0935\u0937 \u092e \u0907\u0938\u0915\u093e \u093f\u0935 \u093e\u0930 \u0906 \u0914\u0930 [\u092e\u0947 \u091f \u094b \u092e\u093f\u0928\u0932\u093e] LOC \u0947 \u092e \u0928\u090f \u092a \u0930\u0938\u0930\u094b\u0902 \u0915\u0940 \u093e\u092a\u0928\u093e \u0908 | [M] <B-LOC> \u092e\u0947 \u091f \u094b <B-LOC> <I-LOC> \u092e\u093f\u0928\u0932\u093e <I-LOC> \u0947 [M] \u0928\u090f \u092a \u0930\u0938\u0930\u094b\u0902 [M] \u093e\u092a\u0928\u093e \u0908 [M] \u092a\u093e \u093e \u0915\u094b [\u092e\u0947 \u095b] PROD \u0941 \u0927\u093e\u0935\u0927 \u0915 \u0915 \u0947 \u092a \u092e \u092d\u0940 \u092a\u0930\u094b\u0938\u093e \u091c\u093e \u0938\u0915\u0924\u093e \u0939\u0948 \u0964 [M] \u092a\u093e \u093e [M] <B-PROD> \u092e\u0947 \u095b <B-PROD> [M] \u092a\u0930\u094b\u0938\u093e [M]",
                "formula_coordinates": [
                    17.0,
                    73.0,
                    256.93,
                    456.09,
                    65.93
                ]
            }
        ],
        "doi": "10.18653/v1/2020.coling-main.343"
    },
    "Natural Language to Code Generation in Interactive Data Science Notebooks": {
        "authors": "Pengcheng Yin; Wen-Ding Li; Kefan Xiao; Abhishek Rao; Yeming Wen; Kensen Shi; Joshua Howland; Paige Bailey; Michele Catasta; Henryk Michalewski; Alex Polozov; Charles Sutton; Jacob Andreas; Johannes Bufe; David Burkett; Charles C Chen; Joshua Clausman; Jean Crawford; Kate Crim; Jordan Deloach; Leah Dorner; Jason Eisner; Hao Fang; Alan Guo; David Leo; Wright Hall; Kristin Delia Hayes; Kellie Hill; Diana Ho; Wendy Iwaszuk; Smriti Jha; Dan Klein; Theo Lanman; Percy Liang; C H Lin; Ilya Lintsbakh; Andy Mcgovern; Aleksandr Nisnevich; Adam Pauls; Dmitrij Petters; Brent Read; Dan Roth; Subhro Roy; Jesse Rusak; Beth Ann Short; Div Slomin; B Snyder; Stephon Striplin; Yu Su; Zachary Tellman; Sam Thomson; A A Vorobev; Izabela Witoszko; Jason Wolfe; A G Wray; Yuchen Zhang; Jacob Austin; Augustus Odena; Maxwell Nye; Maarten Bosma; David Dohan; Ellen Jiang; Carrie Cai; Michael Terry; Tom Brown; Benjamin Mann; Nick Ryder; Melanie Subbiah; Jared D Kaplan; Prafulla Dhariwal; Arvind Neelakantan; Pranav Shyam; Girish Sastry; Bei Chen; Fengji Zhang; A Nguyen; Daoguang Zan; Zeqi Lin; Jian-Guang Lou; Weizhu Chen; Mark Chen; Jerry Tworek; Heewoo Jun; Qiming Yuan; Henrique Ponde; Harrison Edwards; Yura Burda; Nicholas Joseph; Greg Brockman; Alex Ray; Raul Puri; Gretchen Krueger; Michael Petrov; Heidy Khlaaf; Pamela Mishkin; Xinyun Chen; Petros Maniatis; Rishabh Singh; Hanjun Dai; Max Lin; Denny 2022 Zhou;  Spreadsheetcoder; Qinyu Cheng; Linyang Li; Guofeng Quan; Feng Gao; Xiaofeng Mou; Xipeng 2022a Qiu; Zhoujun Cheng; Tianbao Xie; Peng Shi; Chengzu Li; Rahul Nadkarni; Yushi Hu; Caiming 2022 Xiong; Dragomir R Radev; Mari Ostendorf; Luke Zettlemoyer; Matthias Feurer; Aaron Klein; Katharina Eggensperger; Daniel Fried; Armen Aghajanyan; Jessy Lin; Sida I Wang; Eric Wallace; Freda Shi; Ruiqi Zhong; Yujian Gan; Qiuping Huang; Matthew Purver; John R Woodward; Jinxia Xie; Peng- Sheng Huang; Luyu Gao; Aman Madaan; Shuyan Zhou; Uri Alon; Ehsan Hosseini-Asl; Bryan Mccann; Chien-Sheng Wu; Semih Yavuz; Richard 2020 Socher; Junjie Huang; Chenglong Wang; Jipeng Zhang; Cong Yan; Haotian Cui; Jeevana Priya Inala; Colin Clement; Nan Duan; Jianfeng Gao; Sean Kandel; Andreas Paepcke; Joseph Hellerstein; Jeffrey Heer 2011 Wrangler; Shubhra ( Santu; ) Karmaker; Micah J Hassan; Lei Smith; Chengxiang Xu; Kalyan Veeramachaneni Zhai; Thomas Kluyver; Benjamin Ragan-Kelley; Fer- Nando P\u00e9rez; Brian Granger; Matthias Bussonnier; Jonathan Frederic; Kyle Kelley; Jessica Hamrick; Jason Grout; Sylvain Corlay; Paul Ivanov; Dami\u00e1n Avila; Safia Abdalla; Yuhang Lai; Chengxi Li; Yiming Wang; Tianyi Zhang; Scott Wen; Daniel Yih; Sida Fried; Tao Wang;  Yu; Chia-Hsuan Lee; Oleksandr Polozov; Matthew Richardson;  Kaggledbqa; Zi Lin; Jeremiah Liu; Jingbo Shang;  Neural; Reginald Long; Panupong Pasupat; Arpit Narechania; Arjun Srinivasan; John T Stasko;  Nl4dv; Alfredo Nazabal; Christopher K I Williams; Gio- Vanni Colavizza; Camila Rangel Smith; Erik Nijkamp; Bo Pang; Hiroaki Hayashi; Lifu Tu; Huan Wang; Yingbo Zhou; Silvio Savarese; Anders Andreassen; Guy Gur-Ari; David Bieber; Aitor Lewkowycz; David Luan; David A Patterson; Joseph Gonzalez; Quoc V Le; Chen Liang; Llu\u00eds-Miquel Mungu\u00eda; Daniel Rothchild; David R So; Jianlin Su; Yu Lu; Shengfeng Pan; Bo Wen; Yunfeng Liu;  Roformer; April Yi Wang; Dakuo Wang; Jaimie Drozdal; Michael Muller; Soya Park; Justin D Weisz; Xuye Liu; Lingfei Wu; Casey Dugan;  Documen; Yu Feng; Rastislav Bodik; Josh Andres; Erick Oduor;  Autods; Vera Liao; Yunfeng Zhang; Udayan Khurana; Horst Samulowitz; Lisa Amini; Jason Wei; Xuezhi Wang; Dale Schuurmans; Ed Chi; Zhengkai Wu; Vu Le; Ashish Tiwari; Sumit Gulwani; Arjun Radhakrishna; Ivan Radicek; Gustavo Soares; Chen Henry Wu; Torsten Scholak; Michihiro Yasunaga; Chien-Sheng Wu; Ming Zhong; Vic- Tor Zhong; Bailin Wang; Chengzu Li; Connor Boyle; Ansong Ni; Ziyu Yao; Lingpeng Kong; Rui Zhang; Noah A Smith; Yunyi Yang; Yunhao Li; Xiaojun 2020 Quan; Tao Yu; Yang Er; Suyi Li; Eric Xue; Victoria Xi; Yi Chern Lin; Tianze Tan; Zihan Shi; Youxuan Li; Michihiro Jiang; Sun- Grok Yasunaga; Tao Shim; Alexander R Chen; Zifan Fabbri; Luyao Li; Yuwen Chen; Shreya Zhang; Vincent Dixit; Caiming Zhang; Richard Xiong; Walter S Socher; Dragomir R Lasecki;  Radev;  Cosql; Yi Chern Tan; Victoria Lin; Irene Z Li; Tao Chen; Emily Ji; Shreya Dixit; David Proctor; Sungrok Shim; Jonathan Kraft; Vin- Cent Zhang; R 2019b Radev",
        "pub_date": "",
        "abstract": "Computational notebooks, such as Jupyter notebooks, are interactive computing environments that are ubiquitous among data scientists to perform data wrangling and analytic tasks. To measure the performance of AI pair programmers that automatically synthesize programs for those tasks given natural language (NL) intents from users, we build ARCADE, a benchmark of 1,078 code generation problems using the pandas data analysis framework in data science notebooks. AR-CADE features multiple rounds of NL-to-code problems from the same notebook. It requires a model to understand rich multi-modal contexts, such as existing notebook cells and their execution states as well as previous turns of interaction. To establish a strong baseline on this challenging task, we develop PACH-INCO, a 62B code language model (LM) for Python computational notebooks, which significantly outperforms public code LMs. Finally, we explore few-shot prompting strategies to elicit better code with step-by-step decomposition and NL explanations, showing the potential to improve the diversity and explainability of model predictions. ARCADE is publicly available at https://github.com/ google-research/arcade-nl2code/.",
        "sections": [
            {
                "heading": "Introduction",
                "text": [
                    "Data science is the process of extracting insights from data (Wang et al., 2021a), and has become an integral part of decision making and knowledge discovery (Donoho, 2017). Data scientists and machine learning (ML) practitioners often use computational notebooks, which are interactive environments such as Jupyter notebooks (Kluyver et al., 2016) and Google Colab, in their work. Data scientists spend a significant amount of time on data wrangling tasks to process raw data into usable forms (illustrated in Fig. 1), as well as exploratory data analysis (EDA) to gain insights * Correspondence to pcyin@google.com For each month in that year, how many games that has a rating of more than four? pd.pivot_table (df, index=df['ADDED'].dt.year, ..., aggfunc=np.count_nonzero, fill_value='0').rename_axis( index='Year', columns='Month')",
                    "What is the amount of games added in each year for each month? (show a table with index as years, columns as months and fill null values with 0) for decision making (Agashe et al., 2019;Wang et al., 2022a). This has motivated research on automating and accelerating the data science workflow in general (Aggarwal et al., 2019;Wang et al., 2021a,b), with particular interest in data wrangling and EDA tasks (Bavishi et al., 2019;Jain et al., 2021;Nazabal et al., 2020;Kandel et al., 2011). Meanwhile, large language models (LLMs) trained on code can assist developers by translating natural language (NL) intents into executable programs (Chen et al., 2021a;Austin et al., 2021;Chowdhery et al., 2022;Nijkamp et al., 2022;Fried et al., 2022), with promising applications in synthesizing code for data wrangling and EDA tasks (Jain et al., 2021;Rajkumar et al., 2022;Cheng et al., 2022b). Computational notebooks also present unique challenges to LLMs, as notebooks freely mix NL, code, graphics, and execution results (Perkel, 2021), and because of their interactivity, notebooks feature multiple interdependent NL-to-code problems (Heyman et al., 2021).",
                    "Several benchmarks have been proposed to evaluate program synthesis of data science programs from NL intents, but these datasets have several limitations. First, some datasets derive from data science tutorial notebooks (Agashe et al., 2019;Chandel et al., 2022), which tend to contain NL text (e.g., exercise questions) that is verbose and elaborate, instead of the concise, ephemeral style that developers write when interacting with code LMs (Barke et al., 2022, more in \u00a73). Other datasets assume that the developer provides extra information, such as unit tests or input/output examples (Chandel et al., 2022;Jain et al., 2022), but such systems pose an extra burden to users who might not normally write such tests or examples during their workflow (Pimentel et al., 2019). Finally, existing datasets usually contain independent tasks with isolated contexts (Lai et al., 2022), or a limited number of contextually dependent problems (Huang et al., 2022), rather than having multiple, related tasks such as in Fig. 1. Therefore, there is a need for a benchmark with realistic NL intents, rich notebook context, and a series of interrelated problems, so as to better reflect real-world usage by data scientists.",
                    "To fill this gap, we present ARCADE, 1 a new benchmark for code generation for data wrangling and EDA tasks in computational notebooks ( \u00a73). ARCADE consists of 1,078 problems spanning across 136 notebooks based on 106 ML datasets. It features a series of NL utterances written by professional data scientists with the intention of interacting with an AI assistant (e.g., green texts in Fig. 1), with high-quality code solutions using the pandas library. To mitigate the risk of data leakage, 60% of the problems are created from scratch, based on recent ML datasets on Kaggle (e.g., the csv file in c 1 , Fig. 1). 2 ARCADE also challenges LLMs with grounded language understanding, where a model needs to leverage variable states (e.g., df ['TIME'] in c 2 ) to interpret NL semantics (e.g., \"min and max\" in u 1 ). Finally, problems in ARCADE are challenging, involving richer data science API usage than existing benchmarks.",
                    "To demonstrate how ARCADE can motivate new research on LLMs for data science, we develop PACHINCO, a 62B code LM tailored for Python computational notebooks, trained on a mixture of NL, source code, and Jupyter notebooks data ( \u00a74). PACHINCO significantly outperforms public code LMs on ARCADE ( \u00a75.2). Even so, all models have difficulty on our benchmark, showing that it is a challenging task. Further, we explore few-shot prompting strategies to alter the style of model predictions, such as decomposing code into step-bystep structures and adding inline NL explanations. Not only is code in this style potentially more understandable to novice data scientists, prompting the model to explain its solutions also improves the diversity of the model's predictions ( \u00a75.3)."
                ],
                "publication_ref": [
                    "b0",
                    "b1",
                    "b0"
                ],
                "figure_ref": [
                    "fig_0",
                    "fig_0",
                    "fig_0",
                    "fig_0"
                ],
                "table_ref": []
            },
            {
                "heading": "Problem Statement",
                "text": [
                    "A computational notebook is an interactive computing environment that allows mixing code, text, and graphics. A notebook consists of a sequence of Markdown or source code cells. Given a partial notebook context with n cells {c i } n i=1 and a userspecified intent u for the next cell c n+1 (e.g., u 1 in Fig. 1 for n = 1), we aim to generate code for c n+1 that fulfills the user's intent (Agashe et al., 2019). We refer to the pair ({c i }, u) as a problem. This process could proceed sequentially with multiple rounds between the user and a system (Heyman et al., 2021), so a single notebook can contain multiple problems. To satisfy subsequent intents (e.g., u 4 ), a system will leverage the updated notebook context (e.g., {c i } 5 i=1 ) which includes previous problems (e.g., those involving u 1 to u 3 ).",
                    "As in Fig. 1, problems within a notebook often have interesting dependency structures. They may share execution context (e.g., DataFrame df), form semantically coherent turns (e.g., c 4 and c 5 ), or exhibit non-trivial long range data dependencies (e.g., from c 6 to c 2 , or c 7 to c 3 ). These dependency structures are more diverse than existing multi-turn code generation tasks with sequentially dependent problems (Nijkamp et al., 2022)."
                ],
                "publication_ref": [
                    "b0"
                ],
                "figure_ref": [
                    "fig_0",
                    "fig_0"
                ],
                "table_ref": []
            },
            {
                "heading": "ARCADE: A Benchmark of pandas",
                "text": [
                    "Data Science Code Generation 3.1 Constructing ARCADE ARCADE consists of 1,078 NL-to-code problems from 131 notebooks based on 106 unique ML datasets, sourced from existing data science notebooks on GitHub (Existing Tasks split) and new ones created from scratch (New Tasks split). The problems are annotated by professional data science freelancers. This section outlines the dataset creation process. See Appendix A for more details.",
                    "Repurposing Existing Notebooks To build the Existing Tasks split, we identify candidate code cells performing data wrangling and EDA tasks from existing high-quality notebooks, and then manually annotate these cells with NL intents. Specifically, we perform static analysis to identify notebooks with rich code cells related to data wrangling and EDA tasks (e.g., by identifying cells using pandas functions) from public notebook corpora such as JuICe (Agashe et al., 2019) and BIG-QUERY. We then select 63 notebooks with the greatest number of candidate code cells for annotation, covering 36 ML datasets from a variety of domains. Annotation consists of judging the quality of candidate cells, fixing errors, and creating intents summarizing the code (described below)."
                ],
                "publication_ref": [
                    "b0"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Creating Notebooks for Novel ML Datasets",
                "text": [
                    "The Existing Tasks split captures realistic problems and notebook contexts, but may result in artificially high evaluation accuracies due to potential leakage of evaluation notebooks in the training data of LLMs, which is a common issue in LLM evaluation (Brown et al., 2020). 3 To prevent contamination, we additionally build the New Tasks split with 660 problems in notebooks created from scratch. Specifically, we create notebooks with wrangling and EDA tasks for 70 tabular ML datasets that appeared on Kaggle since February 2022 and are manually verified to differ from existing datasets on the Web. For each Kaggle dataset, we instructed the annotators to create a notebook with tasks that would provide insights for building an ML model for the dataset. To make the problems more challenging, we also encouraged them to make tasks that require at least 5 pandas API calls to solve.",
                    "Annotating NL Intents When creating NL intents for a problem, 4 annotators are instructed to phrase their intents in the way they prefer when interacting with an AI system to help them implement the existing code solution, while keeping the intents natural and concise, without redundant elaboration such as line-by-line explanation. In addition, to 3 JuICe and BigQuery primarily contain source files from 2019 or earlier, which exacerbates this issue. 4 For New Tasks, intents are created before the solutions.",
                    "make the intents more challenging, we encourage annotators to refer to entities and variables in the intents using semantic rewrites without introducing ambiguity (e.g., use \"convert all binary columns to bool\" instead of listing columns verbatim), reminiscent of synonym substitution for labeling utterances in text-to-SQL (Gan et al., 2021).",
                    "Mitigating Ambiguity in NL Intents Creating succinct NL intents without ambiguity could be non-trivial in this open-domain code generation setting, especially when there could be multiple plausible interpretations of an intent. For example, without the underlined part of u 5 (Fig. 1), a programmer or a system may propose alternative solutions using different table schema. Therefore, for such open-ended problems where there could be multiple alternative ways to present the answer, we ask annotators to provide extra specification in their intents about the desired output (e.g., schema of the output DataFrame, such as the underlined part in u 5 ). Even with these additional semantic constraints, empirically we observe that about 50% of intents are still underspecified, making ARCADE a challenging benchmark for handling realistic NL intents with uncertainty. We present more analysis in \u00a73.2 and introduce a robust evaluation metric that mitigates this issue in \u00a73.3. Annotation Guideline Besides mitigating ambiguity in intents, there are many other aspects to consider during annotation, such as notebook style (e.g., removing background material and hints in tutorial notebooks in Existing Tasks to avoid solution leakage), task diversity, and quality control, which we discuss in a 35-page annotation guideline provided to annotators, outlined in Appendix B."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_0"
                ],
                "table_ref": []
            },
            {
                "heading": "Dataset Analysis",
                "text": [
                    "We first present some analysis on ARCADE and then compare it to existing datasets in Tab. ited variety in output type (e.g., u 2 , u 3 , Fig. 1), or contain sufficient output specifications ( \u00a73.1). The remaining half are underspecified: (a) only 10% of the ambiguous intents lack descriptions of target columns in output DataFrames; more interestingly, (b) 42% imply entity sets as outputs (e.g., Where are the top 10 customers receiving the highest ::::::: incomes located?), answerable either using container types with entity names only (e.g., a List or Series of locations), or DataFrames with entities and additional columns (e.g. ::::::: incomes) mentioned in the intents; (c) 23% imply output with complex schema, such as a nested row index or table header (e.g., Show the time of the day and the fare price for each airline) which is difficult to infer without extra information, and (d) 20% require outputs with more complex structures (e.g., multiple variables) or imply additional post-processing steps such as data imputation, while (e) the remaining 5% have complex intents that are difficult to understand without additional clarifications. Notebook Context Helps Disambiguate Intents Notably, while half of the intents are underspecified, 25% of those cases can be disambiguated by referring to prior rounds of problems in the context with similar query/output patterns. These are often follow-up queries (e.g., Which of them are . . .) of a prior turn (e.g., Show me all . . .), analogous to similar thematic relation patterns in contextual semantic parsing (Yu et al., 2019b). Comparing Existing and New Tasks Comparing the Existing Tasks and New Tasks splits, the latter is more challenging, as measured by the number of pandas API invocations and the AST size of reference solutions (Tab. 1, Bottom). understanding, where the model needs to ground semantic concepts in the intents (e.g., \"max and min\" in u 1 , Fig. 1) to the corresponding variable execution states in the context (e.g., the TIME column in df). The need for understanding semi-structured data and performing necessary transformations (Pasupat and Liang, 2015) using an open-domain programming language (PL, Python) makes language grounding in ARCADE more difficult than in existing EDA tasks using domain-specific PLs, such as semantic parsing over databases (Yu et al., 2019b "
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_0",
                    "fig_0"
                ],
                "table_ref": []
            },
            {
                "heading": "Evaluation by Fuzzy Output Matching",
                "text": [
                    "We aim to synthesize programs in notebooks using only cell contexts and NL intents without extra specification such as unit tests ( \u00a72). As in \u00a73.2, those intents are often underspecified and have multiple alternative solutions. We therefore approximately match the execution output of a predicted program with the annotated reference to determine if they are functionally equivalent primarily based on two categories of heuristics. 6 First, we canonicalize variables with different container data types. Second, we allow for partial matching between complex DataFrames. Specifically, for a reference frame v with a set of column vectors {v i }, each representing the cell values for the i-th column, a prediction v is considered equivalent with v iff for any v i \u2208 v, v i \u2208 v. Intuitively, we consider a predicted program correct if its output DataFrame contains all the columns (and cell entries) in the 5 Calculated by counting function names in a predefined list of functions from pandas, numpy, and similar libraries.",
                    "6 For code that in-place modifies a variable (e.g., df in c2), we treat the modified variable as the output.",
                    "reference frame, since a user could easily create a more compact view of the frame by selecting a subset of target columns. Empirically, we find our evaluation metric is reliable in identifying solutions with alternative output structures, with a relatively low false-negative rate (Appendix J)."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "PACHINCO: Adapting Code LMs to Computational Notebooks",
                "text": [
                    "We introduce PACHINCO, an LM for notebooks.  [2] # Schema of Dataframes: # Columns in df with example values: # Stu_Name (Mike),Engineering (90),English (89),Math (92) [3] Get the students with an average score above 90 for science subjects of problems with at least one correct sample given a sample size k. To reduce variance, we estimate pass@k (k \u2264 30) by drawing 50 samples for each problem (Chen et al., 2021a). Decoding temperature t is 0.2 for k = 1 and 0.8 for k > 1. Refer to Appendix E for inference details.",
                    "Base"
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "LM Prompting Strategies",
                "text": [
                    "We explore two prompting strategies: prompting using the notebook context of a problem ( \u00a75.2), and few-shot prompting with extra exemplars as a prompt prefix before the notebook context ( \u00a75.3) to impose more control on the predicted code's style.",
                    "Prompting with Notebook Contexts Fig. 3 depicts an example problem at c 3 for prompting, where the prompt is the notebook context (preceding cells c 1 and c 2 ) and the current intent. The context also includes NL descriptions of the imported DataFrame schema (c 2 ), such as its columns and example cell values, crucial for grounded understanding of structured knowledge (Xie et al., 2022). Completion 3a shows an example prediction. For the following problems after c 3 (not shown), we use annotated reference solutions to previous turns in their contexts, reminiscent of multi-turn taskoriented dialogue evaluation (Andreas et al., 2020).",
                    "Using Extra Few-shot Exemplars Besides the basic setting, we also explore prompting using four we also use a preamble to further elicit step-wise decomposition in predictions. See Appendix L for a complete list of example prompts."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_5"
                ],
                "table_ref": []
            },
            {
                "heading": "Main Results",
                "text": [
                    "Tab. 2 reports pass@k on ARCADE using notebook contexts as prompts. PACHINCO achieves strong performance on both the Existing Tasks split and the New Tasks split due to its larger size and domain-specific fine-tuning. For reference, we also report the results using the CODEX API. PACHINCO significantly outperforms the smaller cushman API, while davinci-002 is stronger. While we cannot gain much insight from the results due to limited knowledge about davinci-002, through error analysis, we find that davinci-002 is better at instruction following, especially in understanding NL descriptions of complex DataFrame schema ( \u00a75.1). Intuitively, compared to existing benchmarks, NL understanding on ARCADE is more challenging given its succinct and potentially ambiguous intents together with rich contexts. Therefore, the gap between CODEXdavinci-002 and our models could be larger on AR-CADE compared to that on other datasets in Tab. 3. We leave improving the instruction following skills of PACHINCO as interesting future work. Comparing Existing Tasks and New Tasks The pass@k scores on Existing Tasks are significantly higher than on New Tasks across all models. However, comparing the improvements after Python and notebook-specific fine-tuning of the base LM, Further Analysis We report more ablation experiments, such as pass@k w.r.t. problem complexity and the notebook context size in Appendix G."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Few-shot Prompting Results",
                "text": [
                    "Next, we investigate few-shot prompting to help a model better understand the task while controlling 132 Step-by-step prompting leads to much greater diversity than the baselines. (C) Self-consistency decoding accuracy using 1 reranked sample on New Tasks.",
                    "the style of predictions. 8 Tab. 4 summarizes the results on New Tasks. We start with the prompting strategy of predicting just the Step-by-Step Code (SbS) without preambles or explanations (i.e., only the code part of Completion 3b in Fig. 3), which improves over the baseline using only notebook contexts (c.f. Tab. 2). SbS prompting is especially effective for problems without adequate contexts, yielding 6% absolute improvements for the first two rounds of problems in a notebook as compared to the zero-shot baseline. More interestingly, even if we include more context in the baseline such that its prompt length matches SbS prompting (Baseline + More Context), SbS prompting still outperforms, again suggesting the complimentary value of extra exemplars.",
                    "Step-by-step Prompting Improves Code Style SbS prompting also changes the style of predicted code, which is decomposed into more lines (LoC \u2191 , Tab. 4) where each line is simpler (Tokens/API per Line \u2193 ). In contrast, if we instead prompt the model using exemplars with \"vanilla\"-styled code following the common practice of chaining multiple pandas API calls in a single line (Vanilla Code, e.g., Completion 3a in Fig. 3), we get less pass@k improvement over the baseline while the code style remains consistent.",
                    "Next, using preambles (+Preamble) to further encourage the model to produce step-by-step solutions improves the level of decomposition (LoC \u2191 , Tokens/API per Line \u2193 ) while maintaining pass@k. More surprisingly, with additional inline NL explanations for each step (+Pre. + Explanation), PACHINCO produces even more decomposed solutions with slightly improved accuracy. As a result, those predictions have rich NL comments, with the number of comment lines nearly equal to the number of code lines. Interestingly, the predicted solutions are also more complex, as indicated by the increased pandas API usage (# API \u2191 ). However, as we explain in Appendix H, on Existing Tasks, while prompting with NL explanations still alters the code style, pass@k is slightly worse. This is likely due to the fact that this split contains problems similar to the base LM's training data, and prompting the model to generate additional NL comments breaks its \"flow\" of generating code by memorization. Moreover, this split is also dominated by simpler tasks requiring fewer steps, while explanation-based prompting favors predicting more complex solutions with richer API usage and more code tokens (Tab. 4). Nevertheless, prompting with explanations yields more diverse predictions and could also help developers better understand the generated solutions, as we discuss next and also in \u00a76."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_5",
                    "fig_5"
                ],
                "table_ref": []
            },
            {
                "heading": "Step-by-Step Prompting Diversifies Solutions",
                "text": [
                    "We also explore whether SbS prompting helps produce more diverse solution approaches. Intuitively, more output diversity could improve the odds of finding a solution at higher sample sizes. Determining whether two solutions are \"different\" is difficult and subjective, but we approximate this in two ways. First, we use the sequence of pandas API calls as a signature of the high-level solution pattern. Second, since two solutions might have the same functionality (executing to the same output), we also cluster predictions based on their outputs.",
                    "Figs. 4a and 4b plot the cumulative distributions of the number of unique solution patterns and output clusters on the New Tasks split. SbS prompting increases diversity on both metrics compared to the baselines. Notably, prompting with NL explanations yields even more solution patterns.",
                    "Diverse predictions could help handle underspecified intents ( \u00a73.2), since they might correspond to different interpretations of an ambiguous intent. Having diverse predictions also allows us to trans-late better pass@k performance into better performance on a single suggestion using post-hoc reranking such as self-consistency decoding (Wang et al., 2022b), where we return the user one prediction from the largest output cluster instead of showing all k predictions (Fig. 4c). SbS prompting significantly improves over baselines. Notably, the 1-sample accuracy of SbS with NL explanations outperforms pass@5 of the baseline in Tab. 2. Refer to Appendix I for further analysis.",
                    "As a side note, while SbS prompting leads to improved sample diversity, it may not directly improve code quality. If we consider functional correctness to approximate code quality, we observe that vanilla few-shot prompting and SbS variants have a similar fraction of correct samples (\u223c 15%). This suggests that for SbS prompting, it is higher sample diversity that may contribute to improved pass@k (k > 1) and reranking accuracy instead of other potential factors."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_6"
                ],
                "table_ref": []
            },
            {
                "heading": "Case Study: How Useful is Predicted",
                "text": [
                    "Code with Step-wise Explanations?",
                    "Finally, we remark that besides improving solution diversity, step-by-step prompting with NL explanations could also potentially help novice data scientists understand model-generated solutions, as shown in the following qualitative case study. First, NL explanations could help users follow the flow of complex data transformations for programs involving a chain of pandas operations. By decomposing and explaining how data is manipulated after individual transformation steps, it is easier for users to understand the solution and track its dataflow behind the scene, especially when some steps involve complex computation (Fig. 17), or the underlying schema is less intelligible (e.g., column names with abbreviations, Fig. 18). Additionally, some inline explanations also describe the output of intermediate steps, which is particularly helpful when these steps involve advanced pandas functions whose output structure may not be obvious, such as pd.unstack (Fig. 19) Meanwhile, step-wise NL explanations serve as high-level procedural descriptions of code, which enable users to easily browse through and understand different solution approaches without being distracted by nuances in the actual code implementation (Fig. 20). Moreover, explanations also help users verify the code solutions by identifying potentially incorrect steps (Fig. 21). The observations presented here offer insight into potential future avenues to improve the utility of code LMs for developers through the use of step-by-step explanations, which we leave as important future work."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_21",
                    "fig_21",
                    "fig_21",
                    "fig_3",
                    "fig_21"
                ],
                "table_ref": []
            },
            {
                "heading": "Related Work",
                "text": [
                    "Automating Data Science The amount of expertise required in data science has called for development of systems to automate its lifecycle (Wang et al., 2021b). Much work has focused on automating feature engineering and tuning of ML models (AutoML, He et al., 2021;Karmaker et al., 2020), with well-established systems (Feurer et al., 2015) and benchmarks (Z\u00f6ller and Huber, 2021). This paper focuses on automating tabular data wrangling and EDA tasks, which account for nearly the same amount of code and documentations in notebooks as that for ML-related tasks (Agashe et al., 2019;Wang et al., 2022a). Along this line, existing research synthesizes data wrangling programs using I/O examples (Bavishi et al., 2019;Shi et al., 2020) or partial table contents (Chen et al., 2021c), followed by recent efforts using LLMs with additional NL specifications (Jain et al., 2021;Bavishi, 2022). This paper considers code generation in notebooks with multiple contextually dependent problems (see \u00a73.2 for recent work). In addition, other works have also considered applications such as synthesizing visualization plots (Amar et al., 2005;Wang et al., 2019;Narechania et al., 2020;Fu et al., 2020;Wu et al., 2022b). Context-driven Code Generation Our work is another application of context-driven code generation, which maps a series of contextually dependent utterances to programs, such as domain-specific logical forms (Zettlemoyer and Collins, 2009;Long et al., 2016;Iyyer et al., 2017;Andreas et al., 2020), SQL queries over databases (Hemphill et al., 1990;Suhr et al., 2018;Yu et al., 2019a,b), or generalpurpose PLs (Nijkamp et al., 2022). ARCADE further offers contextually dependent utterances exhibiting non-trivial dependencies ( \u00a72), with target programs defined in a general-purpose PL."
                ],
                "publication_ref": [
                    "b0",
                    "b2"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Conclusion",
                "text": [
                    "In this paper we present ARCADE, a code generation benchmark for data wrangling and EDA tasks in computational notebooks, featuring problems with realistic NL intents and rich contexts. We also develop PACHINCO, a 62B LM tailored for data science. PACHINCO outperforms public LMs on ARCADE, while being effective in few-shot learning to improve code style and solution diversity."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Limitations",
                "text": [
                    "We discuss limitations of our work that hopefully could inspire future research in this avenue. Task Coverage in ARCADE ARCADE consists of realistic data wrangling and EDA tasks for a variety of ML datasets. In particular, we focus on problems that can be solved using pandas because of its popularity in data science -90% of Kaggle notebooks use pandas. Still, our annotated problems may not cover all the types of tasks in these two categories. As an example, data visualization is an important part of EDA. Our dataset also includes 59 natural language to plotting problems, which are not used in this paper due to challenges in automated evaluation (Chen et al., 2021b). Future work might consider evaluation of plotting tasks using unit tests (Lai et al., 2022). Additionally, some of the existing datasets in Tab. 1 usually contain broader types of problems other than the wrangling and EDA tasks considered in this paper (e.g., fitting ML models, \u00a77). We leave expanding the task spectrum as important future work. Session-level Evaluation ARCADE features multiple contextually dependent problems in computational notebooks. As the first step towards evaluating code LMs in this interactive program synthesis paradigm, we report turn-level accuracy, and generate notebook context for prompting using ground-truth solutions for the prior turns of a problem ( \u00a75.1), following the common evaluation protocol in task-oriented dialogue (Hosseini-Asl et al., 2020;Andreas et al., 2020). Future work could consider a more realistic scenario of session-level evaluation where history contexts consist of model-predicted code instead of the reference (Yang et al., 2020;Nijkamp et al., 2022). However, this evaluation setting is still not ideal without modeling the user (e.g., asking follow-up questions to correct a model's predictions in a turn before proceeding to the next round, see Austin et al., 2021), which often requires building specialized simulators (Cheng et al., 2022a). Reliance on Large Language Models Our experiments are based on public and in-house large code LMs (PACHINCO), which require adequate computational resources 9 and create carbon emissions (Patterson et al., 2021). Their predictions could also be subject to known issues such as misalignment with user intents; for a discussion 9 FLOPs usage of fine-tuning PACHINCO is 3.6 \u00d7 10 22 . of these and other risks of code language models, see Chen et al. (2021a, Appendices E-H) and Chowdhery et al. (2022, Section 6.4). To reduce the amount of computational resources required, our initial prompting experiments ( \u00a75.2) and error analysis (Appendix J) suggest that leveraging program execution information (e.g., schema descriptions) could be a promising direction to improve sample efficiency and reduce the size of code LMs (Nye et al., 2021), while explicit modeling of code-intent correspondence (Zhang et al., 2022) could be a viable path to mitigate alignment issues in model predictions. In addition, as generative AI coding tools are becoming more available to developers, more efforts are required to understand the potential limitations of those systems and the risks they may pose, such as producing insecure code and over-reliance on model predictions (Chen et al., 2021a). We leave addressing those issues as important future work. "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Supplementary Materials A Details of Dataset Construction",
                "text": [
                    "In this section we elaborate on the process of building ARCADE."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.1 Mining Examples from Existing Notebooks",
                "text": [
                    "To build the Existing Tasks split with annotated NL-to-code problems from publicly-available notebooks, we first identify candidate code cells performing data wrangling and EDA tasks from existing high-quality data science notebooks, and then manually annotate these cells with NL intents.",
                    "Collecting Notebooks for Annotation To form a pool of candidate notebooks, we use JuICe (Agashe et al., 2019), a collection of Jupyter notebooks from GitHub, together with additional notebooks from BIGQUERY 10 , yielding over 1.5M notebooks in total. These notebooks are first filtered and neardeduplicated, similar to PACHINCO's training data preprocessing step in Appendix D. We then identify candidate code cells from the remaining notebooks for annotation. Specifically, we select code cells that are either (1) contain pandas programs with at least three API calls, or (2) preceded by a Markdown cell with a short question as its content (e.g., What are the top 10 producers?). The first heuristic is useful to identify complex wrangling tasks, while the second one is particularly effective in finding interesting dataset-specific EDA tasks, and the existing Markdown texts also provide reference for labeling intents later. Next, we group the notebooks with at least one candidate cell based on their underlying ML datasets (e.g., imported using pd.read_csv()), and then select the top 5 notebooks with the greatest number of candidate cells from a curated set of 36 dataset groups for annotation. This set contains ML datasets from a variety of domains and schema. We favor notebooks with more candidate cells so that we could extract multiple NL-to-code problems within the same notebook.",
                    "Annotation We hired a group of data scientists to annotate the notebooks selected above, following the process outlined in \u00a73.1. Annotation primarily consists of judging the quality of candidate code cells, fixing any errors, and creating NL intents summarizing the code. Throughout the annotation process, we find that re-purposing notebooks in the wild to build our benchmark is not an easy task. As an example, many notebooks in JuICe are data science tutorials, which often contains documentation that includes background knowledge, reference materials, and even solution hints. Those extra information makes the code generation task easier, and may not reflect the style of ordinary notebooks authored by data scientists in their day-to-day work. We therefore ask the annotators to clean the notebook and remove such extra information whenever possible."
                ],
                "publication_ref": [
                    "b0"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.2 Creating Notebooks with Examples from Scratch",
                "text": [
                    "The problems derived from high-quality GitHub notebooks could capture realistic tasks and notebook contexts, but may result in artificially high evaluation accuracies due to potential leakage of evaluation notebooks to the training data of LLMs, which is a common issue in LLM evaluation (Brown et al., 2020).",
                    "To defend against this data contamination, we additionally annotated 660 problems by creating notebooks from scratch. Sourcing Novel ML Datasets To ensure that those newly-created examples can be used to evaluate the generalization ability of code LMs on unseen ML datasets, we create notebooks targeting data wrangling and EDA tasks for 70 tabular ML datasets that have been recently uploaded to the Kaggle data science platform since February 2022. Those short-listed datasets are manually selected from a pool of 600 datasets with reasonably complex schema (e.g., having columns with diverse data type), and are verified by our annotators that no older-versioned datasets with similar schema appeared before.",
                    "Creating Notebooks For each ML dataset, the annotators were asked to create one notebook with a series of wrangling and EDA tasks annotated with NL intents. Specifically, we ask annotators to come up with tasks that they would like to perform in order to gain insights into these recently appeared ML datasets in order to build models for them. We follow the same standard to create intents as in creating",
                    "Existing Tasks. To make the problems more challenging, annotators are encouraged to create harder tasks whose code solutions require at least 5 pandas API calls."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A.3 Annotation Process and Quality Assurance",
                "text": [
                    "Eight freelancers proficient in English and reported skill in pandas are hired from Upwork, with an average of 3 years of experience. All the annotators went through a qualification round with data science interview questions. In building the Existing Tasks split, each freelancer first performed a trial batch by annotating a single notebook, and received detailed comments from the first author, before proceeding with annotating the rest of assigned notebooks. Each annotated sample is reviewed by the first author. Annotators spent 3 \u223c 4 minutes to create each problem on average. To create the more challenging New Tasks split from scratch, we only invite the top-3 performers for this task since it is harder than labeling existing notebooks. Each created notebook is first peer reviewed by another annotator, before a final round of review by the first author. Since the annotators have already worked on the prior task of creating examples in existing notebooks, they are fairly familiar with the requirement, and are able to create each problem in 13 minutes on average. To further improve quality, we also did another round of manual review for the set of problems in the two splits that a strong code LLM fails to predict the annotated solution (based on fuzzy output matching) within a budget of 50 samples. 11"
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "B Outline of ARCADE Annotation Guideline",
                "text": [
                    "In this section we provide a brief outline of our annotation guideline.",
                    "Existing Tasks The annotators are given a list of Jupyter notebooks. Each notebook uses pandas to perform certain data analysis tasks. For each notebook, an annotator is asked to:",
                    "1. Identify code cells that contain instructive code snippets that perform data wrangling or exploratory data analysis tasks.",
                    "2. Fix the notebook and make them clean and executable."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "For each code snippet identified in",
                "text": [
                    "Step 1, create natural language descriptions of the task. Also verify the code solution and fix them as appropriate. Finally, remove any redundant text in the notebook (e.g., solution outline or hints for tutorial notebooks) that could give away to the refernce solution.",
                    "Instruction on Creating Natural Intents Specifically, for step 3, in order to collect realistic NL intents, the annotators are given the following high-level description, followed by detailed instructions and examples.",
                    "Below we share some suggestions to write good intents.",
                    "Keep it natural without redundant explanations. Imagine an AI programmer can help you accomplish simple data wrangling and EDA tasks, what kind of intents will you send to the system? Our goal is to collect real inputs to such a system from data scientists like you.",
                    "One idea to write good intents is to keep it concise such that another programmer could quickly understand and implement a solution that executes to the same outputs. You are encouraged to create simple, short intents while describing the desired outputs without much ambiguity.",
                    "New Tasks For each ML dataset we provided, an annotator creates a Colab notebook with code snippets for some interesting data wrangling and exploratory data analysis tasks using this dataset. Each code snippet is paired with its natural language intent, simliar to the process of annotating Existing Tasks. We ask annotators to feel free to work on any tasks that they may find interesting for the given dataset, as long as the code solution for the task should consist of multiple lines and use different pandas API functions. Different from annotating Existing Tasks, we ask them to first create a natural language intent for their task, and then write a code solution in the next cell.",
                    "Below is an excerpt from the annotation guideline describing the types of data wranling and EDA tasks to create."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "What Tasks to Create",
                "text": [
                    "In general, you may create whatever exploratory data analysis tasks that you find interesting for the given datasets. To come up with interesting tasks, you can think in this way: before training your ML models for the dataset, what kind of data wrangling or EDA tasks would you like to perform on the dataset? Below are some more concrete descriptions of such wrangling or EDA tasks: Data Preprocessing/Wrangling Tasks which involves modifying existing dataframes or creating new ones. Such as normalizing column names, adding new columns, modifying existing columns (e.g., converting string values to date times), generating new dataframes using ops like group_by, and so on. Some datasets we shared are just raw data without any preprocessing or cleaning. Feel free to . Please also refer to Section: Identify Code Snippets to Annotate in our previous annotation guideline for more examples.",
                    "Exploratory Data Analysis Tasks that Require Some Wrangling and Preprocessing Answering interesting EDA questions using the given dataset, but some data wrangling steps are required in order to derive the answer. For example, given a dataframe df of user shopping history and credit card expiration dates in the format of df.loc[0]['cc_exp'] = '08/26'. To answer the EDA question \"How many users have a credit card expiring in 2024?\", we need to first convert the expiration year from the string-formatted cc_exp column.",
                    "To encourage the annotators to create more complex tasks, we also provide the following high-level instruction:"
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Complexity of Tasks",
                "text": [
                    "You should create relatively complex tasks that require multiple steps and also a combination of different pandas APIs to solve them. Avoid problems that can be solved using one-liner code such as df.group_by(...).sort_values(...). An ideal task should be reasonably complex and needs to be broken down into multiple smaller steps to solve, and each step may require using one or multiple pandas functions.",
                    "As a general rule of thumb, you should aim at creating tasks that either have at least 50 tokens or use at least 4 pandas APIs (dataframe/series indexing, like df[df['continent'] == 'NA'] is also counted as one API usage). You can find more concrete example tasks at the end of this doc.",
                    "Full Guideline Our annotation guideline is 35-pages long in total, which we will provide on a perrequest basis. Please contact pcyin@google.com to request access."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "C Descriptions of Existing Data Science Code Generation Dataset",
                "text": [
                    "Here, we describe existing natural language to code generation datasets in data science domain listed in Tab. 1 in more detail. JuICe (Agashe et al., 2019) contains exercise problems in assignment notebooks from data science tutorials or coures, where the NL intents are usually elaborative assignment problem definitions. Notebooks in JuICe are not executable so evaluation is performed by surface-level matching (exact match or BLEU) between reference and predicted programs. "
                ],
                "publication_ref": [
                    "b0"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "D Details of Fine-tuning PACHINCO",
                "text": [
                    "Pre-processing Python Source Code Data We detail the preprocessing steps for the Python source code corpus used in the first stage of fine-tuning in the data card (Appendix K). Pre-processing Notebooks Data We apply additional domain-specific pre-processing steps for the Jupyter notebooks corpus, such as filtering out notebooks without any Markdown cells, or with fewer than 4 code cells. In addition, to mitigate the risk of having notebooks similar to the evaluation notebooks from GitHub in the Existing Tasks split leaked into the training data, we perform near de-duplication against notebooks in Existing Tasks at the cell level. Specifically, we cluster the cells of notebooks in both the evaluation and training sets based on a fuzzy-matching similarity metric, and remove any training notebooks that has one cell that falls into the same cluster as a cell from one of the evaluation notebooks. This process eliminates \u223c350K notebooks from the fine-tuning data. Our final training set consist of \u223c3.8M notebooks and \u223c9.6B tokens in total. Linearize Notebooks to Python Source Code We convert computational notebooks for finetuning ( \u00a74) and evaluation ( \u00a75.1) to Python source code using nbconvert. 12 Specifically, Markdown and code cells in a notebook are concatenated using the special delimiter '# In[]:', and text in Markdown cells is commented out using the '# ' prefix. See Listing 7 for an example of the linearized notebook for Fig. 1 (up to c 3 ). Jupyter notebooks that are converted to Python files in such format are common in GitHub repositories, which mitigates the domain transfer gap between general Python code and notebook-specific data, and also allows us to prompt public code LLMs that have not been specifically trained on Jupyter notebooks data. Fine-tuning Hyper-parameters For the two-stage fine-tuning ( \u00a74), we use the similar training recipe of the base LM. Specifically, we apply the learning rate decay scheduling 0.2/ \u221a t, where t is the number of steps. At the first stage of fine-tuning on Python source data, we train the model for 124K steps (1 epoch) with a batch size of 256. Afterwards, we reload the optimizer state and continue training on the Jupyter notebooks data (9.6B tokens) using the same hyper parameter for 3 epochs (\u223c 572K steps). The model is implemented in JAX 13 , and is fine-tuned on 512 TPU v4 chips."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_0"
                ],
                "table_ref": []
            },
            {
                "heading": "E Inference Setup",
                "text": [
                    "For CODEGEN, we use the inference script from the official GitHub repository. 14 For INCODER, we follow the official inference example script and use the release on Huggingface model hub. 15 We convert each example in our dataset to Python source code to a prompt, as outlined in \u00a75.1. Notebooks are linearized using nbconvert similar as generating fine-tuning data (Appendix D). One exception is INCODER, for which we follow Fried et al. ( 2022) and use the Jupyter notebook linearization template used in its pre-training.",
                    "At inference time, by default we left-truncate notebook context up to 900 tokens (measured by PACH-INCO's vocabulary), which fit in the context window size of all LLMs we evaluated. We also make sure to always include NL schema descriptions in prompts given their importance in understanding NL intents. In addition, for few-shot experiments in \u00a75.3, we use additional 1,200 tokens to accommodate the prompt prefix, making the total maximal prompt length to be 2,100. Due to its excessive length, we only perform few-shot prompting experiments on PACHINCO since its rotatory positional embedding (Su et al., 2021) could generalize to encode longer contexts at inference time. We use nucleus sampling with a top probability of 0.95 and a temperature of 0.8 to draw 50 samples for each problem. For pass@1 evaluation, we use a temperate of 0.2, which gives very similar results compared to greedy decoding for all the models considered in Tab. 2. Due to rate limit in open AI API, we therefore use greedy decoding for pass@1 evaluation for CODE-cushman-001 and CODE-davinci-002. We set the maximum target length to be 512 tokens. Fig. 5 depicts the scaling curve of ARCADE with respect to the number of parameters for CODEGEN mono models. The pass rate scales nearly log-linearly as a function of model size, and the performance has not saturated, especially on the New Tasks split. This shows ARCADE is a reliable dataset to study the scaling behavior of code LLMs. The slope of the curve on New Tasks is also smaller than on other datasets, suggesting that this problem set is more challenging for CODEGEN models. It is also interesting to extrapolate CODEGEN models to 62B according to the scaling curve and compare with our models at similar size. This gives a projected pass@10 of 22% on New Tasks, wihch is lower than PALM after the first-stage Python fine-tuning (28%)."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_8"
                ],
                "table_ref": []
            },
            {
                "heading": "F CODEGEN Scaling Curve on ARCADE",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "G Break-down Analysis of pass@k on ARCADE",
                "text": [
                    "Accuracy with Problem Complexity To better understand PACHINCO's performance on problems at different levels of complexity, we plot pass@30 with respect to the number of pandas function calls in the annotated reference solutions, as shown in Fig. 6. For problems with similar complexity, PACHINCO generally achieves higher pass rate on Existing Tasks, again suggesting that the New Tasks split is still more challenging even after controlling problem complexity. Fig. 7 plots pass@30 with respect to the AST size of reference programs. Similar to Fig. 6, results on New Tasks are generally lower. Meanwhile, it seems that AST size correlates better with pass@k [0 , 2) [2, 4) [4, 6) [6, 8) [8, 10) [10, 12) Num. Pandas Function 20% 40% 60% 80% Pass@30 Existing Tasks New Tasks  compared to the number of API usage, while the latter metric offers more intuitive information about the data transformation steps involved. How Much Notebook Context is Useful? ARCADE requires a model to leverage rich programmatic and NL context in test notebooks to generate code solutions for the current cell. To study PACHINCO's performance with varying amount of available notebook context, we control the number d of context cells {c i } n\u22121 i=n\u2212d ( \u00a72) when generating code for each problem (at cell c n ) in our dataset. Fig. 8 depicts pass@30 as a function of the context size d. Since we use the first preceding cell c n\u22121 to store the NL intent u n for c n (Appendix L), having only one context cell is equivalent to the \"cold-start\" setting of only using the intent u n (besides schema description) to predict c n . PACHINCO achieves a pass rate of 44% (existing tasks) and 17% (new tasks) in this challenging setting (d = 1), with errors mostly due to failure in referring to variables that the solution relies on, whose information is not present in the short context. Indeed, including additional context cells is crucial for good performance. In particular, having 3 context cells could already lift the pass@30 to 72% and 36% on the two splits -1.6 \u223c 2\u00d7 higher than d = 1. The results also start to plateau after including 5 \u223c 7 context cells, with diminishing returns after including more cells, which is in line with findings in Agashe et al. (2019). 16 Empirically, we observe that using more context helps to reduce schema understanding errors (e.g., using undefined columns in DataFrames). Fig. 9 illustrates the distribution of execution error types on failed predictions. Notably, using more notebook context cells significantly reduces the chance of NameErrors caused by using undefined variables in context. The number of KeyErrors is also reduced, indicating that the model makes fewer schema understanding errors when referring to columns in DataFrames. Does Problem Location Impact Performance? Another interesting angle to study the effect of context is through the lens of model accuracy when solving problems c n at different locations. Intuitively, problems located later in a notebook (n is larger) would have more context available, therefore they could be easier to answer (Wang and Cho, 2016). Fig. 10 shows pass@30 on problems grouped by their preceding context size, which shows increased task success rate when solving problems with more context, confirming the prior intuition. 17    "
                ],
                "publication_ref": [
                    "b0"
                ],
                "figure_ref": [
                    "fig_9",
                    "fig_10",
                    "fig_9",
                    "fig_21"
                ],
                "table_ref": [
                    "tab_11"
                ]
            },
            {
                "heading": "H Additional Few-shot Prompting Results",
                "text": [
                    "Plots for the Results on New Tasks in Tab. 4 Fig. 11 plots the few-shot prompting results on New Tasks presented in Tab. 4. Here we also report breakdown results of pass rate on problems with varying level of complexity.",
                    "Step-by-step prompting and its variants are helpful across the board, especially for harder tasks with more than 7 pandas function calls. This might suggest the value of step-by-step decomposition when synthesizing complex programs.",
                    "Few-shot Prompting Results on Existing Tasks We also report results of prompting PACHINCO using few-shot exemplars on the Existing Tasks split in Fig. 12. Compared to the results obtained on New Tasks (Fig. 11), while few-shot prompting, especially step-by-step prompting, is still effective compared to the baseline, the gap is not as profound as the results on New Tasks. The difference between different prompting methods is also less significant, and using NL explanations (SbS + Preamble + Explanations) is less 147  effective compared to the two baseline zero-shot approaches. This is likely due to potential evaluation data leakage. Intuitively, as the model relies on memorization to generate code that it has encountered during training to solve problems in Existing Tasks, using few-shot exemplars to \"nudge\" the model to generate code in a different style would be less effective.This issue is perhaps more problematic for prompting with additional inline explanations, as generating those extra interspersed NL comments would likely break the model's \"flow\" of generating code (without such explanations) that it has memorized. Additionally, explanation-based prompting favors generating more complex code solutions with more steps (LoC \u2191 ) and API calls, as indicated in Figs. 11 and 12, which could actually be counter-productive for Existing Tasks, where more than 70% of the tasks are simple and require less than 4 API calls to solve them. Nevertheless, these results reiterate the value of the New Tasks split as a more reliable benchmark to better differentiate different prompting strategies."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_21",
                    "fig_13",
                    "fig_21",
                    "fig_21"
                ],
                "table_ref": []
            },
            {
                "heading": "I Further Analysis of Solution Diversity",
                "text": [
                    "Here we provide further analysis of the diversity in solution patterns, measured by the number of distinct pandas API call sequences used in the samples. Fig. 13 and Fig. 14 depict cumulative distributions of the number of solution patterns for different subsets of the predictions on the two task splits: all predictions, only those that execute successfully, and only the correct predictions. In each case, we see that step-by-step prompting leads to increased diversity compared to the baselines, and prompting with NL explanations further increases the diversity. While increased diversity is helpful in finding a correct solution at higher sample size k, it is also helpful when considering only correct solutions because a user might want to see a variety of solution approaches, whether for educational purposes or to choose the one they like best (which is partially subjective). Refer to \u00a76 for such examples. Next, Fig. 15a presents the cumulative distribution of the number of output clusters for predictions on Existing Tasks, where step-by-step prompting variants produce more functionally diverse solutions that execute to different results. Finally, Fig. 15b shows self-consistency reranking accuracy on the Existing Tasks split. While step-by-step code prompting is still helpful due to improved prediction diversity, similar to the results on the New Tasks split (c.f. Fig. 4c), the results obtained with prompting using additional NL explanations becomes worse, due to the relatively lower success rate of this prompting strategy (Fig. 12, see Appendix H for more discussions). "
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_21",
                    "fig_21",
                    "fig_21",
                    "fig_21",
                    "fig_6",
                    "fig_13"
                ],
                "table_ref": []
            },
            {
                "heading": "J Error Analysis J.1 Summary of Error Types",
                "text": [
                    "To understand the types of errors that LLMs make on ARCADE, especially on challenging problems, we conduct an error analysis on model predictions on the New Tasks split (Tab. 2). Overall, we notice a significant drop in execution errors after two-stage code fine-tuning (base LM \u2192Python-finetuned LM \u2192PACHINCO, \u00a74). Out of all the incorrect predictions from PACHINCO under the fuzzy output matching evaluation metric ( \u00a73.3), roughly 35% of the samples result in execution errors, while the remaining 65% predictions have executable programs but are functionally incorrect. Summary of Inexecutable Predictions First, for inexecutable samples, we present an analysis of the distribution of different execution error types, as illustrated in Fig. 16. The primary source of execution error is KeyError and AttributeError due to reference to non-existing indices or columns in DataFrames. While in the prompts we provide NL schema descriptions for DataFrames loaded to notebooks ( \u00a75.1), such descriptions for intermediate DataFrames that are later derived in the context are still missing due to limited prompt length, and the model may not be able infer their schema information solely from the source code. This could be especially problematic for APIs that create compound intermediate DataFrames with complex schema, such as pd.groupby, which accounts for that more than 50% of those KeyErrors and AttributeErrors. Similarly, other execution errors such as ValueError and TypeError are often caused by the insufficient knowledge about the DataFrame contents. For example, ValueError occurs when a model tries to calculate the mean of a column which has NaN values. This finding suggests the importance of developing LLMs that could handle longer context (Wu et al., 2022a) in order to include more DataFrame information in prompts. We gave a detailed case study on these types of execution errors later in this section. Summary of Executable but Incorrect Predictions Next, we conduct a manual analysis on 50 randomly sampled incorrect predictions that are executable. The cause of these errors can be grouped into the following categories: 1. Complex problems requiring non-trivial reasoning or data transformation steps (43%); 2. Errors in interpreting NL intents, such as missing a requirement specified in the intent (e.g., round to two decimal places) in the code solution (26%); 3. Errors caused by underspecified intents ( \u00a73.2, 19%); 4. False-negatives due to limited coverage of the fuzzy-matching evaluation metric ( \u00a73.3, 6%); 5. Annotation errors (6%). The primary source of errors is due to complex problems, which reiterates the motivation of ARCADEevaluating code LLMs on challenging data wrangling and EDA tasks. The second majority type of errors (misunderstanding intents) suggests room to improve PACHINCO's skill in instruction following. Next, a non-trivial amount of errors are caused by underspecified intents, which are common in the setting of prompting LLMs using ambiguous instructions ( \u00a73.2), calling for future research to specifically address this issue. Finally, our evaluation metric based on fuzzy output matching seems effective in identifying plausible alternative solutions. Still, there are non-trivial cases where there are multiple ways of presenting the outputs (e.g., DataFrames with nested columns or different orientations, Fig. 30)."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_16",
                    "fig_20"
                ],
                "table_ref": []
            },
            {
                "heading": "J.2 Case Study",
                "text": [
                    "Case Study for Inexecutable Predictions Execution error has error message from the notebook environment. We can classify these errors into more fine-grained categories in Fig. 16. As the result shows, KeyError is the top error mode in the execution errors. Over 50% of the KeyError are associated with the pd.groupby API call. pd.groupby API call changes the dataframe schema as the model generates more data transformation code. For example, pd.groupby().mean() will remove non-numeric columns in the dataframe. This requires the model to have a profound understanding of the dataframe schema. We gave an example in Fig. 22. The column shipping_fee is string value which will be removed after df.groupby(ship_state).sum().",
                    "The secondary source of execution error is AttributeError, which shares a similar cause to the KeyError. This is because AttributeError is often triggered by calling a non-existing column as an attribute of a dataframe. An example is given in Fig. 23, where the model tries to call the non-existing column signupdate as an attribute of df_users, leading to an AttributeError. These two error modes suggest that building a better schema-aware language model is a promising future research direction.",
                    "We also present Fig. 24 and Fig. 25 as examples for TypeError and ValueError, respectively. These two error modes are often caused by insufficient knowledge of the column types and example values. For example, the model tried to compare a string-value column to a integer in Fig. 24, which causes TypeError. Fig. 25 showcased that the model tries to apply numeric operation pd.DataFrame.mean() on a column with NaN values, leading to ValueError. These errors suggest room to improve NL schema descriptions ( \u00a75.1) with column type annotation and more example cell values."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_16",
                    "fig_3",
                    "fig_5",
                    "fig_6",
                    "fig_8",
                    "fig_6",
                    "fig_8"
                ],
                "table_ref": []
            },
            {
                "heading": "Case Study for Executable but Incorrect Predictions",
                "text": [
                    "To complement the discussion earlier in Appendix J, we showcase examples of representative semantic errors, where the predictions are executable but functionally incorrect.",
                    "The primary source of semantic error is complex reasoning. Two complex problems are given in Fig. 26 and Fig. 27. In Fig. 26, the model need to infer that the last 10 years can be computed using the code dt.datetime.today().year -10. Fig. 27 is another example of complex data wrangling steps. To generate the correct program, the model need to compare the current rank to the past rank, while ensuring that the 2021 rank entries exist, and then aggregate the information.",
                    "Misinterpretation of NL intents is the secondary source of semantic errors. In Fig. 28, the generated program does not reflect the search constraint in the intent (institute type is IIT). Another source of semantic errors is underspecified intents with multiple plausible interpretations. As an example, in Fig. 29 the predicted program provides one plausible interpretation by calculating the sum of front-and left-facing trees, while the reference code implements another interpretation, which presents a table with the two numbers listed separately. Such cases are hard to cover by the fuzzy-matching evaluation metric, which may suggest the importance of collecting multiple reference interpretations for underspecified intents.",
                    "Finally, Fig. 30 illustrates an issue with the coverage of the evaluation function based on output matching. In this example with complex output DataFrames, the model gives an acceptable answer which differs from the reference in its DataFrame schema and orientation.",
                    "u: What are the five most common genres for shows released during the year having the highest percent increase in votes?  u: In which year, within the last ten years, did Israel receive the highest amount of financial aid, in constant amount? Show the year and amount received. .value_counts().sort_index()  u: Return a matrix with the average ticket prices to and from all the cities for each ticket class.  ",
                    "Incorrect"
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_9",
                    "fig_10",
                    "fig_9",
                    "fig_10",
                    "fig_3",
                    "fig_3",
                    "fig_20"
                ],
                "table_ref": []
            },
            {
                "heading": "K Data Card for the Training Data of PACHINCO",
                "text": [
                    "We provide a data card for the training data of PACHINCO as outlined in \u00a74, and also report training data composition in Tab. 6."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Motivation",
                "text": [
                    "For what purpose was the dataset created? Who created the dataset? Who funded the creation of the dataset?",
                    "The dataset was created for training code and language models by a team of researchers."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Composition",
                "text": [
                    "What do the instances that comprise the dataset represent (e.g., documents, photos, people, countries)?",
                    "Dataset comprises of Python source code files and Jupyter notebooks from GitHub, filtered by license so as to exclude code with restrictive licenses.",
                    "How many instances are there in total (of each type, if appropriate)?",
                    "The data makeup is given in Table 6.",
                    "Does the dataset contain all possible instances or is it a sample (not necessarily random) of instances from a larger set?",
                    "The dataset is a small (random) subset of a larger set.",
                    "What data does each instance consist of?",
                    "Each instance is encoded content of a source code file.",
                    "Is there a label or target associated with each instance?",
                    "No, there are no labels associated with each instance."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_11"
                ]
            },
            {
                "heading": "Is any information missing from individual instances?",
                "text": [
                    "No.",
                    "Are relationships between individual instances made explicit?",
                    "No.",
                    "Are there recommended data splits?",
                    "We use random splits for the training, validation, and test.",
                    "Are there any errors, sources of noise, or redundancies in the dataset?",
                    "\u2022 Python files were near deduplicated at the file level using a custom implementation of minhash algorithm, so lower level redundancies (lines, code blocks) may still exist.",
                    "\u2022 Some files were misclassified in the license tagging and filtration process given that license classification algorithm can have false positives and negatives.",
                    "Is the dataset self-contained, or does it link to or otherwise rely on external resources?",
                    "The dataset is self-contained.",
                    "Does the dataset contain data that might be considered confidential?",
                    "No.",
                    "Does the dataset contain data that, if viewed directly, might be offensive, insulting, threatening, or might otherwise cause anxiety?",
                    "Given the dataset contains source code, it is not likely there is any offensive text in it, however no explicit measures are in place to eliminate such data if it were present."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Collection Process",
                "text": [
                    "How was the data associated with each instance acquired?",
                    "The data was collected from publicly available sources.",
                    "What mechanisms or procedures were used to collect the data?",
                    "The data was collected using a variety of software programs to extract and clean source code files.",
                    "If the dataset is a sample from a larger set, what was the sampling strategy?",
                    "The dataset is small subset of publicly available code from Github, sampled randomly.",
                    "Who was involved in the data collection process?",
                    "A team of researchers.",
                    "Over what timeframe was the data collected?",
                    "April -July 2022",
                    "Were any ethical review processes conducted?",
                    "No."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Preprocessing, cleaning, and labeling",
                "text": [
                    "Was any preprocessing, cleaning, or labeling of the data done (e.g., discretization or bucketing, tokenization, part-of-speech tagging, SIFT feature extraction, removal of instances, processing of missing values)?",
                    "License filtration, quality filtration and deduplication were applied to the source code files.",
                    "\u2022 License classification was done using Google License Classifier library. Source code files with restricted licenses were filtered out.",
                    "\u2022 Python files were deduplicated at the file level using a custom variant of minhash algorithm. Locality sensitive hashes of file content were used to create partitions of potentially duplicate files based on collisions in the hash buckets. For each pair in the partitions, Jaccard Similarity and Edit Distance scores were calculated to create an \"edge\" for a pair whenever the scores are higher than the specified threshold. This was followed by application of connected components algorithm to return the sets of duplicates.",
                    "\u2022 Jupyter notebooks were first deduplicated following the same procedure as deduplicating Python files, and then deduplicated at individual cell level against the evaluation dataset ( \u00a74).",
                    "Is the software used to preprocess, clean, or label the instances available?",
                    "No."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Uses",
                "text": [
                    "Has the dataset been used for any tasks already?",
                    "Yes, we use the dataset for pre-training other code and language models.",
                    "Is there a repository that links to any or all papers or systems that use the dataset?",
                    "No.",
                    "What (other) tasks could the dataset be used for?",
                    "The dataset can be used for training of other code and language models.",
                    "Is there anything about the composition of the dataset or the way it was collected and pre-processed/cleaned/labeled that might impact future uses?",
                    "The dataset is static in nature and thus will become progressively more \"stale\". It will not include any new source code repositories that were created/updated later on Github.",
                    "Are there tasks for which the dataset should not be used?",
                    "This should not be used for any unacceptable code or language modeling use cases e.g. generating code or language with toxic/biased connotations."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Distribution",
                "text": [
                    "Will the dataset be distributed to third parties outside of the entity (e.g., company, institution, organization) on behalf of which the dataset was created?",
                    "No. A prompt in this setup is the concatenation of a prompt prefix (with few-shot exemplars) and the notebook context (with prior rounds of problems and NL schema descriptions). The part of a prompt that corresponds to notebook context is the same as the previous setting (e.g. Listing 7), except that we insert the preamble # Solution: Let's solve this problem step-by-step. as appropriate after the last cell delimiter. For prompt prefix, Listing 1 gives an example prompt prefix for Step-by-Step prompting, while Listing 4 shows the same set of few-shot exemplars for Vanilla Code prompting.",
                    "As mentioned in \u00a75.1, we created three prompt prefixes for each of the four different styles, and report results averaged over these three restarts. Listings 1 to 3 show the three groups of prompt prefixes for",
                    "Step-by-Step, and Listings 4 to 6 show those for Vanilla Code prompting. Each prompt prefix has four exemplars, and some exemplars are shared across different prefixes. Note that some prompt prefixes in Step-by-Step also contain one simple problem that does not require decomposition and explanation (e.g. Exercise 3, Listing 1). We find this to be useful to not bias a model from generate overly complex code solutions for simpler problems. We did not put much effort in prompting engineering. Actually, those prompt prefixes were created before we collected 70% of the problems in our dataset. # You are a professional data scientist. Answer the following questions using pandas and matplotlib.   # You are a professional data scientist. Answer the following questions using pandas and matplotlib.   # You are a professional data scientist. Answer the following questions using pandas and matplotlib.   # You are a professional data scientist. Answer the following questions using pandas and matplotlib.   # You are a professional data scientist. Answer the following questions using pandas and matplotlib.    # You are a professional data scientist. Answer the following questions using pandas and matplotlib. B2. Did you discuss the license or terms for use and / or distribution of any artifacts?",
                    "License information of source code that our dataset is based on is provided in the data card section in the appendix. License of our newly created ARCADE dataset will be included in the public data release.",
                    "B3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided that it was specified? For the artifacts you create, do you specify intended use and whether that is compatible with the original access conditions (in particular, derivatives of data accessed for research purposes should not be used outside of research contexts)?",
                    "Our training data consists of permissively licensed source code files from Github, which is discussed in the data card section in the appendix. For the ML datasets and notebooks we used to build the annotated ARCADE dataset, they are reviewed by a legal team to ensure they could be used for the purpose of research and publication.",
                    "B4. Did you discuss the steps taken to check whether the data that was collected / used contains any information that names or uniquely identifies individual people or offensive content, and the steps taken to protect / anonymize it? This is discussed in the data card section in the appendix. For our annotated ARCADE dataset, we anonymize information of the annotators.",
                    "B5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and linguistic phenomena, demographic groups represented, etc.? Our data primarily concerns with source code. Code-related data statistics is presented in Section 3 and the data card section in the appendix.",
                    "B6. Did you report relevant statistics like the number of examples, details of train / test / dev splits, etc. for the data that you used / created? Even for commonly-used benchmark datasets, include the number of examples in train / validation / test splits, as these provide necessary context for a reader to understand experimental results. For example, small differences in accuracy on large test sets may be significant, while on small test sets they may not be. This is discussed in the data card section in the appendix."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Acknowledgements",
                "text": [
                    "We are grateful to Meg Risdal and Goeff Thomas from Kaggle for help with dataset collection, and Miltos Allamanis for research discussion. We thank Jo Chick from the research partnership team, and Rebecca Watson, Ashley Dawe and Kimberly Herrera from Upwork to help with managing the annotation project. We thank Aroma Mahendru for writing the data card section. We also thank Cheriskumar Patel, Preet Patel, and Jayendra Parmar for general assistance with the project. We thank anonymous reviewers for their insightful comments."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "",
                "text": [
                    "C Did you run computational experiments? Section 5.",
                    "C1. Did you report the number of parameters in the models used, the total computational budget (e.g., GPU hours), and computing infrastructure used? Section 4 (model size), Section 8 (Training FLOPs), Appendix D (compute environments). D2. Did you report information about how you recruited (e.g., crowdsourcing platform, students) and paid participants, and discuss if such payment is adequate given the participants' demographic (e.g., country of residence)? Appendix A.3 describes the recruitment process of annotators.",
                    "D3. Did you discuss whether and how consent was obtained from people whose data you're using/curating? For example, if you collected data via crowdsourcing, did your instructions to crowdworkers explain how the data would be used? Appendix B provides instructions to annotators including the usage of the data collected (evaluate AI pair programmers).",
                    "D4. Was the data collection protocol approved (or determined exempt) by an ethics review board?",
                    "An ethical review of the data collection protocol was not required.",
                    "D5. Did you report the basic demographic and geographic characteristics of the annotator population that is the source of the data? Appendix A.3 mentions that the freelancers are proficient in English. We will try to provide more demographic information of the annotators in the final version."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            }
        ],
        "references": [
            {
                "ref_id": "b0",
                "title": "JuICe: A large scale distantly supervised dataset for open domain context-based code generation",
                "journal": "Association for Computational Linguistics",
                "year": "2019",
                "authors": "Rajas Agashe; Srinivasan Iyer; Luke Zettlemoyer"
            },
            {
                "ref_id": "b1",
                "title": "How can AI automate end-to-end data science?",
                "journal": "",
                "year": "2019",
                "authors": "Charu Aggarwal; Djallel Bouneffouf; Horst Samulowitz; Beat Buesser; Thanh Hoang; Udayan Khurana; Sijia Liu; Tejaswini Pedapati; Parikshit Ram; Ambrish Rawat"
            },
            {
                "ref_id": "b2",
                "title": "Low-level components of analytic activity",
                "journal": "",
                "year": "2005",
                "authors": "Robert A Amar; James R Eagan; John T Stasko"
            }
        ],
        "figures": [
            {
                "figure_label": "1",
                "figure_type": "figure",
                "figure_id": "fig_0",
                "figure_caption": "[ 1 ]1import pandas as pd df = pd.read_csv('dataset/Gamepass_Games_v1.csv') [2] def get_avg(x): try: return float(x[0]) , float(x[1]) except: return 0, 0 df['min'], df['max'] = zip(*df['TIME'].str.replace( ' hours','').str.split(\"-\").apply(get_avg)) Extract min and max hours as two columns [3] df['ADDED'] = pd.to_datetime( df['ADDED'],format=\"%d %b %y\",errors='coerce') [4] df['GAMERS']=df['GAMERS'].str.replace( ',',' ').astype(int) added_year=df[df['GAMERS'].idxmax()]['ADDED'].year In which year was the most played game added? [5] df[(df['ADDED'].dt.year== added_date.year) & (df['RATING']>4)].groupby( df[\"ADDED\"].dt.month)['GAME'].count()",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_1",
                "figure_caption": "['GAME'].str.contains('Fallout')] fallout.groupby(fallout['ADDED'].dt.year).get_group( 2021)['max'].mean() What is the average maximum completion time for all fallout games added in 2021? [7]",
                "figure_data": ""
            },
            {
                "figure_label": "1",
                "figure_type": "figure",
                "figure_id": "fig_2",
                "figure_caption": "Figure 1 :1Figure 1: An example of a computational notebook adapted from our dataset, with examples of reading data (cell c1), data wrangling (c2, c3), and exploratory data analysis (c4 \u223c c7). Annotated NL intents (ui) are shown in green.",
                "figure_data": ""
            },
            {
                "figure_label": "2",
                "figure_type": "figure",
                "figure_id": "fig_3",
                "figure_caption": "Figure 2 :2Figure 2: Histogram of the number of pandas API calls.least 5 API calls to solve. As discussed in \u00a75, with more complex held-out problems targeting recent ML datasets, the New Tasks split is a more robust benchmark and more challenging for code LLMs. Comparing with Existing Datasets Tab. 1 compares ARCADE with existing data science code generation datasets. We remark that ARCADE is the only benchmark that satisfies all the following criteria: First, . . . . . . . . . . ARCADE . . . . . . . . . . . features . . . . . . . . . . succinct . . . . and . . . . . . . . . . realistic . . . . . . . . intents . . . as . . . . . . . . . . problem . . . . . . . . . . . . . . . . . specifications (\"Intents Type\" column, Tab. 1), which are significantly shorter (\"Intent Length\" column) than the verbose Markdown problem definitions found in tutorial or assignment notebooks (c.f. JuICe, DSP). AR-CADE also does not rely on extra specifications such as unit tests (c.f. DSP), which better capture the real-world scenario where developers prompt LMs using ephemeral comments for code completion (Barke et al., 2022). Most of these intents are often underspecified (mentioned earlier in \u00a73.2), requiring a more robust evaluation metric to consider alternative answers (discussed in \u00a73.3), while motivating future research on improving prediction diversity to cover plausible problem interpretations (explored in \u00a75.1) or explicit modeling of intent uncertainty (Lin et al., 2022). Second, . . . . . . . . . . . ARCADE . . . . . . . . . . contains . . . . . . . more . . . . . . . . . related . . . . . . . . . . . . problems . . . in . . a . . . . . . . single . . . . . . . . . . . notebook (\"P./N.B.\" column) with diverse dependency patterns (e.g., Fig. 1), capturing the essence of interactive computing. This makes our",
                "figure_data": ""
            },
            {
                "figure_label": "3",
                "figure_type": "figure",
                "figure_id": "fig_5",
                "figure_caption": "Figure 3 :3Figure 3: An example problem. Cells 1-2 (c1, c2) are the notebook context, and Cell 3 (c3) contains the intent. Cells 3a and 3b show two example completions of c3.",
                "figure_data": ""
            },
            {
                "figure_label": "4",
                "figure_type": "figure",
                "figure_id": "fig_6",
                "figure_caption": "Figure 4 :4Figure4: Cumulative distributions of the number of (A) unique API sequences and (B) output clusters, extracted from PACHINCO's 50 predictions on the New Tasks split. Curves that appear more to the right represent prompting methods with greater diversity in the samples. Step-by-step prompting leads to much greater diversity than the baselines. (C) Self-consistency decoding accuracy using 1 reranked sample on New Tasks.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_7",
                "figure_caption": "DSP (Chandel et al., 2022)  contains problems from a filtered set of JuICe notebooks that are executable and also associated with unit tests for auto-grading. Hence the intents in DSP follow similar patterns as those in JuICe. To ensure that the free-form model-predicted code is compatible with unit tests, DSP uses the unit test code itself as extra model input besides NL intents to constrain the model to generate code that could be directly consumed by the tests. ExeDS (Huang et al., 2022) is a concurrent work to this paper. It is another set of filtered problems from JuICe. Similar to this work, ExeDS uses hand-annotated intents, and compares the execution output between reference and predicted code for evaluation instead of relying on unit tests ( \u00a73.3). NLGP(Heyman et al., 2021)  is another collection of the NL-to-code problems in Jupyter notebooks with short annotated intents for simple data manipulation tasks, where most notebooks have one associated problem.DS-1000 (Lai et al., 2022) is a collection of data science problems derived from StackOverflow questions. It primarily features problems using synthetic contexts with minimal working examples, and therefore does not concerns with code generation in notebooks with interrelated problems on general ML datasets.",
                "figure_data": ""
            },
            {
                "figure_label": "5",
                "figure_type": "figure",
                "figure_id": "fig_8",
                "figure_caption": "Figure 5 :5Figure 5: Scaling curve of CODEGENmono models on ARCADE and existing code generation benchmarks. Results on HumanEval are selected from the best temperature t \u2208 {0.2, 0.6, 0.8} (Nijkamp et al., 2022).",
                "figure_data": ""
            },
            {
                "figure_label": "6",
                "figure_type": "figure",
                "figure_id": "fig_9",
                "figure_caption": "Figure 6 :6Figure 6: pass@k of PACHINCO w.r.t problem complexity",
                "figure_data": ""
            },
            {
                "figure_label": "7",
                "figure_type": "figure",
                "figure_id": "fig_10",
                "figure_caption": "Figure 7 :7Figure 7: pass@k of PACHINCO w.r.t AST size of reference programs.",
                "figure_data": ""
            },
            {
                "figure_label": "8910",
                "figure_type": "figure",
                "figure_id": "fig_11",
                "figure_caption": "Figure 8 :Figure 9 :Figure 10 :8910Figure 8: pass@30 as w.r.t the number of context cells from the notebook.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_12",
                "figure_caption": "few-shot prompting code style metrics on Existing Tasks.",
                "figure_data": ""
            },
            {
                "figure_label": "12",
                "figure_type": "figure",
                "figure_id": "fig_13",
                "figure_caption": "Figure 12 :12Figure 12: Plots for few-shot prompting evaluation on Existing Tasks.",
                "figure_data": ""
            },
            {
                "figure_label": "1314",
                "figure_type": "figure",
                "figure_id": "fig_14",
                "figure_caption": "Figure 13 :Figure 14 :1314Figure13: Cumulative distributions of the number of unique API sequences extracted from PACHINCO's 50 predictions on the New Tasks split, for all predictions (left), only executable predictions (middle), or only correct predictions (right). Curves that appear more to the right represent prompting methods with greater diversity in the samples.",
                "figure_data": ""
            },
            {
                "figure_label": "15",
                "figure_type": "figure",
                "figure_id": "fig_15",
                "figure_caption": "Figure 15 :15Figure 15: Distribution of the number of output clusters and self-consistency decoding accuracy on Existing Tasks.",
                "figure_data": ""
            },
            {
                "figure_label": "16",
                "figure_type": "figure",
                "figure_id": "fig_16",
                "figure_caption": "Figure 16 :16Figure 16: Frequency of execution errors on New Tasks.",
                "figure_data": ""
            },
            {
                "figure_label": "1720",
                "figure_type": "figure",
                "figure_id": "fig_17",
                "figure_caption": "Figure 17 :Figure 20 :1720Figure 17: An example prediction from PACHINCO with a complex single step. u: Convert crash dates to datetime and show the total number of vehicles involved in crashes over the years. # Step 1: Convert crash date to datetime df['CRASH DATE'] = pd.to_datetime(df['CRASH DATE']) # Step 2: Create a new column with the year of the crash date df['CRASH YEAR'] = df['CRASH DATE'].dt.year # Step 3: Return the total number of vehicles involved in crashes in each year result = df.groupby('CRASH YEAR')['TOT VEH'].sum()",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_18",
                "figure_caption": "#Figure 21: Two predictions from PACHINCO. NL explanations help users identify incorrect steps.u: What are the average shipping fees for each state, starting from highest to lowest? (rounded to 2 decimal places)? Reference Solution: df['shipping_fee']=df['shipping_fee'].apply(total_float) df.groupby('ship_state').mean()['shipping_fee'].sort_values(ascending=False).round(2) Incorrect Model Output: df.groupby('ship_state').sum()['shipping_fee'].sort_values(ascending=False).apply( lambda x: round(x,2)) # Error Text: RuntimeError: KeyError: 'shipping_fee'Figure 22: An example of KeyError: the model calls a column which is removed after the pd.groupby().mean() API call. u: Show how many new users signed up for every year since 2000 Reference Solution: df_users[df_users['Customer Since']>datetime.fromisoformat('2000-01-01')]['Customer Since'].apply(lambda x: x.year)\\.value_counts().sort_index()",
                "figure_data": ""
            },
            {
                "figure_label": "262728",
                "figure_type": "figure",
                "figure_id": "fig_19",
                "figure_caption": "Figure 26 :Figure 27 :Figure 28 :262728Figure 26: An example of complex reasoning: the model has to infer the API call (dt.datetime.today().year -10) from the last-ten-years constraint in the intent.",
                "figure_data": ""
            },
            {
                "figure_label": "30",
                "figure_type": "figure",
                "figure_id": "fig_20",
                "figure_caption": "Figure 30 :30Figure 30: An example of plausible alternative prediction that is labeled as incorrect due to limited coverage of the evaluation metric.",
                "figure_data": ""
            },
            {
                "figure_label": "1",
                "figure_type": "figure",
                "figure_id": "fig_21",
                "figure_caption": "Listing 1 :1Step-by-Step Prompt Prefix (Group 1",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_22",
                "figure_caption": "#Schema of Dataframes: 30 # Columns in df with example values: 31 # name (Peter), gender (m), DOB (1992/01/17) 32 33 18 This prompt is not exactly the same as the one in our dataset. It is adapted to align with the illustrative example in Fig. Let's solve this problem step-by-step. 44 # Step 1: convert date of birth in to datetime 45 df['DOB'] = pd.to_datetime(df['DOB']) 46 # Step 2: get the number of male born in 1992 num_male_students = len(df[(df['DOB'].dt.year == 1992) & (df['gender'] == 'm')]) 48 # Step 3: get the number of female born in that year 49 num_female_students = len(df[(df['DOB'].dt.year == 1992) & (df['gender'] == 'f')]) Get the students with an averaged score above 90 for science subjects.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_23",
                "figure_caption": "##Let's solve this problem step-by-step. 82 # Step 1: Create a new column with the average score of engineering and math 83 df['Science_Avg'] = (df['Engineering'] + df['Math']) / 2 84 # Step 2: Get the rows whose average score is above 90 85 df_score_above_90 = df[df['Science_Avg'] > 90] 86 # Step 3: Return the student name and average scores 87 result = df_score_above_90[['Stu_Name', 'Science_Avg']] Problem: What is the population of California? Solution: Let's solve this problem step-by-step. 120 result = df[df['state'] == 'CA']['population'] What is the most expensive phone in each brand.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_24",
                "figure_caption": "Let's solve this problem step-by-step. 153 # Step 1: Group models by their brands. 154 model_by_brand_df = df.groupby('brand') 155 # Step 2: Find the index of rows that have the highest price in each group 156 idx = model_by_brand_df['price'].idxmax() 157 # Step 3: Get the rows using the index 158 expensive_models_df = df.loc[idx] 159 # Step 4: Return the brand name, model and price. 160 result = expensive_models_df[['brand', 'model', 'price']]    ",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_25",
                "figure_caption": "##Schema of Dataframes: 196 # Columns in df with example values: 197 # name (Peter), gender (m), DOB (1992/01/17) Let's solve this problem step-by-step. 210 # Step 1: convert date of birth in to datetime 211 df['DOB'] = pd.to_datetime(df['DOB']) 212 # Step 2: get the number of male born in 1992 213 num_male_students = len(df[(df['DOB'].dt.year == 1992) & (df['gender'] == 'm')]) 214 # Step 3: get the number of female born in that year 215 num_female_students = len(df[(df['DOB'].dt.year == 1992) & (df['gender'] == 'f')]) Columns in df with example values: 235 # Stu_Name (Mike), Engineering (90), English (89), Math (92) Get the students with an averaged score above 90 for science subjects.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_26",
                "figure_caption": "#Let's solve this problem step-by-step. 248 # Step 1: Create a new column with the average score of engineering and math 249 df['Science_Avg'] = (df['Engineering'] + df['Math']) / 2 250 # Step 2: Get the rows whose average score is above 90 251 df_score_above_90 = df[df['Science_Avg'] > 90] 252 # Step 3: Return the student name and average scores 253 result = df_score_above_90[['Stu_Name', 'Science_Avg']] Solution: Let's solve this problem step-by-step. 286 result = df[df['state'] == 'CA']['population'] What is the most expensive phone in each brand.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_27",
                "figure_caption": "Let's solve this problem step-by-step.319# Step 1: Group models by their brands.320 model_by_brand_df = df.groupby('brand') 321 # Step 2: Find the index of rows that have the highest price in each group 322 idx = model_by_brand_df['price'].idxmax() 323 # Step 3: Get the rows using the index 324 expensive_models_df = df.loc[idx] 325 # Step 4: Return the brand name, model and price. 326 result = expensive_models_df[['brand', 'model', 'price']]    ",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_28",
                "figure_caption": "###Let's solve this problem step-by-step.414 # Step 1: convert date of birth in to datetime 415 df['DOB'] = pd.to_datetime(df['DOB']) 416 # Step 2: get the number of male born in 1992 417 num_male_students = len(df[(df['DOB'].dt.year == 1992) & (df['gender'] == 'm')]) 418 # Step 3: get the number of female born in that year 419 num_female_students = len(df[(df['DOB'].dt.year == 1992) & (df['gender'] == 'f')]) Make a new column \"grade\" for letter grades (A: 90+, B: 70-90, C: <70) and plot the number of students in each grade. Solution: Let's solve this problem step-by-step. 452 # Step 1: Define a function to convert scores to letter grades. 453 def get_grade(score): 454 if score >= 90: 455 return 'A' 456 elif 70 <= score < 90: Step 2: Convert scores to letter grades. 461 df['grade'] = df.score.apply(get_grade) 462 # Step 3: Count the number of students by grade. 463 count_df = df['grade'].value_counts() Columns in df with example values: 485 # model (Pixel 6), brand (Google), price (387), release (2022) What is the most expensive phone in each brand.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_29",
                "figure_caption": "Let's solve this problem step-by-step. 498 # Step 1: Group models by their brands. 499 model_by_brand_df = df.groupby('brand') 500 # Step 2: Find the index of rows that have the highest price in each group 501 idx = model_by_brand_df['price'].idxmax() 502 # Step 3: Get the rows using the index 503 expensive_models_df = df.loc[idx] 504 # Step 4: Return the brand name, model and price. 505 result = expensive_models_df[['brand', 'model', 'price']]",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_30",
                "figure_caption": "= pd.read_csv('employee.csv') DOB'] = pd.to_datetime(df['DOB']) 556 num_male_students = len(df[(df['DOB'].dt.year == 1992) & (df['gender'] == 'm')]) 557 num_female_students = len(df[(df['DOB'].dt.year == 1992) & (df['gender'] == 'f')]) Get the students with an averaged score above 90 for science subjects.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_31",
                "figure_caption": "[df['state']  == 'CA']['population'] What is the most expensive phone in each brand.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_32",
                "figure_caption": "[df.groupby('brand')['price'].idxmax()][['brand', 'model', 'price']]    ",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_33",
                "figure_caption": "DOB'] = pd.to_datetime(df['DOB']) 708 num_male_students = len(df[(df['DOB'].dt.year == 1992) & (df['gender'] == 'm')]) 167 709 num_female_students = len(df[(df['DOB'].dt.year == 1992) & (df['gender'] == 'f')]) Get the students with an averaged score above 90 for science subjects.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_34",
                "figure_caption": "#Science_Avg'] = (df['Engineering'] + df['Math']) / 2 743 df[df['Science_Avg'] > 90][['Stu_Name', 'Science_Avg']] Columns in df with example values: 763 # state (WA), capital (Seattle), population (1.4 millon) [df['state'] == 'CA']['population']",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_35",
                "figure_caption": "#= pd.read_csv('phones.csv') Schema of Dataframes: 795 # Columns in df with example values: What is the most expensive phone in each brand.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_36",
                "figure_caption": "[df.groupby('brand')['price'].idxmax()][['brand', 'model', 'price']]    ",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_37",
                "figure_caption": "###Columns in df with example values: 846 # Year (1896), City (Athens), Country (Greece), Nations (14) = pd.read_csv('employee.csv') DOB'] = pd.to_datetime(df['DOB']) 894 num_male_students = len(df[(df['DOB'].dt.year == 1992) & (df['gender'] == 'm')]) 895 num_female_students = len(df[(df['DOB'].dt.year == 1992) & (df['gender'] == 'f')]) Make a new column \"grade\" for letter grades (A: 90+, B: 70-90, C: <70) and plot the number of students in each grade. grade'] = df.score.apply(lambda x: 'A' if x >= 90 else ('B' if 70 <= x < 90 else 'C')) 929 df.grade.value_counts().plot(kind='bar') [df.groupby('brand')['price'].idxmax()][['brand', 'model', 'price']]Listing 7: The notebook context part of the prompt for u2 in Fig.Columns in df with example values: 982 # GAME (Mass Effect Legendary Edition), RATIO (1.87), GAMERS (84,143), COMP % (4.1), TIME (100-120 hours), RATING (4.8), ADDED (06 Jan 22), True_Achievement (5442), Game_Score (2915) min'],df['max']=zip( * df['TIME'].str.replace(\" hours\",'').str.strip('+').str.split(\"-\").apply(get_avg)) ADDED']=pd.to_datetime(df['ADDED'],format=\"%d %b %y\",errors='coerce') In which year was the most played game added? you describe the limitations of your work? Section 8 A2. Did you discuss any potential risks of your work? Section 8 A3. Do the abstract and introduction summarize the paper's main claims? Section 1 A4. Have you used AI writing assistants when working on this paper? Left blank. B Did you use or create scientific artifacts? Section 3 introduces a new dataset. Section 4 describes models trained on Github source code data. B1. Did you cite the creators of artifacts you used? Not applicable. Left blank.",
                "figure_data": ""
            },
            {
                "figure_label": "1",
                "figure_type": "table",
                "figure_id": "tab_0",
                "figure_caption": "Existing Tasks also has extra 59 plotting problems in our release (excluded here), which are not used in this paper ( \u00a79).",
                "figure_data": "1."
            },
            {
                "figure_label": "",
                "figure_type": "table",
                "figure_id": "tab_2",
                "figure_caption": "LM PACHINCO is based on PALM, a family of decoder-only LMs for NL tasks(Chowdhery  et al., 2022). Specifically, we use the 62B PALM model trained on 1.3T tokens with a mixture of conversational, webpages and code data (Section F, Chowdhery et al. (2022)). Starting with this base LM, we first fine-tune on Python source code and then fine-tune further on Jupyter notebooks. into Python code. Refer to Appendix D for details and Appendix K for a data card.",
                "figure_data": "Fine-tuning on Python Code We first fine-tune the base LM on a corpus of near-deduplicated,permissively-licensed Python source code filesfrom GitHub, with 64B tokens in total. We finetunePALM for 1 epoch following the hyper parameterssetup in Chowdhery et al. (2022). This model isalready a strong code LM, even outperforming thelarger code LM PALM-Coder 540B on existingprogram synthesis benchmarks ( \u00a75.2).Fine-tuning on Notebooks We then perform a second stage of fine-tuning on a large collectionof 3.8M Jupyter notebooks from GitHub (9.6B to-kens). Since our evaluation notebooks in the Ex-isting 5 ExperimentsModels We evaluate PACHINCO and state-of-the-art public code LLMs, namely CODEGEN (Ni-jkamp et al., 2022) and INCODER (Fried et al., 2022). We test both the monolingual (Python-only) and the multilingual version of CODEGEN. IN-CODER may be a more appealing comparison sinceit is trained on 5GB of Jupyter notebooks.Inference and Metrics We convert each prob-lem into a prompt ( \u00a75.1) and draw samples usingnucleus sampling. Following Chen et al. (2021a), we report pass@k metric, defined as the fraction"
            },
            {
                "figure_label": "2",
                "figure_type": "table",
                "figure_id": "tab_3",
                "figure_caption": "pass@k using notebook context as prompts.",
                "figure_data": "pass@kExisting Tasks 1 5 30New Tasks 1 530Existing ModelsINCODER 1B20.8 30.9 47.0 2.3 4.0 9.9INCODER 6B28.2 40.6 56.2 3.5 7.1 15.8CODEGEN multi 350M 9.0 13.6 21.3 0.8 0.9 2.6 18.7 25.9 39.3 1.5 2.6 6.8 CODEGEN multi 2B 20.0 28.5 42.8 1.7 3.4 8.9 CODEGEN multi 6B CODEGEN multi 16B 20.9 31.4 47.1 2.5 4.8 12.4 CODEGEN mono 350M 11.3 18.5 32.8 1.5 1.9 5.1 24.7 35.5 52.9 3.1 6.3 16.0 CODEGEN mono 2B 28.7 42.2 60.9 4.0 8.6 20.4 CODEGEN mono 6B CODEGEN mono 16B 32.6 46.2 63.9 6.1 12.1 25.2CODE-cushman-00138.1 50.4 68.8 8.9 14.5 31.0CODE-davinci-00253.0 66.3 81.5 23.4 36.0 54.7Our ModelsBase PALM 62B35.7 49.4 67.8 7.2 12.7 26.4+ Python f.t.43.6 58.8 75.3 11.9 21.7 40.7+ PACHINCO48.9 64.3 78.3 18.0 30.5 47.7\u2212 Schema Desc.44.2 60.0 75.0 13.0 22.2 36.1additional NL-to-code exemplars as prompt prefixbefore the notebook context. As shown in Fig. 3(Completion 3b), we focus on prompting LMs togenerate code that follows a multi-line, step-by-step (SbS) decomposition structure, in contrastwith the common practice of chaining multiple APIcalls in a single line (Completion 3a). Each stepis also optionally inlined with NL explanations .Such step-wise explanations could help novice de-velopers understand model predictions, and theyhave been found effective for reasoning (Wei et al.,2022; Gao et al., 2022) and program induction (Nyeet al., 2021) tasks. Following Kojima et al. (2022),"
            },
            {
                "figure_label": "3",
                "figure_type": "table",
                "figure_id": "tab_4",
                "figure_caption": "Evaluation of existing code LMs and PaLM 62B after the first-stage fine-tuning on Python code.",
                "figure_data": "Impact of Fine-tuning The base PALM model outperforms most public code LMs and is onpar with CODEGEN mono 16B. Fine-tuning on Python (+Python f.t., Tab. 2) and notebooks data(+PACHINCO) further closes the domain gap withimproved pass@k. The absolute gain after fine-tuning on Python code is higher than continuedtraining on notebooks, likely because the semanticgap between NL data and Python code is larger than"
            },
            {
                "figure_label": "",
                "figure_type": "table",
                "figure_id": "tab_6",
                "figure_caption": "in information visualization. IEEE Symposium on Information Visualization, 2005. INFOVIS 2005., pages 111-117. Luke Zettlemoyer and Michael Collins. 2009. Learning context-dependent mappings from sentences to logical form. In Annual Meeting of the Association for Computational Linguistics.",
                "figure_data": "Tianyi Zhang, Tao Yu, Tatsunori Hashimoto, Mike Lewis, Wen tau Yih, Daniel Fried, and Sida I. Wang. 2022. Coder reviewer reranking for code generation. ArXiv, abs/2211.16490.Marc-Andr\u00e9 Z\u00f6ller and Marco F Huber. 2021. Bench-mark and survey of automated machine learning frameworks. Journal of artificial intelligence re-search, 70:409-472."
            },
            {
                "figure_label": "",
                "figure_type": "table",
                "figure_id": "tab_8",
                "figure_caption": "# Step 1: Get the year that has the highest percent increase in votes. max_year_pct_change = pct_change_votes.idxmax() # Step 2: Get the genres for each shows in that year. genres = drama[drama['Year of Release']==max_year_pct_change]['Genre']   ",
                "figure_data": "# Step 3: Count each genregenre_counts = {}for genre in genres:for genre in genre.split(','):if genre not in genre_counts:genre_counts[genre] = 0genre_counts[genre] += 1# Step 4: Return the most common genresmost_common_genres = pd.Series(genre_counts).sort_values(ascending=False)most_common_genres[:5]"
            },
            {
                "figure_label": "",
                "figure_type": "table",
                "figure_id": "tab_9",
                "figure_caption": "What are the top five models with most number of bikes having mileage less than 5000 kilometers? Figure24: An example of TypeError: the model is intent to compare a string-value column to an integer. What is the average number of filed charges for drug related cases? What is the number of deaths by accident as a percentage of total deaths in the last ten years?",
                "figure_data": "Reference Solution:import datetime as dtlast_ten_years = age[(age['Death year']>=dt.datetime.today().year-10)]total_deaths = last_ten_years.groupby('Death year').size()deaths_by_accident = last_ten_years[last_ten_years['Manner ofdeath'].str.contains('accident')].groupby('Death year').size()deaths_by_accident / total_deaths * 100Incorrect Model Output:(age[(age['Manner of death']=='accident') & (age['Death year'].between(2007,2017,inclusive='left'))].shape[0] / age[age['Death year'].between(2007,2017,inclusive='left')].shape[0])*100Reference Solution:df_bikes=bikes[bikes['Ridden for']<5000]df_bikes['Model Name'].value_counts().head()Incorrect Model Output:model=bikes.groupby('Model Name')['Comfort'].mean().loc[bikes_models.index].idxmax()# Error Text:RuntimeError: TypeError: '<' not supported between instances of 'str' and 'int'Reference Solution:int(district[district.crime_type.str.contains('narcotic',case=False,na=False)].num_charges.mean())"
            },
            {
                "figure_label": "6",
                "figure_type": "table",
                "figure_id": "tab_11",
                "figure_caption": "Data Composition of the fine-tuning data for PACHINCO.In this section we provide detailed examples of prompts used in our experiments. As in \u00a75.1, there are two categories of experiments in \u00a75, namely prompting using notebook context ( \u00a75.2) and few-shot prompting with extra exemplars pre-pended to notebook context ( \u00a75.3). Here, we list the prompts for u 2 in Fig.1in these two types of prompting experiments. Prompting using Notebook Context In the basic setup without extra few-shot exemplars, the prompt basically consist of all the prior notebook context, including NL descriptions of schema information and previous rounds of problems. Listing 7 shows the complete prompt for u 2 in Fig.1in this setup.18 At inference time, a code LM will complete the last code cell after the cell delimiter '# In[ ]:'. Note that for INCODER we follow Fried et al. (2022) and use a special template to linearize notebooks (Appendix E). Prompting using Additional Few-shot Exemplars We have four prompting styles for few-shot experiments. Here, we show the prompt prefix ( \u00a75.1) for Vanilla Code and Step-by-Step+Explanations prompting, as the remaining two styles are just simplified version of the latter by removing inline explanations (SbS + Preamble) and preambles (Step-by-Step).",
                "figure_data": "LanguageTokensSource FilesPython Jupyter Notebooks63,786,481,126 9,613,648,61960,397,107 3,796,713"
            }
        ],
        "formulas": [
            {
                "formula_id": "formula_0",
                "formula_text": "Base",
                "formula_coordinates": [
                    5.0,
                    306.14,
                    208.86,
                    21.82,
                    14.19
                ]
            },
            {
                "formula_id": "formula_1",
                "formula_text": "Incorrect",
                "formula_coordinates": [
                    28.0,
                    149.67,
                    486.57,
                    32.96,
                    5.98
                ]
            }
        ],
        "doi": "10.18653/v1/D19-1546"
    },
    "Binary and Ternary Natural Language Generation": {
        "authors": "Zechun Liu; Barlas Oguz; Meta Ai; Aasish Pappu; Yangyang Shi; Raghuraman Krishnamoorthi",
        "pub_date": "",
        "abstract": "Ternary and binary neural networks enable multiplication-free computation and promise multiple orders of magnitude efficiency gains over full-precision networks if implemented on specialized hardware. However, since both the parameter and the output space are highly discretized, such networks have proven very difficult to optimize. The difficulties are compounded for the class of transformer text generation models due to the sensitivity of the attention operation to quantization and the noise-compounding effects of autoregressive decoding in the high-cardinality output space. We approach the problem with a mix of statistics-based quantization for the weights and elastic quantization of the activations and demonstrate the first ternary and binary transformer models on the downstream tasks of summarization and machine translation. Our ternary BART base achieves an R1 score of 41 on the CNN/DailyMail benchmark, which is merely 3.9 points behind the full model while being 16x more efficient. Our binary model, while less accurate, achieves a highly nontrivial score of 35.6. For machine translation, we achieved BLEU scores of 21.7 and 17.6 on the WMT16 En-Ro benchmark, compared with a full precision mBART model score of 26.8. We also compare our approach in the 8-bit activation setting, where our ternary and even binary weight models can match or outperform the best existing 8-bit weight models in the literature. Our code and models are available at: https://github.com/facebookresearch/ Ternary_Binary_Transformer.",
        "sections": [
            {
                "heading": "Introduction",
                "text": [
                    "Generative pre-trained transformers (Brown et al., 2020;Lewis et al., 2020;Radford et al., 2018) have emerged as powerful and generic tools, driving breakthroughs not only in language understanding but the field of AI in general. These models owe * Equal contribution their success mainly to their seemingly infinite ability to scale to ever-larger data and model sizes. Unfortunately, such scaling comes at the cost of large computational requirements, putting extensively large generative transformers out of reach of all but the most resource-rich institutions. Even moderately sized pre-trained transformers have limited applications due to their size and computational cost. Making generative transformers more efficient is imperative for widening their use to more devices and practical applications.",
                    "In this work, we explore making generative pretrained transformers more efficient via the quantization of their weights and activations. Quantizing the weights of a neural network is useful for compression and allows the model to be stored more efficiently. However, compression alone does not reduce computation costs since the network's activations need to be computed in full precision. Quantizing both weights and activations allows computation to be performed with lower precision, potentially leading to significant efficiency gains depending on the quantization level and hardware implementation. Quantizing neural networks have a long history, and multiple works have attempted to quantize pre-trained transformers at various quantization levels (Shen et al., 2020;Zhang et al., 2020;Liu et al., 2022;Qin et al., 2021). Most of this work focuses on encoder-only models (mainly BERT) for sentence and token classification tasks. Quantizing text generation models has generally been regarded as a more difficult task (Behnke et al., 2021;Tao et al., 2022) due to the large output vocabulary and sequential decoding. Recent work has tackled this problem, though only for mild quantization levels (down to 8-bit activations) and with mixed success.",
                    "In contrast, we are interested in very low-bit quantization, down to ternary and even binary weights and activations. In order to achieve this, we combine and unify best practices for weight and activation quantization and present a frame-work that uses gradient-matching quantization for weights and elastic quantization for activations. We apply our method to natural language generation tasks and, for the first time, demonstrate low-bit generative transformers of competitive accuracy. Our ternary (weight and activation) model lags a full-precision BART (Lewis et al., 2020) model by only 4 points in ROUGE on the XSUM summarization dataset. In contrast, our model with ternary weights and 8-bit activations comes within 1 point and even outperforms comparable state-of-the-art models with 8-bit weights. We also demonstrate a fully binary (weights and activations) model. While not as competitive, it is able to achieve a highly non-trivial ROUGE-1 score of 31.7.",
                    "Our results also extend to machine translation models. On the WMT16 En-Ro benchmark, we quantize an mBART model to extend the ternaryweight 8-bit activation SoTA by 1.2 points while demonstrating fully ternary and fully binary translation models for the first time.",
                    "We summarize our contributions as follows: \u2022 We propose a novel combination of statisticsbased weight quantization with learning-based activation quantization, which enables stably training transformer encoder-decoder models to converge in the fully ternary/binary settings, which was not previously possible.",
                    "\u2022 We significantly improve the state-of-the-art text generation models in the 8-bit activation and ternary/binary weight settings while setting the first non-trivial baselines for the fully ternary and fully binary settings."
                ],
                "publication_ref": [
                    "b11",
                    "b20",
                    "b31",
                    "b33",
                    "b37",
                    "b2",
                    "b1",
                    "b7",
                    "b20"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Method",
                "text": [
                    "In this section, we first introduce the previous practices in binarization and ternarization. Then, we introduce a unified statistic-based weight binarization / ternarization method that can alleviate the gradient mismatch issue and enhance the quantized weights entropy. Lastly, we analyze the difference between weight quantization and activation quantization and propose an elastic ternarization method for activations. We abbreviate our method as TBT, short for \"Ternary / Binary Transformer\"."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Preliminary",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Ternarization",
                "text": [
                    "Ternary neural networks, where real values are quantized to three levels, are first introduced in (Li et al., 2016). Thus, these values can be repre-sented in 2 bits, leading to a 16\u00d7 reduction in size and computation. Moreover, the computations can be calculated multiplication-free, leading to even further computation gains on suitable hardware. The recent work integrates the ternarization algorithm in natural language models for quantizing the weights and activations in classification tasks (Zhang et al., 2020) and ternarizing the weight (8bit activations are used) in generative models (Li et al., 2022;Tao et al., 2022). The general formula (Li et al., 2016) for ternarization is as follows:",
                    "X i T = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 \u2212\u03b1 T , if X i R < \u2212\u2206 0, if \u2212 \u2206 \u2a7d X i R \u2a7d \u2206 +\u03b1 T , if X i R > \u2206 (1) \u2206 = 0.7 \u2022 ||X R || l1 n X R (2) \u03b1 T = i X i R \u2022 1 |X i R |>\u2206 i 1 |X i R |>\u2206(3)",
                    "Here X T denotes the ternary weights/activations, and X R represents their real-valued counterparts. n X R denotes the total number of elements in the tensor. \u2206 is the ternary threshold, and \u03b1 T is the scaling factor that minimizes l2-loss between X T and X R ."
                ],
                "publication_ref": [
                    "b21",
                    "b37",
                    "b21"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Binarization",
                "text": [
                    "The neural network binarization denotes representing the weights and/or activation with bi-level values. It is first proposed in BNN (Courbariaux et al., 2016) and has evolved in the follow-up works (Rastegari et al., 2016;Liu et al., 2018). Rastegari et al. (2016) formulates binarization as:",
                    "X i B = \u03b1 B \u2022Sign(X i R ) = \u2212\u03b1 B , if X i R < 0 +\u03b1 B , if X i R \u2a7e 0 (4) \u03b1 B = ||X R || l1 n X R(5)",
                    "Here X B can represent binary weights or binary activations. \u03b1 B denotes the scaling-factor that minimize the l2 loss between X R and \u03b1 B \u2022Sign(X R ).",
                    "The acceleration and compression effect of ternary/binary neural networks is significant. By representing the weights and activations with {\u22121, 0, 1}, the network enjoys \u223c16\u00d7 memory saving compared to its 32-bit floating-point counterpart. When further binarize the weights and activations to only 1-bit (i.e., {\u22121, 1}), up to 32\u00d7 model-size reduction and 58\u00d7 speedup on CPUs have been achieved (Rastegari et al., 2016), where the matrix multiplication operations are replaced with light-weighted bitwise XNOR operations.",
                    "Despite its appealing characteristics, naively binarizing or ternarizing the transformer model for natural language generation results in several accuracy drops or even a total failure in training. It has been observed that the attention layers of the transformer network are difficult to quantize to low bits. Also, the auto-regressive decoding tends to accumulate errors due to quantization. Given the nature of generative language networks that require highprecision output, quantizing both the activations and weights in these models to extreme bit values is non-trivial and has not been explored before."
                ],
                "publication_ref": [
                    "b12",
                    "b32",
                    "b26",
                    "b32",
                    "b32"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Stats-based max-entropy isometric weight quantization",
                "text": [
                    "We propose a statistics-based method for weight binarization/ternarization. Particularly, this novel quantization method considers maximizing the entropy of the quantized weights and reducing the gradient mismatch in the backward pass. Previous works (Courbariaux et al., 2016;Bai et al., 2021b;Zhang et al., 2020) are mainly focused on minimizing the l2 loss between the quantized weights and the real-valued weights to find the optimal quantization scheme,",
                    "\u03b1 * = arg min ||\u03b1 \u0174Q \u2212 W R || l2(6)",
                    "where \u0174Q denotes binary/ternary weights and \u03b1 * denotes the optimal scaling factor calculated. Despite the broad application and great success of the classic quantization scheme, we found that merely minimizing the l2 loss neglects several critical but intractable issues in ultra-low-bit weight quantization: (1) The information entropy of the quantized weights is not considered. Eq. 1 and Eq. 4 calculate the quantized weights to minimize the distance to the real-valued weights, which could lead to imbalanced quantized weight distribution and harm the quantized weights representation capacity.",
                    "(2) The quantization function Eq. 1 and Eq. 4 are not isometric, meaning that it does not consider the magnitude consistency between the quantized weights and real-valued weights, while we find that magnitude consistency contributes significantly to accurate gradient estimation.",
                    "Considering the above two limitations in previous solutions, we are motivated to design a novel quantization function that enhances information entropy and reduces gradient mismatch. To boost the weights representation capability, in information theory, more information is preserved when the quantized weights contain higher entropy:",
                    "max p i H = \u2212p i log(p i ), s.t. N i=1 p i = 1 (7)",
                    "with p i denoting the proportion of real-valued weights being quantized to i th quantization level in total N levels. Eq. 7 can be easily solved with a Lagrange multiplier, and the optimal p * i = 1 N , i \u2208 {1, 2, . . . , N }, suggesting the best quantization scheme to preserve maximum information entropy is to distribute the real-valued weights in all quantization levels as evenly as possible.",
                    "For reducing the gradient mismatch, as suggested by the previous binarization work (Liu et al., 2020b), the magnitude difference between the quantized weight and the real-valued weight will greatly influence the gradient scale and a mismatch in magnitude will be amplified in back-propagation and cause gradient vanishing or explosion during training. Thus it is important to ensure the magnitude of real-valued weights and quantized weights are consistent.",
                    "Combining two requirements discussed above, we proposed max-entropy isometric weight quantization. In ternarization, it is formulated as",
                    "W i T = \u03b1 T \u230aClip( W i R \u2212 \u00b5 T \u03b1 T , \u22121, 1)\u2309 where \u00b5 T = W R , \u03b1 T = 4 3 \u2022 ||W R \u2212 \u00b5 T || l1 n W R(8)",
                    "Where W T and W R refer to the ternary weights and real-valued weights, respectively. The rounding function \u230a\u2022\u2309 and Clip(\u2022) function quantize weights to {\u22121, 0, 1}. \u00b5 T is the mean of realvalued weights and n W R denotes the number of weights in the weight matrix. Scaling factor \u03b1 is calculated from the weight statistics and follows the entropy rule to scale the real-valued weight W R to be evenly distributed in quantization levels. In the ternary case, the weights are quantized to {\u2212\u03b1 T , 0, \u03b1 T }. When the real-valued weights are initialized as uniformly and symmetrically distributed (He et al., 2015;Glorot and Bengio, 2010), the scaling factor \u03b1 T will distribute 5, 1.5], such that the output ternary weights We propose a statistic-based quantization method for weights ternarization/binarization and adopt a learning-based asymmetric quantization method for activation in ReLU/Softmax output (X \u2208 R n + ) and learning-based asymmetric quantization method for activations that contain both positive and negative values in other layers (X \u2208 R n ).",
                    "W i R \u03b1 T to [\u22121.",
                    "will have near uniform distribution in three ternary levels. Meanwhile, Eq. 8 is an isometric mapping where the real-valued weights are scaled by 1 \u03b1 T to near [-1, 1] and time \u03b1 T to scale back after quantization. In this way, the magnitude is preserved.",
                    "Correspondingly, in the binary case we have,",
                    "W i B = \u03b1 B \u2022 Sign( W i R \u2212 \u00b5 B \u03b1 B )",
                    "where",
                    "\u00b5 B = W R , \u03b1 B = ||W R \u2212 \u00b5 B || l1 n W R(9)",
                    "Here W B denotes the binary weights, where substracting the average \u00b5 B makes the realvalued weight zero-centered before binarization and thus encourages an even distribution in binarized weights. Then the scaling factor \u03b1 B matches the magnitude between real-valued and binary weights. Particularly, in Eq. 9,",
                    "W i B = \u03b1 B \u2022 Sign( W i R \u2212\u00b5 B \u03b1 B ) = \u03b1 B \u2022 Sign(W i R \u2212 \u00b5 B )",
                    ", we explicitly include the \u03b1 B in the denominator to keep the binarization function isometric and the gradients w.r.t. weights can be calculated straight-forwardly as:",
                    "\u2202W i B \u2202W i R ST E \u2248 1 | W i R \u2212\u00b5 B \u03b1 B |<1 (10)",
                    "STE is abbreviated for straight-through estimator (Bengio et al., 2013), which replaces the nondifferentiable Sign function with Clip function in the backward pass. We show that the proposed maxentropy isometric weight quantization improves the accuracy of weight binarization / ternarization by 6.0 / 11.53 RougeL scores on the CNN/DailyMail benchmark, respectively. More details can be found in Sec. 3.2."
                ],
                "publication_ref": [
                    "b12",
                    "b6",
                    "b37",
                    "b24",
                    "b16",
                    "b15",
                    "b8"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Learning-based activation quantization",
                "text": [
                    "In contrast to neural network weights that are stored on the disk, activations are calculated on-the-fly. The distribution of activations in a particular layer depends on the network weights as well as the corresponding input sequence, and thus varies from batch to batch. In order to have the quantization function better capture the underlying activation distribution, we propose learning-based activation quantization.",
                    "Inspired by BiT (Liu et al., 2022), we divide the activation layers into two categories: the activation layers with non-negative values (X R \u2208 R + ), i.e., Softmax/ReLU layer outputs and the rest of the layers with both positive and negative activations (X R \u2208 R). We binarize / ternarize the first activation category (X R \u2208 R + ) to {0, \u03b1} / {0, \u03b1, 2\u03b1}, and symmetrically quantize the later activation category (X R \u2208 R) to {\u2212\u03b1, \u03b1} and {\u2212\u03b1, 0, \u03b1} in binary and ternary cases respectively. In this way, the activation distribution matches the original fullprecision activations and thus reduces the quantization error. Further, we learn to scale the real-valued activations to better fit quantization thresholds, and this learnable scaling factor can be updated endto-end with the gradients from the network loss to better account for overall network optimization.",
                    "In the ternary case, we propose the elastic ternarization function formulated as,",
                    "X i T = \u03b1 T Xi T = \uf8f1 \uf8f2 \uf8f3 \u03b1 T \u230aClip( X i R \u03b1 T , 0, 2)\u2309, if X R \u2208 R + \u03b1 T \u230aClip( X \u2032i R \u03b1 T , \u22121, 1)\u2309, if X R \u2208 R(11)",
                    "where X R and X T denote real-valued and ternary activations, respectively. To keep the formula concise, we set X \u2032 R = X R \u2212 X R , denoting the zeromean real-valued activations. \u03b1 T is the scaling factor. Different from the weight quantization, the scaling factor in Eq. 11 is learned with the gradient update. We follow the practice in (Zhou et al., 2016;Esser et al., 2019) to calculate the gradients with straight-through estimation (STE) bypassing the non-differentiable rounding function:",
                    "\u2202X i T \u2202\u03b1 T ST E \u2248 \uf8f1 \uf8f2 \uf8f3 Xi T \u2212 X i R \u03b1 T \u20221 0\u2a7dX i R \u2a7d2\u03b1 T , if X R \u2208 R + Xi T \u2212 X \u2032i R \u03b1 T \u20221 |X \u2032i R |\u2a7d\u03b1 T , if X R \u2208 R(12)",
                    "The learnable scaling factor can dynamically adapt to different activation distributions and improve the ternarization accuracy. In the binary case, it is formulated as.",
                    "X i B = \u03b1 B Xi B = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 \u03b1 B \u230aClip( X i R \u03b1 B , 0, 1)\u2309, if X R \u2208 R + \u03b1 B \u2022 Sign( X \u2032i R \u03b1 B ), if X R \u2208 R(13)",
                    "Here X B denotes the binary activations.",
                    "Correspondingly, the gradients w.r.t. the scaling factor \u03b1 can be easily calculated as",
                    "\u2202X i B \u2202\u03b1 B ST E \u2248 \uf8f1 \uf8f2 \uf8f3 Xi B \u2212 X i R \u03b1 B \u20221 0\u2a7dX i R \u2a7d\u03b1 B , if X R \u2208 R + Sign(X \u2032i R ), if X R \u2208 R(14)",
                    "We demonstrate that with the learning-based activation quantization method and statistics-based weight quantization scheme, the proposed TBT for the first time is able to quantize the BART model for natural language generation tasks to ternary and even binary weights and activations, and achieve reasonable accuracy on summarization and translation benchmarks."
                ],
                "publication_ref": [
                    "b2",
                    "b13"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Experiments",
                "text": [
                    "In this section, we evaluate the effectiveness of our low-bit quantization scheme for natural language generative model on text summarization benchmarks: CNN/DailyMail (Nallapati et al., 2016) and XSUM (Narayan et al., 2018). We additionally experiment on the machine translation task with mBART on WMT16 English-Romanian (En-Ro) dataset (Bojar et al., 2016a)."
                ],
                "publication_ref": [
                    "b27",
                    "b28",
                    "b9"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Experimental settings",
                "text": [
                    "We follow recent work (Li et al., 2022) in training the quantized network with initialization and knowledge distillation from a full-precision pretrained model. Specifically, we use the BARTbase (Lewis et al., 2019) as our full-precision baseline for summarization tasks and mBARTlarge (Liu et al., 2020a) for the translation task. We train the quantized models for 20 epochs on 8 GPUs with a batch size of 128 and a learning rate of 2.5e-4 for 8-bit activation models and 5e-4 for binary and ternary activation models."
                ],
                "publication_ref": [
                    "b19",
                    "b23"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Summarization",
                "text": [
                    "For the summarization task, we adopt the following benchmarks:",
                    "The XSUM dataset (Narayan et al., 2018) consists of 226k documents sampled from the online news website of BBC, together with short, one sentence summaries. Since the summaries are very short, abstractive methods tend to do better on this dataset. CNN/DailyMail (Nallapati et al., 2016) is another news summarization benchmark, with longer documents (~30 sentences) and longer, multisentence summaries. The dataset contains close to 300k document-summary pairs.",
                    "We use BART-base model (Lewis et al., 2019), which is an English-only encoder-decoder transformer with 140 million parameters. We compare using the standard ROUGE-{1,2,l} metrics for this task.",
                    "For the ternary weights and 8-bit activations setting, we compare with two state-of-the-art methods QuantBart (Tao et al., 2022) and DQ-BART (Li et al., 2022). For the fully ternary setting, and the binary quantization experiments, there is no prior art. Therefore we provide a naive quantization baseline, using popular implementations from previous work (Li et al., 2016;Courbariaux et al., 2016), and adapt the binary and ternary methods proposed for the BERT models (Bai et al., 2021b;Qin et al., 2021;Zhang et al., 2020) to BART.",
                    "Our main results are summarized in Table 1. In the ternary weights and 8-bit activations setting, TBT improves previous SoTA by up to 2.3 points in ROUGE score on XSUM, and up to 0.5 points on CNN/DailyMail. Both improvements are significant.",
                    "Further quantizing weights to binary, while keeping activations at 8-bit, we are still able to achieve a ROUGE-L score of 33.3 on XSUM, which is 0.8 points higher than the previous ternary SoTA (DQ-BART), and comparable on CNN/DailyMail. This is the first demonstration of a binary-weight generative transformer model of competitive accuracy to our knowledge. Additionally, TBT binary weight BART model achieves 1.2 points higher ROUGE score on CNN compared with the SoTA pruning method with the same compressed model size.",
                    "Moving on to ternary and binary activations, there is no prior art, and previous implementations fail to produce meaningful results. Our method, on the other hand, achieves ROUGE-L scores of 29.1 and 38.3 on XSUM and CNN/DailyMail in the fully ternary setting, which are 6.6 and 3.8 points behind the full-precision baseline respectively. Our fully binary (weights and activations) model has a wider gap at 10.4 and 8.9 points, however still manages to produce highly non-trivial output at ROUGE-L scores of 25.3 and 33.2 points for XSUM and CNN/DailyMail."
                ],
                "publication_ref": [
                    "b28",
                    "b27",
                    "b19",
                    "b21",
                    "b12",
                    "b6",
                    "b1",
                    "b37"
                ],
                "figure_ref": [],
                "table_ref": [
                    "tab_0"
                ]
            },
            {
                "heading": "Machine translation",
                "text": [
                    "We also evaluate our model on machine translation. We adopt the En-Ro benchmark from the  WMT'16 shared task (Bojar et al., 2016b) to be compatible with previous work. Our base model is an mBART-large model (Liu et al., 2020a), a 680 million parameter multi-lingual encoder-decoder transformer pre-trained on 25 languages. Table 2 shows our results. In the ternary weight setting with 8-bit activations, we improve the previous SoTA by 1.2 points, achieving 24.63 BLEU. Remarkably our binary weight model also outperforms the previous ternary weight SoTA by almost a full point. It scores 24.3 BLEU -only 1.5 points behind a full mBART model while being 16\u00d7 smaller.",
                    "In the fully ternary and binary settings, where previous methods failed to converge, TBT models are able to reach practical levels of performance, with ternary TBT mBART achieving 21.7 BLEU, and TBT binary mBART at 17.59."
                ],
                "publication_ref": [
                    "b10",
                    "b23"
                ],
                "figure_ref": [],
                "table_ref": [
                    "tab_1"
                ]
            },
            {
                "heading": "Ablations",
                "text": [
                    "As stated earlier, our main proposed modeling improvement is a combination of two methods: statistics-based quantization for the weights, and learning-based quantization for the activations.",
                    "We ablate the contribution of these methods and present the results in Table 3.",
                    "The results clearly show that while each method can give moderate gains by itself over the baseline, these improvements are not sufficient by themselves to produce meaningful results. None of the ablated models can achieve an R2 score above 1.5. It's only the combination of the two, which together stabilize the training and result in good convergence for fully ternary and binary models."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_2"
                ]
            },
            {
                "heading": "Sequence length analysis",
                "text": [
                    "In language generation tasks, the error compounding issue in the recursive decoder generation process will largely amplify the quantization error or even lead to divergent results, and thus is an harsh factor to test the robustness of a quantization method. The average generated sequence length indicates whether the quantized model can overcome the compounding error and generate reasonable length of text.",
                    "In Table 4 we compare the generated sequence length between the proposed method and the baseline method (i.e., TWN (Li et al., 2016) for ternary, BWN (Courbariaux et al., 2016) for binary). Our method successfully produces summarizations with comparable length as the full-precision model on XSUM benchmark, even when both weights and activations are binarized.",
                    "Compared to XSUM dataset, for which the document are summarized to only one sentence, CNN/DailyMail is more challenging because it allows longer summary. We can clearly see that, the text generate with our 8-bit activation models can maintain near the similar average length as the full-precision BART model, while the binary and ternary activation models deviate moderately. In contrast, the baseline method is only able to derive"
                ],
                "publication_ref": [
                    "b21",
                    "b12"
                ],
                "figure_ref": [],
                "table_ref": [
                    "tab_3"
                ]
            },
            {
                "heading": "Weights Activations",
                "text": [
                    "Ternary weights (! ! ) reasonable summarization with 2-bit weight 8-bit activations and fails at lower bit-width, showing the difficult natural of the language generation tasks.",
                    "! ! in 1 \"# row Real-valued activations (# $ ) (f) (e) (h) (g)"
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Visualization",
                "text": [
                    "To further understand the effectiveness of the proposed method, we visualize weight and activation histograms in the BART model ternarized with the baseline method and the proposed method in Fig. 2. Both the baseline method and our method use per-row weight ternarization, and thus a tensor tensor will have #row of scaling factors. As we can see in Fig. 2 (b) and (g), the proposed method allows the weights to be more evenly distributed in three ternarization levels, which can allow higher information entropy in quantized weights, as discussed in Sec. 2.2. Additionally, we calculate the quantized weight distribution entropy (i.e., Eq. 7) in 96 fully-connected layers in the BART-base model and found that the proposed TBT method achieves consistently higher entropy in quantized weights than the baseline method in all the layers. Further, an interesting phenomenon we can see in Fig. 2 (a) (e) is that ternary weights in a baseline model are very close to the Gaussian distribution, in contrast, weights ternarized with TBT are capturing a more sophisticated distribution. This phenomenon implies that the proposed method helps the weights learn more informative patterns and thus better satisfy the high demand for language generation tasks.",
                    "For activation quantization, it is evident that the attention layer and the SoftMax output only contain the positive activations (X R \u2208 R + ). If simply ternarized to {\u2212\u03b1, 0, \u03b1}, the ternary activations will waste one representative level (Fig. 2(d)) and therefore lead to lower accuracy. Instead, the proposed method uses a two-set ternarization method that ternarizes the non-negative activation layer (X R \u2208 R + ) to {0, \u03b1, 2\u03b1}, and learns the scaling factor \u03b1 to better fit the underlying real-valued distribution. This ternarization method greatly reduces information loss and enhances the final accuracy.",
                    "8-bit activation quantization) and evaluated on language modeling and summarization. However, our method outperforms these works substantially, while also demonstrating accurate generative transformers with both weights and activations quantized to 2-bit and even 1-bit for the first time."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_1",
                    "fig_1",
                    "fig_1",
                    "fig_1"
                ],
                "table_ref": []
            },
            {
                "heading": "Conclusion",
                "text": [
                    "We have demonstrated high accuracy ternary and binary natural language generation models based on a pre-trained transformer encoder-decoder backbone. Quantizing both the weights and the activations of the network allow these models to run on special-purpose hardware using binary and ternary arithmetic, which doesn't require multiplication modules. Therefore our results promise multiple orders of magnitude gains in efficiency while running these models, and can drastically expand the use cases of such models beyond just high end gpu servers. We are especially excited about the implications of our results for larger text generation models such as GPT-3 (Brown et al., 2020). These models have both demonstrated impressive capabilities, while also presenting enormous scaling and computational challenges. Low-bit quantization is a promising approach to mitigate some of these issues. Whether our approach will scale to these models is an open problem and an exciting future research direction."
                ],
                "publication_ref": [
                    "b11"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Limitations",
                "text": [
                    "We conduct experiments on public datasets of finite sentence length, while generalizability to extremely long sequences or even streaming data has not been verified. Furthermore, the generalizability of the proposed quantization method to other tasks, including computer vision or speech recognition, remains to be tested. In addition, binarization and ternarization require bit-packing to have actual memory savings and dedicated hardware support for real-time acceleration, which is more of a hardware implementation aspect and not studied in this paper."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Ethics Statement",
                "text": [
                    "We affirm that we contribute to society, avoid harm, and are honest and trustworthy. We respect previous work and appropriately cite the methods and datasets we are using. All data we use is public and no private data is involved. There is some potential risk if the translation technique is maliciously used by a third party and thus we are committed to maintaining the compression techniques we have developed and the general summarization/machine translation techniques used correctly without incurring any form of discrimination. B3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided that it was specified? For the artifacts you create, do you specify intended use and whether that is compatible with the original access conditions (in particular, derivatives of data accessed for research purposes should not be used outside of research contexts)? section 4",
                    "B4. Did you discuss the steps taken to check whether the data that was collected / used contains any information that names or uniquely identifies individual people or offensive content, and the steps taken to protect / anonymize it? section 3",
                    "B5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and linguistic phenomena, demographic groups represented, etc.? section 3",
                    "B6. Did you report relevant statistics like the number of examples, details of train / test / dev splits, etc. for the data that you used / created? Even for commonly-used benchmark datasets, include the number of examples in train / validation / test splits, as these provide necessary context for a reader to understand experimental results. For example, small differences in accuracy on large test sets may be significant, while on small test sets they may not be. section 3",
                    "C Did you run computational experiments? section 3",
                    "C1. Did you report the number of parameters in the models used, the total computational budget (e.g., GPU hours), and computing infrastructure used? section 3"
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            }
        ],
        "references": [
            {
                "ref_id": "b0",
                "title": "",
                "journal": "",
                "year": "2019",
                "authors": " Zafrir"
            },
            {
                "ref_id": "b1",
                "title": "",
                "journal": "",
                "year": "2021",
                "authors": " Qin"
            },
            {
                "ref_id": "b2",
                "title": "generative setting",
                "journal": "",
                "year": "2019",
                "authors": " Liu"
            },
            {
                "ref_id": "b3",
                "title": "2021) demonstrate quantized models for machine translation, and",
                "journal": "",
                "year": "2020",
                "authors": " Behnke"
            },
            {
                "ref_id": "b4",
                "title": "for language modeling, though only for moderate quantization levels (4-8 bits). Most recently",
                "journal": "",
                "year": "2021",
                "authors": " Bai"
            },
            {
                "ref_id": "b5",
                "title": "Towards efficient posttraining quantization of pre-trained language models",
                "journal": "",
                "year": "2021",
                "authors": "Haoli Bai; Lu Hou; Lifeng Shang; Xin Jiang; Irwin King; Michael R Lyu"
            },
            {
                "ref_id": "b6",
                "title": "Binarybert: Pushing the limit of bert quantization",
                "journal": "",
                "year": "2021",
                "authors": "Haoli Bai; Wei Zhang; Lu Hou; Lifeng Shang; Jin Jin; Xin Jiang; Qun Liu; Irwin Michael R Lyu;  King"
            },
            {
                "ref_id": "b7",
                "title": "Efficient machine translation with model pruning and quantization",
                "journal": "",
                "year": "2021",
                "authors": "Maximiliana Behnke; Nikolay Bogoychev; Alham Fikri Aji; Kenneth Heafield; Graeme Nail; Qianqian Zhu; Svetlana Tchistiakova; Jelmer Van Der Linde; Pinzhen Chen; Sidharth Kashyap"
            },
            {
                "ref_id": "b8",
                "title": "Estimating or propagating gradients through stochastic neurons for conditional computation",
                "journal": "",
                "year": "2013",
                "authors": "Yoshua Bengio; Nicholas L\u00e9onard; Aaron Courville"
            },
            {
                "ref_id": "b9",
                "title": "Findings of the 2016 conference on machine translation",
                "journal": "Association for Computational Linguistics",
                "year": "2016",
                "authors": "Ond\u0159ej Bojar; Rajen Chatterjee; Christian Federmann; Yvette Graham; Barry Haddow; Matthias Huck; Antonio Jimeno Yepes; Philipp Koehn; Varvara Logacheva; Christof Monz; Matteo Negri; Aur\u00e9lie N\u00e9v\u00e9ol; Mariana Neves; Martin Popel; Matt Post; Raphael Rubino; Carolina Scarton; Lucia Specia; Marco Turchi; Karin Verspoor; Marcos Zampieri"
            },
            {
                "ref_id": "b10",
                "title": "Results of the wmt16 metrics shared task",
                "journal": "",
                "year": "2016",
                "authors": "Ond\u0159ej Bojar; Yvette Graham; Amir Kamran; Milo\u0161 Stanojevi\u0107"
            },
            {
                "ref_id": "b11",
                "title": "Language models are few-shot learners",
                "journal": "",
                "year": "2020",
                "authors": "Tom Brown; Benjamin Mann; Nick Ryder; Melanie Subbiah; Jared D Kaplan; Prafulla Dhariwal; Arvind Neelakantan; Pranav Shyam; Girish Sastry; Amanda Askell"
            },
            {
                "ref_id": "b12",
                "title": "Ran El-Yaniv, and Yoshua Bengio",
                "journal": "",
                "year": "2016",
                "authors": "Matthieu Courbariaux; Itay Hubara; Daniel Soudry"
            },
            {
                "ref_id": "b13",
                "title": "Learned step size quantization",
                "journal": "",
                "year": "2019",
                "authors": "K Steven; Jeffrey L Esser; Deepika Mckinstry; Rathinakumar Bablani; Dharmendra S Appuswamy;  Modha"
            },
            {
                "ref_id": "b14",
                "title": "Training with quantization noise for extreme model compression",
                "journal": "",
                "year": "2020",
                "authors": "Angela Fan; Pierre Stock; Benjamin Graham; Edouard Grave; R\u00e9mi Gribonval; Herve Jegou; Armand Joulin"
            },
            {
                "ref_id": "b15",
                "title": "Understanding the difficulty of training deep feedforward neural networks",
                "journal": "",
                "year": "2010",
                "authors": "Xavier Glorot; Yoshua Bengio"
            },
            {
                "ref_id": "b16",
                "title": "Delving deep into rectifiers: Surpassing human-level performance on imagenet classification",
                "journal": "",
                "year": "2015",
                "authors": "Kaiming He; Xiangyu Zhang; Shaoqing Ren; Jian Sun"
            },
            {
                "ref_id": "b17",
                "title": "Quantized neural networks: Training neural networks with low precision weights and activations",
                "journal": "The Journal of Machine Learning Research",
                "year": "2017",
                "authors": "Itay Hubara; Matthieu Courbariaux; Daniel Soudry"
            },
            {
                "ref_id": "b18",
                "title": "Block pruning for faster transformers",
                "journal": "",
                "year": "2021",
                "authors": "Fran\u00e7ois Lagunas; Ella Charlaix; Victor Sanh; Alexander M Rush"
            },
            {
                "ref_id": "b19",
                "title": "Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
                "journal": "",
                "year": "2019",
                "authors": "Mike Lewis; Yinhan Liu; Naman Goyal; Marjan Ghazvininejad; Abdelrahman Mohamed; Omer Levy; Ves Stoyanov; Luke Zettlemoyer"
            },
            {
                "ref_id": "b20",
                "title": "Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
                "journal": "",
                "year": "2020",
                "authors": "Mike Lewis; Yinhan Liu; Naman Goyal; Marjan Ghazvininejad; Abdelrahman Mohamed; Omer Levy; Veselin Stoyanov; Luke Zettlemoyer"
            },
            {
                "ref_id": "b21",
                "title": "Ternary weight networks",
                "journal": "",
                "year": "2016",
                "authors": "Fengfu Li; Bo Zhang; Bin Liu"
            },
            {
                "ref_id": "b22",
                "title": "Dq-bart: Efficient sequence-tosequence model via joint distillation and quantization",
                "journal": "Short Papers",
                "year": "2022",
                "authors": "Zheng Li; Zijian Wang; Ming Tan; Ramesh Nallapati; Parminder Bhatia; Andrew Arnold; Bing Xiang; Dan Roth"
            },
            {
                "ref_id": "b23",
                "title": "Multilingual denoising pre-training for neural machine translation",
                "journal": "",
                "year": "2020",
                "authors": "Yinhan Liu; Jiatao Gu; Naman Goyal; Xian Li; Sergey Edunov; Marjan Ghazvininejad; Mike Lewis; Luke Zettlemoyer"
            },
            {
                "ref_id": "b24",
                "title": "Bi-real net: Binarizing deep network towards real-network performance",
                "journal": "International Journal of Computer Vision",
                "year": "2020",
                "authors": "Zechun Liu; Wenhan Luo; Baoyuan Wu; Xin Yang; Wei Liu; Kwang-Ting Cheng"
            },
            {
                "ref_id": "b25",
                "title": "Bit: Robustly binarized multi-distilled transformer",
                "journal": "",
                "year": "2022",
                "authors": "Zechun Liu; Barlas Oguz; Aasish Pappu; Lin Xiao; Scott Yih; Meng Li; Raghuraman Krishnamoorthi; Yashar Mehdad"
            },
            {
                "ref_id": "b26",
                "title": "Bi-real net: Enhancing the performance of 1-bit cnns with improved representational capability and advanced training algorithm",
                "journal": "",
                "year": "2018",
                "authors": "Zechun Liu; Baoyuan Wu; Wenhan Luo; Xin Yang; Wei Liu; Kwang-Ting Cheng"
            },
            {
                "ref_id": "b27",
                "title": "Abstractive text summarization using sequence-to-sequence rnns and beyond",
                "journal": "",
                "year": "2016",
                "authors": "Ramesh Nallapati; Bowen Zhou; Caglar Gulcehre; Bing Xiang"
            },
            {
                "ref_id": "b28",
                "title": "Don't give me the details, just the summary! topic-aware convolutional neural networks for extreme summarization",
                "journal": "Association for Computational Linguistics",
                "year": "2018",
                "authors": "Shashi Narayan; Shay B Cohen; Mirella Lapata"
            },
            {
                "ref_id": "b29",
                "title": "Fully quantized transformer for machine translation",
                "journal": "",
                "year": "2019",
                "authors": "Gabriele Prato; Ella Charlaix; Mehdi Rezagholizadeh"
            },
            {
                "ref_id": "b30",
                "title": "Bibert: Accurate fully binarized bert",
                "journal": "",
                "year": "2021",
                "authors": "Haotong Qin; Yifu Ding; Mingyuan Zhang; Yan Qinghua; Aishan Liu; Qingqing Dang; Ziwei Liu; Xianglong Liu"
            },
            {
                "ref_id": "b31",
                "title": "Improving language understanding by generative pre-training",
                "journal": "",
                "year": "2018",
                "authors": "Alec Radford; Karthik Narasimhan"
            },
            {
                "ref_id": "b32",
                "title": "Xnor-net: Imagenet classification using binary convolutional neural networks",
                "journal": "Springer",
                "year": "2016",
                "authors": "Mohammad Rastegari; Vicente Ordonez; Joseph Redmon; Ali Farhadi"
            },
            {
                "ref_id": "b33",
                "title": "Q-bert: Hessian based ultra low precision quantization of bert",
                "journal": "",
                "year": "2020",
                "authors": "Sheng Shen; Zhen Dong; Jiayu Ye; Linjian Ma; Zhewei Yao; Amir Gholami; W Michael; Kurt Mahoney;  Keutzer"
            },
            {
                "ref_id": "b34",
                "title": "Compression of generative pre-trained language models via quantization",
                "journal": "Long Papers",
                "year": "2022",
                "authors": "Chaofan Tao; Lu Hou; Wei Zhang; Lifeng Shang; Xin Jiang; Qun Liu; Ping Luo; Ngai Wong"
            },
            {
                "ref_id": "b35",
                "title": "Gobo: Quantizing attention-based nlp models for low latency and energy efficient inference",
                "journal": "IEEE",
                "year": "2020",
                "authors": "Ali Hadi Zadeh; Isak Edo"
            },
            {
                "ref_id": "b36",
                "title": "Q8bert: Quantized 8bit bert",
                "journal": "IEEE",
                "year": "2019",
                "authors": "Ofir Zafrir; Guy Boudoukh; Peter Izsak; Moshe Wasserblat"
            },
            {
                "ref_id": "b37",
                "title": "Ternarybert: Distillation-aware ultra-low bit BERT",
                "journal": "",
                "year": "2020",
                "authors": "Wei Zhang; Lu Hou; Yichun Yin; Lifeng Shang; Xiao Chen; Xin Jiang; Qun Liu"
            },
            {
                "ref_id": "b38",
                "title": "Dorefa-net: Training low bitwidth convolutional neural networks with low bitwidth gradients",
                "journal": "",
                "year": "2016",
                "authors": "Shuchang Zhou; Yuxin Wu; Zekun Ni; Xinyu Zhou; He Wen; Yuheng Zou"
            },
            {
                "ref_id": "b39",
                "title": "Did you discuss the experimental setup, including hyperparameter search and best-found hyperparameter values? section 3",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b40",
                "title": "error bars around results, summary statistics from sets of experiments), and is it transparent whether you are reporting the max, mean, etc",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b41",
                "title": "for preprocessing, for normalization, or for evaluation",
                "journal": "",
                "year": "",
                "authors": " Nltk;  Spacy;  Rouge"
            },
            {
                "ref_id": "b42",
                "title": "crowdworkers) or research with human participants? Left blank",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b43",
                "title": "Did you report the full text of instructions given to participants, including e.g., screenshots, disclaimers of any risks to participants or annotators",
                "journal": "",
                "year": "",
                "authors": " D1"
            },
            {
                "ref_id": "b44",
                "title": "crowdsourcing platform, students) and paid participants, and discuss if such payment is adequate given the participants' demographic",
                "journal": "",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b45",
                "title": "Did you discuss whether and how consent was obtained from people whose data you're using/curating? For example, if you collected data via crowdsourcing, did your instructions to crowdworkers explain how the data would be used?",
                "journal": "",
                "year": "",
                "authors": " D3"
            },
            {
                "ref_id": "b46",
                "title": "Was the data collection protocol approved (or determined exempt) by an ethics review board? No response",
                "journal": "",
                "year": "",
                "authors": " D4"
            },
            {
                "ref_id": "b47",
                "title": "Did you report the basic demographic and geographic characteristics of the annotator population that is the source of the data? No response",
                "journal": "",
                "year": "",
                "authors": " D5"
            }
        ],
        "figures": [
            {
                "figure_label": "1",
                "figure_type": "figure",
                "figure_id": "fig_0",
                "figure_caption": "Figure 1 :1Figure 1: Overview of TBT. A transformer block contains the multi-head self-attention and feed-forward network.We propose a statistic-based quantization method for weights ternarization/binarization and adopt a learning-based asymmetric quantization method for activation in ReLU/Softmax output (X \u2208 R n + ) and learning-based asymmetric quantization method for activations that contain both positive and negative values in other layers (X \u2208 R n ).",
                "figure_data": ""
            },
            {
                "figure_label": "2",
                "figure_type": "figure",
                "figure_id": "fig_1",
                "figure_caption": "Figure 2 :2Figure 2: Weight and activation histogram comparison between the baseline TWN method and TBT method for ternarizing BART model on CNN/DailyMail benchmark. The weights are taken from the fully-connected layer of the value matrix in 1 st self-attention block in the decoder and activations are the attention outputs of the same layer.",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_2",
                "figure_caption": "you discuss any potential risks of your work? Section 7 A3. Do the abstract and introduction summarize the paper's main claims? Section 1 A4. Have you used AI writing assistants when working on this paper? Left blank. B Did you use or create scientific artifacts? section 4 B1. Did you cite the creators of artifacts you used? section 4 B2. Did you discuss the license or terms for use and / or distribution of any artifacts? section 4",
                "figure_data": ""
            },
            {
                "figure_label": "1",
                "figure_type": "table",
                "figure_id": "tab_0",
                "figure_caption": "Comparison of quantization methods for text summarization on XSUM and CNN/DailyMail benchmarks. We use the \"E-W-A (#bits)\" notation referring to the number of bits of embeddings, weights and activations, (specifically, 1 denotes binary, 2 denotes ternary). The results of QuantBart, DQ-BART and BlockPruning are quoted from their paper. Additionally, we implement the algorithm developed in BinaryBert, BiBert and TernaryBert to the BART model and report the results, denoted with * . We use the rouge-{1,2,L} as evaluation metrics.",
                "figure_data": "XSUMCNN/DailyMail"
            },
            {
                "figure_label": "2",
                "figure_type": "table",
                "figure_id": "tab_1",
                "figure_caption": "Comparison of quantization methods on mBART-large model for translation on WMT16 En-Ro.",
                "figure_data": "Method#Bits (E-W-A) Size (GB) BLEUmBART (Liu et al., 2020a) 32-32-32 DQ-BART (Li et al., 2022) 8 -8 -8 DQ-BART (Li et al., 2022) 2 -2 -82.44 0.61 0.3126.82 25.91 23.48TBT TBT TBT TBT2 -2 -8 2 -2 -2 1 -1 -8 1 -1 -10.31 0.31 0.16 0.1624.63 21.70 24.30 17.59"
            },
            {
                "figure_label": "3",
                "figure_type": "table",
                "figure_id": "tab_2",
                "figure_caption": "Ablation study on the effects of the proposed learning-based activation quantization method and stats-based weight quantization method on XSUM and CNN/DailyMail benchmark.",
                "figure_data": "Method#Bits (E-W-A) R1XSUM R2RL1 Baseline (TWN) 2 + Activation(learning-based) 2 -2 -2 15.05 1.38 12.13 2 -2 -2 12.80 1.21 11.4 3 + Weight(stats-based) 2 -2 -2 13.79 0.87 12.74 4 + Both 2 -2 -2 36.21 14.38 29.075 Baseline (BWN) 6 + Activation(learning-based) 1 -1 -1 1 -1 -1 7 + Weight(stats-based) 1 -1 -1 10.96 0.29 10.00 1.90 0.01 1.78 1.90 0.01 1.78 8 + Both 1 -1 -1 31.68 11.19 25.29CNN/DailyMail R1 R2 RL9 Baseline (TWN) 10 + Activation(learning-based) 2 -2 -2 13.34 0.99 12.58 2 -2 -2 12.92 0.32 12.42 11 + Weight(stats-based) 2 -2 -2 19.34 0.42 18.42 12 + Both 2 -2 -2 41.03 18.18 38.3013 Baseline (BWN) 14 + Activation(learning-based) 1 -1 -1 1 -1 -1 15 + Weight(stats-based) 1 -1 -1 15.05 0.35 14.01 2.78 0.08 2.48 2.78 0.08 2.48 16 + Both 1 -1 -1 35.56 11.71 33.23"
            },
            {
                "figure_label": "4",
                "figure_type": "table",
                "figure_id": "tab_3",
                "figure_caption": "Generated average sequence length comparison between baseline method and our method.",
                "figure_data": "Method#Bits (E-W-A)XSUMCNN/DailyMailBART-base32-32-3230.7399.89Baseline TBT2 -2 -8 2 -2 -828.53 32.0493.63 95.78Baseline TBT2 -2 -2 2 -2 -248.41 30.7114.88 88.38Baseline TBT1 -1 -8 1 -1 -862.0 31.57128.0 97.08Baseline TBT1 -1 -1 1 -1 -162.0 29.81128.0 67.51"
            }
        ],
        "formulas": [
            {
                "formula_id": "formula_0",
                "formula_text": "X i T = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 \u2212\u03b1 T , if X i R < \u2212\u2206 0, if \u2212 \u2206 \u2a7d X i R \u2a7d \u2206 +\u03b1 T , if X i R > \u2206 (1) \u2206 = 0.7 \u2022 ||X R || l1 n X R (2) \u03b1 T = i X i R \u2022 1 |X i R |>\u2206 i 1 |X i R |>\u2206(3)",
                "formula_coordinates": [
                    2.0,
                    326.78,
                    223.61,
                    198.37,
                    140.13
                ]
            },
            {
                "formula_id": "formula_1",
                "formula_text": "X i B = \u03b1 B \u2022Sign(X i R ) = \u2212\u03b1 B , if X i R < 0 +\u03b1 B , if X i R \u2a7e 0 (4) \u03b1 B = ||X R || l1 n X R(5)",
                "formula_coordinates": [
                    2.0,
                    304.86,
                    561.74,
                    220.29,
                    73.74
                ]
            },
            {
                "formula_id": "formula_2",
                "formula_text": "\u03b1 * = arg min ||\u03b1 \u0174Q \u2212 W R || l2(6)",
                "formula_coordinates": [
                    3.0,
                    107.57,
                    476.12,
                    182.29,
                    21.44
                ]
            },
            {
                "formula_id": "formula_3",
                "formula_text": "max p i H = \u2212p i log(p i ), s.t. N i=1 p i = 1 (7)",
                "formula_coordinates": [
                    3.0,
                    331.5,
                    148.69,
                    193.65,
                    34.7
                ]
            },
            {
                "formula_id": "formula_4",
                "formula_text": "W i T = \u03b1 T \u230aClip( W i R \u2212 \u00b5 T \u03b1 T , \u22121, 1)\u2309 where \u00b5 T = W R , \u03b1 T = 4 3 \u2022 ||W R \u2212 \u00b5 T || l1 n W R(8)",
                "formula_coordinates": [
                    3.0,
                    332.5,
                    481.27,
                    192.65,
                    79.2
                ]
            },
            {
                "formula_id": "formula_5",
                "formula_text": "W i R \u03b1 T to [\u22121.",
                "formula_coordinates": [
                    3.0,
                    306.14,
                    741.66,
                    216.58,
                    32.45
                ]
            },
            {
                "formula_id": "formula_6",
                "formula_text": "W i B = \u03b1 B \u2022 Sign( W i R \u2212 \u00b5 B \u03b1 B )",
                "formula_coordinates": [
                    4.0,
                    112.2,
                    521.93,
                    135.59,
                    29.42
                ]
            },
            {
                "formula_id": "formula_7",
                "formula_text": "\u00b5 B = W R , \u03b1 B = ||W R \u2212 \u00b5 B || l1 n W R(9)",
                "formula_coordinates": [
                    4.0,
                    144.93,
                    553.75,
                    144.94,
                    47.38
                ]
            },
            {
                "formula_id": "formula_8",
                "formula_text": "W i B = \u03b1 B \u2022 Sign( W i R \u2212\u00b5 B \u03b1 B ) = \u03b1 B \u2022 Sign(W i R \u2212 \u00b5 B )",
                "formula_coordinates": [
                    4.0,
                    70.86,
                    701.29,
                    218.28,
                    37.93
                ]
            },
            {
                "formula_id": "formula_9",
                "formula_text": "\u2202W i B \u2202W i R ST E \u2248 1 | W i R \u2212\u00b5 B \u03b1 B |<1 (10)",
                "formula_coordinates": [
                    4.0,
                    361.13,
                    437.22,
                    164.02,
                    33.1
                ]
            },
            {
                "formula_id": "formula_10",
                "formula_text": "X i T = \u03b1 T Xi T = \uf8f1 \uf8f2 \uf8f3 \u03b1 T \u230aClip( X i R \u03b1 T , 0, 2)\u2309, if X R \u2208 R + \u03b1 T \u230aClip( X \u2032i R \u03b1 T , \u22121, 1)\u2309, if X R \u2208 R(11)",
                "formula_coordinates": [
                    5.0,
                    71.68,
                    314.1,
                    218.19,
                    65.17
                ]
            },
            {
                "formula_id": "formula_11",
                "formula_text": "\u2202X i T \u2202\u03b1 T ST E \u2248 \uf8f1 \uf8f2 \uf8f3 Xi T \u2212 X i R \u03b1 T \u20221 0\u2a7dX i R \u2a7d2\u03b1 T , if X R \u2208 R + Xi T \u2212 X \u2032i R \u03b1 T \u20221 |X \u2032i R |\u2a7d\u03b1 T , if X R \u2208 R(12)",
                "formula_coordinates": [
                    5.0,
                    68.86,
                    534.47,
                    221.0,
                    78.3
                ]
            },
            {
                "formula_id": "formula_12",
                "formula_text": "X i B = \u03b1 B Xi B = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 \u03b1 B \u230aClip( X i R \u03b1 B , 0, 1)\u2309, if X R \u2208 R + \u03b1 B \u2022 Sign( X \u2032i R \u03b1 B ), if X R \u2208 R(13)",
                "formula_coordinates": [
                    5.0,
                    71.11,
                    684.98,
                    218.76,
                    67.86
                ]
            },
            {
                "formula_id": "formula_13",
                "formula_text": "\u2202X i B \u2202\u03b1 B ST E \u2248 \uf8f1 \uf8f2 \uf8f3 Xi B \u2212 X i R \u03b1 B \u20221 0\u2a7dX i R \u2a7d\u03b1 B , if X R \u2208 R + Sign(X \u2032i R ), if X R \u2208 R(14)",
                "formula_coordinates": [
                    5.0,
                    307.44,
                    111.21,
                    217.71,
                    76.21
                ]
            },
            {
                "formula_id": "formula_14",
                "formula_text": "! ! in 1 \"# row Real-valued activations (# $ ) (f) (e) (h) (g)",
                "formula_coordinates": [
                    8.0,
                    136.69,
                    91.96,
                    358.79,
                    188.92
                ]
            }
        ],
        "doi": "10.18653/v1/W16-2301"
    },
    "SAFECONV: Explaining and Correcting Conversational Unsafe Behavior": {
        "authors": "Mian Zhang; Jin \u22c4 Lifeng; Linfeng Song; \u22c4 Haitao; Wenliang Chen; Dong Yu",
        "pub_date": "",
        "abstract": "One of the main challenges open-domain endto-end dialogue systems, or chatbots, face is the prevalence of unsafe behavior, such as toxic languages and harmful suggestions. However, existing dialogue datasets do not provide enough annotation to explain and correct such unsafe behavior. In this work, we construct a new dataset called SAFECONV for the research of conversational safety: (1) Besides the utterancelevel safety labels, SAFECONV also provides unsafe spans in an utterance, information able to indicate which words contribute to the detected unsafe behavior; (2) SAFECONV provides safe alternative responses to continue the conversation when unsafe behavior detected, guiding the conversation to a gentle trajectory. By virtue of the comprehensive annotation of SAFECONV, we benchmark three powerful models for the mitigation of conversational unsafe behavior, including a checker to detect unsafe utterances, a tagger to extract unsafe spans, and a rewriter to convert an unsafe response to a safe version. Moreover, we explore the huge benefits brought by combining the models for explaining the emergence of unsafe behavior and detoxifying chatbots. Experiments show that the detected unsafe behavior could be well explained with unsafe spans and popular chatbots could be detoxified by a huge extent. The dataset is available at https://github.com/mianzhang/SafeConv. Warning: This paper contains cases that may be offensive or upsetting.",
        "sections": [
            {
                "heading": "Introduction",
                "text": [
                    "Safety of artificial intelligence models is a topic that attracts mounting attention and concerns from the community (Challen et al., 2019). In this work, we focus on the safety of open-domain conversational models, or chatbots. Current popular chatbots are generally Transformers (Vaswani et  Canned Response",
                    "Figure 1: A case of unsafe spans and contextual rewriting. On the left, the chatbot expresses offensiveness to the user with the word fool. On the right, two methods generating an alternative response are compared.",
                    "2017) trained end-to-end with Language Modeling objectives on large corpora (Radford et al., 2019;Zhang et al., 2020;Wang et al., 2020), where offensive, unreliable and toxic content may exist (Gehman et al., 2020). Thus there are risks for these chatbots to generate responses with unsafe behavior, such as direct offensiveness, agreement to a toxic statement or harmful advice, reflecting patterns learned from the training data (Wolf et al., 2017;Nozza et al., 2021).",
                    "Current endeavors to mitigate such unsafe behavior of chatbots mainly fall on two lines: how to detect unsafe responses and how to steer conversational models towards generating safe responses. In the first line, several related datasets with utterancelevel safety labels are proposed (Dinan et al., 2019;Baheti et al., 2021;Sun et al., 2022) to support checkers for recognition of potential unsafe utterances. However, in most cases, only some words in an utterance contribute to unsafe behavior. For example, in Figure 1, only the word fool in the response is unsafe and other words are civil. Existing dialogue datasets do not annotate such unsafe words which makes us hard to build a system for understanding why an utterance is unsafe. Along the second line, replacing detected unsafe"
                ],
                "publication_ref": [
                    "b1",
                    "b24",
                    "b37",
                    "b32",
                    "b8",
                    "b33",
                    "b20",
                    "b7",
                    "b0"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Dataset",
                "text": "",
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Source",
                "text": [
                    "Multi-Turn Safety-Graduated Utterance-level Safety Labels Unsafe Spans Safe Alternatives (Qian et al., 2019) Reddit + Gab \u2713 -\u2713 --ADHOMINTWEETS (Sheng et al., 2021) Twitter + Silver --\u2713 --BAD (Xu et al., 2020) Human + Silver \u2713 -\u2713 --TOXICHAT (Baheti et al., 2021) Reddit + Silver --\u2713 --DIASAFETY (Sun et al., 2022) Social Media + Silver --\u2713 --SaFeRDialogues (Ung et al., 2022) Human + Silver",
                    "\u2713 - \u2713 - - SAFECONV (Ours) Social Media \u2713 \u2713 \u2713 \u2713 \u2713",
                    "Table 1: Comparison of dialogue safety datasets. \"\u2713\" denotes the property of datasets. \"Silver\" means the dataset includes dialogues generated by trained chatbots or language models.",
                    "responses with safe alternatives is an important direction because it could be deployed in real-time conversational systems in an plug-and-play manner, requiring no extra training or finetuning of chatbots. To this end, Xu et al. (2020) prepares canned responses as safe alternatives. However, the canned responses are just one of two types of safe contextual-irrelevant utterances. We propose contextual rewriting, a new way to generate safe, diverse, and context-relevant alternative responses given the context and unsafe response. As shown in Figure 1, the alternative response produced by contextual rewriting is a better choice to replace the unsafe response, improving coherence and contextual relevance of the response. However, no datasets provide explicit supervision on how to respond nicely and toxicity-free while conforming to the conversational context when unsafe behavior occurs.",
                    "To tackle the above issues, we propose SAFE-CONV, a large-scale dataset of dialogues for the research of conversational safety, where (1) in addition to utterance-level safety labels, spans making an utterance unsafe are annotated for locating of unsafe behavior; and (2) for unsafe utterances, safe alternatives are provided to exemplify how to respond nicely and toxicity-free in specific contexts. Moreover, SAFECONV contains safety-graduated dialogues, which cover infrequent, implicit unsafe behavior, and frequent, explicit unsafe behavior (see subsection 3.1). We compare SAFECONV with related datasets in Table 1 regarding the characteristics of data and annotations. From the table, we find that SAFECONV is more well-rounded with diverse data and comprehensive annotations for conversational safety.",
                    "Our experiments show that SAFECONV can not only support a state-of-the-art safety checker, but also two novel components for conversational unsafe behavior: a tagger to expose spans that make an utterance unsafe and a contextual rewriter to generate a safe, context-relevant alternative response in place of unsafe ones. Futhermore, we show that by combining the checker and the tagger, we can gain a deeper understanding of where the unsafe behavior comes from and by combining the checker and the rewriter, popular chatbots can be detoxified to a huge extent in an effective plug-and-play manner."
                ],
                "publication_ref": [
                    "b23",
                    "b27",
                    "b0",
                    "b29"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Related Work",
                "text": [
                    "Dialogue Safety Datasets Datasets concerning dialogue safety with annotations in different forms have been constructed in recent years. For unsafety detection, Qian et al. (2019), Xu et al. (2020), Baheti et al. (2021), Ung et al. (2022) and Sun et al. (2022) provided utterance-level binary safety labels in their proposed dialogue datasets. Baheti et al. (2021) annotated the stance of each utterance to previous ones in the same dialogue to help unsafety detection indirectly. To steer the conversation from unsafety failures, Qian et al. (2019) and Ung et al. (2022) rendered intervention and feedback from a third party or given by the conversation partner, respectively, in natural language that signals the occurrence of unsafety in utterances and discourages the usage of unsafe expressions. Ung et al. (2022) further required annotators to give a graceful response to acknowledge the feedback and take the conversation to an acceptable and friendly trajectory, from which chatbots could learn to recover from safe failures. However, as far as we know, SAFECONV is the first dataset with the annotation of unsafe spans and context-relevant safe alternatives.",
                    "Toxicity Mitigation To detect unsafe contents, transformer-based classifiers (Devlin et al., 2019;Liu et al., 2019) are the predominant methods due to their strong representation power, upon which some datasets (Davidson et al., 2017;Hartvigsen et al., 2022) can be leveraged to train decent and powerful toxicity detectors. Finer toxicity detection, namely extracting toxic spans or phrases, can be seen as sequence labeling (Yang et al., 2018). For text detoxification, Nogueira dos Santos et al. (2018) and Laugier et al. (2021) trained an encoderdecoder model to rewrite toxic utterances into nontoxic ones. Dathathri et al. (2020) and Krause et al. (2021) leveraged a discriminator to constrain the language model for non-toxic generation and Dale et al. (2021) improved upon Krause et al. (2021) with a paraphrasing model for content preserving. Ouyang et al. (2022) and Glaese et al. (2022) injected human feedback via reinforcement learning to make the generated responses more helpful, correct, and harmless."
                ],
                "publication_ref": [
                    "b23",
                    "b0",
                    "b29",
                    "b0",
                    "b23",
                    "b29",
                    "b29",
                    "b6",
                    "b23",
                    "b4",
                    "b11",
                    "b36",
                    "b19",
                    "b14",
                    "b3",
                    "b13",
                    "b2",
                    "b13",
                    "b21",
                    "b9"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Data Collection",
                "text": [
                    "SAFECONV is a dataset containing utterance-level safety labels, unsafe spans, and safe alternative responses. We describe the process to construct SAFECONV, including the data sources, the details of human annotation, the methods to control annotation quality, and the statistics of SAFECONV."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Data Sources",
                "text": [
                    "To cover frequent, explicit unsafe behavior, such as explicit offensiveness, and infrequent, implicit unsafe behavior, such as agreement to harmful suggestions, we choose the dialogues of our dataset from two public large-scale conversational datasets: LCCC-base (Wang et al., 2020) and PchatbotW (Qian et al., 2021). LCCC-base contains high-quality multi-turn dialogues from Weibo which have gone through a rigorous data cleaning pipeline. Specifically, to avoid potential toxic issues, they conduct both rule-based filtering, which removes dialogues containing toxic words and sensitive content, and classifier-based filtering, which filters out dialogues regarding sensitive topics. PchatbotW sourced their dialogues crawled from Weibo, however, compared to LCCC, their data cleaning procedures relating to toxicity are not as comprehensive: they only filter dialogues with sensitive words. Therefore, PchatbotW contains more frequent, explicit unsafe behavior while for LCCC-base, more infrequent and implicit, which we call the safety-graduated attribute of SAFE-CONV. Moreover, the dialogues from two sources differ in content types, with LCCC-base containing mainly daily conversation and PchatbotW having more cases of comments over a post, such as a news headline. We verify the safety-graduated attribute by a trained safety checker (see subsection 3.2), which demonstrates that there are around 11.6% unsafe dialogues in LCCC-base while 17.7% in PchatbotW. We refer dialogues from LCCC-base and PchatbotW as L-dialogues and P-dialogues, respectively."
                ],
                "publication_ref": [
                    "b32",
                    "b22"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Data Selection",
                "text": [
                    "In an attempt to include a higher percentage of dialogues with unsafe responses in our dataset, we train a safety checker to pre-examine the safety of L-dialogues and P-dialogues and select dialogues with unsafe label for annotation. Due to the lack of large-scale corpus for unsafe languages classification in Chinese 1 , we translate the dataset from Jigsaw toxicity competition 2 into Chinese and regard comments with 0.5 or higher scores on toxicity as unsafe and others as safe. Then we randomly sample 50,000/5,000/5,000 comments for training/evaluation/testing from the translated data with the ratio of positive and negative comments as 1:1. Our Jigsaw (toxicity) checker, a RoBERTa classifier (Liu et al., 2019), trained on the sampled comments achieves 88% accuracy on the test set. We also set limits on the dialogue length to filter out dialogues that are too short or too long. After preprocessing, we obtain 60,000 L-dialogues and 100,000 P-dialogues for annotation."
                ],
                "publication_ref": [
                    "b23"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Human Annotation",
                "text": [
                    "We divide conversational unsafety into three coarse categories according to the target:",
                    "\u2022 Self Unsafety: Responses that belittle oneself or indicate self-inflicting harm.",
                    "\u2022 User Unsafety: Responses that express offensiveness to users or give them harmful suggestions.",
                    "\u2022 Third-party Unsafety: Responses that contain offensiveness to other individuals or groups in society or relate to sensitive topics.",
                    "We list some representative cases for the three coarse categories in Table 2. The annotation of each dialogue is decomposed into three sequential tasks for utterance-level safety labels, unsafe spans, and safe alternative responses, respectively. Each  dialogue is assigned to three workers and each annotator performs the three tasks independently.",
                    "Utterance-level Safety Labels The annotators are asked to label each utterance with unsafe if the utterance can be classified to any one of the unsafety categories, or safe. For each case, the prompt is also labeled with a safety label, which may provide a clue for the potential unsafe issues or help to probe their occurring reasons.",
                    "Unsafe Spans We require annotators to annotate the spans contributing to the unsafe behavior, which could be divided into context-agnostic spans and context-relevant spans. Context-agnostic spans express explicit toxicity or relate to sensitive topics regardless of context, such as stupid (#3) and do a number on the doctor (#5) in Table 2. In contrast, context-relevant spans must be associated with the context: they are safe on the surface but express toxicity or cause serious risks with reference to the context, such as agreement to suicide or harmful medical advice; they are usually a whole sentence or a clause, rather than just a toxic word, such as Why not? (#6) in Table 2. Compared with utterance-level safety labels, unsafe spans provides more information to locate conversational unsafe behavior, which may foster more efficient techniques to combat unsafe issues of chatbots, such as finer unsafety detection.",
                    "Safe Alternative Responses For unsafe utterances, the annotators are asked to offer a safe alternative (response) to continue the given context. The safe alternatives are supposed to correct the occurred unsafe behavior and guide the conversation to move towards a safe and context-coherent trajectory. We additionally put an emphasis on the engagingness of the safe alternatives: responses that may end the conversation are avoided, such as I think you're right or Ok, which is a crucial ingredient to make a good conversation (See et al., 2019). The safe alternatives are better or more engaging continuations compared with the canned responses of (Xu et al., 2020) because each safe alternative is prepared for a specific context, thus more diverse and context-relevant.",
                    "Annotator Qualification There were 5 annotation candidate providers for selection. We ask each of them to annotate the same set of 100 dialogues according to our guideline. These 100 dialogues are also annotated by the authors of the paper. Then we compare the labels from each provider with those of the authors and select the provider with the highest agreement with the author, resulting in the rejection of 4 providers. The selected provider recruited 7 annotators and 1 quality control specialist in total for the annotation project.",
                    "Quality Control There are 16 batches of data in total. Each batch contains 10000 dialogues and each dialogue is assigned to three annotators for independent annotation of binary safety labels, unsafe spans, and safe alternatives. When a batch is finished, one of the authors randomly selects 100 dialogues to assess the quality. Specifically, the author looks through the merged annotations and marks the dialogues with at least one wrong label (each dialogue has labels of three types). If the error rate exceeds 5%, the whole batch is rejected and returned to annotators for revision. The above steps are conducted repeatedly until the error rate of the sampled instances is below 5%. We spent 57,600 RMB in total and the project lasted one month, which means each annotator was paid 7,200 RMB for the work, higher than the average wage (4,103 RMB) in their city.",
                    "Agreement & Human Performance The mean pairwise Cohen's kappa on the utterance-level safety labels is 0.61, indicating that there is high inter-annotator reliability. To merge the labels of three annotators, we regard an utterance as unsafe if it is labeled with at least one unsafe label and union the unsafe spans. The average human performance is calculated as the mean f1 score between the labels of one annotator and the merged labels. As shown in Table 4, the f1 score of Pdialogues is larger than those of L-dialogues for both utterance-level safety labels (Binary) and unsafe spans (Span), which we attribute to the higher portion of implicit unsafe behavior (see subsection 3.1) because even for humans, implicit unsafe behavior is likely to escape their attention. Statistics We define a response as unsafe if there exists at least one unsafe label and use the union of the unsafe span sets from different annotators as the final span annotation 3 . For safe alternatives, we keep all the rewritten responses. The statistics of SAFECONV are shown in Table 3. The ratio of unsafe responses of L-dialogues (12.5%) is lower than that of P-dialogues (19.3%). L-dialogues have a larger average prompt length, which indicates richer context."
                ],
                "publication_ref": [
                    "b26"
                ],
                "figure_ref": [],
                "table_ref": [
                    "tab_2",
                    "tab_2",
                    "tab_2",
                    "tab_4",
                    "tab_3"
                ]
            },
            {
                "heading": "Base Models",
                "text": [
                    "The comprehensive annotation of SAFECONV could support three usages for mitigating conversational unsafe behaviors: a checker predicting an utterance being safe or unsafe, a tagger extracting unsafe spans, and a rewriter generating safe alternatives for unsafe utterances. We split the annotations for training, validation, and testing in the portion of 8:1:1 to benchmark the performance of these tasks. Our implementation is based on the Hugging-Face Transformers library (Wolf et al., 2020). Specifically, the checker is initialized as RoBERTa-base (Liu et al., 2019)  of the span are tagged as I; O denotes a word not belonging to any unsafe span. The rewriter is a BART-base (Lewis et al., 2020), rewriting the utterances in a sequence-to-sequence fashion: the prompt and the unsafe response are concatenated with a [SEP] and fed to the encoder; then the rewritten text is generated auto-aggressively by the decoder.",
                    "Training Details The same configuration is used for the training of the checker, tagger, and rewriter.",
                    "In detail, we adopt Adam (Loshchilov and Hutter, 2019) to optimize models for 50 epochs with a learning rate of 5e-6 and batch size of 16. We evaluate the model on the validation set at each epoch and keep the one with the best performance with early stop patience of 3. All the results are averaged over four runs.",
                    "Evaluation We compare the checker trained on SAFECONV (C SAFECONV ) with the checker trained on COLD (C COLD ) dataset (Deng et al., 2022) and the checker of Baidu 4 (C Baidu ). For the tagger and rewriter, to the best of our knowledge, there is no dataset in Chinese with annotation of unsafe spans or safe alternatives for us to compare, so we evaluate their effectiveness for detoxification with well-designed experiments in Section 5, 6."
                ],
                "publication_ref": [
                    "b34",
                    "b23",
                    "b15",
                    "b18"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Results",
                "text": [
                    "We report precision, recall, and f1 score of the unsafe category of the evaluated checkers in Table 5. C SAFECONV outperforms the other checkers substantially on the overall f1 score, indicating that there is a substantial domain difference between the training data of C COLD and C Baidu and our dataset, potentially due to dialogue contexts. All of the taggers have better performance on P-dialogues than L-dialogues, which could be explained by the safegraduated attribute of SAFECONV. In addition, the tagger achieves 57.9% precision, 54.8% recall, and 4 https://ai.baidu.com/tech/textcensoring 56.3% f1 score of the retrieved unsafe spans and the rewriter achieves 63.0% bleu and 1.61 perplexity."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_5"
                ]
            },
            {
                "heading": "Explainable Safety Checking",
                "text": [
                    "With the tagger for unsafe spans in hand, when an utterance is recognized as unsafe, we are able to explain the decision of the checker-which words contribute to the unsafe behavior. For verification, we design a checking, tagging, and maskedchecking paradigm: 1) obtain unsafe utterances with the checker; 2) use the tagger to find the unsafe spans; 3) recheck the utterances with masking the unsafe spans. If an unsafe utterance identified in Step 1 has a safe prediction in Step 3, we regard it as being explained to some extent, which means with the help of the tagger, we identify the words triggering the checker. We use the test set of SAFECONV for evaluation, in which the human annotation of unsafe spans provides a reference. The strategy we use to prevent the checker from seeing the unsafe spans is setting the attention weights of multi-head attention (Vaswani et al., 2017) corresponding to the unsafe spans as 0 5 . The results are presented in Table 6. After masking the unsafe words yielded by the tagger, a staggering 85.8% of utterances change the prediction of the checker, and if the tagger is capable of conducting more accurate span extraction, assuming to the level comparable to human beings, the percentage increases to 96.7%. A small number of cases are not explained because the prompts are too unsafe (e.g., having multiple unsafe spans) or the annotated unsafe spans are false. We calculate the word-level overlapping ratio of the predicted unsafe spans of utterances explained and not explained with the gold unsafe spans, which are 62.3% and 16.3%, respectively. This indicates again that if we want to convert an unsafe utterance to a safe version while maintaining the original meaning as much as possible, an effective way is to avoid the words contributing to unsafe behaviorunsafe spans can well explain the prediction of a safety checker.  "
                ],
                "publication_ref": [
                    "b31"
                ],
                "figure_ref": [],
                "table_ref": [
                    "tab_6"
                ]
            },
            {
                "heading": "Correct Conversational Unsafe Behavior via Contextual Rewriting",
                "text": [
                    "One solution to avoid unsafe behavior is to conduct a check-reject-regenerate cycle-checking the generated response with a safety checker, refusing it if it is unsafe, and regenerating a new responserepeatedly until a safe response surfaces. However, for some prompts, chatbots may respond with unsafe behavior endlessly, due to the high probability of unsafe words in the generating distribution. A more efficient method is one-time checking and rewriting-directly rewriting unsafe responses into detoxified ones with a rewriter trained on unsafesafe response pairs. However, no dataset could support a satisfactory rewriter in the past. Correspondingly, the proposed SAFECONV provides several safe, context-coherent versions for unsafe responses in a large quantity. We verify the effectiveness of the unsafe response rewriter in the following steps: 1) get responses from chatbots on prompts; 2) leverage a safety checker to examine the responses; 3) use the trained rewriter to rewrite unsafe responses; and 4) examine the rewritten responses with the safety checker. In practice, after obtaining the trained rewriter, we run the whole process four times and average the results to eliminate the randomness induced by stochastic sampling when decoding sequences 6 .",
                    "Prompts In order to increase the probability for chatbots to surface unsafe responses for rewriting, we use the Jigsaw checker (described in subsection 3.2) to search unsafe responses from 50,000 prompt-response pairs from LCCC-large (Wang et al., 2020) and 50,000 from PChatbotW (Qian et al., 2021) and only keep their prompts. We get 14,632 prompts in total. Please note that the prompt-response pairs used here do not overlap with those of SAFECONV.",
                    "Chatbots Four state-of-the-art open-source chatbots are used to generate responses. CDialGPTbase (Wang et al., 2020), a decoder-based chatbot with 95.5M parameters, is trained with a large corpus of conversations collected mainly from Weibo comments. Different from CDialGPT-base, CDialGPT-large is trained with more dialogues from a mixup of multiple data sources. EVAbase (Gu et al., 2022) is a encoder-decoder-based conversational model with 300M parameters pretrained on cleaned WDC-Dialogue (Zhou et al., 2021). Different from EVA-base, EVA-large has a larger scale of 970M parameters.",
                    "Results As shown in Table 7. By conducting a check-rewrite strategy, the number of unsafe responses can be reduced substantially, approximately 63%, 60%, 65%, and 68% for the four evaluated chatbots, respectively, which demonstrates the effectiveness of the rewriter powered by SAFE-CONV. To illustrate whether the rewriter takes a shortcut to detoxify an utterance, for example, by simply producing I don't know or safe but meaningless sentences, we randomly select 100 cases that are successfully converted from unsafe to safe from the results of all the chatbots and ask five annotators to evaluate the responses. We focus on three aspects of the rewritten utterances:",
                    "\u2022 Fluency: Whether the generated response is fluent and easy to understand.",
                    "\u2022 Coherence: Whether the generated response is semantically coherent with the context.",
                    "\u2022 Informativeness: Whether the generated response is diverse and with new information.",
                    "The scores follow a 5-point Likert scale (1, 2, 3, 4, or 5). As shown in Table 8, compared to the original responses of the chatbots, the rewritten responses have close Fluency and Coherence while losing a little informativeness. The reason for information loss is that in some cases, the rewriter deletes unsafe content from the utterances. However, we think the huge benefit of reducing unsafe behavior by rewriting overwhelms this weak point.",
                    "Finetuning with Safety Feedback Although the rewriter trained on SAFECONV has achieved satisfying performance in mitigating the unsafe behavior of chatbots, there are also failed cases accounting for around 40%. We are interested in the CDialGPT-base (Wang et al., 2020) 95.5M 484.0 174.5 (63.9% \u21d3) 85.0 (82.4% \u21d3) CDialGPT-large (Wang et al., 2020) 95.5M 439.8 176.0 (60.0% \u21d3) 89.0 (79.8% \u21d3) EVA-base (Gu et al.,  question: can we further improve the rewriter by making it aware of its bad generations? We further finetune the rewriter on the feedback of the safety checker with PPO (Schulman et al., 2017;Ouyang et al., 2022), a policy optimization method in Reinforcement Learning (RL). Specifically, the objective to optimize is:",
                    "J (\u03b8) = E (x,y \u2032 )\u223cR \u03b8 [r(x, y \u2032 ) \u2212 \u03b2log R \u03b8 (y \u2032 |x) R \u03b8 \u2032 (y \u2032 |x) ],",
                    "where \u03b8 and \u03b8 \u2032 are the parameters of the rewriter to optimize and before finetuning; x, y and y \u2032 denote the prompt, response and rewritten response. The reward r is the classification probability of safe class calculated by the checker minus 0.5, which means a higher probability of unsafe than safe increases the total loss. Similar to Ouyang et al. (2022), we add KL penalty from the rewriter before finetuning at the model distribution of each token to avoid over-optimization and set \u03b2 as 0.02.",
                    "In the experiment, we generate the data for finetuning from 100,000 LCCC-large and 100,000 PChatbotW prompt-response pairs. In detail, 1) we find 26,752 potential unsafe prompt-response pairs with the Jigsaw checker, 2) rewrite the responses with the rewriter trained on SAFECONV, 3) generate safety labels on the rewritten responses, 4) and select 1,284 unsafe instances as the data for finetuning. We also split the 1,284 instances into training/validation/test sets and optimize the rewriter until the reward on the validation set does not increase, which only takes 2 to 4 epochs.",
                    "Table 7 shows the results after RL finetuning. As we can see, the number of unsafe responses is reduced again by around 20%, which is quite effi-cient because the cost of finetuning is small, about 20 minutes on an Nvidia V100. We conduct human evaluation of the RL-finetuned rewriter and the results are shown in Table 8. We could see that the finetuned rewriter generates responses with the best fluency and coherence, and close informativeness, suggesting that injecting feedback on safety from the checker could not only substantially improve the detoxification performance of the rewriter, but also make the responses more fluent and contextually coherent. We also ask annotators to label the responses with safety labels. The percentages of unsafe responses at each stage are shown in the last column of Table 8. The relative reduction percentages after rewriting (56.1% \u21d3) and finetuning (82.9% \u21d3) generally align with those in Table 7, indicating that the checker is trustable. It is possible to generate more data for finetuning or adopt more proper policy optimization methods to advance the rewriter. We leave them for future work.",
                    "Ablation In order to study the role of context in rewriting, we train a rewriter, also a BART-base, on SAFECONV without using the context (the input of the encoder is formatted as \"[CLS] response [SEP]\") and use it to rewrite the unsafe responses of chatbots. The comparison between contextual rewriting (w/ context) and non-contextual rewriting (w/o context) is illustrated in Table 9. The results are also averaged over four runs. We could see that without referring to the context, more unsafe responses exist in the rewritten utterances, indicating that context is a crucial factor for successful rewriting to alleviate unsafe behavior in conversation.  Error Analysis There are cases that can not be detoxified by the rewriter, we conclude them into two main categories: 1) Parroting. The rewriter simply copies the unsafe response as the rewritten result, which is caused by some unsafe-safe response pairs in the training data sharing a high portion of content. 2) Partial success. Only part of the unsafe behaviors in the response are been erased. For example, the context is \"That idiot lost his wallet again.\" and the response is \"He is such a stupid person.\". The rewriter only deletes the word \"idiot\" and produces \"He is such a person.\", which is still irritating. We attribute this phenomenon to false annotations."
                ],
                "publication_ref": [
                    "b32",
                    "b22",
                    "b32",
                    "b38",
                    "b32",
                    "b32",
                    "b25",
                    "b21",
                    "b21"
                ],
                "figure_ref": [],
                "table_ref": [
                    "tab_8",
                    "tab_9",
                    "tab_8",
                    "tab_9",
                    "tab_9",
                    "tab_8",
                    "tab_10"
                ]
            },
            {
                "heading": "Conclusion",
                "text": [
                    "In this paper, we study how to explain and correct unsafe behavior in conversation and propose SAFECONV, to the best of our knowledge, the first large-scale dataset with comprehensive annotations for conversational safety. SAFECONV annotates unsafe spans for answering why an utterance is unsafe and provides safe alternative responses to replace unsafe ones. Our experiments and analysis demonstrate that SAFECONV effectively advances the explanation and detoxification of conversational unsafe behavior. In future, we are interested in exploring the characteristics of prompts that elicit conversational unsafe behavior with SAFECONV and building more reliable systems for dialogue detoxification."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Ethics Considerations",
                "text": [
                    "Dataset & Annotation SAFECONV is proposed to help reduce unsafe behavior in a conversation. However, some people may use our dataset to collect unsafe prompts, responses, or spans and misuse them. This is a common issue for all public datasets regarding toxicity or safety. We believe that our dataset creates more value than risks. Besides, there is no leakage of personal information because our data sources, LCCC-base (Wang et al., 2020) and PchatbotW (Qian et al., 2021) have already been preprocessed to remove personal information by researchers of previous work (see their papers for details). Also, though our dataset contains more instances compared to previously proposed datasets, the dialogues are mostly from social media and may not cover types of conversational unsafe behavior found in other media. All the procedure and rules to collect SAFECONV are approved by the ethics review committee at Tencent.",
                    "Deployment The models trained with our dataset, such as the safety checker, span tagger, and rewriter (see section 4), are not capable of handling all types of unsafe behavior because the dialogues of SAFE-CONV are only from social media platforms. In addition, though SAFECONV is designed to build a more civil conversational environment, there may exist wrong usages of the dataset, such as training a rewriter that converts safe responses to unsafe ones and using the trained safety checker or span tagger to gather unsafe expression for misconduct.",
                    "SAFECONV is available to the public under a usage agreement for research and related purposes only and we urge people interested to use it ethically."
                ],
                "publication_ref": [
                    "b32",
                    "b22"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Limitations",
                "text": [
                    "For the dataset, although we adopt several methods to assure a high quality of the dataset, mislabeled data still exist due to the subjectivity of the annotators. For example, annotators may have different opinions on whether to regard \u5c41\u6c11(shitizen) as unsafe because \u5c41\u6c11(shitizen) is a rare word in Chinese and could be both derogatory and selfdeprecating humorously in most cases. Moreover, our dataset is in Chinese. Directly translating SAFECONV to other languages with translation tools may induce erroneous labels due to syntactic and cultural differences between languages. We call for endeavors to fix it, such as annotating similar datasets in other languages or improving translation strategies.",
                    "For the experiments, firstly, in Section 6, we evaluate the performance of the rewriter based on chatbots of restricted sizes. However, there are large chatbots that we do not include in the evaluation due to the limitation of computing resources, such as EVA-xLarge with up to 2.8B parameters, on which the detoxifying results will lead to more comprehensive results. Secondly, as shown in Table 8, the overall contextual coherence and informativeness of the responses from current state-of-the-art chatbots in Chinese are still not satisfying. Evaluating SAFECONV on more powerful chatbots based on large language models is worth exploring in the future.",
                    "C2. Did you discuss the experimental setup, including hyperparameter search and best-found hyperparameter values? 4,5,6 C3. Did you report descriptive statistics about your results (e.g., error bars around results, summary statistics from sets of experiments), and is it transparent whether you are reporting the max, mean, etc. or just a single run? 4,5,6 C4. If you used existing packages (e.g., for preprocessing, for normalization, or for evaluation), did you report the implementation, model, and parameter settings used (e.g., NLTK, Spacy, ROUGE, etc.)? 4 D Did you use human annotators (e.g., crowdworkers) or research with human participants? 3 D1. Did you report the full text of instructions given to participants, including e.g., screenshots, disclaimers of any risks to participants or annotators, etc.? Some content involves confidential information of the company and can not be made public.",
                    "D2. Did you report information about how you recruited (e.g., crowdsourcing platform, students) and paid participants, and discuss if such payment is adequate given the participants' demographic (e.g., country of residence)? 3 D3. Did you discuss whether and how consent was obtained from people whose data you're using/curating? For example, if you collected data via crowdsourcing, did your instructions to crowdworkers explain how the data would be used? 3 D4. Was the data collection protocol approved (or determined exempt) by an ethics review board? 8 D5. Did you report the basic demographic and geographic characteristics of the annotator population that is the source of the data? 3"
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_9"
                ]
            },
            {
                "heading": "Acknowledgements",
                "text": [
                    "We thank the anonymous reviewers for their valuable comments."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "3",
                "text": [
                    "B3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided that it was specified? For the artifacts you create, do you specify intended use and whether that is compatible with the original access conditions (in particular, derivatives of data accessed for research purposes should not be used outside of research contexts)? 3 B4. Did you discuss the steps taken to check whether the data that was collected / used contains any information that names or uniquely identifies individual people or offensive content, and the steps taken to protect / anonymize it? 8 B5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and linguistic phenomena, demographic groups represented, etc.? 3 B6. Did you report relevant statistics like the number of examples, details of train / test / dev splits, etc. for the data that you used / created? Even for commonly-used benchmark datasets, include the number of examples in train / validation / test splits, as these provide necessary context for a reader to understand experimental results. For example, small differences in accuracy on large test sets may be significant, while on small test sets they may not be."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Left blank.",
                "text": [
                    "C Did you run computational experiments? 4,5,6 C1. Did you report the number of parameters in the models used, the total computational budget (e.g., GPU hours), and computing infrastructure used? 4,5,6",
                    "The Responsible NLP Checklist used at ACL 2023 is adopted from NAACL 2022, with the addition of a question on AI writing assistance."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            }
        ],
        "references": [
            {
                "ref_id": "b0",
                "title": "Just say no: Analyzing the stance of neural dialogue generation in offensive contexts",
                "journal": "Association for Computational Linguistics",
                "year": "2021",
                "authors": "Ashutosh Baheti; Maarten Sap; Alan Ritter; Mark Riedl"
            },
            {
                "ref_id": "b1",
                "title": "Artificial intelligence, bias and clinical safety",
                "journal": "BMJ Quality & Safety",
                "year": "2019",
                "authors": "Robert Challen; Joshua Denny; Martin Pitt; Luke Gompels; Tom Edwards; Krasimira Tsaneva-Atanasova"
            },
            {
                "ref_id": "b2",
                "title": "Text detoxification using large pre-trained neural models",
                "journal": "Association for Computational Linguistics",
                "year": "2021",
                "authors": "David Dale; Anton Voronov; Daryna Dementieva; Varvara Logacheva; Olga Kozlova; Nikita Semenov; Alexander Panchenko"
            },
            {
                "ref_id": "b3",
                "title": "Plug and play language models: A simple approach to controlled text generation",
                "journal": "",
                "year": "2020-04-26",
                "authors": "Sumanth Dathathri; Andrea Madotto; Janice Lan; Jane Hung; Eric Frank; Piero Molino; Jason Yosinski; Rosanne Liu"
            },
            {
                "ref_id": "b4",
                "title": "Automated hate speech detection and the problem of offensive language",
                "journal": "",
                "year": "2017",
                "authors": "Thomas Davidson; Dana Warmsley; Michael Macy; Ingmar Weber"
            },
            {
                "ref_id": "b5",
                "title": "Cold: A benchmark for chinese offensive language detection",
                "journal": "",
                "year": "2022",
                "authors": "Jiawen Deng; Jingyan Zhou; Hao Sun; Fei Mi; Minlie Huang"
            },
            {
                "ref_id": "b6",
                "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
                "journal": "Association for Computational Linguistics",
                "year": "2019",
                "authors": "Jacob Devlin; Ming-Wei Chang; Kenton Lee; Kristina Toutanova"
            },
            {
                "ref_id": "b7",
                "title": "Build it break it fix it for dialogue safety: Robustness from adversarial human attack",
                "journal": "",
                "year": "2019",
                "authors": "Emily Dinan; Samuel Humeau; Bharath Chintagunta; Jason Weston"
            },
            {
                "ref_id": "b8",
                "title": "RealToxi-cityPrompts: Evaluating neural toxic degeneration in language models",
                "journal": "Online. Association for Computational Linguistics",
                "year": "2020",
                "authors": "Suchin Samuel Gehman; Maarten Gururangan; Yejin Sap; Noah A Choi;  Smith"
            },
            {
                "ref_id": "b9",
                "title": "Improving alignment of dialogue agents via targeted human judgements",
                "journal": "",
                "year": "2022",
                "authors": "Amelia Glaese; Nat Mcaleese; Maja Tr\u0119bacz; John Aslanides; Vlad Firoiu; Timo Ewalds; Maribeth Rauh; Laura Weidinger; Martin Chadwick; Phoebe Thacker"
            },
            {
                "ref_id": "b10",
                "title": "",
                "journal": "",
                "year": "",
                "authors": "Yuxian Gu; Jiaxin Wen; Hao Sun; Yi Song; Pei Ke; Chujie Zheng; Zheng Zhang; Jianzhu Yao; Xiaoyan Zhu; Jie Tang"
            },
            {
                "ref_id": "b11",
                "title": "ToxiGen: A large-scale machine-generated dataset for adversarial and implicit hate speech detection",
                "journal": "Association for Computational Linguistics",
                "year": "2022",
                "authors": "Thomas Hartvigsen; Saadia Gabriel; Hamid Palangi; Maarten Sap; Dipankar Ray; Ece Kamar"
            },
            {
                "ref_id": "b12",
                "title": "The curious case of neural text degeneration",
                "journal": "",
                "year": "2020-04-26",
                "authors": "Ari Holtzman; Jan Buys; Li Du; Maxwell Forbes; Yejin Choi"
            },
            {
                "ref_id": "b13",
                "title": "GeDi: Generative discriminator guided sequence generation",
                "journal": "",
                "year": "2021",
                "authors": "Ben Krause; Akhilesh Deepak Gotmare; Bryan Mccann; Nitish Shirish Keskar; Shafiq Joty; Richard Socher; Nazneen Fatema Rajani"
            },
            {
                "ref_id": "b14",
                "title": "Civil rephrases of toxic texts with self-supervised transformers",
                "journal": "Online. Association for Computational Linguistics",
                "year": "2021",
                "authors": "L\u00e9o Laugier; John Pavlopoulos; Jeffrey Sorensen; Lucas Dixon"
            },
            {
                "ref_id": "b15",
                "title": "BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
                "journal": "",
                "year": "2020",
                "authors": "Mike Lewis; Yinhan Liu; Naman Goyal; Marjan Ghazvininejad; Abdelrahman Mohamed; Omer Levy; Veselin Stoyanov; Luke Zettlemoyer"
            },
            {
                "ref_id": "b16",
                "title": "",
                "journal": "",
                "year": "",
                "authors": "Yinhan Liu; Myle Ott; Naman Goyal; Jingfei Du; Mandar Joshi; Danqi Chen"
            },
            {
                "ref_id": "b17",
                "title": "Roberta: A robustly optimized bert pretraining approach. ArXiv preprint, abs",
                "journal": "",
                "year": "1907",
                "authors": "Luke Zettlemoyer; Veselin Stoyanov"
            },
            {
                "ref_id": "b18",
                "title": "Decoupled weight decay regularization",
                "journal": "",
                "year": "2019-05-06",
                "authors": "Ilya Loshchilov; Frank Hutter"
            },
            {
                "ref_id": "b19",
                "title": "Fighting offensive language on social media with unsupervised text style transfer",
                "journal": "Short Papers",
                "year": "2018",
                "authors": "Cicero Nogueira Dos Santos; Igor Melnyk; Inkit Padhi"
            },
            {
                "ref_id": "b20",
                "title": "HONEST: Measuring hurtful sentence completion in language models",
                "journal": "Online. Association for Computational Linguistics",
                "year": "2021",
                "authors": "Debora Nozza; Federico Bianchi; Dirk Hovy"
            },
            {
                "ref_id": "b21",
                "title": "Training language models to follow instructions with human feedback",
                "journal": "ArXiv preprint",
                "year": "2022",
                "authors": "Long Ouyang; Jeff Wu; Xu Jiang; Diogo Almeida; L Carroll; Pamela Wainwright; Chong Mishkin; Sandhini Zhang; Katarina Agarwal; Alex Slama;  Ray"
            },
            {
                "ref_id": "b22",
                "title": "Pchatbot: A largescale dataset for personalized chatbot",
                "journal": "",
                "year": "2021",
                "authors": "Xiaohe Hongjin Qian; Hanxun Li; Yu Zhong; Yueyuan Guo; Yutao Ma; Zhanliang Zhu; Zhicheng Liu; Ji-Rong Dou;  Wen"
            },
            {
                "ref_id": "b23",
                "title": "A benchmark dataset for learning to intervene in online hate speech",
                "journal": "",
                "year": "2019",
                "authors": "Jing Qian; Anna Bethke; Yinyin Liu; Elizabeth Belding; William Yang Wang"
            },
            {
                "ref_id": "b24",
                "title": "Language models are unsupervised multitask learners",
                "journal": "OpenAI blog",
                "year": "2019",
                "authors": "Alec Radford; Jeffrey Wu; Rewon Child; David Luan; Dario Amodei; Ilya Sutskever"
            },
            {
                "ref_id": "b25",
                "title": "Proximal policy optimization algorithms",
                "journal": "",
                "year": "2017",
                "authors": "John Schulman; Filip Wolski; Prafulla Dhariwal; Alec Radford; Oleg Klimov"
            },
            {
                "ref_id": "b26",
                "title": "What makes a good conversation? how controllable attributes affect human judgments",
                "journal": "Long and Short Papers",
                "year": "2019",
                "authors": "Abigail See; Stephen Roller; Douwe Kiela; Jason Weston"
            },
            {
                "ref_id": "b27",
                "title": "nice try, kiddo\": Investigating ad hominems in dialogue responses",
                "journal": "Association for Computational Linguistics",
                "year": "2021",
                "authors": "Emily Sheng; Kai-Wei Chang; Prem Natarajan; Nanyun Peng"
            },
            {
                "ref_id": "b28",
                "title": "On the safety of conversational models: Taxonomy, dataset, and benchmark",
                "journal": "",
                "year": "2022",
                "authors": "Hao Sun; Guangxuan Xu; Jiawen Deng; Jiale Cheng; Chujie Zheng; Hao Zhou; Nanyun Peng; Xiaoyan Zhu; Minlie Huang"
            },
            {
                "ref_id": "b29",
                "title": "SaFeR-Dialogues: Taking feedback gracefully after conversational safety failures",
                "journal": "",
                "year": "2022",
                "authors": "Megan Ung; Jing Xu; Y-Lan Boureau"
            },
            {
                "ref_id": "b30",
                "title": "Annual Meeting of the Association for Computational Linguistics",
                "journal": "Association for Computational Linguistics",
                "year": "",
                "authors": ""
            },
            {
                "ref_id": "b31",
                "title": "Attention is all you need",
                "journal": "",
                "year": "2017-12-04",
                "authors": "Ashish Vaswani; Noam Shazeer; Niki Parmar; Jakob Uszkoreit; Llion Jones; Aidan N Gomez; Lukasz Kaiser; Illia Polosukhin"
            },
            {
                "ref_id": "b32",
                "title": "A large-scale chinese short-text conversation dataset",
                "journal": "Springer",
                "year": "2020",
                "authors": "Yida Wang; Pei Ke; Yinhe Zheng; Kaili Huang; Yong Jiang; Xiaoyan Zhu; Minlie Huang"
            },
            {
                "ref_id": "b33",
                "title": "Why we should have seen that coming: comments on microsoft's tay \"experiment,\" and wider implications",
                "journal": "The ORBIT Journal",
                "year": "2017",
                "authors": "J Marty;  Wolf; W Keith; Frances S Miller;  Grodzinsky"
            },
            {
                "ref_id": "b34",
                "title": "Transformers: State-of-the-art natural language processing",
                "journal": "Association for Computational Linguistics",
                "year": "2020",
                "authors": "Thomas Wolf; Lysandre Debut; Victor Sanh; Julien Chaumond; Clement Delangue; Anthony Moi; Pierric Cistac; Tim Rault; Remi Louf; Morgan Funtowicz; Joe Davison; Sam Shleifer; Clara Patrick Von Platen; Yacine Ma; Julien Jernite; Canwen Plu; Teven Le Xu; Sylvain Scao; Mariama Gugger; Quentin Drame; Alexander Lhoest;  Rush"
            },
            {
                "ref_id": "b35",
                "title": "Recipes for safety in open-domain chatbots",
                "journal": "",
                "year": "2020",
                "authors": "Jing Xu; Da Ju; Margaret Li; Y-Lan Boureau; Jason Weston; Emily Dinan"
            },
            {
                "ref_id": "b36",
                "title": "Design challenges and misconceptions in neural sequence labeling",
                "journal": "",
                "year": "2018",
                "authors": "Jie Yang; Shuailong Liang; Yue Zhang"
            },
            {
                "ref_id": "b37",
                "title": "DIALOGPT : Large-scale generative pre-training for conversational response generation",
                "journal": "",
                "year": "2020",
                "authors": "Yizhe Zhang; Siqi Sun; Michel Galley; Yen-Chun Chen; Chris Brockett; Xiang Gao; Jianfeng Gao; Jingjing Liu; Bill Dolan"
            },
            {
                "ref_id": "b38",
                "title": "Eva: An opendomain chinese dialogue system with large-scale generative pre-training",
                "journal": "",
                "year": "2021",
                "authors": "Hao Zhou; Pei Ke; Zheng Zhang; Yuxian Gu; Yinhe Zheng; Chujie Zheng; Yida Wang; Chen Henry Wu; Hao Sun; Xiaocong Yang"
            }
        ],
        "figures": [
            {
                "figure_label": "",
                "figure_type": "table",
                "figure_id": "tab_0",
                "figure_caption": "al.,   ",
                "figure_data": "\u6bd4\u5c14\u5077\u5403\u4e86\u6211\u7684\u751c\u751c\u5708\uff0c\u6211 \u8981\u9524\u4ed6\u3002(Bill ate my donut and I'm going to punch him.)\u4f60\u60f3\u804a\u70b9\u522b\u7684\u5417\uff0c\u732b\u54aa\u5982\u4f55\uff1f (Hey do you want to talk about something else? How about wetalk about cats?)\u4f60\u662f\u50bb\u5b50\u5427\uff0c\u6ca1\u5fc5\u8981\u4e3a\u4e86\u8fd9\u70b9\u5c0f\u4e8b\u5927\u52a8\u5e72\u6208\u3002(You are a fool. There is noContextual Rewritingneed to go to war over such a trivial matter.)\u4f60\u592a\u51b2\u52a8\u4e86\uff0c\u6ca1\u5fc5\u8981\u4e3a\u4e86\u8fd9 \u70b9\u5c0f\u4e8b\u5927\u52a8\u5e72\u6208\u3002(You are too impulsive.There is no need to goto war over such atrivial matter.)"
            },
            {
                "figure_label": "2",
                "figure_type": "table",
                "figure_id": "tab_2",
                "figure_caption": "",
                "figure_data": ""
            },
            {
                "figure_label": "3",
                "figure_type": "table",
                "figure_id": "tab_3",
                "figure_caption": "Summary statistics of SAFECONV. \"Avg.\", \"Resp.\", \"Prom.\", and \"Alter.\" are the abbreviations of \"Average\", \"Response\", \"Prompt\", and \"Safe Alternative Response\".",
                "figure_data": "#Safe Resp.#Unsafe Resp.#Safe Prom.#Unsafe Prom.Avg. #SpanAvg. Alter. LengthAvg. Prom. LengthAvg. Resp. LengthL-dialogues 52,4807,52055,8474,1531.110.837.522.6P-dialogues 80,67319,32792,4247,5761.115.132.532.6SAFECONV 133,153 26,847 148,271 11,7291.114.134.428.9"
            },
            {
                "figure_label": "4",
                "figure_type": "table",
                "figure_id": "tab_4",
                "figure_caption": "Single annotator performance to the final annotation for the detecting tasks.",
                "figure_data": "P-dialogues L-dialogues SAFECONVBinary0.840.710.81Span0.790.610.76"
            },
            {
                "figure_label": "5",
                "figure_type": "table",
                "figure_id": "tab_5",
                "figure_caption": "with a linear binary classification head on the top and the input of the encoder is formatted as \"[CLS] prompt [SEP] response [SEP]\", where the [CLS] and [SEP] are special tokens. The tagger shares the same structure and input format as the checker except that the size of the label space is 3-BIO tagging scheme is adopted, where the first word of the unsafe span is tagged as B and the other words Performance of checkers. C Random is the checker assigning random safety labels to utterances.",
                "figure_data": "P-dialoguesL-dialoguesSAFECONVPre. Rec. F1Pre. Rec. F1Pre. Rec. F1C Random C COLD C Baidu18.9 49.1 27.3 13.9 49.6 21.7 17.4 50.1 25.8 30.9 35.2 32.9 29.3 32.0 30.6 30.5 34.3 32.3 61.1 43.2 50.6 56.2 22.7 32.4 60.2 37.7 46.4C SAFECONV 79.6 76.2 77.8 72.3 59.3 65.1 77.9 71.7 74.6Human86.9 82.5 84.2 79.6 65.1 71.6 85.3 78.2 81.3"
            },
            {
                "figure_label": "6",
                "figure_type": "table",
                "figure_id": "tab_6",
                "figure_caption": "Results of explainable checking.",
                "figure_data": ""
            },
            {
                "figure_label": "7",
                "figure_type": "table",
                "figure_id": "tab_8",
                "figure_caption": "Evaluation of the rewriters. The penultimate column presents the number of unsafe responses after rewriting. The last column shows the rewriting results of the rewriter further finetuned with feedback from the checker. The relative reduction percentage (\u21d3) is calculated with regard to \"#Unsafe Resp. (Before Rewriting)\".",
                "figure_data": "2022) EVA-large (Gu et al., 2022)300M 970M445.0 502.8156.3 (64.9% \u21d3) 160.5 (68.1% \u21d3)75.5 (83.0% \u21d3) 71.5 (85.8% \u21d3)Flue. Cohe. Info. UnsafeBefore Rewriting After Rewriting3.27 3.252.27 2.292.85 2.7592.6% 36.5%After Finetuning3.382.392.799.7%"
            },
            {
                "figure_label": "8",
                "figure_type": "table",
                "figure_id": "tab_9",
                "figure_caption": "Human evaluation of the responses.",
                "figure_data": ""
            },
            {
                "figure_label": "9",
                "figure_type": "table",
                "figure_id": "tab_10",
                "figure_caption": "Ablation on the role of context.",
                "figure_data": ""
            }
        ],
        "formulas": [
            {
                "formula_id": "formula_0",
                "formula_text": "\u2713 - \u2713 - - SAFECONV (Ours) Social Media \u2713 \u2713 \u2713 \u2713 \u2713",
                "formula_coordinates": [
                    2.0,
                    77.55,
                    147.72,
                    422.7,
                    26.26
                ]
            },
            {
                "formula_id": "formula_1",
                "formula_text": "J (\u03b8) = E (x,y \u2032 )\u223cR \u03b8 [r(x, y \u2032 ) \u2212 \u03b2log R \u03b8 (y \u2032 |x) R \u03b8 \u2032 (y \u2032 |x) ],",
                "formula_coordinates": [
                    8.0,
                    76.65,
                    399.13,
                    206.68,
                    35.51
                ]
            }
        ],
        "doi": "10.18653/v1/2021.emnlp-main.397"
    },
    "Program Chairs' Report on Peer Review at ACL 2023": {
        "authors": "Anna Rogers; Marzena Karpinska ~jordan Boyd-Graber; Naoaki Okazaki",
        "pub_date": "",
        "abstract": "We present a summary of the efforts to improve conference peer review that were implemented at ACL'23. This includes work with the goal of improving review quality, clearer workflow and decision support for the area chairs, as well as our efforts to improve paper-reviewer matching for various kinds of nonmainstream NLP work, and improve the overall incentives for all participants of the peer review process. We present analysis of the factors affecting peer review, identify the most problematic issues that the authors complained about, and provide suggestions for the future chairs. We hope that publishing such reports would (a) improve transparency in decision-making, (b) help the people new to the field to understand how the *ACL conferences work, (c) provide useful data for the future chairs and workshop organizers, and also academic work on peer review, and (d) provide useful context for the final program, as a source of information for meta-research on the structure and trajectory of the field of NLP.",
        "sections": [
            {
                "heading": "Introduction",
                "text": [
                    "With the continued growth of our field and the rising number of conference submissions, peer review draws more and more attention from the community-as an application area (Hua et al., 2019;Anjum et al., 2019;Stelmakh et al., 2019, inter alia), in meta-research (Rogers and Augenstein, 2020;Church, 2020, inter alia), in initiatives to organize and release peer review data (Kang et al., 2018;Jecmen et al., 2022;Dycke et al., 2022, inter alia), and, of course, in the regular heated social media discussions during submission deadlines, review release dates, and acceptance notifications. It is unlikely that peer review will ever be perfect -it remains 'the least bad system' we have for ensuring the quality of scientific publications (Smith, 2010). Still, with each iteration we should learn a little more about what works better for organizing peer review at such scale, and in a community so diverse in expertise and experience.",
                    "As a step in that direction, ACL'23 makes its peer review report public and an official part of the conference proceedings, complementing the introduction and other administrative materials. The goal is to increase the visibility of the results of the conference process, as well as any incidental findings from conference organizations and the lessons learned the hard way that may be useful to the future chairs and workshop organizers. Such publications also provide extra incentives for the future program chairs to invest more effort in the analysis of their process, and they provide a useful background to the composition of the final program that may be useful for meta-science research (since they essentially document the selection process for that program). Last but not least, such publications will improve the transparency of the *ACL conference process, which may be useful to the researchers who are new to the field.",
                    "We present the core statistics per track ( \u00a72), analysis of resubmissions ( \u00a73) and core demographics ( \u00a74), our efforts for improving peer review quality ( \u00a75), improving decision support for the chairs ( \u00a76), out analysis of various factors contributing to review scores and final decisions ( \u00a77), ethics review and best paper selection ( \u00a78), and our efforts towards improving incentives for the authors, reviewers and chairs ( \u00a79). We conclude with overall recommendations for future conference organizers ( \u00a710). The materials we developed will be available at a dedicated repository 1 .",
                    "The results presented here are based on the analysis of internal data of ACL'23, as well as exit surveys that we sent to the chairs, authors and reviewers. We received responses from 25 senior area chairs (SACs) (35.7% response rate), 134 area chairs (ACs) (30.5% response rate), 510 reviewers (11.4% response rate), and 556 authors (4.07% response rate of all authors 2 )."
                ],
                "publication_ref": [
                    "b16",
                    "b1",
                    "b32",
                    "b19",
                    "b33"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Tracks and Acceptance Statistics",
                "text": [
                    "ACL'23 had 26 tracks, most of which have also been offered at other recent NLP conferences. At the suggestion of EMNLP 2022 chairs, we kept their separation of \"Large Language Models\" 3 track from \"Machine Learning for NLP\" track. At community requests we added the following tracks: \"Linguistic Diversity\" and \"Multilingualism and Cross-lingual NLP\". Each track had at least two Senior Area Chairs (SACs), who then recruited area chairs (ACs) for that track. The full list of senior chairs per track is available at the conference website. 4  Internally, in the START system there were also two special tracks: \"Ethics review\" track (which handled the reviews of papers that were flagged for ethical issues), and \"Conflicts of interest\" (COI) track, which handled the papers with which the SACs of the relevant tracks had a COI.",
                    "ACL'23 implemented a hybrid process, in which it was possible to submit papers either directly to the START system (to be reviewed through ACL'23 internal peer review process to be described in this report), or commit it through ACL ROlling Review (ARR) with reviews already performed at ARR. Most submissions to ACL'23 were direct submissions (4559), and 305 more came through ACL Rolling Review (ARR). Table 1 shows acceptance for each type of submission and in each track. ACL Rolling Review (ARR). Table 1 shows that in most tracks, ARR submissions had a much higher acceptance rate, sometimes twice higher. This is to be expected because ARR submissions self-select for high scores and positive reviews before committing to ACL. Since in the hybrid process ARR submissions and direct submissions directly compete for acceptance, a question arises to what extent this is a fair competition. We asked that question to our SACs. 58.3% believe that this process is fair enough, 12.5% -that it is unfair to the direct submissions, and 29.6%-that it is unfair to the ARR submissions. Of 17 SACs who believed that this situation is unfair in some way, 23.5% suggested that they should have separate acceptance rate, 41.2%-that they should have a separate process and acceptance criteria, and 47.1%-that there should be some other solution (many comments pointing to the confusion, the apples-to-oranges comparisons of reviews performed with different evaluation, the less-than-ideal import of openreview data into START (browsing attachments takes more time). Many expressed a preference for a non-hybrid process.",
                    "As program chairs, our biggest challenge with ARR was that by design it provides reviews and metareviews, but the acceptance decisions are then made by our SACs-who generally do not provide extra feedback to either direct submissions or ARR submissions (nor can they be expected to: some tracks had over 300 papers per 3 SACs). For direct submissions, nobody expects SAC-level feedback. But to ARR authors, who likely self-selected for high scores and positive reviews, to be rejected without explanation is more frustrating, and we received a lot of angry emails demanding extra feedback (even though neither we nor ARR promised that). It seems that by design, a process where there are acceptance quotas, and decisions are fully decoupled from feedback, will necessarily leave the majority of authors rejected without explanation-and hence disappointed and unsure what they could do to improve their work (and we agree that this would indeed be frustrating to the authors).",
                    "The above factors could transform into a bigger problem in the future. We only had 305 ARR submissions, but if a majority of our submissions came with high scores and positive reviews-this just would not be a useful signal anymore. The acceptance odds of direct submissions would decrease (as compared to a process where everyone starts at the same stage of peer review). The SAC-ing would become harder (since selecting among high-quality papers is less easy than among papers of varying quality), and the authors would be disappointed because many would be rejected with high scores and no idea what they could do differently."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_0",
                    "tab_0"
                ]
            },
            {
                "heading": "Resubmissions",
                "text": [
                    "Among the 4559 direct submissions to ACL'23, 754 indicated that they were resubmissions (see fig. 1a). The biggest \"donors\" were EACL 5 (296), EMNLP (258), ICLR (103), AAAI (52), and ACL Rolling Review 6 (39). Although the selectivity of top-tier conferences means that the majority of papers are * All information is self-reported, not independently verified, and does not correspond to any specific definition of affiliation, gender, or country (e.g., some authors from Edinburgh may elect to list their country as \"Scotland\" rather than \"UK\".) rejected, the bulk of the ACL'23 submissions are new, which means that at this point the burden of re-reviewing is relatively low. It is possible that this is due to the wider acceptance of Findings as a publication channel, as more *ACL conferences continue to offer this option.",
                    "Moreover, ACL'23 authors had the option to submit previous reviews as an attachment, but only 243 submissions used this option, which suggests that most resubmitters preferred to have a completely new set of reviewers. ARR allows that option within ARR, but the ARR submissions themselves did not have a high rate of revise-and-resubmit (only 8/305), as shown in fig. 1b.",
                    "Intuitively, one could expect that resubmissions have a higher chance of acceptance, since these are the papers that have received feedback and had a chance to revise. But fig. 1c suggests otherwise. See more analysis in \u00a77.3."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_0",
                    "fig_0",
                    "fig_0"
                ],
                "table_ref": []
            },
            {
                "heading": "Authors and Reviewers at ACL'23",
                "text": [
                    "We received a record 4864 submissions (4559 direct, 305 from ARR) from the total of 13,658 authors, reviewed by 4490 reviewers. This section reviews our recruitment process and the three demographic variables (country, affiliation type, and gender) to which we had access in the global START profiles of all participants of ACL peer review process.",
                    "Reviewer recruitment. We initially sent review invitations to the reviewer list which we had received from the organizers of previous conferences. We also required the authors of all submissions to nominate at least one experienced reviewer, whom we also sent invitations.",
                    "As we elicited reviewer data, we found that for a quarter of our reviewers 7 there is no reliable Semantic Scholar publication history data that can be used for paper-reviewer matching. For conferences that fully rely on automated paper-reviewer matching based on publication history, this factor obviously sets a bound on their possible performance. Often the author pages exist because Semantic Scholar automatically created them, but the authors did not claim them and did not clean them up, which may result in the addition of publications by namesake authors (e.g. the automatically created profile for \"Anna Rogers\" originally had contributions from at least three researchers with that name.) This is particularly worrying because at this point many venues have used this information for paper-reviewer matching, and urged the NLP community to maintain their Semantic Scholar profiles. We also specifically reminded about this, but still a quarter of our sign-up pool stated that their publication history is not accurate. In addition to this problem, matching based on publication history has the issue with establishing expertise of different authors on on multi-author publications. Hence, we developed an alternative matching approach described in \u00a75.2. Affiliation types. Figure 2a presents the overall distribution of the affiliations of our authors and reviewers (as stated in START profiles). The biggest group of authors, reviewers, and chairs are academic faculty. The second biggest group (by absolute numbers) in all three categories is industry, which is relevant to the recent concerns about the influence of industry on academic NLP research (Abdalla et al., 2023). Furthermore, students form at least 26% of reviewer pool (Ph.D. 22.7%, M.Sc. 3.3%). This was also our experience as area chairs at other recent conferences, and it highlights the need to continue the reviewer training efforts.",
                    "Gender distribution. Based on the information in softconf profile, about 20% of ACL peer review participants in all roles did not answer the question about their gender (Figure 2b). For a part of this population this is likely a deliberate choice, but judging by how many other fields in the START profiles were not accurately filled in or updated, in many cases this likely signals simply the lack of desire to fill in forms, especially for the new authors who had to register in START last minute in order to make a submission. Considering only those profiles that responded to this question, we see a heavy imbalance for \"male\", in agreement with the reports on under-representation of women in Computer Science (Jaccheri et al., 2020;Pantic and Clarke-Midura, 2019), where a lot of NLP research is currently happening. This underscores the need to continue the Diversity and Inclusion efforts.",
                    "Top contributing countries. The analysis of the countries of all authors and reviewers suggests that the balance between reviewing and submitting papers is considerably off for many locations, and particularly China. 8 We believe that this is at least partly due to the fact that our recruitment efforts started with the pool of the previous conferences. That pool needs to be deliberately expanded by more active and targeted reviewer recruitment efforts among Chinese institutions. Church (2020) estimates that at 20% acceptance rate the authors of published papers \"owe\" the community at least 15 reviews per each publication (3 for their own paper, and 4x3 for the papers that didn't get in). While some dis-balance between the author and reviewer list is to be expected (e.g., since many junior authors are not yet qualified to review, and many senior authors perform other organization roles)-we clearly need to decrease it in order to decrease the reviewer load. Our default quota was six papers 9 per reviewer, in line with most recent conferences. This is a significant workload, and it can hardly be expected to improve the quality of reviews. Moreover, the more reviewers are in the pool, the smaller the trade-off between optimizing for best matches or smaller workload per reviewer."
                ],
                "publication_ref": [
                    "b17",
                    "b27",
                    "b9"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Efforts towards improving review quality",
                "text": [
                    "This section describes the following steps that ACL'23 proposed and implemented within its peer review process to improve review quality: review tutorials ( \u00a75.1), Area-Contribution-Language paper-reviewer matching ( \u00a75.2), flagging of review issues by the authors ( \u00a75.3). The efforts to improve the overall incentives are decribed in \u00a79.2 and \u00a79.3."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Reviewer training",
                "text": [
                    "As part of reviewer training, we prepared the following public materials (as a revision of an earlier tutorial 10 , developed by Anna Rogers and Isabelle Augenstein for ARR):",
                    "\u2022 ACL'23 Peer Review Process: the general tutorial about review process for novice reviewers, that covers the basic structure of *ACL peer review process, author response, and discussion period, as well as tips for planning the time, reporting conflicts of interest and assessing whether to ask for reassignment. These materials were optional for experienced reviewers, and could be used across different *ACL venues as is. \u2022 ACL'23 Peer Review Policies: the tutorial explaining our review form and responsible NLP checklist ( \u00a79.1), as well as our peer review policy: specific, professional reviews with scores supported by the text. Our list of reviewer heuristics such as \"reject if not SOTA\" currently contains 14 heuristics (continued from the original eight heuristics pioneered at EMNLP 2020 (Cohn et al., 2020)). We asked even experienced reviewers to read this tutorial. The future chairs could reuse parts of this tutorial, with necessary updates to the review form description and review policies.",
                    "Feedback. The exit survey indicates that the reviewers found the materials clear (43% respondents rated them as at 4 out of 4 and 40.5% -as 3 out of 4 on 4-point scale). One avenue of improvement suggested in many free comments was adding examples of good reviews.",
                    "We also asked the reviewers about their preferences for alternative formats, and the self-paced text-based tutorial was the majority choice (62.5% vs 13% preferring video tutorials and 9.6% preferring interactive tutorial with quizzes). But 13.4% respondents said that they would probably never be able to spend time on reviewer training, no matter what format it is offered in. This suggests that reviewer training, while valuable, will not help in all cases, and could perhaps be interpreted as an upper bound on the effect of any reviewer training."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "ACL paper-reviewer matching: Area-Contribution-Language",
                "text": [
                    "One of the peer review issues that authors (and chairs) often complain about is \"meh\" reviews: the reviewer does not really find any significant problems with methodology or execution of the paper, but the overall recommendation is middling. This could be a symptom of paper-reviewer mismatch: the reviewer just is not sufficiently interested in the overall topic or approach, and hence no matter how good the paper is, it would not elicit much enthusiasm. In a recent survey (Thorn Jakobsen and Rogers, 2022) of authors, reviewers and ACs about their prior experience at NLP venues, many reviewers stated that \"the area match was right, but... the subject of the paper was not interesting to me (e.g. I would prefer another NLP task, model, or data)\" (54%), or the paper was not asking a research question that would be interesting for me\" (45%). At the same time, over 27% of the author respondents in that survey reported that they had experience of reviews where the reviewer was not interested in the subject of the paper.",
                    "Most recent *ACL conferences and ARR work with some version of an automated paper-reviewer matching system that computes affinity scores between the abstract and title of the submission and the candidate reviewer, based on their publication history. Interestingly, the same survey by Thorn Jakobsen and Rogers (2022) found that both authors, reviewers, and ACs generally considered these scores to be the least important factor for paper-reviewer matching. Besides the limitations of the current systems, one factor here is probably the noise in the reviewer publication history data (only 75% of our reviewers indicated that their Semantic Scholar profiles were accurate enough to use for review assignments, see \u00a74). Then there is also the inherent difficulty with establishing level of expertise on a particular topic in multi-author papers.",
                    "A traditional alternative to affinity scores, that also addresses the issue with reviewer interest, is bidding: the reviewers explicitly say which papers they would be interested in. But this process is rather laborious: for a big track, a reviewer would need to indicate their interest for hundreds of papers. It also opens up the possibility of collusion rings (Littman, 2021). In our experience, many reviewers do not even respond to bidding calls on time, which once again leads to some part of assignments being essentially random. Thus, we experimented with a new workflow that we dub ACL (Area-Contribution-Language) paperreviewer-matching. It is a keywords-based matching process that explicitly targets three dimensions of submissions: track sub-areas (topical match), contribution types (match by focus/methodology), and target language (for submissions not focusing on English). To the extent possible, the paper-reviewer matching aimed to provide matches across all these dimensions. This approach further enabled us to provide the ACs with explanations for the specific matches (see \u00a76.3).",
                    "Track sub-areas. Each track at ACL 2023 had an associated set of keywords describing its potential sub-areas. The goal was to describe the biggest expected sub-areas, and hopefully provide the authors with a better idea of the kind of work that the track was inviting. The full list of our keywords is publicly available in our blog post. 11 Our keywords were provided by the SACs of all tracks independently, but the future chairs may wish to take a more top-down approach to editing this list, and to ask their SACs to check that the list still describes the sub-areas for which the most submissions are expected, and the individual keywords are sufficiently clear for the authors.",
                    "Language(s). Due to the \"default\" status of English (Bender, 2019), submissions targeting other languages may be perceived as \"niche\" by reviewers. Additionally, the lack of expertise in a language may make it harder for reviewers to spot potential issues. Hence, for papers on languages other than English, we endeavoured to also maximize reviewer matches along this dimension.",
                    "Contribution types. The contribution types cross-cut tracks, and we hope they would help to decrease the amount of cases where the reviewer just fundamentally does not recognize a certain type of work (Bawden, 2019) and hence scores it down, or has unreasonable expectations (e.g. experimental results in a position paper). For example, the category of compute/data-efficiency creates a de-facto equivalent of efficiency track spread across all tracks.",
                    "Our contribution types are based on COLING 2018 classification (Bender and Derczynski, 2018), which we extended as follows: (1) NLP engineering experiment (most papers proposing methods to improve state-of-the-art), (2) approaches for low-compute settings, efficiency, (3) approaches for low-resource settings, (4) data resources, (5) data analysis (6) model analysis & interpretability, (7) reproduction studies, (8) position papers, (9) surveys, (10) theory, (11) publicly available software and pre-trained models.",
                    "Implementation. To collect the information for this kind of matching, we asked the authors at submission time to specify their preferred track (up to two), the best-matching keywords in that track (multiple selection possible, or \"other\" option with free text entry), the best matching contribution type(s) and target language(s). Correspondingly, at reviewer recruitment stage we asked the reviewers to fill in a form specifying their preferences for the tracks, keywords, contribution types, and the language(s) the work on which they could review. The matching itself was based on Integer Linear Programming, aiming to maximize matches across the three keyword types (with more types of matching being more valuable than e.g. more matches only by area). As a fallback, we also retrieved Semantic Scholar profile data for the reviewers and computed the similarity between submission abstracts to the abstracts in the publication history of candidate reviewers, but this factor was given the lowest priority in the assignment strategy.",
                    "The Area-Contribution-Language matches, as well as the most similar paper of the reviewer, then also became the basis for the rationales for the match (see \u00a76.3). The SACs were given the opportunity to selectively check and adjust the matches as described in \u00a76.2 (although few of them did), and the ACs and SACs were able to see the rationales for the matches when considering the reviews.",
                    "From the analysis of the final 12606 reviews in START, 1052 (8.3%) did not have the match information (due to manual reviewer reassignment by the chairs, most likely emergency reviewers). Of the remaining 93.7% reviews made by our criteria, only 1.13% reviews with automated assignment were assigned based on the similarity scores from publication history, after exhausting the possible keywords-based matches in the reviewer pool. 82.9% reviews had at least one match by the type of area, 84.97% -by contribution type. Importantly for DEI efforts and development of NLP for languages other than English, we had 1167 reviews for submissions that specified at least one target language other than English -and we were able to provide a reviewer matching by (at least one) language in 63.58% such reviews.",
                    "Feedback. When asked to rate on 4-point scale how well the paper-reviewer matching worked for them, 85.5% ACL'23 reviewers rated it positively (35.7% at 4/4, 49.8% at 3/4). When asked for the kinds of mismatch, if any, 28.4% pointed at the topic, 13.7% at the methods, 10.4% at the type of contribution, 4.5% at languages, and 5.7% at other kinds of mismatch.",
                    "We conclude that Area-Contribution-Language assignments are overall a promising direction that can contribute to DEI efforts in the field and diversity of its contributions (see also \u00a77). The matches could be further refined by (a) revising the area keywords 12 , and (b) more targeted reviewer recruitment to include speakers of various languages. One of our SACs suggested providing a glossary together with the list of keywords. We also recommend investing effort into a dedicated interface for checking reviewer assignments that would enable ACs to help with reviewer assignment checks while seeing the up-to-date reviewer availability information, and highlighting the possible problems with the current assignments (such as imperfect matches, rare types of contributions or languages that may need extra attention, insufficient pool for a area or a contribution that turns out to be more popular this year)."
                ],
                "publication_ref": [
                    "b39",
                    "b22",
                    "b3",
                    "b4"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Review issue flagging",
                "text": [
                    "Even with all the above efforts, we anticipated that there would still be problematic and mismatched reviews. Given that the only people with the incentive to read the reviewer guidelines and enforce them are the authors, we developed a way for them to flag reviews for specific issues, which the ACs could be given specific instructions about, and be able to address more systematically.",
                    "Unfortunately, the START system does not have an editor for the author response form or meta-review form. Hence we had to provide the authors and ACs with the list of possible issues, and ask them to specify their type and rationale in plain text form, as shown in Figure 3. As could be expected, even with a template there were many format errors. We recommend that the future conferences use a form with a multi-selector, per each reviewer.",
                    "The authors actively used this feature at ACL'23, flagging 12.9% of all reviews. This is reassuring: judging by the intensity of online discussions of peer review at each review release day, most reviews are bad). The frequency of various reported issues is shown in Table 3. The biggest reported problem is the heuristics such as \"not novel\", \"not surprising\", \"too simple\", and \"not SOTA\". Particularly concerning are the rude/unprofessional reviews: even though there are only 1.69%, they have the most potential to impact the mental health of the authors, and we should strive for that number to be 0.",
                    "The author-reported issues should be interpreted as a lower bound on the number of review issues, because of 100 papers were reviewed but withdrew before the final decisions. It is possible that they did because they (a) agreed with the criticism and wished to revise the paper, or (b) that they disagreed but did not see a chance to persuade the reviewers. Assuming the latter, and that all their reviews were problematic, this would raise the upper bound of problematic reviews to 15.3%. But it is unlikely that all Feedback. When asked to rate the utility of this system at ACL'23 on 4-point scale, with 4 being the highest score, 42.1% of the authors in our exit survey rated it at 4/4, and 40.3% -at 3/4. We interpret it as overwhelming support, and recommend that this feature is maintained in the future conferences. However, the qualitative analysis of the authors' comments suggests that in some cases the ACs did not respond to the flagged issues properly, which entails the need for further training and monitoring by the SACs.",
                    "Our follow-up analysis suggests that ACs reported addressing the author-flagged issues in at least 30.59% submissions (judging by their using a similar template to Figure 3 in the \"confidential notes to chairs\" in the meta-review. This should be interpreted as a lower bound: since the interface was very clunky, it is possible that some ACs did consider the flagged issues, but did not report their actions. But, clearly, many issues were not properly addressed, and there is much room for improvement and further training of ACs. Still, given that this is the first implementation of this system, this is a promising approach and it should improve in the future."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_2",
                    "fig_2"
                ],
                "table_ref": [
                    "tab_3"
                ]
            },
            {
                "heading": "Reviewer discussion",
                "text": [
                    "Similarly to most of the recent *ACL conferences, we implemented the author response period: a week during which the authors have the opportunity to read the reviews and send their response. The goal of this process is improving the quality of the reviews, and we supplemented that goal with the above new option for the authors to flag specific types of review issues ( \u00a75.3). The authors could (but didn't have to) provide a response and flag review issues; this was done for 88.3% of reviewed submissions. In 57.3% review forms the reviewers indicated that they read the response (it is possible that more did read the response but did not fill in the form).",
                    "Those comments were seen by the ACs, not the reviewers. The ACs had the option to initiate reviewer discussions for the cases where they saw significant disagreements, quality issues, or misunderstandings. Each paper had an associated \"forum\" on START, where the reviewers could communicate in an  anonymized fashion (as R1, R2, R3). The ACs were provided with instructions and suggested starter message template.",
                    "In total, out of 4559 direct submissions to ACL, 4069 had received reviews, and for 2901 out of those the ACs initiated discussions. In total, ACL review process generated 8553 messages (3879 by the ACs). However, only 2107 discussions (72.63%) had at least one response from at least one reviewer. Somewhat consistently, the discussions were overall initiated by 77.4% of all ACs. We conclude that both AC and reviewer involvement have room for improvement.",
                    "We reviewed one case of a strong paper that ended up being rejected. The AC could have been persuaded by a \"champion\" reviewer, and there was one such expert in the set who was surprised by the final outcome-but they did not engage in the forum discussion. We followed up with the reviewer, and they explained that since their review was already positive, they did not feel that they needed to be \"on the case\" anymore. We cannot establish how common this misconception is, but we would urge all reviewers to always read all reviews and author response, and when certain of the merit of a paper-to try to make sure that the AC is convinced."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Improving decision support for the chairs",
                "text": [
                    "In addition to the efforts for improving the quality of peer review ( \u00a75), we implemented the following steps for facilitating the decision support by ACs and SACs: revised SAC and AC guidelines ( \u00a76.1), guidance for assignment checking ( \u00a76.2), match rationales ( \u00a76.3), Soundness/Excitement scores ( \u00a76.4)."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Updated SAC and AC guidelines",
                "text": [
                    "We updated the SAC/AC guidelines that we received from the program chairs of ACL'21 in following ways. We reformatted it to Markdown to utilize the ecosystem of GitHub (e.g., version control, asynchronous collaboration among PCs, automated deployment). The guides were built by Sphinx 13 with MyST extension 14 , which enables to use Markdown and variables (making it easy to keep the consistency of dates and external URLs between SAC and AC guides and for the future chairs to adapt to their timeline). We also adjusted the existing instructions and created new instructions to incorporate everything we developed, from the new reviewer guidelines to guidelines for making recommendations. We shared the guides before the review process so that SACs and ACs can be prepared for the tasks and workloads.",
                    "Feedback. 83.3% SACS and 90.3% ACs rated the clarity of instructions at 3/4 or 4/4. Some of the free-text comments indicated a preference for shorter guidelines, but since the process is complex, and the guidelines need to serve both new and experienced chairs, there are limits to how much they can be shortened."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Support for checking assignments",
                "text": [
                    "As mentioned above, the usual workflow in large conferences is that the assignments are made automatically based on affinity scores between candidate reviewers' publication history and submissions. Usually, the automated assignments are then shown to the ACs and SACs to check manually, but this is very difficult in practice: SACs cannot process such a large volume on their own, so they need to rely on ACs. But ACs, at least on START, do not have access to the list of possible reviewers together with their current number of assignments and all their COIs, which means that even if they spot an error-it is difficult for them to identify and recommend an available alternative. Providing the up-to-date quota and COI information on all reviewers in track to the ACs is not possible in the current START platform. There are also no detailed guidelines for this step, which means that even if ACs had the reviewer information, everybody would be suggesting alternatives based on different criteria.",
                    "In our experience as SACs in previous conferences, although the automated assignments are not perfect, very few ACs actually report the problems or propose alternatives. To see whether this was widespread, we asked our SACs in the exit about whether, in their experience, the ACs asked to check the automated assignments usually recommend many changes. Only 9 of our respondents previously served as SACs in this set-up, but most of them (6/9) concurred with our experience, reporting that ACs adjust very few assignments. When asked why the ACs do not recommend more changes, 33.3% SACs stated that there are no adjustments because the ACs don't really check, 29.9%-that it happens because the automated assignments are already good enough, 29.2%-because of the difficulty with sharing up-to-date reviewer availability information with them, and 20.8%-that there are no better candidates even if the ACs check. 37.5% indicated that there are also other issues contributing to the ACs not recommending more changes.",
                    "We interpret these results as pointing to the fundamental issue of systematically sharing up-to-date reviewer availability information together with their preferences, experience, and profile information, in a way that would make it easy for the ACs to perform such checks and recommend alternatives.",
                    "Given that the above factors make it unrealistic to adjust assignments with help of ACs, and that the volume of assignments to check was too large for SACs, we experimented with an alternative approach: since we had the \"explanations\" for the matches and also the quantitative information about different types of contributions, languages and area keywords, this information would make it possible for SACs to identify the types of submissions most in need of extra checks, and to focus on those. This way the workload would remain manageable, and the SACs would be able to do that while having full access to the latest reviewer availability data. To assist in this process, we developed Jupyter notebooks with quantitative analysis per track (identifying which keywords, types of contributions and languages were rare and could need extra attention)-as well as reviewer lookup functionality by preferred keywords, languages or types of contribution (or any combination thereof). This solution was better than nothing, but admittedly clunky and could be much improved.",
                    "Feedback. 66.7% of SACs stated that they believed selective checking to be overall sufficient given sufficiently strict reviewer pool criteria (although in our specific case not all reviewers in our pool were up to all SAC's standards).",
                    "Caveat: we encountered difficulty with uploading the final automated assignments due to dynamic computation of conflicts-of-interest in START. Because of that, several hundred automated assignments had to be redone manually at the last minute. For the conferences based on START, we strongly recommend that this computation is frozen after the main part of reviewers and chairs are added to the tracks."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Paper-reviewer match rationales",
                "text": [
                    "Given the information for the paper-reviewer matches that we had collected ( \u00a75.2), we were able to provide the ACs with a list of rationales for each match (except for those reviewers who were added manually by the chairs, and for whom we did not have this information.) A sample \"explanation\" for a match is shown in Figure 4a. The idea was to provide the AC with not only the general information about the reviewer, but also what are their interests that match this submission. Importantly, we highlighted the cases where the author-stated type of contribution or language was not among the reviewer's stated l (a) Example of paper-reviewer match rationales. The most similar paper titles directly link to the papers (based on Semantic Scholar). For contributions and languages, the rationales either show the match, or alert to the lack of the match, so that the AC could take that into account.",
                    "(b) Chair feedback on which features of the match explanation they found the most useful. interests, which would ideally provide the AC with grounds to check potential bias against certain kinds of work.",
                    "Feedback. This feature received overwhelming support from the chairs: 87.5% SACs and 73.9% ACs rated its utility at 3 or 4 out of 4 (Figure 4b). Among the suggestions for the future improvement, the SACs suggested indicating whether the reviewer was an emergency reviewer, and how late the review was, as well as some elements of reviewer history (e.g. whether they were late for other conferences). The numerical similarity scores were less useful than the titles of the most similar papers. While predominantly the ACs were very positive about easily accessible links to reviwer profiles (Figure 4b), some ACs raised fair concerns about the effect of this feature on reviewer deanonymization: the reviewers are already visible to ACs since they need this information for chasing late reviews, but providing links to reviewer profiles increases the saliency of the reviewers' identities, and hence may by itself increase bias against, for instance, student reviewers."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_3",
                    "fig_3",
                    "fig_3"
                ],
                "table_ref": []
            },
            {
                "heading": "Soundness/Excitement scores",
                "text": [
                    "While most of the experimental aspects of the ACL 2023 process was focused on matching reviewers to papers more effectively, a larger change visible to authors and reviewers was the introduction of two new scores on the review form to replace the Overall Recommendation that was previously the centerpiece of *CL review forms.",
                    "We asked reviewers for two scores: Soundness and Excitement. 15 Our goal was that any sound paper would be accepted to some ACL affiliated venue (i.e., Findings), but that the \"main conference\" distinction (limited by space) would be focused on the most exciting papers. Our hope was that Soundness, as a more specific rubric with more objective criteria, would be less noisy than a single Overall Recommendation score, which would help reduce the randomness of decisions. The AC guidelines had explicit instructions for how these scores should map to their recommended status.",
                    "One more factor motivating our proposal was that the Soundness/Excitement distinction could help with the author-reviewer communication during the author response. When a reviewer points out issues with Soundness, the authors generally have a fair chance to clear any misunderstandings or issues with review quality, and the chairs are interested in this kind of discussion. The Excitement, however, is subjective, and the authors do not have a fair chance to convince reviewers that their general views or research agenda are wrong. The Soundness/Excitement distinction helps to focus the response on the Soundness issues, and hence have a more productive discussion.",
                    "Feedback. Judging by the exit surveys, this change was overall well received: over 80% of the chairs, reviewers and authors either expressed support or did not object to this change. 38.1% authors, 35.1% reviewers and 29.9% ACs indicated that while the idea was good, it could be better executed. Among the named issues was the clarity of communication about what these scores meant, the difference in granularity (our scale for Excitement had 9 points, and Soundness only 5), and the wording could be adjusted to remove the semblance to Overall recommendation score. We made these recommendations to the program chairs of EMNLP 2023, who decided to keep this system.",
                    "From the communication with the authors who expressed dislike for this system, our impression is that one of the factors here is the mistaken impression that the final decisions are overall based on scores, and the papers with similar scores should be guaranteed the same outcome-whereas in reality the chairs know that scores can be noisy and miscalibrated, and hence the final decisions are made on case-by-case basis, with the full view of the reviews and meta-review, and also taking into account the acceptance quotas and their editorial priorities. 16 The Soundness/Excitement scores were rather intended to make it harder for the chairs to just sort by the scores."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "What Factors Contribute to ACL Peer Review Outcome?",
                "text": [
                    "Here we present the results of statistical analysis of ACL'23 data, with the goal of explicating what factors contributed to the final decisions and to the quality of individual reviews. We hope that this process both improves the transparency around chair decision-making, and highlights the potential biases and points of improvement for future conferences.",
                    "For the new authors, we should explain the general process for the acceptance decisions at ACL'23. First, the reviewers contribute their reviews. At the author response the authors see the reviews and have an opportunity to respond: a process mostly intended to clarify any misunderstandings (we disallowed submitting new results). Then the ACs initiate the reviewer discussion, with the goal to clarify misunderstandings and improve the quality of the reviews. Based on the final reviews and their own expertise, they write the meta-reviews and make recommendations for acceptance (Main track or Findings) or rejection. They are not concerned with the acceptance quotas. Their recommendations and meta-reviews (as well as reviews and author response if necessary) are then considered by the SACs, who have the constraint of the target acceptance quota (which we set at about 22% for the main track and 35% for Findings). Their decisions are based on three main factors: meta-reviews, quotas, and editorial priorities (with case-by-case consideration as needed). If they run out of their quota, they may additionally rank more papers by priority that may be accepted to main/track Findings if there is space (e.g., because some tracks did not use their quota fully). The final step is that the program chairs confirm the SAC decisions, and try to fit in as many papers of the ranked \"maybes\" as possible. In our case, that resulted in accepting more Findings papers than we originally planned based on prior conferences."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Review Scores: Overall Distribution",
                "text": [
                    "We start by exploring the overall distribution of the new Excitement and Soundness scores (described in \u00a76.4) and how they mapped to the three possible decision outcomes (Rejection, acceptance to the Main track, or Findings). Both Excitement and Soundness are ordinal variables, and we use the mean as a rough estimate of the central tendency. Figure 5a shows that for both scores the means are higher for main track than for Findings, and for Findings they are higher than for rejections. For Excitement this is fully in line with our instructions to the chairs. For the main track, this suggests that higher (above 3) Soundness scores 16 This is a general problem, and we imagine this would have also happened in the case of an Overall recommendation score. The drawback of the Soundness plus Excitement system is that less noisy decision cutoffs make outliers more salient  To obtain the significance values for each IV (Table 5), we use the ANOVA() function in R on the fitted model (Type III Anova). As expected, all four IVs are significant (p<0.05) but at different levels. The SAC Recommendation ( 2 (8) = 1438.12, p< 0.001) 21 and AC Recommendation ( 2 (8) = 209.71, p< 0.001) significantly predict the Outcome with the SAC Recommendation appearing to be a better predictor (as expected, since AC recommendation are made without regards to the acceptance quotas). The mean Soundness score ( 2 (2) = 10.88, p= 0.0043) and mean Excitement score ( 2 (2) = 9.67, p = 0.0080) are also significant at p<.05.",
                    "To establish the exact contributions of mean Soundness and Excitement scores to acceptance decisions for the Main track and Findings, we can look at Table 4 again. Note that since it is a multinomial regression model, the coefficients indicate an increase in log odds rather than directly interpretable odds (for which the coefficients need to be exponentiated). The \"Findings Coeff\" and \"Main Coeff\" correspond to the log-odds of being accepted into the Findings and Main track as opposed to being rejected.",
                    "Soundness. In the case of the mean Soundness score the coefficient is positive for both Findings (0.71) and the Main track (0.76). This means that for one unit increase in the mean Soundness score the log-odds of being accepted as opposed to being rejected increase by 0.71 for Findings and 0.76 for the Main track. By taking the exponential of these values, we see that for one unit increase in the mean Soundness score the odds to be accepted increase 2.03 times for Findings and 2.14 times for the Main track.",
                    "Excitement. Similarly, both coefficients are positive for the mean Excitement score for both Findings (0.61) and the Main track (0.03). This means that for one unit increase in the mean Excitement score the log-odds of being accepted vs rejected increase by 0.61 for Findings and 0.03 for the Main track. By taking the exponential of these values we see that for one unit increase in the mean Excitement score the odds of being accepted increase 1.84 times for Findings and 1.03 times for the Main track. While the values are still positive, this increase is much lower 22 than for the mean Soundness scores, especially for the Main track. The overall distribution of these scores per acceptance status is shown in Figure 5b.",
                    "AC Recommendations. Since AC Recommendation is an ordinal variable, it is coded using polynomial contrast, so the L indicates linear effect, Q a quadratic effect, C a cubic effect, and so on. Here we look mostly at the linear effect since it has a direct (linear) effect on the outcome. We see that both coefficients are positive, indicating that with an increase of one unit, the log-odds of being accepted vs being rejected increase by 2.66 units for Findings and 4.50 units for the Main track. By taking the exponential of these values we see that one unit increase in AC Recommendation corresponds to a 14.30-fold increase in the odds of being accepted into Findings (vs being rejected) and 90.02-fold increase in the odds of being accepted into the Main track (vs being rejected). SAC Recommendations. SAC Recommendation is also an ordinal variable, hence we see the same types of coefficients. However, the magnitude of the SAC's decision appears to be much greater with a greater effect on the final outcome. With one unit increase in SAC Recommendation the log-odds of being accepted vs being rejected increase by 5.84 units for Findings, and 28.26 units for the Main track. pseudo-R 2 =0.794 (Cox and Snell, 1989) and Nagelkerke pseudo-R 2 =0.913 (Nagelkerke, 1991). 21 2 denotes likelihood ratio chi-square statistic. 22 This latter finding seems counter-intuitive, given that our AC guidelines stressed that Findings is a venue for all sound work, while \"sound& exciting\" would be the basis for recommendations to the main track-but even among the papers accepted to the main track 39% have at least one \"negative\" Excitement score (Figure 7b). At the same time, even among the Findings papers, only 49% have predominantly negative Excitement ratings, so there is a preference for at least some Excitement. This could be related to the confusion about the meaning of the scores in the initial iteration (see subsection 6.4). Converting these values to their exponentials, we see that one unit increase in SAC Recommendation corresponds to a 343.78-fold increase in the odds of being accepted into the Findings (vs being rejected) and a massive increase of 1.88 \u21e5 10 12 for the odds of acceptance into the Main track (vs being rejected).",
                    "The model hence shows that the SAC recommendation is a much stronger predictor than the AC recommendation, which helps to explain why it is possible for a paper to be rejected even with a positive meta-review. AC recommendations are made without regards to the acceptance quotas, and SACs necessarily have to override them in many cases."
                ],
                "publication_ref": [
                    "b12",
                    "b25"
                ],
                "figure_ref": [
                    "fig_4",
                    "fig_4",
                    "fig_7"
                ],
                "table_ref": [
                    "tab_5"
                ]
            },
            {
                "heading": "The Impact of Other Submission Properties",
                "text": [
                    "There are many properties of submissions that could systematically make a difference to their final outcome. In this section we investigate the possible effect of the type of contribution, the target languages, whether the reviews were problematic (as reported by the authors), and whether the paper was available as a preprint. To establish the importance of these factors, we fit another multinom() model, similarly to what we did in Table 4, and obtain the significance levels for each variable using Type III Anova. While the ordinal model would potentially better preserve the natural order of the final outcome (rejection being the worst and acceptance to the main track being the best outcome), the fitted model violated the assumptions of the ordinal model.",
                    "Since this model does not include strong predictors such as reviewer scores and chair recommendations, the fit of this model is relatively poor 23 compared to the model in Table 4, which has a McFadden's pseudo-R 2 of approximately 0.80 (indicating a substantial improvement over the null model). In contrast, this model has a McFadden's pseudo-R 2 of approximately 0.01, suggesting that it barely improves upon the null model. Nevertheless, this model can still be used to establish the individual contributions of the submission-level properties, which likely interact in complex ways in the scores and recommendations. Statistically significant factors are also not necessarily strong predictors by themselves.",
                    "The results of this experiment are shown in Table 6. According to this analysis, the following factors have a statistically significant impact on submission outcome: low-quality reviews, preprinting, short/long paper type, and three types of contributions (software, reproduction, and theory).",
                    "To also assess the relative importance of our predictors in forecasting the final outcome, we employed a Random Forest algorithm (Liaw and Wiener, 2002). The results are shown in Figure 6. The most crucial predictor was Review Issues (i.e., author complaints about reviews 25 ) with a Mean Decrease Gini value of 46.09. This suggests that this predictor played the most significant role in reducing the Gini impurity, and therefore, in improving the precision of our model. The second factor with the biggest Mean Decrease Gini is Preprinting (22.84). This analysis does not state the absolute importance of any factor (e.g., that Its 3-class accuracy is 52%, vs 90% for the model shown in Table 4. This is the accuracy of the model on the withheld test set when the model is fitted with 70% of the data. The accuracy of the model on all data is about 1% higher. Signif. codes: 'p < 0.001' '***', 'p < 0.01' '**', 'p < 0.05' '*', 'p < 0.1' '.', 'p > 0.1' ' '. The number of author complaints likely reflects (at least) two factors: the reviews that were truly problematic, and simply negative reviews since the authors are more likely to complain about those. In the latter case the leading cause for rejection is the negative review. Mean Decrease Gini Significance Not Significant Significant"
                ],
                "publication_ref": [
                    "b21"
                ],
                "figure_ref": [],
                "table_ref": [
                    "tab_4",
                    "tab_4",
                    "tab_6",
                    "tab_4"
                ]
            },
            {
                "heading": "Variable Importance",
                "text": [
                    "Figure 6: The importance of predictors in predicting the Outcome, ranked by mean decrease in Gini impurity.",
                    "Predictor significance is indicated by color, with dark purple for not significant and dark green for significant predictors as per levels of significance indicated in Table 6. Preprinting increases the chances of acceptance by X%), and we are not claiming that these effects are independently large-but they do appear to be statistically significant. We will discuss these factors further: short/long papers in \u00a77.3.1, contribution types in \u00a77.3.2, review issues in \u00a77.5.5, preprints in \u00a77.5.7."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_6"
                ]
            },
            {
                "heading": "Short/long papers",
                "text": [
                    "Short papers have had significantly lower acceptance rates at most recent *ACL conferences. To mitigate that, we highlighted the problem in the reviewer instructions, had a separate Soundness formulation for short papers, and asked the SACs to consider the short and long papers separately, with their own target acceptance quotas. Despite all that, the significant effect of paper type (Table 6) is obvious: the long papers had 23.50% acceptance rate to main track vs 16.53% for short, and for Findings, the rate was respectively 41.89% vs 35.58%. The core reason seems to be that the source reviewer scores are systematically lower, despite all calls to not expect 120% thoroughness of short papers."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_6"
                ]
            },
            {
                "heading": "Types of contribution",
                "text": [
                    "We were pleasantly surprised to find a significant positive effect for the contributions of theory, reproductions, and pre-trained models and software (Table 6). The two latter types are in line with the findings by (Magnusson et al., 2023) who report that reproducibility efforts are rewarded. This effect is also visible from simply considering the differences in acceptance rates for papers with and without these contribution types, shown in Table 7. In fact, the \"average\" acceptance rate of 46.92% is the closest to the most \"mainstream\" type of contribution (NLP engineering experiment, 61.5% submissions) -and all other contribution types except surveys have the acceptance rate at least slightly higher than that.  The lack of a visible disadvantage in acceptance rates for non-mainstream types of contributions is a very positive finding. Consider the case of efficiency-oriented papers: they did not have a dedicated track, but their acceptance rate was not lower (and even a bit higher) than for the average in the pool (where the majority of engineering-oriented submissions focuses on performance). In effect, every track was an efficiency track, allowing both access to the area expertise and reviewers with interest in this type of contribution. We cannot establish to what extent this is due to Area-Contribution-Language matching or an overall increased interest in the need for efficient NLP solutions. But as long as such contributions are in the minority, we would recommend ensuring the matches by this criterion.",
                    "A complication for our analysis arises for two contribution types that also had large associated tracks: resources and interpretability. In this case, it is possible that the lack of difference in acceptance rate is due to the extra effort of ensuring the reviewers with matching interests through the track mechanism.",
                    "To check for that, we compare the acceptance rates for these types of contributions inside and outside of the dedicated tracks (Table 8). We find that in all cases the match between tracks and contribution types yields a 3-6% increase above the average acceptance rate of 46.92%. An interesting case is interpretability and model analysis, which has a 4.45% higher acceptance rate outside of its dedicated track (probably indicating an appreciation for papers that perform analysis in addition to some other type of contribution)."
                ],
                "publication_ref": [
                    "b23"
                ],
                "figure_ref": [],
                "table_ref": [
                    "tab_6",
                    "tab_7",
                    "tab_8"
                ]
            },
            {
                "heading": "How Much do ACL Reviewers Agree?",
                "text": [
                    "The issues with consistency of peer review were recently highlighted in the ML community by the two NeurIPS experiments (Price, 2014;Cortes and Lawrence, 2021;Beygelzimer et al., 2021). By treating peer review as an annotation problem (Rogers and Augenstein, 2020), we can apply the existing methodology for analyzing inter-annotator agreement (IAA). We consider three reviewers (annotators) per paper, discarding the rare cases of 4 reviews (from emergency assignments). We compute Krippendoff's \u21b5 (Krippendorff, 2011) on the Soundness and Excitement scores (Table 9). We treat these scores as ordinal data. We also experiment with mapping both scores to binary \"positive/negative\" categories (3-5 > \"sound\" for Soundness and 3.5-5 > \"exciting\" for Excitement, since the borderline scores were 2 for Soundness was 2 and 3 for Excitement)."
                ],
                "publication_ref": [
                    "b30",
                    "b11",
                    "b5",
                    "b20"
                ],
                "figure_ref": [],
                "table_ref": [
                    "tab_9"
                ]
            },
            {
                "heading": "26",
                "text": [
                    "\"Ordinal\" refers to the \u21b5 coefficient computed using raw scores treated as ordinal variables. The percentage agreement for Soundness was computed using the raw scores (5-point scale). In order to match the scale length the percentage agreement for Excitement was computed on the rounded scores (i.e., 3.5 was treated as 4.0, etc.). \"Categorical\" denotes scores converted into either positive or negative decisions based on the given threshold (3.0 for Soundness and 3.5 for Excitement).   Consistent with the general perception of inconsistency in peer review, \u21b5 shows a level of IAA that seems far too low (the rule of thumb is that \"substantial\" agreement is in the range of 0.6-0.8 (Artstein and Poesio, 2008;Paun et al., 2022)). However, the raw agreement for the accepted papers (in the categorical view, i.e. as sound/unsound, exciting/unexciting) is almost twice higher for Soundness than for Excitement. We interpret this as an indication that although the scores are still noisy, it helps to ask more specific questions with more objective criteria. The much lower raw agreement on the Excitement is also in line with our point that this is overall a less relevant direction for the author response and reviewer discussion. Arguably we do not even want a high agreement on Excitement: everybody interested in the same thing could indicate that the field is ossifying and stagnating.",
                    "As a sanity check, we also analyzed IAA for the raw reviewer scores of EMNLP 2022 and EACL 2023. Both of these conferences used a single \"overall recommendation\" score, formulated differently for short and long papers. In EMNLP 2022, for 3092 observations for 3 reviewers (discarding R4 data), with scores treated as ordinal data, we got \u21b5 0.316 for the short papers, 0.31 for long, and 0.318 for the whole distribution -which is almost exactly the same as our \u21b5 for both our scores (in the ordinal case). In EACL 2023, for 1121 subjects for 3 reviewers we got \u21b5 0.317 for the short papers, 0.34 for long, and 0.348 for the whole distribution.",
                    "A related question is \"what kind of disagreements do we actually have?\" Figure 7a shows the distribution of individual score values for all papers in a given acceptance status, which suggests that even papers accepted to the main conference had some very negative reviews. Figure 7b breaks down the scores into \"positive\" (Soundness >= 3, Excitement >= 3.5) and \"negative\", and considers the combinations of three reviews as \"all positive\" (+ + +), \"all negative\" (---), \"2 positive, 1 negative\" (+ + -) and \"2 negative, 1 positive\" (--+). We can see that despite disagreements on the exact scores, the papers accepted to the main track have a high ratio of \"positive\" review combinations for Soundness (88%, only 11% papers with one negative Soundness score). But for Excitement our SACs accepted to the main track 39% papers with one negative Excitement score, and 37% papers with a single \"champion\" reviewer. For Findings, they even accepted 37% papers which only 1 reviewer was excited about. Figure 7c shows the total number of submissions with various combinations of positive and negative Soundness and Excitement scores, and Figure 7d shows the same categories, but with the number of accepted papers with that score combination.",
                    "Our data indicates that despite noisy scores and high disagreement, the mechanism of ACs and SACs does \"rescue\" many papers with one negative review, and at least the raw agreement does improve for the more specific Soundness score. Judging by the community feedback ( \u00a75), in this first implementation there was a lot of confusion about what the scores meant, and we expect that in future iterations the agreement could improve further."
                ],
                "publication_ref": [
                    "b2",
                    "b28"
                ],
                "figure_ref": [
                    "fig_7",
                    "fig_7",
                    "fig_7",
                    "fig_7"
                ],
                "table_ref": []
            },
            {
                "heading": "Analysing Reviews and Review Scores",
                "text": [
                    "In this section, we take a step back from the final acceptance decisions and look only at the individual reviews and their scores, rather than the final outcome of the submission."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Do the Area-Contribution-Language matches impact reviewer scores?",
                "text": [
                    "To answer this question, Figure 8 shows the distributions of the individual reviewer scores for Soundness, Excitement, reviewer Confidence, and Reproducibility for all cases where the reviews were or weren't matched by the area, contribution type, or language. The biggest visible impact is in reviewer Confidence, where the contributions are not matched by area: the ratio of reviews with high scores (4+) is decreased by about 14%. A worrying observation is that there is a 5% increase in high Confidence scores for the submissions where the reviewer is not matched by language and could be expected to feel less rather than more confident. We also observe an 11% increase in Soundness ratings 3+ from reviewers matched by language vs those mismatched, and 7% in Reproducibility."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_8"
                ],
                "table_ref": []
            },
            {
                "heading": "Do the Area-Contribution-Language matches impact the reviewer activity?",
                "text": [
                    "To establish whether Area-Contribution-Language matching had any effect on reviewer activity, we counted the reviewers as \"active\" if they had at least one forum message or more than one review edit. The distributions of active/inactive reviewers that are/aren't well-matched to submissions by Area-Contribution-Language criteria are shown in Figure 9. At a glance, there are a lot more matched & active reviewers, but since generally a lot more reviewers were matched than mismatched (see Table 2), we would generally expect that to be the case even by chance.",
                    "To establish whether there are any statistically significant effects, we first fit a generalized linear model (GLM) using the glm() function in R. 27 The dependent variable was binary (the activity of the reviewer). The predictors were a contribution match (binary variable), a studied language match (threelayer categorical variable), 28 and an area match (binary variable), all of which were treated as categorical variables (at least one matching keyword of the correct type). The link function was logit, corresponding to a binomial distribution of the response variable (logistic regression).",
                    "To validate the assumptions of the GLM, we examined the variance inflation factors (VIFs) using the vif() function in R to assess multicollinearity among predictors. The VIFs were all close to 1, suggesting that multicollinearity was not a concern. We also visually inspected residual plots to assess the model fit and did not find any obvious deviations from homoscedasticity or linearity. For the language we consider three categories: (1) non-English language match, (2) non-English language mismatch, and (3) match only by English; under the assumption that all reviewers will be familiar with English. Signif. codes: 'p < 0.001' '***', 'p < 0.01' '**', 'p < 0.05' '*', 'p < 0.1' '.', 'p > 0.1' ' '.  The results of the GLM (see Table 10) suggest that contribution match is a significant predictor of the reviewer's activity ( = 0.16, SE = 0.08, z = 1.97, p = 0.048). Since the estimates relate to log-odds we consider the exponential of the reported value (1.178) which suggests that the odds of the reviewer being active when the contribution type is well-matched are 1.178 times higher than when the contribution does not match the reviewer's expertise. The remaining variables, that is language match and area match, are not significant predictors in this model (p > 0.05). 30  Finally, we considered the language match as a binary variable, excluding English language papers. We conduct a Chi-square test ( 2) to examine the association between the language match (excluding English) and reviewer activity Table 11. The test reveals no significant association between the language match and reviewer activity ( 2 (1)=0.73432, p = 0.3915). The chi-square test was performed using Pearson's Chi-squared test with Yates' continuity correction with the chisq.test() function in R.",
                    "We conclude that of the Area-Contribution-Language matching rubrics, only the contribution type contributes to improvement in reviewer activity. Although the effect is modest (1.178 times increase in likelihood of reviewer activity), given that reviewer activity post-submission is very important, and its level needs to be improved ( \u00a75.4), we would urge the future chairs to consider this criterion in the assignments. It also provides a quick and interpretable way to consider the variety of the types of work 30 McFadden's pseudo-R 2 of the model is 0.0008231973, which is very low. This suggests that our model does not explain much of the variability in the data. However, it is important to note that in the context of generalized linear models, the interpretation of pseudo-R 2 is not as straightforward as it is in ordinary least squares regression. The pseudo-R 2 is not necessarily a measure of the proportion of variance explained by the model in the data. Instead, it is a measure of the likelihood improvement per observation relative to the null model. Despite the low pseudo-R 2 , our model could still provide valuable insights into the relationships between the independent variables (match type) and the reviewer's activity.  continuity correction for the effect of language match (excluding English) on the reviewer's activity that are being submitted, and to provide extra attention to the assignments for the non-mainstream kinds of work."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_9"
                ],
                "table_ref": [
                    "tab_12",
                    "tab_13"
                ]
            },
            {
                "heading": "Do reviewer confidence scores reflect their experience?",
                "text": [
                    "START profiles contain self-reported reviewer experience labels (\"never\", \"first time\", \"3 or fewer events\", \"4 events and more\". We explored the relationship between this data and reviewer Confidence scores but found no strong effect. We do observe a small (about 4%) increase in the volume of 4+ Confidence scores for the most experienced reviewers, and it's significant according to the ordinal logistic regression model 31 . But the effect is quite small, and judging by this data we don't recommend relying on confidence as a proxy for reviewer experience. Moreover, we observe no relation between this reviewer experience data and the number of review issues reported by the authors. This is a rather depressing finding from the perspective of reviewer training, and we hope that it is rather due to START profiles not being updated by the reviewers."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Do the reviewer scores correlate with length of the reviews?",
                "text": [
                    "The ACL review form had the following text input fields: summary, reasons to accept, reasons to reject, questions to the authors, missing references, suggestions&typos, and confidential notes to the chairs. We roughly estimated the length of these inputs by splitting on the whitespace, and computed Spearmans correlation (Spearman, 1987) between these variables and reviewer scores for Soundness, Excitement, 31 We fit model in R using the polr() function from the MASS package (Venables and Ripley, 2002) with reviewer's confidence as an ordinal DV and experience as a three-layer categorical IV. We compare this model to an intercept-only model using the Anova() function. While the difference between these models is significant, McFadden's pseudo-R 2 is extremely low (4.247533 \u21e5 10 4 ). Confidence, and Reproducibility. The results are shown in Figure 10.",
                    "As could be expected, we observe a significant negative correlation (-0.35-0.36) between the length of Reasons to Reject and both Soundness and Excitement scores, and the opposite trend for the Reasons to Accept (0.28-0.37). Interestingly, the length of Reasons to Accept also correlates positively with the Reproducibility score, indicating that the community appreciates this factor (0.15). Confidence has a similar correlation with the length of missing references. Finally, there is a high correlation between the length of \"questions to the authors\" and \"suggestions\", indicating that the reviewers who engage with the submission deeply use both of these fields.",
                    "The highest positive correlation is between our Soundness and Excitement scores 32 (0.68), which is in line with the intuition that unsound work would probably not be found exciting either."
                ],
                "publication_ref": [
                    "b34"
                ],
                "figure_ref": [
                    "fig_10"
                ],
                "table_ref": []
            },
            {
                "heading": "What factors are associated with review issues?",
                "text": [
                    "As discussed in \u00a75.3, we introduced a mechanism for the authors to flag specific types of issues with reviews, and we received such flags for 12.9% of the reviews. Figure 11 shows the ratio of reviews with complaints (True) and without (False). For both Soundness and Excitement there is a clear trend towards more complaints with lower scores, but there are also complaints for high scores (e.g., 43.1% of reviews which the authors complained about had Soundness 4). This makes more sense if we consider the figure Figure 11d, which shows that 95% complaints are made about reviews where at least one of the scores is 3 or less. This suggests that reported review issues are associated with negative reviews, even for Excitement (although we tried to make it clear that this score is subjective and does not need arguing).",
                    "To explore other possible factors that could make the reviews more likely to be reported we fit a GLM model using the glm() function in R. The dependent variable is the presence or absence of reported issues (binary variable), and the predictors are the Excitement score (ordinal), Soundness score (ordinal), Confidence score (ordinal), Reproducibility score (ordinal), length of Reasons to Reject (interval), length of Reasons to Accept (interval), the Contribution Match (binary), Area Match (binary), Language Match (three-layer factor), Reviewer's Experience (three-layer factor), and Reviewer's Activity (binary). The link 32 This finding is important for the model reported in Table 4: the acceptance decisions are indeed based on both factors, and they are meant to capture different information, but the high correlation between these two variables suggests that the estimates obtained in Figure 11: Reviewer scores vs the amount of issues reported with reviews. In each plot, True/False refers to the reviews which were or were not flagged for review issues by the authors.",
                    "function was logit, corresponding to a binomial distribution of the response variable (logistic regression). 33  The coefficients of the fitted model are presented in Table 12.",
                    "We further employ the type III Anova using the ANOVA() function in R in order to obtain significance levels for each factor which are presented in Table 13. While McFadden's pseudo-R 2 of the fitted model is only 0.067, several variables of this model are significant predictors of the review issues.",
                    "The most significant factors are Soundness, Excitement, and the length of Reasons to Accept. All of these variables have a negative relationship with the reviewer issues, perhaps unsurprisingly, with higher scores the review is less likely to be reported. Similarly, longer text in the Reason to Accept field leads to less chance of the review being reported. Counter-intuitively, the positive coefficient associated with the reviewer being active suggests that when the reviewer is active (i.e. with at least one review revision or a forum message) the log-odds of the review issue increase by about 0.32, all else being equal. That is, the more active reviewers (putting in more effort) are actually receiving more complaints.",
                    "Other significant factors are Language Match and the reviewer's confidence; both associated with negative coefficients. This suggests that when the reviewer is familiar with the non-English language investigated in the study, the log-odds of a review issue decrease by approximately 0.26 (i.e., the review is 1.29 times less likely to be flagged for issues). Similarly, the negative coefficient of the reviewer's",
                    "We inspect the residuals plots and compute the variance inflation factor to assure that the assumptions of GLM are not violated. Signif. codes: 'p < 0.001' '***', 'p < 0.01' '**', 'p < 0.05' '*', 'p < 0.1' '.', 'p > 0.1' ' '. Signif. codes: 'p < 0.001' '***', 'p < 0.01' '**', 'p < 0.05' '*', 'p < 0.1' '.', 'p > 0.1' ' '. Confidence suggests that with an increased Confidence score the likelihood of the review to be reported decreases though by a small margin."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_0",
                    "fig_0",
                    "fig_0"
                ],
                "table_ref": [
                    "tab_4",
                    "tab_16",
                    "tab_17"
                ]
            },
            {
                "heading": "Do we have bad actors?",
                "text": [
                    "To explore the possibility that many reported review issues are due to individual unprofessional reviewers, let us consider the fact that 1,620 reviews with reported issues were authored by 1311 reviewers, i.e. about a third of our total pool. But most of these reviewers had more than three reviews, and 1060 of them were only reported once. Of the remaining reviewers, 201 were flagged twice, and 50 reviewers had more than 3 complaints. We conclude that while there are indeed some unprofessional reviewers, and conferences need to systematically share such information and develop a system to address this problem, there are few such cases (6.2% if we consider all reviewers with more than 2 flags, and 1.2% with more than 3 flags). An interesting takeaway from Figure 11c is that the reviews that are problematic according to the authors, do not have lower confidence scores, so these are unlikely to be the new reviewers or the reviewers unfamiliar with the area. According to folk wisdom, the bad reviewer is usually Reviewer2 (sometimes Reviewer3). We clear their good name: at ACL'23, the most issues were reported for Reviewer1, as shown in Figure 12."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_0",
                    "fig_11"
                ],
                "table_ref": []
            },
            {
                "heading": "Can the reviewers tell who the authors are?",
                "text": [
                    "In 567/12606 (4.5%) reviews the reviewers indicated that they have seen the paper, either by seeing a preprint (533) or by other means (34). Additionally, 513 (4.1%) reviewers indicated that they had a good guess of the author identity based on the paper content. 11460 (90.9%) ACL'23 reviews were reported as fully anonymous.",
                    "The community \"recall\" on the preprinted submissions is as follows: we had 628 submissions (13.8% lxiv of all direct submissions) for which the authors had disclosed preprints. The reviewers identified 306 (49%) of them. Hence, we estimate that although in our sample the number of \"guesstimates\" based on content is about the same as the number of preprinted papers, if the current 1-month embargo period was to be lifted, and the volume of preprints were to increase -the latter would also increase, while the volume of \"guessed\" authorship cases should stay the same (at about 4-5%). Interestingly, our reviewers reported another 102 submissions, for which preprints were not disclosed by the authors. We recommend that the future chairs investigate at earlier stages whether such cases are due to false memories of similar preprints, or preprint policy violations.",
                    "7.5.8 Do preprints affect the peer review process?",
                    "Having established that reviewers do have a high recall for preprints ( \u00a77.5.7), we investigate the possible connection between the reviewer's awareness of the author identity on their Soundness, Excitement, and Confidence scores by fitting Cumulative Link Mixed Effect models with the Laplace approximation using the clmm() function for the ordinal package in R (Christensen, 2022). The response variable is the given score and the predictor is the Anonymity answer (fixed effects). We also employ random intercepts for the paper (SubmissionID) and reviewer (ReviewerID) to account for this variability (random effects). 36",
                    "Soundness. The results of the model fitted for the effect of Anonymity on the Soundness scores are present in Table 14. The Anonymity has five possible values: (1) the reviewer does not know the authors (reference level), (2) the reviewer may know the authors, (3) the reviewer knows the authors via means other than online posting, (4) the reviewer knows the authors via online posting prior to the anonymity period, and (5) the reviewer knows the authors via online posting post to the anonymity period. Estimates for different answers to the anonymity question presented in Table 14 suggest that the reviewers were 1.59 times more likely to assign higher Soundness scores when they thought they may know the authors, and 1.75 times more likely to assign higher Soundness scores when they have seen the preprint online. 37",
                    "Excitement. The results of the model fitted for the effect of Anonymity on Excitement are present in Table 15. Estimates for different answers to the anonymity question presented in Table 15 suggest that the reviewers were 1.49 times more likely to assign higher Excitement scores when they thought they may know the authors, and 1.73 times more likely to assign higher Excitement scores when they have seen the preprint online.",
                    "Confidence. The results of the model fitted for the effect of Anonymity on reviewer's Confidence are present in Table 16. Estimates for different answers to the anonymity question presented in the table suggest that the reviewers were 1.29 times more likely to report higher Confidence scores when they 36 We validate the model fit by examining residual plots and convergence criteria. The residual plots showed no clear patterns or extreme outliers, and the satisfactory convergence indicates a reasonable model fit. We further observe that, perhaps unsurprisingly, both SubmissionID and ReviewerID account for a substantial portion of the variability in each of the response variables. 37 We take the exponential of each coefficient. thought they may know the authors, and 1.80 times more likely to assign higher Confidence scores when they saw the preprinted online.",
                    "We thus conclude that submissions with preprints, as well as submissions where the reviewers believe they could guess the authors, systematically receive higher ratings for both Soundness and Excitement, as well as higher Confidence scores. We further note that preprinted papers are disproportionately recommended for consideration for best paper awards (and without such a recommendation from at least one reviewer the submissions are not considered by the best paper committee). In total, only 1.6% papers received any reviewer nominations at all, and for 30% of those papers, the authors had disclosed preprints.",
                    "While our data shows the pattern of higher scores, acceptance chances, and best paper nominations for preprinted submissions, the causal mechanism remains a question: is it because such papers are inherently higher quality, or because of the benefits of community feedback they may receive, or because of the well-documented reviewer biases towards towards famous names and institutions (Peters and Ceci, 1982;Tomkins et al., 2017, among many others)? Since these possibilities necessitate different actions on the part of the chairs who strive for higher-quality program, the causal question needs to be answered for informed policy decisions. Since we observe an increase in likelihood of higher scores both for real preprints and for submissions where the reviewers only thought that they might know the authors (although the effect is smaller in that case), we can conclude that the social factor is definitely present-but more research is needed to establish its exact contribution. But the fact that we only had 13.8% preprints suggests that the current 1-month embargo policy is effective in at least reducing the volume of the problem.",
                    "8 Special Review Processes"
                ],
                "publication_ref": [
                    "b29",
                    "b40"
                ],
                "figure_ref": [],
                "table_ref": [
                    "tab_18",
                    "tab_18",
                    "tab_19",
                    "tab_19",
                    "tab_20"
                ]
            },
            {
                "heading": "Ethics review",
                "text": [
                    "Following the practice started at NAACL 2021, we formed an Ethics Committee (EC) dedicated to ethical issues. The review process was based on work in prior conferences and further developed by ARR and recommendations from the ACL ethics committee. Initially there were 235 technical reviews flagging 218 papers for ethics concerns, and the SACs narrowed down the list based on the guidelines developed by the ethics chairs) to 75 papers, 6 of which did not make it to the ethics review (either withdrawn or cleared). 20 papers under ethics review were labeled accept as-is, 43 received conditional accepts, and 6 were recommend for rejection. Of those recommended for rejection, 1 was accepted nonetheless, 1 was rejected as a result, and 4 were rejected on technical grounds. Of the conditionally accepted ones, 26 were rejected on technical grounds, and 1 was withdrawn. 16 passed the technical review and were conditionally accepted, meaning the ethics issues had to be addressed in the camera-ready version, to be verified by the SAC (based on EC guidance) prior to final acceptance.",
                    "The authors of all conditionally accepted papers submitted the camera-ready version and a short response that explained how they had made the changes requested. The SAC double-checked these revised submissions and responses, and confirmed that the ethical concerns had been addressed. As a result, all conditionally accepted papers were accepted to the main conference or Findings."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Best paper selection",
                "text": [
                    "ACL'23 implemented the new ACL award policy, aiming to expand the pool of work that is recognized as outstanding. In total, only 73 papers, i.e. 1.6% of all direct 38 submissions were nominated by the reviewers or ACs for consideration for awards. These papers were assessed by the Best Paper Award Committee, and with their help we selected 4 best papers, 4 special awards (social impact, resource, reproduction, theme paper), and 39 outstanding papers. The best and outstanding papers will be announced in a dedicated plenary session for Best Paper Awards on July 10 2023.",
                    "We encountered several issues with implementing the best paper policy as described in the wiki. With 73 nominated papers, to keep it down to 10 papers per judge and have 2 reviews per paper, we had to recruit 15 judges. At this scale, the workload is compatible with organizing a separate track: recruitment, paper assignments, chasing late reviews -only this time recruiting exclusively very senior and busy people, and it is very important to upheld diversity considerations (which we weren't able to do full justice). For the future, we recommend that a separate chair role is created for managing this process, similar in scope to the role of the ethics review chairs.",
                    "Furthermore, since the diversity considerations in the committee selection entail incompatible time zones, we found it impractical to require the judges to meet and jointly decide on the cases where they disagree (as recommended in the policy). Hence, after the judges cast their votes 39 , the PCs made the final decisions on the basis of their recommendations (in particular, in the cases where one judge recommended outstanding paper and the other recommended not considering it further), we upheld the objections to flaws in the papers, shallowness of analysis, and ethical issues, which left us with 39 papers (a little short of the 1-1.5% total submissions policy target for the outstanding papers).",
                    "Finally, the ACL award policy described an Area Chair Award: the award that the SACs of a given track can give to one paper in their track, fully on their own authority. This was part of the guidelines for the final SAC recommendations, but we did not require them to be made at the same time. We sent out reminders after that, but received such nominations from only 12/26 tracks (with the theme track nomination transformed into the special Theme paper award). We recommend batching these recommendations with the final SAC recommendations as a single task. 9 Improving the Incentives 9.1 Improving Reporting Incentives for the Authors: Responsible NLP checklist Following the effort started by NAACL 2022 and continuted at ACL Rolling Review (Carpuat et al., 2021), we used the Responsible NLP Checklist as a way to ensure that all submissions conform to a certain minimum standard of reporting on their reproducibility efforts, data collection principles, and consideration of broader impacts. However, at NAACL 2022 and ACL Rolling Review, these checklists are only used internally during peer review.",
                    "To improve the transparency of NLP research and create a stronger incentive to invest effort in this work, we made the Responsible NLP Checklists an official part of all published papers. The authors filled out the checklist information in a special form, and we later used that form to generate pdf versions of the checklist, which was appended to every paper pdf for the ACL Anthology.",
                    "This change was announced in our Call for Papers, and we additionally communicated it to the authors. The authors had the opportunity to update the checklist form during the preparation of the camera-ready version of their papers.",
                    "One modification to the checklist was introducing a mandatory question about AI writing assistance. This was motivated by the introduction of OpenAI's ChatGPT (OpenAI, 2022), the precedent of AIassisted scientific paper writing of Meta's Galactica (Taylor et al., 2022), and, more importantly, a massive wave of promotion for AI \"writing assistants\" shortly before our direct submission deadline. We did not aim to completely ban AI-assisted writing (which does have legitimate use cases such as assistance to non-native English speakers), but to improve transparency: just like with the other ethics-related questions in the checklists, our posted policy required authors to explicitly state what they did. Our question and policy were subsequently adopted by ACL Rolling Review. Magnusson et al. (2023) have reported that the higher rate of \"yes\" responses to the Reproducibility checklist at 4 NLP conferences. Given that our checklist includes reproducibility questions, and reproducibility positively correlates with both Soundness and Excitement, we would expect the Responsible NLP checklist to perform the same role. The reviewers themselves were predominantly positive about it: 66.99% rated it as \"somewhat useful\", 18.13% as \"very useful\", and only 14.35% -as \"not useful\".",
                    "Table 17 shows the ratios of submissions answering 'yes' to the questions of the checklist, and the acceptance rates for the submissions that answered 'yes' vs those that didn't. For most questions of the checklist, there is a small increase in acceptance rate for submissions that answer 'yes'. The most significant increases are for reporting limitations (so we recommend that the conferences keep mandating this section), reporting hyperparameters and computation budget (in line with the high correlation between reproducibility ratings and reviewer scores \u00a77.5), citing relevant work, contributing scientific artifacts such as models and software (in line with our finding of a significant effect for this contribution type discussed in \u00a77. 3).",
                    "An interesting case is the \"catch question\" A3 (does your abstract accurately summarize your work?). It drew some criticism as \"meaningless bureaucracy\", since all submissions should respond \"yes\" to it. It was actually intended to see that the responders were not just clicking through the checklist. Most authors did respond 'yes', but those 2.24% that didn't saw a -25.4 decrease in acceptance rate. We interpret this as suggesting that the sloppiness in filling out the checklist correlates with sloppiness elsewhere in the work.",
                    "Finally, our new question about the use of writing assistants is the only one where the response 'Yes' is associated with a decrease in acceptance rate, although not very large."
                ],
                "publication_ref": [
                    "b7",
                    "b23"
                ],
                "figure_ref": [
                    "fig_2"
                ],
                "table_ref": [
                    "tab_7"
                ]
            },
            {
                "heading": "Improving Incentives for Reviewers: Reviewer Awards",
                "text": [
                    "Arguably the biggest source of issues with peer review quality is the lack of incentives to invest more work in invisible service labor. One direction is reputational awards, eg via creating reviewer profiles, as in Publons. Another is material awards, such as monetary prizes similar to the best paper awards. Yet Caveats: despite our calls to nominate reviewers and chairs, relatively few ACs and SACs did that: only 7/70 SACs and 28/438 ACs. We recommend that the AC/SAC guidelines are expanded with a section about these awards, and that ACs are asked to start keeping track of potential outstanding reviewers at the (a) review quality check stage, (b) discussion stage, rather than only during meta-reviews (as we did). The SACs could be asked to start keeping track of outstanding ACs at the (a) assignment checks, if that is the process used by the venue, (b) meta-reviews, (c) nominating on the basis of quantitative analysis of the activity in the discussion forum and the number of author-reported review issues that the AC addressed."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Improving Incentives for Chairs: Peer Review Reports",
                "text": [
                    "Our final proposal for improving the incentives for peer review work was to increase its visibility by placing the program chair reports and any findings from their analysis of the internal conference data as an official part of the proceedings for the respective conference. This report is aiming to create a precedent for that. In the past, there have been two options for publishing such work: standalone research papers that undergo their own peer review, and miscellaneous blog posts and reports published in ACL wiki. But the former is not appropriate for reporting on incidental findings (since most of the program chairs work is not executed as a research project targeting a specific research question). The latter is unfortunately too difficult to discover, especially for the people outside of our field or new organizers who may not know which blog posts and wikis to search.",
                    "This initiative aims to improve the transparency of the overall process, and lets the younger members of the community have more insight into how the *ACL conferences work. Moreover, given the increasing attention to peer review in NLP community (Gao et al., 2019;Caragea et al., 2019) and more broadly in ML conferences (Price, 2014;Stelmakh, 2020;Beygelzimer et al., 2021), it would be useful to make the incidental findings from the conferences more easily discoverable, incl. to the researchers in the ML community and other fields.",
                    "The main difficulty for the program chairs and the publication chairs with implementing this proposal is that the full report needs to be prepared before the conference, when there is a lot of other work. To implement this, the set of volunteer roles would need to be expanded (see section 10). We also recommend that to the extent possible, the future chairs start documenting their workflow for the report early on (perhaps during the main review cycle)."
                ],
                "publication_ref": [
                    "b14",
                    "b6",
                    "b30",
                    "b36",
                    "b5"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Recommendations",
                "text": [
                    "Improving logistics. There are several sources of papers to the ACL main conference that the program chairs have no control over: TACL, CL, Industry Track Papers, SRW papers. This means that the PCs need to ingest four different sources of information with potentially little means of interacting with the relevant authors (in contrast to direct submissions). ARR is in a liminal space between direct submissions and these other papers. The timing and format of how the papers enter ACL should be standardized.",
                    "Desk rejections. Desk reject requirements should be clearly stated in the call for papers or in the ACL Paper formatting guidelines. The guidelines omit rules or lack clear thresholds for rejection. For example, there is no minimum separation between captions and tables/figures nor between section titles and the text above and below. Nor are there minimum text sizes for text within tables or figures. Adding clear rules would make the first pass reviewing more efficient and fair. ACL also needs to communicate more clearly about the role of the aclpubcheck script: it's a necessary but not sufficient check. Many authors assume that if they pass the aclpubcheck script, then they have followed all formatting guidelines. Soundness/Excitement scores. With predominantly positive feedback in the exit survey ( \u00a76.4), and evidence of significant improvement in raw agreement ( \u00a77.4), we believe this experiment was successful and should be continued. The formulation of the scores and the review form should be improved, and care should be taken to reduce the overall complexity of the form.",
                    "Review issue flagging. This feature received overwhelming support from the authors, and should be continued and standardized (i.e., cleanly incorporated into author response form)-especially since it lxx is likely to improve after several iterations, when everybody is more familiar with it and the reviewer guidelines. More AC training is needed to address the flagged issues.",
                    "Continued reviewer policy publications. 12.9% of all ACL'23 reviews were flagged by the authors for various issues, with the most frequent problem being reviewer heuristics such as \"too simple\" and \"not SOTA\". It is reassuring to know that the ratio of bad reviews is already not very high, but of course we should strive to further decrease it. The reviewer guidelines, in combination with the review issue flagging mechanism, serve a double purpose: even if the reviewers do not read them, the authors will (since they have the incentive to call out problematic reviews), and then the area chairs also will (to handle the author-flagged issues). Hence, eventually, these policies will become widely known across the community, and enforced by it. We urge the future chairs to continue publishing their reviewer policy or simply re-use ours, and explicitly point to it in review, author response, and meta-review forms.",
                    "Reviewer assignment check support. There is currently no convenient interface for the ACs to look up the assigned reviewers and browse the alternatives with up-to-date availability information. Its lack is a major hurdle for the chairs, and it may cause either delays in the process or skipping the checks.",
                    "Reviewer match explanations. Our area chairs were very positive about this feature. For venues not using an interpretable assignment algorithm such as our keywords-based process, at the very least, the reviewer profiles and relevant papers should be provided directly with the review, without any extra search.",
                    "Post-acceptance decision litigation. Having increased the acceptance rate for Findings, we were surprised to still receive a large volume of emails from the authors who, considering their scores and meta-review, argued that either their paper should have been accepted to the main track, or that it shouldn't have been rejected. It appears that some subcommunities share their scores with each other, under the mistaken impression that if one paper with certain scores was accepted, others with similar scores should be too. We had no capacity for anything beyond checking for clerical errors. The peer review process is by no means perfect, and there was certainly some noise in the decisions-but it is also certain that many authors who disagree with their decisions would try to argue their case if given the chance. If such litigation is not an announced an official part of the conference process-doing so for the select few would not be fair to all the other authors who also disagree with their decisions. We recommend that the future chairs either build this into their process and dedicate time and resources to it, or pre-announce that decisions are final and will not be reconsidered, beyond the cases of clerical errors.",
                    "Area-Contribution-Language matching. The results of our experiment with exactly matching the reviewers with submissions by these areas allowed us to establish that it is possible to ensure a fair acceptance rate for most \"non-mainstream\" contribution types, and for the 63.8% of the submissions that had target languages other than English, we were able to provide a reviewer competent in that language. These results are by no means perfect, and it is important that the future venues improve on them, perhaps with other methods. But Area-Contribution-Language matching could be considered a fair baseline for the future conferences, when considering the success rates for different types of submissions and languages. All that is needed from the chairs is to include in submission forms the checkboxes for different types of contributions, and input fields for the target languages other than English. At the very minimum, the chairs would then be able to analyze the acceptance rates of different types of submissions, and compare it with ours (Table 7). One step further would be to also solicit this information from the reviewers, and estimate the quality of automated matches by the explicit keyword matches (see Table 2).",
                    "One more practical takeaway for future work is that if we used a solution relying purely on publication history from Semantic Scholar-25% of our matches would have been made on unreliable information. For embeddings-based solutions to work better, we would first need to provide them with better data, and this will take a bigger Semantic Scholar cleaning campaign than what we were able to elicit.",
                    "Reconsidering the acceptance rate for Findings. The initial iterations of Findings starting with EMNLP 2020 had the Findings acceptance rate at about 35%. This is the target rate we gave to our SACs, and then we tried to accommodate as many of their ranked preferences as we could. Although lxxi we had over 40% rate with Findings, still, in many SAC comments we saw that they were overriding acceptance recommendations of ACs only to meet the quotas. While the quota for the Main track will stay at 20-25% for venue ranking reasons, we do not see why Findings could not be further extended to have room for most sufficiently sound work. About 60% of our direct submissions had at least two positive (above-borderline) reviews for Soundness and at least one for Excitement. Assuming some noise in the negative reviews for Soundness, it would be only reasonable to expect that at least 45%-50% submissions are Findings-worthy. Of course, the track SACs would not have to accept that many (the ratio of high-quality papers may vary between tracks and years), but when they do not see good reasons to reject -they should not be constrained by the Findings quota. This step would presumably also further decrease the burden of re-reviewing for resubmissions. We also recommend developing a standard process for Findings authors to apply for presentation at topically matching workshops, and for at least virtual poster presentation slots at the main conference.",
                    "Further research on the effect of preprinting on peer review. We find that the preprinted papers have consistently higher ratings (for both Soundness, Excitement, and reviewer confidence), get more recommendations for awards, and a higher acceptance rate. There are several possible underlying causes (from reviewer biases to higher initial paper quality and benefits of community feedback), which likely all contribute to this effect. Since these factors necessitate different actions if they were the major contributor to the observed effect, for informed policy decisions it is necessary to establish how they intermix. We observe however that although the present 1-month embargo policy does not solve this problem, it is effective at mitigating it, since we only had 13.8% such papers.",
                    "Consistently working to improve peer review concistency. Our analysis shows that the inconsistency in numerical reviewer score ratings is remarkably consistent across *ACL conferences (at about \u21b5 0.3 across EMNLP'22,EACL'23,and ACL'23). Among the likely culprits are miscalibrated scales, different interpretations of scales, at least some reviewers not even reading the guidelines, and reviewer biases. That said, we do see almost twice the raw agreement for our Soundness score (that is supposed to be more objective) over Excitement (more subjective), when the scores are mapped to the sound/unsound vs exciting/unexciting categorical variables. This suggests that asking more concrete questions does help (as long as the reviewer form does not become too complicated), and we can continue improving peer review on the basis of the general NLP methodology for iterating on guidelines and measuring agreement.",
                    "Ethics review. The innovation of the ethics review is useful and necessary, but it should be explicitly built into the timeline. We particularly struggled with the conditional accepts.",
                    "Responsible NLP Checklist. With predominantly positive reviewer feedback and evidence of improved acceptance rates for submissions that follow the best reporting practices, we believe that this is an important instrument for creating the right incentives for better science. We also recommend continuing to make it public, to strengthen these incentives.",
                    "AI-assisted reviews. We did not expect this happen so soon, but already at ACL'23 some chairs reached out to us with questions about reviews that they suspected to be at least partly generated. The reviewer guidelines will need to be updated with respect to that as well, including how sending papers to cloud-based language models may violate confidentiality.",
                    "Review policy updates. The rise of popular commercial systems such as ChatGPT that are claimed to be general-purpose, made an unfortunate match with our field's tendency to expect the popular systems in all papers as universal baselines. We did not consider this at ACL'23, since ChatGPT fell out of scope of 3-month policy for considering contemporaneous work, but we did already have at least one precedent of a reviewer asking for a comparison with ChatGPT. We recommend that future chairs develop a clear policy in the reviewer guidelines about requests for comparisons with \"closed\" systems, to avoid numerous issues with evaluation methodology and benchmark data contamination (Rogers, 2023).",
                    "Expanding the set of volunteer roles. Our experience suggests that PC-ing a conference of ACL'23 size is a job that can no longer be realistically done by 3 volunteers. Early on, we introduced a visa lxxii support team 41 to start early with issuing the letters of invitation for Canada. We also had crucial help from two PC assistants: Youmi Ma, an administrative assistant who handled much of the conference email, and Marzena Karpinska, who helped with analysis of peer review data in this report. In the future, we recommend that a dedicated role of a peer review chair is created, whose responsibility will be to supplement PC report with analysis of the data of the respective conference and comparing it with any records from previous conferences (so as to establish the effect of any new policies), and to coordinate the peer review awards selection and logistics (see \u00a79.2). The growing volume of nominations for best papers requires a best paper chair, handling in effect the organization of a separate track and review process. Finally, we could have used a lot of help in the conference schedule: ideally there would be a dedicated schedule chair, ideally serving at several conferences so as to reduce friction and reuse the skill set as much as possible, as well as incorporate feedback from several events. Given that ACL had papers from SRW, Industry, ARR, TACL, CL, Findings, and the Main Conference, it's not necessarily feasible that the main track PCs can effectively coordinate scheduling all of these papers.",
                    "Another option would be for each conference to have two sets of PC chairs, one remaining from the previous year and one new. This would lighten the workload and ensure a smoother process (since people do not learn how to do everything from scratch each time). The first-year PCs would do the bulk of the work after the paper notifications are sent, and the second-year PCs would concentrate on the review process, analysis and the report. The first-year PCs would observe that and have better knowledge for designing the review process (CFP, SAC nominations, review criteria, etc).The second-year PCs would observe the COI requirements."
                ],
                "publication_ref": [
                    "b31"
                ],
                "figure_ref": [],
                "table_ref": [
                    "tab_7"
                ]
            },
            {
                "heading": "",
                "text": [
                    "11 Acknowledgements ACL'23 was the result of an incredible effort of 70 SACs, 438 ACs, 4490 reviewers, and 13,658 authors. We also thank our 2 ethics chairs and their 21 reviewers, as well as 15 judges on the best paper committee.",
                    "We thank the ARR team, and particularly Jonathan K. Kummerfeld, Thamar Solorio and Mausam, for their help with integrating ARR submissions and analyzing them.",
                    "We had a chance to learn from the past chairs Smaranda Muresan, Preslav Nakov and Aline Villavicencio (ACL 2022), Yoav Goldberg, Zornitsa Kozareva, Yue Zhang (EMNLP 2022), and Anna Rumshisky, Luke Zettlemoyer, Dilek Hakkani-Tur (NAACL 2021). We also thank EMNLP 2022 and EACL 2023 (Isabelle Augenstein, Andreas Vlachos) for sharing their score distribution data for our analysis.",
                    "Our work is built on many iterations of previous *ACL conferences, including the AC and SAC guidelines developed at ACL 2021, and peer review tutorials developed by Anna Rogers and Isabelle Augenstein for ACL Rolling Review.",
                    "Our paper-reviewer matching relied on Semantic Scholar data, kindly provided by Kyle Lo (AI2). The Semantic Scholar team also provided extra support to numerous authors working to clean up their profiles.",
                    "Emma Strubell, Ian Magnusson, and Jesse Dodge helped us to prepare publishable versions of Responsible NLP checklist.",
                    "We were only able to devote that much effort to peer review and its analysis thanks to the help of our brilliant assistants Youmi Ma and Marzena Karpinska.",
                    "Richard Gerber (START) responded to numerous issues and implemented several changes at our request, including the possibility to include \"explanations\" for the paper-reviewer matching.",
                    "We deeply thank the ACL Executive (especially Iryna Gurevych, Tim Baldwin, David Yarowsky, Yusuke Miyao, and Emily M. Bender) for their support of many of our crazy ideas, including the reviewer awards and the publication of this report.",
                    "Last but not least, we thank our publication chairs and ACL Anthology team, in particular, Ryan Cotterell and Matt Post -for their infinite patience with this last-minute publication. "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "",
                "text": [
                    "another is punitive incentives, such as penalizing the late reviewers by delaying the reviews for their own submissions (Hauser and Fehr, 2007), or even blocking them from reviewing at future conferences.",
                    "All of these approaches are not without issues. Punitive incentives generally shift the focus to not getting penalized, rather than delivering high-quality reviews. Material awards may introduce the wrong incentives (Squazzoni et al., 2013), and, depending on the institution and the country, the prize may be taxed or not even make it to the recipient. Conference fee waivers also may also reward the reviewer's institution rather than the reviewer, since the institutions usually bear the registration costs. While a survey found that reviewers generally prefer reputational awards over material (Warne, 2016), their value also depends on whether the reviewer's institution rewards such work.",
                    "We proposed to the ACL exec (and received their approval for) an initiative to match the new ACL best paper award policy with recognizing about 1-1.5% of outstanding reviewers and chairs. This combines reputational and material incentives. Instead of monetary prizes, we proposed awarding vouchers for virtual attendance of any *ACL (ACL, NAACL, EACL, AACL, EMNLP) conference of the awardee's choice, to be used within a year of the award date. Since many institutions do not support the attendance of conferences without accepted papers (or even with papers accepted to workshops and Findings), we hope that this measure will increase the overall number of conferences that the awardees can attend.",
                    "We asked the area chairs to nominate the reviewers in their pool who provided extra helpful reviews, high-quality emergency reviews, \"champion\" reviews, reviewers who were particularly active in the discussion phase, or demonstrated exceptional open-mindedness or expertise. We received 51 such nominations. We also asked the Senior Area chairs to nominate exceptional area chairs, receiving 13 nominations. Finally, we as the program chairs also nominated the (3) SACs of the track who were the most on-time, provided the most helpful feedback, and followed our instructions the most closely. Excluding the duplicates, this resulted in 67 total nominations. All awards will be announced on the conference website 40 .",
                    "Since the total number of nominations was within our target number of awards (1-1.5% of total reviewers and chairs), we were able to award all 66 nominations (out of 4998) without creating a selection committee. In the future, we recommend that an extra volunteer role is created for managing the selection of awardees and managing the awards."
                ],
                "publication_ref": [
                    "b15",
                    "b35",
                    "b42"
                ],
                "figure_ref": [],
                "table_ref": []
            }
        ],
        "references": [
            {
                "ref_id": "b0",
                "title": "Aur\u00e9lie N\u00e9v\u00e9ol, Fanny Ducel, Saif M. Mohammad, and Kar\u00ebn Fort. 2023. The Elephant in the Room: Analyzing the Presence of Big Tech in Natural Language Processing Research",
                "journal": "",
                "year": "",
                "authors": "Mohamed Abdalla; Jan Philip Wahle; Terry Ruas"
            },
            {
                "ref_id": "b1",
                "title": "PaRe: A Paper-Reviewer Matching Approach Using a Common Topic Space",
                "journal": "Association for Computational Linguistics",
                "year": "2019",
                "authors": "Omer Anjum; Hongyu Gong; Suma Bhat; Wen-Mei Hwu; Jinjun Xiong"
            },
            {
                "ref_id": "b2",
                "title": "Survey article: Inter-coder agreement for computational linguistics",
                "journal": "Computational Linguistics",
                "year": "2008",
                "authors": "Ron Artstein; Massimo Poesio"
            },
            {
                "ref_id": "b3",
                "title": "The #BenderRule: On Naming the Languages We Study and Why It Matters",
                "journal": "",
                "year": "2019",
                "authors": "Emily M Bender"
            },
            {
                "ref_id": "b4",
                "title": "",
                "journal": "",
                "year": "2018",
                "authors": "Emily M Bender; Leon Derczynski"
            },
            {
                "ref_id": "b5",
                "title": "The NeurIPS 2021 Consistency Experiment",
                "journal": "",
                "year": "2021",
                "authors": "Alina Beygelzimer; Yann Dauphin; Percy Liang; Jennifer Wortman Vaughan"
            },
            {
                "ref_id": "b6",
                "title": "The Myth of Double-Blind Review Revisited: ACL vs",
                "journal": "Association for Computational Linguistics",
                "year": "2019",
                "authors": "Cornelia Caragea; Ana Uban; Liviu P Dinu"
            },
            {
                "ref_id": "b7",
                "title": "",
                "journal": "Responsible NLP research Checklist",
                "year": "2021",
                "authors": "Marine Carpuat; Marie-Catherine De Marneffe; Ivan Vladimir Meza Ruiz"
            },
            {
                "ref_id": "b8",
                "title": "2022. ordinal-Regression Models for Ordinal Data. R package version 2022",
                "journal": "",
                "year": "",
                "authors": "Rune Haubo Bojesen Christensen"
            },
            {
                "ref_id": "b9",
                "title": "Emerging trends: Reviewing the reviewers (again)",
                "journal": "Natural Language Engineering",
                "year": "2020",
                "authors": "Kenneth Ward Church"
            },
            {
                "ref_id": "b10",
                "title": "",
                "journal": "2020. Advice on Reviewing for EMNLP",
                "year": "",
                "authors": "Trevor Cohn; Yulan He; Yang Liu; Bonnie Webber"
            },
            {
                "ref_id": "b11",
                "title": "Inconsistency in Conference Peer Review: Revisiting the 2014 NeurIPS Experiment",
                "journal": "",
                "year": "2021",
                "authors": "Corinna Cortes; Neil D Lawrence"
            },
            {
                "ref_id": "b12",
                "title": "Analysis of Binary Data",
                "journal": "CRC Monographs on Statistics & Applied Probability",
                "year": "1989",
                "authors": "D R Cox; E J Snell"
            },
            {
                "ref_id": "b13",
                "title": "Yes-Yes-Yes: Proactive Data Collection for ACL Rolling Review and Beyond",
                "journal": "",
                "year": "2022",
                "authors": "Nils Dycke; Ilia Kuznetsov; Iryna Gurevych"
            },
            {
                "ref_id": "b14",
                "title": "Does My Rebuttal Matter? Insights from a Major NLP Conference",
                "journal": "Association for Computational Linguistics",
                "year": "2019",
                "authors": "Yang Gao; Steffen Eger; Ilia Kuznetsov; Iryna Gurevych; Yusuke Miyao"
            },
            {
                "ref_id": "b15",
                "title": "An Incentive Solution to the Peer Review Problem",
                "journal": "PLOS Biology",
                "year": "2007",
                "authors": "Marc Hauser; Ernst Fehr"
            },
            {
                "ref_id": "b16",
                "title": "Argument Mining for Understanding Peer Reviews",
                "journal": "Association for Computational Linguistics",
                "year": "2019",
                "authors": "Xinyu Hua; Mitko Nikolov; Nikhil Badugu; Lu Wang"
            },
            {
                "ref_id": "b17",
                "title": "Gender Issues in Computer Science: Lessons Learnt and Reflections for the Future",
                "journal": "",
                "year": "2020",
                "authors": "Letizia Jaccheri; Cristina Pereira; Swetlana Fast"
            },
            {
                "ref_id": "b18",
                "title": "",
                "journal": "2022. A Dataset on Malicious Paper Bidding in Peer Review",
                "year": "",
                "authors": "Steven Jecmen; Minji Yoon; Vincent Conitzer; B Nihar; Fei Shah;  Fang"
            },
            {
                "ref_id": "b19",
                "title": "A Dataset of Peer Reviews (PeerRead): Collection, Insights and NLP Applications",
                "journal": "Association for Computational Linguistics",
                "year": "2018",
                "authors": "Dongyeop Kang; Waleed Ammar; Bhavana Dalvi; Madeleine Van Zuylen; Sebastian Kohlmeier; Eduard Hovy; Roy Schwartz"
            },
            {
                "ref_id": "b20",
                "title": "Computing Krippendorff's Alpha-Reliability",
                "journal": "",
                "year": "2011",
                "authors": "Klaus Krippendorff"
            },
            {
                "ref_id": "b21",
                "title": "Classification and Regression by randomForest",
                "journal": "R News",
                "year": "2002",
                "authors": "Andy Liaw; Matthew Wiener"
            },
            {
                "ref_id": "b22",
                "title": "Collusion Rings Threaten the Integrity of Computer Science Research",
                "journal": "Communications of the ACM",
                "year": "2021",
                "authors": "L Michael;  Littman"
            },
            {
                "ref_id": "b23",
                "title": "Reproducibility in NLP: What Have We Learned from the Checklist?",
                "journal": "",
                "year": "2023",
                "authors": "Ian Magnusson; Noah A Smith; Jesse Dodge"
            },
            {
                "ref_id": "b24",
                "title": "Conditional Logit Analysis of Qualitative Choice Behaviour",
                "journal": "Frontiers in Econometrics",
                "year": "1973",
                "authors": "Daniel Mcfadden"
            },
            {
                "ref_id": "b25",
                "title": "A note on a general definition of the coefficient of determination",
                "journal": "Biometrika",
                "year": "1991",
                "authors": "Nico Nagelkerke"
            },
            {
                "ref_id": "b26",
                "title": "Introducing ChatGPT",
                "journal": "",
                "year": "2022",
                "authors": " Openai"
            },
            {
                "ref_id": "b27",
                "title": "Factors That Influence Retention of Women in the Computer Science Major: A Systematic Literature Review",
                "journal": "Journal of Women and Minorities in Science and Engineering",
                "year": "2019",
                "authors": "Katarina Pantic; Jody Clarke-Midura"
            },
            {
                "ref_id": "b28",
                "title": "Statistical Methods for Annotation Analysis",
                "journal": "Springer International Publishing",
                "year": "2022",
                "authors": "Ron Silviu Paun; Massimo Artstein;  Poesio"
            },
            {
                "ref_id": "b29",
                "title": "The Fate of Published Articles, Submitted Again",
                "journal": "Behavioral and Brain Sciences",
                "year": "1982",
                "authors": "P Douglas; Stephen J Peters;  Ceci"
            },
            {
                "ref_id": "b30",
                "title": "The NIPS experiment",
                "journal": "",
                "year": "2014",
                "authors": "Eric Price"
            },
            {
                "ref_id": "b31",
                "title": "Closed AI Models Make Bad Baselines",
                "journal": "",
                "year": "2023",
                "authors": "Anna Rogers"
            },
            {
                "ref_id": "b32",
                "title": "What Can We Do to Improve Peer Review in NLP?",
                "journal": "Online. Association for Computational Linguistics",
                "year": "2020",
                "authors": "Anna Rogers; Isabelle Augenstein"
            },
            {
                "ref_id": "b33",
                "title": "Classical Peer Review: An Empty Gun",
                "journal": "Breast Cancer Research",
                "year": "2010",
                "authors": "Richard Smith"
            },
            {
                "ref_id": "b34",
                "title": "The Proof and Measurement of Association between Two Things",
                "journal": "The American Journal of Psychology",
                "year": "1987",
                "authors": "Charles Spearman"
            },
            {
                "ref_id": "b35",
                "title": "Does Incentive Provision Increase the Quality of Peer Review? An Experimental Study",
                "journal": "Research Policy",
                "year": "2013",
                "authors": "Flaminio Squazzoni; Giangiacomo Bravo; K\u00e1roly Tak\u00e1cs"
            },
            {
                "ref_id": "b36",
                "title": "Experiments with the ICML 2020 Peer-Review Process",
                "journal": "",
                "year": "2020",
                "authors": "Ivan Stelmakh"
            },
            {
                "ref_id": "b37",
                "title": "PeerReview4All: Fair and Accurate Reviewer Assignment in Peer Review",
                "journal": "PMLR",
                "year": "2019",
                "authors": "Ivan Stelmakh; B Nihar; Aarti Shah;  Singh"
            },
            {
                "ref_id": "b38",
                "title": "Viktor Kerkez, and Robert Stojnic. 2022. Galactica: A Large Language Model for Science",
                "journal": "",
                "year": "",
                "authors": "Ross Taylor; Marcin Kardas; Guillem Cucurull; Thomas Scialom; Anthony Hartshorn; Elvis Saravia; Andrew Poulton"
            },
            {
                "ref_id": "b39",
                "title": "What Factors Should Paper-Reviewer Assignments Rely On? Community Perspectives on Issues and Ideals in Conference Peer-Review",
                "journal": "Association for Computational Linguistics",
                "year": "2022",
                "authors": "Terne Thorn Jakobsen; Anna Rogers"
            },
            {
                "ref_id": "b40",
                "title": "Reviewer Bias in Single-versus Double-Blind Peer Review",
                "journal": "Proceedings of the National Academy of Sciences",
                "year": "2017",
                "authors": "Andrew Tomkins; Min Zhang; William D Heavlin"
            },
            {
                "ref_id": "b41",
                "title": "Modern Applied Statistics with S",
                "journal": "Springer",
                "year": "2002",
                "authors": "N William; Brian D Venables;  Ripley"
            },
            {
                "ref_id": "b42",
                "title": "Rewarding reviewers -Sense or Sensibility? A Wiley Study Explained",
                "journal": "Learned Publishing",
                "year": "2016",
                "authors": "Verity Warne"
            }
        ],
        "figures": [
            {
                "figure_label": "1",
                "figure_type": "figure",
                "figure_id": "fig_0",
                "figure_caption": "Figure 1 :1Figure 1: Resubmissions at ACL'23",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_1",
                "figure_caption": "Figure 2: Author and reviewer pool at ACL'23*",
                "figure_data": ""
            },
            {
                "figure_label": "3",
                "figure_type": "figure",
                "figure_id": "fig_2",
                "figure_caption": "Figure 3 :3Figure 3: Review issue flagging: minimal plain-text implementation in START",
                "figure_data": ""
            },
            {
                "figure_label": "4",
                "figure_type": "figure",
                "figure_id": "fig_3",
                "figure_caption": "Figure 4 :4Figure 4: Example explanation for paper-reviewer matches, and AC utility ratings for individual features displayed.",
                "figure_data": ""
            },
            {
                "figure_label": "5",
                "figure_type": "figure",
                "figure_id": "fig_4",
                "figure_caption": "Figure 5 :5Figure 5: Soundness and Excitement scores per acceptance status",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "figure",
                "figure_id": "fig_6",
                "figure_caption": "Ratio of positive (+) and negative (-) score combinations per acceptance status (c) Total number of submissions with different combinations of positive (+) and negative (-) scores (d) Number of accepted submissions with different combinations of positive (+) and negative (-) scores",
                "figure_data": ""
            },
            {
                "figure_label": "7",
                "figure_type": "figure",
                "figure_id": "fig_7",
                "figure_caption": "Figure 7 :7Figure 7: Review scores vs acceptance outcome. \"Positive\" scores (+) refer to the above-borderline scores (Soundness >=3, Excitement >=3.5), and \"negative\" (-) -to the number of scores below borderline.",
                "figure_data": ""
            },
            {
                "figure_label": "8",
                "figure_type": "figure",
                "figure_id": "fig_8",
                "figure_caption": "Figure 8 :8Figure8: Area-Contribution-Language Matches impact on reviewer scores. In each plot, True/False refers to the reviews where the submissions were/weren't matched by area, contribution or language.",
                "figure_data": ""
            },
            {
                "figure_label": "9",
                "figure_type": "figure",
                "figure_id": "fig_9",
                "figure_caption": "Figure 9 :9Figure 9: Area-Contribution-Language matches vs reviewer activity. In each plot, True/False refers to reviews where the reviewers weren't matched to the submission by area, contribution or language",
                "figure_data": ""
            },
            {
                "figure_label": "10",
                "figure_type": "figure",
                "figure_id": "fig_10",
                "figure_caption": "Figure 10 :10Figure 10: Spearmans' correlation between reviewer scores, confidence, and the length of review text fields. The insignificant correlation was left blank (p>0.05).",
                "figure_data": ""
            },
            {
                "figure_label": "12",
                "figure_type": "figure",
                "figure_id": "fig_11",
                "figure_caption": "Figure 12 :12Figure12: The number of review issues reported for R1, R2, and R3",
                "figure_data": ""
            },
            {
                "figure_label": "1",
                "figure_type": "table",
                "figure_id": "tab_0",
                "figure_caption": "Number of submissions and acceptance rates per track for direct and ARR submissions to ACL'23.",
                "figure_data": "Direct submissionsARR submissions"
            },
            {
                "figure_label": "",
                "figure_type": "table",
                "figure_id": "tab_1",
                "figure_caption": "Match by area Match by contribution Match by language Review count Review %",
                "figure_data": "33English899671.36n/a*n/an/a10528.3573English6915.4837English5584.433334763.783373452.747331641.377English1421.13773520.41373500.40Table 2: The number of reviews matched to submission by different combinations of ACL (Area-Contribution-Language) criteria. The 'n/a' row corresponds to manual assignments by ACs, for which we do not have the matchinformation."
            },
            {
                "figure_label": "3",
                "figure_type": "table",
                "figure_id": "tab_3",
                "figure_caption": "Review issue statistics",
                "figure_data": ""
            },
            {
                "figure_label": "4",
                "figure_type": "table",
                "figure_id": "tab_4",
                "figure_caption": "To establish the odds of a paper being accepted into Findings or the Main track vs it being Rejected, based only on reviewer and chair recommendations, we fit a multinomial log-linear model with multinom() function from the NNET package in R (Venables and Ripley, 2002).18 The dependent variable (DV) is the Outcome coded as a three-layer categorical variable (Main track, Findings, or Reject) with Reject being set as the reference level. The independent variables (IVs) are AC Recommendation (ordinal), SAC Recommendation (ordinal), mean Soundness score (interval), and mean Excitement score (interval).19  The analysis is performed on the papers submitted directly to the conference as the ARR submissions were reviewed through a different process and had different scores. The model coefficients are shown in Table4. The model is a good fit for the data with McFadden's pseudo-R 2 of 0.777(McFadden, 1973).",
                "figure_data": "Findings Coeff Main Coeff Findings SE Main SE(Intercept)-1.483.770.791.43Soundness Mean0.710.760.220.37Excitement Mean0.610.030.230.42AC Recommendation (L)2.664.500.500.94AC Recommendation (Q)-1.16-0.050.430.81AC Recommendation (C)-0.040.100.310.58AC Recommendation (^4)0.04-0.270.190.37SAC Recommendation (L)5.8428.260.470.71SAC Recommendation (Q)-1.0613.590.340.77SAC Recommendation (C)1.187.820.600.82SAC Recommendation (^4)1.524.480.640.74"
            },
            {
                "figure_label": "5",
                "figure_type": "table",
                "figure_id": "tab_5",
                "figure_caption": "Type III Analysis of Deviance for Multinomial Logistic Regression in Table4.17   ",
                "figure_data": ""
            },
            {
                "figure_label": "6",
                "figure_type": "table",
                "figure_id": "tab_6",
                "figure_caption": "Type III Analysis of Deviance for Multinomial Logistic Regression, predicting submission Outcome (Main, Findings, Reject) conditioned on the variables listed in the table.24   ",
                "figure_data": "liv"
            },
            {
                "figure_label": "7",
                "figure_type": "table",
                "figure_id": "tab_7",
                "figure_caption": "Acceptance rate among direct submissions that were reviewed and considered for acceptance, with (Match) and without (Mismatch) given contribution types. The average acceptance rate in this pool is 46.92%.",
                "figure_data": "Contribution type% submissions Match Mismatch Match-MismatchEfficiency9.6250.2746.563.71NLP engineering experiment61.546.6647.33-0.67Software and pre-trained models12.1456.7545.5611.19Data resources1949.2546.372.88Data analysis10.4848.1446.781.36Reproduction studies2.0866.2546.5119.74Approaches for low-resource settings 18.2249.7946.283.51Surveys1.6444.4446.96-2.52Interpretability25.2951.845.276.52Theory3.856.8546.5310.32Position papers2.5753.5446.746.8"
            },
            {
                "figure_label": "8",
                "figure_type": "table",
                "figure_id": "tab_8",
                "figure_caption": "Acceptance rate among direct submissions inside and outside tracks that targeted a resources and interpretability contributions, with (Match) and without (Mismatch) given contribution types. The average acceptance rate in this pool is 46.92%.",
                "figure_data": "lvi"
            },
            {
                "figure_label": "9",
                "figure_type": "table",
                "figure_id": "tab_9",
                "figure_caption": "Inter-reviewer agreement on soundness and excitement scores, measured as raw % agreement (%) and Krippendorff's alpha (\u21b5) with 95% confidence interval[CI].26 We consider only direct submissions to ACL'23 that were fully reviewed, and for which the final decisions were made: 3847 in total, 1805 \"accept\" (to either Main track of Findings), and 2042 \"reject\".",
                "figure_data": ""
            },
            {
                "figure_label": "10",
                "figure_type": "table",
                "figure_id": "tab_12",
                "figure_caption": "to reviews where the reviewers weren't matched to the submission by area, contribution or language Generalized linear model (GLM) estimates for predicting reviewer activity using match categories. Each row represents a different predictor.29   ",
                "figure_data": "Estimate Std. Error z value Pr(>|z|)(Intercept)1.15110.101211.380.0000 ***Match Contribution (True)0.16380.08301.970.0484 *Match Language (False)-0.10760.1142-0.940.3461Match Language (True)0.01140.09210.120.9015Match Area (True)-0.11510.0786-1.460.1432TestChisqdf p-valuePearson's Chi-squared (Yates' correction) 0.73432 1 0.3915"
            },
            {
                "figure_label": "11",
                "figure_type": "table",
                "figure_id": "tab_13",
                "figure_caption": "Results of Pearson's Chi-squared test with Yates'",
                "figure_data": ""
            },
            {
                "figure_label": "",
                "figure_type": "table",
                "figure_id": "tab_14",
                "figure_caption": "Table 4 should be interpreted with caution.",
                "figure_data": "Review IssuesFALSE TRUE2.9% 9%29.9%43%41.2%42.3%23%2.9% 5.5%Soundness 1 2 3 4 50%25%50%75%100%(a) SoundnessExcitementReview IssuesFALSE TRUE2.6% 3.8% 0%18.3% 12.9%23.5% 25.5% 25%21.6% 27.7% 50%18.2% 19.8% 75%3.8% 2.2% 7.8% 10.8% 100%1 1.5 2 2.5 3 3.5 4 4.5 5(b) ExcitementReview IssuesFALSE TRUE10.5% 11.8%53.7% 53.9%29.5% 28.8%5.8% 4.5%Confidence 1 2 3 4 50%25%50%75%100%(c) Reviewer confidenceLowest ScoreReview IssuesFALSE TRUE3% 0%16%10% 29% 25%33% 13%50%10% 43%75%24%5%3% 2% 6% 100%1 1.5 2 2.5 3 3.5 4 4.5 5(d) Min(Soundness, Excitement)lxii"
            },
            {
                "figure_label": "",
                "figure_type": "table",
                "figure_id": "tab_15",
                "figure_caption": "Estimate Std. Error z value Pr(> |z|)    ",
                "figure_data": "(Intercept)0.59990.25702.3340.0196 *Soundness-0.38160.0479-7.9671.63e-15 ***Excitement-0.45840.0549-8.349< 2e-16 ***Confidence-0.08550.0393-2.1760.0295 *Reproducibility0.06090.03351.8160.0693 .Reasons to Reject0.00040.00021.5080.1315Reasons to Accept-0.00520.0011-4.7482.06e-06 ***Match Contribution (True)0.07630.11480.6640.5066Match Area (True)-0.13520.1030-1.3130.1892Match Language (False)0.02700.14760.1830.8550Match Language (True)-0.26390.1275-2.0700.0384 *Experience (Experienced)-0.07440.0684-1.0870.2769Experience (Zero)-0.02740.1164-0.2350.8143Reviewer Active (True)0.31720.07374.3031.69e-05 ***"
            },
            {
                "figure_label": "12",
                "figure_type": "table",
                "figure_id": "tab_16",
                "figure_caption": "Coefficients of the Generalized Linear Model predicting the review issues. The table includes the coefficient estimate, standard error, z-value, and p-value for each predictor.34   ",
                "figure_data": "LR Chisq Df Pr(>Chisq)Soundness64.6510.0000 ***Excitement70.4510.0000 ***Confidence4.7110.0300 *Reproducibility3.3110.0688 .Reasons to Reject2.2310.1353Reasons to Accept24.1710.0000 ***Match Contribution0.4510.5035Match Area1.6910.1940Match Language4.6120.0998 .Experience1.2420.5386Reviewer Active19.3510.0000 ***"
            },
            {
                "figure_label": "13",
                "figure_type": "table",
                "figure_id": "tab_17",
                "figure_caption": "Type III Analysis of Deviance for the variables in the Generalized Linear Model predicting whether issues were reported for the given review.35   ",
                "figure_data": ""
            },
            {
                "figure_label": "14",
                "figure_type": "table",
                "figure_id": "tab_18",
                "figure_caption": "Cumulative Link Mixed Model Results for the effect of Anonymity on the Soundness scores. The reference level is Anonymity (1) (i.e., not knowing the authors).",
                "figure_data": "lxv"
            },
            {
                "figure_label": "15",
                "figure_type": "table",
                "figure_id": "tab_19",
                "figure_caption": "Cumulative Link Mixed Model Results for the effect of Anonymity on the Excitement scores. The reference level is Anonymity (1) (i.e., not knowing the authors).",
                "figure_data": ""
            },
            {
                "figure_label": "16",
                "figure_type": "table",
                "figure_id": "tab_20",
                "figure_caption": "Cumulative Link Mixed Model Results for the effect of Anonymity on the Confidence scores. The reference level is Anonymity (1) (i.e., not knowing the authors).",
                "figure_data": "lxvi"
            }
        ],
        "formulas": [],
        "doi": ""
    },
    "Detecting and Mitigating Hallucinations in Machine Translation: Model Internal Workings Alone Do Well, Sentence Similarity Even Better": {
        "authors": "David Dale; Elena Voita; Lo\u00efc Barrault; Marta R Costa-Juss\u00e0; Meta Ai",
        "pub_date": "",
        "abstract": "While the problem of hallucinations in neural machine translation has long been recognized, so far the progress on its alleviation is very little. Indeed, recently it turned out that without artificially encouraging models to hallucinate, previously existing methods fall short and even the standard sequence log-probability is more informative. It means that internal characteristics of the model can give much more information than we expect, and before using external models and measures, we first need to ask: how far can we go if we use nothing but the translation model itself ? We propose to use a method that evaluates the percentage of the source contribution to a generated translation. Intuitively, hallucinations are translations \"detached\" from the source, hence they can be identified by low source contribution. This method improves detection accuracy for the most severe hallucinations by a factor of 2 and is able to alleviate hallucinations at test time on par with the previous best approach that relies on external models. Next, if we move away from internal model characteristics and allow external tools, we show that using sentence similarity from cross-lingual embeddings further improves these results. We release the code of our experiments. 1",
        "sections": [
            {
                "heading": "Introduction",
                "text": [
                    "Hallucinations in machine translation (MT) are cases when the model generates output that is partially or fully unrelated to the source sentence. While generally this phenomenon is not frequent and has low impact on corpus-level automatic metrics, the impact of hallucinations on user experience can be rather dramatic. For example, if a translation system generates The staff were very friendly and helpful in response to an input sentence about e.g. a marvelous view from the window, a user is unlikely to trust this system in future.",
                    "1 https://github.com/facebookresearch/stopes/tree/ main/demo/alti/detecting_hallucinations While the problem of hallucinations is known, addressing it remains challenging. Firstly, hallucinations are very rare. This is why previous work mostly resorted to settings where models are encouraged to hallucinate, by e.g. artificially perturbing source sentence (Lee et al., 2019;Raunak et al., 2021), adding specific types of noise to the training data (Raunak et al., 2021), working under domain shift (Wang and Sennrich, 2020;M\u00fcller et al., 2020), among others (Zhou et al., 2021). Secondly, hallucinations are hard to identify with automatic metrics. Often, hallucinations were defined as translations with low quality according to some metric such as adjusted BLEU or chrF (Lee et al., 2019;Raunak et al., 2021;M\u00fcller and Sennrich, 2021) or translations satisfying some heuristic condition (Berard et al., 2019;Raunak et al., 2021). Overall, it is not clear whether proposed methods detect naturally occurring hallucinations well.",
                    "Recently, when revisiting previous work in a relatively clean setting, Guerreiro et al. (2022) found that existing detection methods fall short and the standard sequence log-probability is the most informative. To show this, the authors gathered a large dataset with professional annotations of translations that, according to 10 previously proposed methods, are likely to be hallucinations. This data (hallucinations along with the model that generated them) made it possible to first, evaluate the performance of various detection methods and second, to work on alleviating hallucinations at test time. For the latter, the idea is \"detect-then-rewrite\": after flagging a translation as likely to be pathological, generate several alternative hypotheses and pick the best one relying on some measure. So far, the best realization of this general framework uses sequence log-probability -Seq-Logprob -for detection, Monte Carlo dropout (Gal and Ghahramani, 2016) to generate several alternative translation hypotheses, and COMET-QE to pick the final candidate (see Guerreiro et al. (2022) for the details).",
                    "We use the same test bed and substantially improve previous results.",
                    "Regarding hallucination detection, we view the observation that Seq-Logprob outperforms previous (specifically targeted to hallucinations) methods as follows: internal model characteristics may contain much more information than we expect. Therefore, before developing or using external models and measures, we ask: how far can we go if we use nothing but the translation model itself ? We propose to use a method that evaluates the percentage of the source contribution to a generated translation. Intuitively, since hallucinations are translations that are \"detached\" from the source, low source contribution should be able to identify hallucinations. Despite the fact that understanding hallucinations was one of the motivations behind the first method evaluating relative source and target contributions, both existing methods only looked at highly artificial hallucinations (Voita et al., 2021;Ferrando et al., 2022). We propose to use ALTI+ by Ferrando et al. (2022), the method that aggregates layer-wise tokens attributions, for both hallucination detection and reranking in the \"detect-then-rewrite\" pipeline. For detection of the most severe hallucinations, it is twice more accurate than Seq-Logprob. For reranking, it performs on par with the previous best COMET-QE. All in all, we improve the overall pipeline results by relying on internal model characteristics alone.",
                    "When allowing external tools, previous work mostly focused on different ways to automatically evaluate quality of a translation example, either with string-based methods or neural quality estimation systems. This idea (the better we estimate translation quality, the better we are at detecting hallucinations) is natural: hallucinations are lowquality translations in the first place. However, implementing this idea in practice is challenging: even state-of-the-art quality estimation system substantially fails (Guerreiro et al., 2022). We hypothesize that instead of targeting quality evaluation, it might be beneficial to use models trained with a rather different objective. Indeed, as we show in this paper, similarity between the source and a translation estimated via cross-lingual sentence embeddings outperforms the best internal method. Apart from cross-lingual sentence similarity (which is expected to be sensitive to highly incorrect translations), we find that cross-lingual natural language inference models (less anticipated in the context of machine translation) also perform quite well. To the best of our knowledge, we are the first to apply these models for hallucination detection.",
                    "Overall, we show that:",
                    "\u2022 by using only the model's inner workings, we",
                    "\u2022 detect the most severe type of hallucinations with twice better precision;",
                    "\u2022 alleviate hallucinations at test time with results on par with the best previous method that relies on an external model; \u2022 models focused on semantic similarity of sentences detect all types of hallucinations with precision 80% higher than previous methods."
                ],
                "publication_ref": [
                    "b23",
                    "b23",
                    "b32",
                    "b19",
                    "b34",
                    "b23",
                    "b20",
                    "b1",
                    "b23",
                    "b11",
                    "b10",
                    "b11",
                    "b31",
                    "b7",
                    "b7",
                    "b11"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Background and Setting",
                "text": [
                    "In this section, we describe the framework and data we use for evaluation of hallucination detection and mitigation methods. This framework was proposed by Guerreiro et al. (2022) and consists of a large dataset of annotated translations along with the model that produced them. To the best of our knowledge, this is the only released data that can be used to analyze hallucinations in a \"clean\" setting."
                ],
                "publication_ref": [
                    "b11"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Model",
                "text": [
                    "The model is Transformer base (Vaswani et al., 2017) from fairseq (Ott et al., 2019) with the standard hyperparameters setting. It was trained on the WMT'18 German-English news translation data excluding Paracrawl (Bojar et al., 2018) -totalling 5.8M sentence pairs. Since Guerreiro et al.",
                    "(2022) used randomly chosen 1/3 of the dataset as a held-out set for analysis, the model was trained on the remaining 2/3 of the dataset. We use the model released by Guerreiro et al. (2022) that has been used to generate the hallucinations we analyze."
                ],
                "publication_ref": [
                    "b29",
                    "b21",
                    "b2",
                    "b11"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Hallucination Dataset",
                "text": [
                    "The hallucination dataset released by Guerreiro et al. ( 2022) contains fine-grained manual annotations of 3415 German-to-English translations generated by the model above. These translations are chosen from a set of 1.8M translations of heldout data as the ones that are likely to be pathological. The criteria used to flag the translations include 10 methods ranging from previously proposed heuristics (Lee et al., 2019;Berard et al., 2019;Raunak et al., 2021) to quality estimation models (Rei et al., 2020b) and uncertainty detectors (Fomicheva et al., 2020;Zerva et al., 2021;Guerreiro et al., 2022). The taxonomy of translation pathologies in the dataset is shown in Figure 1. Here, hallucinations are defined as severe translation errors that are detached from the source. These can be either oscillatory (i.e. contain erroneous repetitions of words and phrases) or largely fluent. The latter is further split by severity of an error into fully detached (the whole content is not supported by the source) and strongly, but not fully, detached (significant proportion of output is not supported by the source). 2 Additionally, the annotated data contains translation errors that are deemed not detached from the source (Figure 1). Overall, 323 examples are judged to be hallucinations, 1044 are less severe translation errors and the rest are correct translations.",
                    "Note that so far, there is no \"canonical\" hallucination taxonomy and previous work used various, mostly overlapping, definitions (Lee et al., 2019;Raunak et al., 2021;Zhou et al., 2021;Ji et al., 2022;Raunak et al., 2022;Guerreiro et al., 2022). We follow the taxonomy by Guerreiro et al. (2022) for consistency with the dataset and the evaluation framework we use and because this taxonomy is general enough for our purposes."
                ],
                "publication_ref": [
                    "b1",
                    "b23",
                    "b26",
                    "b8",
                    "b33",
                    "b11",
                    "b23",
                    "b34",
                    "b24",
                    "b11",
                    "b11"
                ],
                "figure_ref": [
                    "fig_0",
                    "fig_0"
                ],
                "table_ref": []
            },
            {
                "heading": "Reference-Based Oracles",
                "text": [
                    "Following previous work (M\u00fcller and Sennrich, 2021;Guerreiro et al., 2022), we use:",
                    "\u2022 chrF: character n-gram F score of the translation with respect to the reference. We use the CHRF++ version that also takes into account word unigrams and bigrams (Popovi\u0107, 2017);",
                    "\u2022 COMET: a neural quality estimation metric by Rei et al. (2020a) which was shown to be the state-of-the-art reference-based method (Kocmi et al., 2021)."
                ],
                "publication_ref": [
                    "b20",
                    "b11",
                    "b22",
                    "b25"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Internal Measures",
                "text": [
                    "Baseline: Seq-Logprob. This is the standard length-normalized sequence log-probability. Compared to previously introduced methods specifically targeting hallucinations, this simple metric performs the best (Guerreiro et al., 2022).",
                    "We use ALTI: percentage of source contribution.",
                    "We compute the percentage of source impact on the generated translation using the recently introduced ALTI+ (Ferrando et al., 2022). At a high level, it decomposes each transformer block into a sum of functions of individual tokens and views an output representation as a summation of transformed input vectors. Then it evaluates contribution of these vectors to the resulting sum. Among other things, ALTI+ (as well as an earlier Layerwise Relevance Propagation (LRP) -based method by Voita et al. (2021)) was used to show that for artificially created hallucinations, source influence is much lower than for \"healthy\" translations. Our work is the first to test this intuition in a real setting where hallucinations are generated naturally. 3  Formally, for a model and its generated translation, we compute the total source contribution as the sum of contributions of all source tokens. We do it for each target token individually and then average across target tokens. The scores are computed by the same model that produced the translations (Section 2.1)."
                ],
                "publication_ref": [
                    "b11",
                    "b7",
                    "b31"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "External models",
                "text": [
                    "Baseline: COMET-QE. For a reference-free model, we use the state-of-the-art COMET-QE (Rei et al., 2020b) for its superior performance compared to other quality estimators (Mathur et al., 2020;Freitag et al., 2021;Kocmi et al., 2021).",
                    "We use: sentence similarity. Overall, we consider three measures based on pretrained models that evaluate semantic similarity of two sentences:",
                    "\u2022 LASER: cosine similarity of source and translation sentence embeddings from LASER2. LASER2 (Heffernan et al., 2022) improves LASER (Artetxe and Schwenk, 2019) by replacing LSTM encoder with a Transformer and using teacher-student training;",
                    "\u2022 LaBSE: cosine similarity of source and translation sentence embeddings from LaBSE (Feng et al., 2022). LaBSE is a dual-encoder approach based on pretrained transformers and fine-tuned for translation ranking with an additive margin softmax loss;",
                    "\u2022 XNLI: product of the entailment probabilities of source to translation and translation to source. We compute entailment scores with RoBERTa (Conneau et al., 2020) finetuned on a combination of NLI data in 15 languages (Conneau et al., 2018). 4   4 Detection Experiments"
                ],
                "publication_ref": [
                    "b26",
                    "b18",
                    "b12",
                    "b0",
                    "b5",
                    "b3"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Main results",
                "text": [
                    "Overall results are shown in Table 1. We report ROC AUC and precision at 90% recall. 5 In addition to overall results, we also report metrics for fully detached hallucinations separately. First, let us look at internal methods. While for all hallucinations ALTI performs comparably to Seq-Logprob, for fully detached hallucinations it has twice better precision. Since ALTI averages the source contributions over all generated tokens, it is more effective at detecting the most severe hallucinations rather than the ones where only part of the tokens are detached. Note also that for fully detached hallucinations, internal ALTI performs almost on par with the best external methods.",
                    "Among both all and fully detached hallucinations, their precision at 90% recall is roughly twice better than that of Seq-Logprob. While such a good performance might be expected for LaBSE that evaluates crosslingual sentence similarity (in a way, this might be seen as a measure of translation quality), results for XNLI are rather surprising: to the best of our knowledge, models optimized for XNLI have not been used in the context of machine translation. Note also the large difference between LaBSE and LASER: while the former shows big improvements compared to Seq-Lobprob, the latter noticeably lags behind. This is not surprising when looking at training objectives of the underlying models. LaBSE is trained on a translation ranking task and thus explicitly encourages ordering translations by severity of an error; for LASER, this is not the case.",
                    "To further understand differences between detectors, we look at the distributions of the detection scores in Section 4.2 and the detected pathology types in Section 4.3."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Analysing Distributions of the Scores",
                "text": [
                    "For each of the methods, Figure 2 shows distributions of the scores for fully detached hallucinations, strongly detached hallucinations, less severe errors and correct translations.",
                    "Internal methods: partial hallucinations are bimodal. ALTI and Seq-Logprob show similar behavior: errors are distributed similarly to correct translations, and the scores for partial (strongly detached) hallucinations have bimodal distribution. At a high level, for the model, some partial hallucinations \"look\" more like full hallucinations, and some -like errors. This can motivate future work: it would be interesting to understand whether it depends on detachment or on more simple patterns such as e.g. the proportion of hallucinated tokens.",
                    "COMETs: blind to error severity. COMET and COMET-QE scores 6 do not separate hallucinations from less severe errors. This agrees with previous work noting that since quality estimation models are mostly trained on data that lacks negative examples, COMETs may be inadequate at evaluating poor translations in general (Takahashi et al., 2021;Sudoh et al., 2021) and hallucinations in particular (Guerreiro et al., 2022). What is also expected, is that compared to reference-free COMET-QE, the overlap between the scores for correct and incorrect translations is much lower for reference-based COMET. ChrF behaves similarly to COMET.",
                    "LaBSE: ranks hallucination severity best. LaBSE is the only detector with a clear order between full, partial hallucinations, and non-hallucinations. Once again, this is expected because only LaBSE is trained for ranking. Interestingly, for LASER, modes for the three distributions are also ordered; unfortunately, the distributions themselves overlap significantly which makes it not suitable as a detector. Both LaBSE and LASER ignore most of the non-hallucinated translation errors. XNLI: no middle ground. Finally, XNLI distributions are very peaky and concentrated around 0 and 1. This is expected: XNLI's decision is always binary. While this provides good separation between fully detached hallucinations and correct translations, it is hard to estimate error severity."
                ],
                "publication_ref": [
                    "b11"
                ],
                "figure_ref": [
                    "fig_1"
                ],
                "table_ref": []
            },
            {
                "heading": "Detected Pathology Types",
                "text": [
                    "Now we come to fine-grained categories and look at detected pathology types. For each method, we flag a translation as \"detected\" if it belongs to a fraction (e.g. 10%) of the hallucination dataset corresponding to the lowest scores. 7 Then we look at \u2022 the distribution of pathology types contained among detected examples (Figure 3);",
                    "\u2022 recall for different translation types with respect to the whole dataset (Figure 4).",
                    "The three best methods are similar. Figure 3 shows that ALTI, LaBSE and XNLI select similar pathology types. For them, flagged examples consist mostly of fully detached and strongly detached hallucinations, along with other errors.",
                    "LASER is an outlier. Instead of focusing on pathological translations, LASER behaves differently and flags correct translations more. This explains its poor detection performance mentioned above. XNLI flags undergenerations. Figure 4 shows that XNLI (and, to a lesser extent, LaBSE) flags a large proportion of undertranslations. This makes sense: these criteria are symmetric, and if we swap the source and the undergenerated translation, the longer source can be seen as a hallucination.",
                    "Fully detached are the easiest to detect. As expected, fully detached hallucinations are the easiest to detect: all methods detect them entirely when taking 20% of the hallucination dataset (Figure 4), and they are the most frequent among the examples flagged by the best performing methods (Figure 3). This agrees with Guerreiro et al. ( 2022) that oscillatory and strongly detached hallucinations are more difficult to detect, and shows that improvements with our methods mostly come from these types."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_2",
                    "fig_3",
                    "fig_2",
                    "fig_3",
                    "fig_3",
                    "fig_2"
                ],
                "table_ref": []
            },
            {
                "heading": "Mitigating Hallucinations at Test Time",
                "text": [
                    "Finally, let us come to the second part of the \"detectthen-rewrite\" pipeline: for a flagged translation, generate several alternative hypotheses and rerank them (Guerreiro et al., 2022) 8 . This general framework has two degrees of freedom: (i) generation of hypotheses, (ii) reranking approach. We show that",
                    "\u2022 for generating hypotheses, simply applying MC dropout (as done in Guerreiro et al. ( 2022)) outperforms more involved methods such as diverse beam search (Section 5.2);",
                    "\u2022 for reranking, we can match COMET-QE with Here, the types are presented in a multilabel manner, i.e. one translation may contribute to multiple axes.",
                    "internal ALTI and decrease the hallucination rate by using LaBSE (Section 5.3)."
                ],
                "publication_ref": [
                    "b11"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Evaluation methodology",
                "text": [
                    "In this section, we explain the setup for the experiments with automatic evaluation in Sections 5.2 and 5.3. The setup for manual annotation is explained later in Section 5.3.2."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Metrics.",
                "text": [
                    "In our experiments, we use several metrics. First, we use quality evaluation metrics commonly used by the community, i.e. COMET (Rei et al., 2020b) and BLEU. Additionally, we use the two best metrics for hallucination detection: LaBSE and XNLI. We show some of the metrics in the main text and the rest in the appendix.",
                    "Data. First, we analyze the impact of our method on translations of different quality levels. For this, we randomly sample 150 sentences from each of the following groups of the hallucination dataset (Section 2.2): fully detached hallucinations, strongly detached hallucinations, all other translation pathologies, and correct translations (to make sure that our mitigation does not accidentaly ruin them). We apply all versions of the hallucination mitigation algorithm to these 600 sentences. Note that in a practical application, we would apply the mitigation techniques only to the translations labeled by a detection algorithm as potential hallucination. We simulate this later in Section 5.3.2 when performing manual annotation."
                ],
                "publication_ref": [
                    "b26"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Generation Strategies",
                "text": [
                    "To generate alternative hypotheses, Guerreiro et al. ( 2022) use Monte Carlo dropout (Gal and Ghahramani, 2016). This means they leave standard beam search inference intact and achieve variability in translations via activating model dropout at inference. A natural question is whether using other  generation strategies can give better results. For example, if we use e.g. beam search specifically designed to produce diverse translations, can we get better hypotheses?",
                    "To test this, we use the following methods:",
                    "\u2022 DEFAULT: standard decoding without reranking, i.e. beam search with size 5, where we pick only the top 1 candidate; \u2022 BEAM SEARCH: beam search with size n;",
                    "\u2022 sampling from the predicted distribution:",
                    "\u2022 SAMPLING: from the whole distribution;",
                    "\u2022 SAMPLING P=80: from the top p = 80% of the distribution, i.e. nucleus sampling (Holtzman et al., 2020); \u2022 diverse beam search:",
                    "\u2022 DBS_N: method by Vijayakumar et al.",
                    "(2016) with beam widths s = 1, 3, 10;",
                    "\u2022 D_DEC_R: diverse decoding with diversity rates r = 1, 3, 10 (Li et al., 2016); \u2022 Monte Carlo dropout:",
                    "\u2022 MC GREEDY: n iterations of greedy search with dropout;",
                    "\u2022 MC BEAM: the method used in Guerreiro et al. ( 2022), i.e. n iterations of beam search with dropout, each with size 10. Unless stated otherwise, n = 10 in all experiments."
                ],
                "publication_ref": [
                    "b10",
                    "b13"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "The Impact of Generation Strategy",
                "text": [
                    "The results are shown in Figure 5. To disentangle the effect of generation strategy from the subsequent reranker performance, we show the results for all combinations. As rerankers, we considered COMET-QE used in Guerreiro et al. (2022) and the methods proposed in Section 3.",
                    "We see that the MC BEAM method clearly outperforms all the other. This is interesting for two reasons. First, MC dropout is easy to use: one has to apply standard inference with dropout on with-out other changes to the implementation. Next, differently from modifying decoding strategies, here variability in hypotheses comes from model predictive uncertainty (Gal and Ghahramani, 2016;Zerva et al., 2021;Guerreiro et al., 2022). This is one more evidence that understanding model inner characteristics can be beneficial in various settings.",
                    "Based on these results, in what follows we generate hypotheses with beam search with MC dropout."
                ],
                "publication_ref": [
                    "b11",
                    "b10",
                    "b33",
                    "b11"
                ],
                "figure_ref": [
                    "fig_4"
                ],
                "table_ref": []
            },
            {
                "heading": "The Impact of Number of Hypotheses",
                "text": [
                    "We also check whether generating more than 10 hypotheses can improve the overall results. Figure 6 shows the final COMET scores depending on the number of hypotheses. We see that the scores increase with more hypotheses and do not saturate at 10. This implies that in cases when the quality of a translation is much more important than its computational cost, one can potentially improve the quality by generating more candidate hypotheses."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_5"
                ],
                "table_ref": []
            },
            {
                "heading": "Reranking Approaches",
                "text": [
                    "Apart from detecting hallucinations, the methods we propose can be applied as rerankers in the \"detect-than-rewrite\" pipeline."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Automatic Evaluation",
                "text": [
                    "Figure 5 shows that, regardless of the generation method, LaBSE is the best reranker and it performs notably better than the strong COMET-QE baseline. Apart from the average results, Table 2 also shows COMET scores for each pathology type. We can see that reranking with any method is better than no reranking for all groups of original translations. Compared to the COMET-QE baseline, LABSE improves the scores for hallucinations and correct translations, but drops quality for other pathologies.",
                    "The only internal method ALTI performs better than COMET-QE for fully detached hallucinations, but is inferior when looking at other translations: it Pathologies Cor. Avg. Reranker F."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_4"
                ],
                "table_ref": []
            },
            {
                "heading": "S. O.",
                "text": [
                    "No reranking -1.23 -0.97 -0.59 0.27 -0.63 Baseline COMET-QE -0.21 -0.13 -0.14 0.35 -0.03 Ours ALTI -0.17 -0.24 -0.39 0.25 -0.14 LASER -0.11 -0.23 -0.35 0.27 -0.11 LaBSE -0.07 -0.12 -0.26 0.39 -0.01 XNLI -0.12 -0.18 -0.28 0.30 -0.07 is very sensitive to the most severe pathology, but is not capable to rank relatively good translations. Note that for former pathologies, the average COMET scores are negative even after mitigation. As we saw in Figure 2, this may be normal even for correct translations, and may reflect the fact that, while being technically correct, they are far from being perfect."
                ],
                "publication_ref": [],
                "figure_ref": [
                    "fig_1"
                ],
                "table_ref": []
            },
            {
                "heading": "Human evaluation",
                "text": [
                    "Data. To confirm the results of automatic evaluation, we perform a human evaluation. With each method, we translate the same 200 source sentences. They are randomly sampled from the hallucination dataset with the distribution of pathologies roughly mimicking outputs of the best detectors (Figure 3). Overall, for 55% of the sentences their original translations are labeled as hallucinations, 25% as errors and 20% as correct translations. 9  We compare the original translations and three reranking methods: the baseline COMET-QE used in Guerreiro et al. ( 2022), the best overall reranker LaBSE, and the only internal method ALTI.",
                    "Annotation. For each of the 200 source sentence, we deduplicate and shuffle the four translations to mitigate annotator bias. The 602 resulting sentence pairs are labeled by 3 annotators into three categories: Correct, Error, and Hallucination. We aggregate the labels by majority vote; in case of ties (20 out of the 602 sentence pairs after deduplication) we pessimistically assume a hallucination. For hallucinations, all the differences are significant, except the one between ALTI vs COMET-QE. For correct translations, the difference between LaBSE and ALTI is statistically significant.",
                    "We evaluate the statistical significance of the pairwise differences in the proportions of correct and hallucinated translations using two-sided Student test for two related samples with 5% confidence level. We provide more details on the annotation guidelines and inter-annotation agreement in Appendix C.",
                    "Results. Human evaluation results are shown in Figure 7. All reranking methods reduce hallucinatory rate by a factor of 2.5 to 3. Interestingly, when looking at hallucinations, internal ALTI performs on par with COMET-QE: the differences between these two methods are not statistically significant. COMET-QE, however, has less errors. This is expected as it was trained to distinguish correct translations from errors. Coming to LaBSE, we find that it produces slightly less hallucinations than other reranking methods and more correct translations than ALTI; these differences are significant at 5% confidence level. Overall, by using sentence similarity from LaBSE, we improve both on hallucinations detection and mitigation at test time.",
                    "Surprisingly, LaBSE and ALTI outperform COMET-QE with a large margin for hallucination detection, but not for hypotheses reranking. As we explain in Section 4.2, quality estimation models are mostly trained on data that lacks negative examples. Therefore, COMETs may be inadequate at evaluating poor translations in general and hallucinations in particular (Takahashi et al., 2021;Sudoh et al., 2021;Guerreiro et al., 2022). For reranking, the goal is the opposite: finding the best translations (as opposed to the worst), which is closer to the COMET training objective.",
                    "Note that since COMET-QE is the state-of-theart quality estimator, it is a very strong baseline for the reranking stage where the goal is to find a better translation. The fact that we can match its hallucinatory rate reduction by analyzing model inner workings has value from different perspectives.",
                    "For research, it can motivate future work on model understanding; for practitioners, it means that hallucination mitigation is not limited to language pairs where external models such as COMET-QE exist: model understanding might be enough."
                ],
                "publication_ref": [
                    "b11"
                ],
                "figure_ref": [
                    "fig_2",
                    "fig_6"
                ],
                "table_ref": []
            },
            {
                "heading": "Conclusions",
                "text": [
                    "We start by asking how far we can go at detecting and mitigating hallucinations if we use nothing but the translation model itself. Turns out, we can improve the results of the overall \"detect-then-rewrite\" pipeline by evaluating the percentage of source contribution to a generated translation: translations with low source contribution are likely to be \"detached\" from the source, i.e. hallucinations. For detecting the most severe type of hallucinations, this method improves previous results twice; for mitigating hallucinations at test time, it matches the hallucination reduction rate of the previous best external method. We believe this can motivate future research on model analysis. When allowing external models, we expand the methods for handling hallucinations from models specialized for quality estimation to a broader set of objectives, e.g. sentence similarity from cross-lingual embeddings. Apart from showing that LaBSE improves previous results significantly, we also find that models so far overlooked in the context of machine translation (e.g. natural language inference) can be beneficial. We hope future work will build on this idea."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Limitations",
                "text": [
                    "Our analysis and conclusions have been based only on a single translation direction (German to English), a single dataset, and a single transformerbased model. The generalization to other languages, data and models is yet to be verified.",
                    "Even in this setup, we have seen that some of the proposed methods are very good at detecting fully detached hallucinations. However, none of them were able to well separate strongly detached hallucinations (when only a part of the generated translation is unrelated to the source) from correct translations. Perhaps, such partial hallucinations should be detected on the level of individual tokens instead of the whole sentence.",
                    "One of the metrics that we propose, average ALTI source contribution, has an advantage of not requiring any external models except the translation model itself. However, the two best detection metrics (based on LaBSE and on XNLI model) re-quire additional encoders trained on the source and target languages, which limits their applicability for lower-resourced languages or in the settings with limited computational resources.",
                    "Being an internal method is an advantage of ALTI, but it is also a limitation: this method is suitable only for transformer-based translation models. In principle, it can be adapted to other neural architectures, but not to non-neural approaches, such as statistical machine translation."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "Ethical statement",
                "text": [
                    "We do not foresee any considerable risks associated with our work. In principle, our framework for hallucination mitigation could be intentionally reversed to produce lower-quality translations. But there are easier ways to produce a bad translation, such as just sampling the output text randomly, so we do not think that our work poses any additional risks.",
                    "This work is based on the open source dataset and model released by Guerreiro et al. (2022) and thus inherits all their potential biases.",
                    "We will make our code publicly available to ensure reproducibility of our experiments."
                ],
                "publication_ref": [
                    "b11"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "A Implementation and computing",
                "text": [
                    "All our experiments were carried out on a single server with one NVIDIA Quadro GP100 GPU. The total computation time for generating and scoring translations was less than 24 hours.",
                    "To compute BLEU and ChrF++, we use the SacreBLEU package 10 with the default parameters. For COMET and COMET-QE, we use the COMET package 11 with the wmt20-comet-da and wmt20-comet-qe-da-v2 models, respectively. The translation hypotheses, Seq-Logprob, and LASER are computed using the Fairseq framework 12 . To compute ALTI+, we adapt the code 13 by Ferrando et al. (2022). For the inference of LaBSE and the XNLI model, we use the transformers package 14 ."
                ],
                "publication_ref": [
                    "b7"
                ],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "B Mitigating Hallucinations at Test Time",
                "text": [
                    "Table 3 shows XNLI scores after reranking MC dropout hypotheses by various methods. Note that since here XNLI was used both to rerank and well as evaluate quality, in the experiment XNLI can be viewed as an oracle."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_2"
                ]
            },
            {
                "heading": "C Manual Evaluation",
                "text": [
                    "In this appendix we describe the manual evaluation. First, we detail the simple guidelines that were presented to manual annotators. Second, we report the number of annotators and inter-annotation agreement. Third, we report the results of statistical sigificance tests for comparing all the methods.",
                    "Guidelines Annotators were provided with the guidelines shown in Table 4. For the reporting purposes, \"Partial hallucination\" was grouped together with \"Full hallucination\", and \"Undertranslation\" with \"Other\".",
                    "Inter-annotation agreement We evaluated interannotation agreement by Fleiss' Kappa. For the three annotators and the three aggregated labels, it equals 0.57 on the 602 sentence pairs that were labeled (with the 5 original labels, it is 0.55). This may be interpreted as moderate agreement.",
                    "The differences The Tables 5 and 6 compare proportions of correct and hallucinated translations for each of the manually evaluated methods. The Pvalues are computed with paired two-sided Student test (scipy.stats.ttest_rel).",
                    "Each row of the data consists of the German source sentence, its reference English translation (it is not always accurate!), and 1 to 4 machine translation outputs. The machine translation outputs are presented in a random order, to exclude the possibility of bias toward any specific method.",
                    "For each of the machine translations, you need to assign one of the following labels:",
                    "\u2022 OK: An acceptable translation; it conveys the main meaning correctly and does not introduce extra meaning. Some details still may differ, and minor errors are acceptable.",
                    "\u2022 Partial hallucination: a part of the translation is unrelated to the source, or is related very indirectly, such as via a common topic.",
                    "\u2022 Full hallucination: most or all of the translation is unrelated to the source, or is related very indirectly.",
                    "\u2022 Undertranslation: there is no hallucinations, but a significant part of the source is not translated at all.",
                    "\u2022 Other: there are no hallucinations or undertranlsations, but there are other translation errors that make the translation unacceptable. "
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": [
                    "tab_3",
                    "tab_5"
                ]
            },
            {
                "heading": "",
                "text": [
                    "We used a translation model and a dataset described in section 2 B1. Did you cite the creators of artifacts you used?",
                    "Yes, in section 2 B2. Did you discuss the license or terms for use and / or distribution of any artifacts?",
                    "No, the license is included in the reference to the authors B3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided that it was specified? For the artifacts you create, do you specify intended use and whether that is compatible with the original access conditions (in particular, derivatives of data accessed for research purposes should not be used outside of research contexts)? Yes (for the existing artifacts), in section 1 and 2 B4. Did you discuss the steps taken to check whether the data that was collected / used contains any information that names or uniquely identifies individual people or offensive content, and the steps taken to protect / anonymize it? No personal information that we are aware of B5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and linguistic phenomena, demographic groups represented, etc.? it was not provided in the original paper B6. Did you report relevant statistics like the number of examples, details of train / test / dev splits, etc. for the data that you used / created? Even for commonly-used benchmark datasets, include the number of examples in train / validation / test splits, as these provide necessary context for a reader to understand experimental results. For example, small differences in accuracy on large test sets may be significant, while on small test sets they may not be. Sections 4 and 5"
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            },
            {
                "heading": "C Did you run computational experiments?",
                "text": [
                    "Sections 4 and 5 C1. Did you report the number of parameters in the models used, the total computational budget (e.g., GPU hours), and computing infrastructure used? We did not train any models. The infrastructure is reported in Appendix A.",
                    "The Responsible NLP Checklist used at ACL 2023 is adopted from NAACL 2022, with the addition of a question on AI writing assistance.",
                    "C2. Did you discuss the experimental setup, including hyperparameter search and best-found hyperparameter values? Sections 4 and 5.",
                    "C3. Did you report descriptive statistics about your results (e.g., error bars around results, summary statistics from sets of experiments), and is it transparent whether you are reporting the max, mean, etc. or just a single run? For the manual annotations, we compute statistical significance of all the differences in the averages in the Appendix C.",
                    "C4. If you used existing packages (e.g., for preprocessing, for normalization, or for evaluation), did you report the implementation, model, and parameter settings used (e.g., NLTK, Spacy, ROUGE, etc.)? Appendix A D Did you use human annotators (e.g., crowdworkers) or research with human participants? section 5 D1. Did you report the full text of instructions given to participants, including e.g., screenshots, disclaimers of any risks to participants or annotators, etc.? appendix C D2. Did you report information about how you recruited (e.g., crowdsourcing platform, students) and paid participants, and discuss if such payment is adequate given the participants' demographic (e.g., country of residence)?",
                    "The annotators were members of our team and did the job within their normal working hours.",
                    "D3. Did you discuss whether and how consent was obtained from people whose data you're using/curating? For example, if you collected data via crowdsourcing, did your instructions to crowdworkers explain how the data would be used? Not applicable. We used an existing published dataset.",
                    "D4. Was the data collection protocol approved (or determined exempt) by an ethics review board?",
                    "We did not collect any data, except of annotating an already existing dataset D5. Did you report the basic demographic and geographic characteristics of the annotator population that is the source of the data? Left blank."
                ],
                "publication_ref": [],
                "figure_ref": [],
                "table_ref": []
            }
        ],
        "references": [
            {
                "ref_id": "b0",
                "title": "Massively multilingual sentence embeddings for zeroshot cross-lingual transfer and beyond",
                "journal": "Transactions of the Association for Computational Linguistics",
                "year": "2019",
                "authors": "Mikel Artetxe; Holger Schwenk"
            },
            {
                "ref_id": "b1",
                "title": "Naver labs Europe's systems for the WMT19 machine translation robustness task",
                "journal": "Association for Computational Linguistics",
                "year": "2019",
                "authors": "Alexandre Berard; Ioan Calapodescu; Claude Roux"
            },
            {
                "ref_id": "b2",
                "title": "Findings of the 2018 conference on machine translation (WMT18)",
                "journal": "",
                "year": "2018",
                "authors": "Ond\u0159ej Bojar; Christian Federmann; Mark Fishel; Yvette Graham; Barry Haddow"
            },
            {
                "ref_id": "b3",
                "title": "Unsupervised cross-lingual representation learning at scale",
                "journal": "",
                "year": "2020",
                "authors": "Alexis Conneau; Kartikay Khandelwal; Naman Goyal; Vishrav Chaudhary; Guillaume Wenzek; Francisco Guzm\u00e1n; Edouard Grave; Myle Ott; Luke Zettlemoyer; Veselin Stoyanov"
            },
            {
                "ref_id": "b4",
                "title": "Xnli: Evaluating crosslingual sentence representations",
                "journal": "",
                "year": "2018",
                "authors": "Alexis Conneau; Ruty Rinott; Guillaume Lample; Adina Williams; Samuel R Bowman; Holger Schwenk; Veselin Stoyanov"
            },
            {
                "ref_id": "b5",
                "title": "Language-agnostic BERT sentence embedding",
                "journal": "Long Papers",
                "year": "2022",
                "authors": "Fangxiaoyu Feng; Yinfei Yang; Daniel Cer; Naveen Arivazhagan; Wei Wang"
            },
            {
                "ref_id": "b6",
                "title": "Quality-aware decoding for neural machine translation",
                "journal": "",
                "year": "2022",
                "authors": "Patrick Fernandes; Ant\u00f3nio Farinhas; Ricardo Rei; Jos\u00e9 De Souza; Perez Ogayo; Graham Neubig; Andre Martins"
            },
            {
                "ref_id": "b7",
                "title": "Towards opening the black box of neural machine translation: Source and target interpretations of the transformer",
                "journal": "UAE. Association for Computational Linguistics",
                "year": "2022",
                "authors": "Javier Ferrando; Gerard I G\u00e1llego; Belen Alastruey; Carlos Escolano; Marta R Costa-Juss\u00e0"
            },
            {
                "ref_id": "b8",
                "title": "Multi-hypothesis machine translation evaluation",
                "journal": "Online. Association for Computational Linguistics",
                "year": "2020",
                "authors": "Marina Fomicheva; Lucia Specia; Francisco Guzm\u00e1n"
            },
            {
                "ref_id": "b9",
                "title": "Alon Lavie, and Ond\u0159ej Bojar. 2021. Results of the WMT21 metrics shared task: Evaluating metrics with expert-based human evaluations on TED and news domain",
                "journal": "",
                "year": "",
                "authors": "Markus Freitag; Ricardo Rei; Nitika Mathur; Chi-Kiu Lo; Craig Stewart; George Foster"
            },
            {
                "ref_id": "b10",
                "title": "Dropout as a bayesian approximation: Representing model uncertainty in deep learning",
                "journal": "",
                "year": "2016",
                "authors": "Yarin Gal; Zoubin Ghahramani"
            },
            {
                "ref_id": "b11",
                "title": "Looking for a needle in a haystack: A comprehensive study of hallucinations in neural machine translation",
                "journal": "",
                "year": "2022",
                "authors": "M Nuno; Elena Guerreiro;  Voita; F T Andr\u00e9"
            },
            {
                "ref_id": "b12",
                "title": "Bitext mining using distilled sentence representations for low-resource languages",
                "journal": "",
                "year": "2022",
                "authors": "Kevin Heffernan; Onur \u00c7elebi; Holger Schwenk"
            },
            {
                "ref_id": "b13",
                "title": "The curious case of neural text degeneration",
                "journal": "",
                "year": "2020",
                "authors": "Ari Holtzman; Jan Buys; Li Du; Maxwell Forbes; Yejin Choi"
            },
            {
                "ref_id": "b14",
                "title": "Yejin Bang, Andrea Madotto, and Pascale Fung. 2022. Survey of hallucination in natural language generation",
                "journal": "",
                "year": "",
                "authors": "Ziwei Ji; Nayeon Lee; Rita Frieske; Tiezheng Yu; Dan Su; Yan Xu; Etsuko Ishii"
            },
            {
                "ref_id": "b15",
                "title": "Hitokazu Matsushita, and Arul Menezes. 2021. To ship or not to ship: An extensive evaluation of automatic metrics for machine translation",
                "journal": "",
                "year": "",
                "authors": "Tom Kocmi; Christian Federmann; Roman Grundkiewicz; Marcin Junczys-Dowmunt"
            },
            {
                "ref_id": "b16",
                "title": "Clara Fannjiang, and David Sussillo. 2019. Hallucinations in neural machine translation",
                "journal": "",
                "year": "",
                "authors": "Katherine Lee; Orhan Firat; Ashish Agarwal"
            },
            {
                "ref_id": "b17",
                "title": "A simple, fast diverse decoding algorithm for neural generation",
                "journal": "",
                "year": "2016",
                "authors": "Jiwei Li; Will Monroe; Dan Jurafsky"
            },
            {
                "ref_id": "b18",
                "title": "Results of the WMT20 metrics shared task",
                "journal": "Association for Computational Linguistics",
                "year": "2020",
                "authors": "Nitika Mathur; Johnny Wei; Markus Freitag; Qingsong Ma; Ond\u0159ej Bojar"
            },
            {
                "ref_id": "b19",
                "title": "Domain robustness in neural machine translation",
                "journal": "",
                "year": "2020",
                "authors": "Mathias M\u00fcller; Annette Rios; Rico Sennrich"
            },
            {
                "ref_id": "b20",
                "title": "Understanding the properties of minimum Bayes risk decoding in neural machine translation",
                "journal": "",
                "year": "2021",
                "authors": "Mathias M\u00fcller; Rico Sennrich"
            },
            {
                "ref_id": "b21",
                "title": "fairseq: A fast, extensible toolkit for sequence modeling",
                "journal": "Association for Computational Linguistics",
                "year": "2019",
                "authors": "Myle Ott; Sergey Edunov; Alexei Baevski; Angela Fan; Sam Gross; Nathan Ng; David Grangier; Michael Auli"
            },
            {
                "ref_id": "b22",
                "title": "chrF++: words helping character n-grams",
                "journal": "",
                "year": "2017",
                "authors": "Maja Popovi\u0107"
            },
            {
                "ref_id": "b23",
                "title": "The curious case of hallucinations in neural machine translation",
                "journal": "Online. Association for Computational Linguistics",
                "year": "2021",
                "authors": "Vikas Raunak; Arul Menezes; Marcin Junczys-Dowmunt "
            },
            {
                "ref_id": "b24",
                "title": "Salted: A framework for salient long-tail translation error detection",
                "journal": "",
                "year": "2022",
                "authors": "Vikas Raunak; Matt Post; Arul Menezes"
            },
            {
                "ref_id": "b25",
                "title": "COMET: A neural framework for MT evaluation",
                "journal": "Online. Association for Computational Linguistics",
                "year": "2020",
                "authors": "Ricardo Rei; Craig Stewart; Ana C Farinha; Alon Lavie"
            },
            {
                "ref_id": "b26",
                "title": "Unbabel's participation in the WMT20 metrics shared task",
                "journal": "Association for Computational Linguistics",
                "year": "2020",
                "authors": "Ricardo Rei; Craig Stewart; Ana C Farinha; Alon Lavie"
            },
            {
                "ref_id": "b27",
                "title": "Is this translation error critical?: Classification-based human and automatic machine translation evaluation focusing on critical errors",
                "journal": "Online. Association for Computational Linguistics",
                "year": "2021",
                "authors": "Katsuhito Sudoh; Kosuke Takahashi; Satoshi Nakamura"
            },
            {
                "ref_id": "b28",
                "title": "Multilingual machine translation evaluation metrics fine-tuned on pseudonegative examples for wmt 2021 metrics task",
                "journal": "Online. Association for Computational Linguistics",
                "year": "2021",
                "authors": "Kosuke Takahashi; Yoichi Ishibashi; Katsuhito Sudoh; Satoshi Nakamura"
            },
            {
                "ref_id": "b29",
                "title": "Attention is all you need",
                "journal": "Curran Associates, Inc",
                "year": "2017",
                "authors": "Ashish Vaswani; Noam Shazeer; Niki Parmar; Jakob Uszkoreit; Llion Jones; Aidan N Gomez; Illia Kaiser;  Polosukhin"
            },
            {
                "ref_id": "b30",
                "title": "Diverse beam search: Decoding diverse solutions from neural sequence models",
                "journal": "",
                "year": "2016",
                "authors": "K Ashwin; Michael Vijayakumar;  Cogswell; R Ramprasath; Qing Selvaraju; Stefan Sun; David Lee; Dhruv Crandall;  Batra"
            },
            {
                "ref_id": "b31",
                "title": "Analyzing the source and target contributions to predictions in neural machine translation",
                "journal": "Long Papers",
                "year": "2021",
                "authors": "Elena Voita; Rico Sennrich; Ivan Titov"
            },
            {
                "ref_id": "b32",
                "title": "On exposure bias, hallucination and domain shift in neural machine translation",
                "journal": "Online. Association for Computational Linguistics",
                "year": "2020",
                "authors": "Chaojun Wang; Rico Sennrich"
            },
            {
                "ref_id": "b33",
                "title": "IST-unbabel 2021 submission for the quality estimation shared task",
                "journal": "",
                "year": "2021",
                "authors": "Chrysoula Zerva; Ricardo Daan Van Stigt; Ana C Rei; Pedro Farinha;  Ramos; G C Jos\u00e9; Taisiya De Souza; Miguel Glushkova; Fabio Vera; Andr\u00e9 F T Kepler;  Martins"
            },
            {
                "ref_id": "b34",
                "title": "Detecting hallucinated content in conditional neural sequence generation",
                "journal": "Online. Association for Computational Linguistics",
                "year": "2021",
                "authors": "Chunting Zhou; Graham Neubig; Jiatao Gu; Mona Diab; Francisco Guzm\u00e1n; Luke Zettlemoyer; Marjan Ghazvininejad"
            }
        ],
        "figures": [
            {
                "figure_label": "1",
                "figure_type": "figure",
                "figure_id": "fig_0",
                "figure_caption": "Figure 1 :1Figure 1: Taxonomy of translation types (based on the dataset by Guerreiro et al. (2022)).",
                "figure_data": ""
            },
            {
                "figure_label": "2",
                "figure_type": "figure",
                "figure_id": "fig_1",
                "figure_caption": "Figure 2 :2Figure 2: Kernel density estimation of the distribution of the detection criteria by translation pathology type.For each method, the X axis shows the values of the criterion (higher are better), and the Y axis shows the density.",
                "figure_data": ""
            },
            {
                "figure_label": "3",
                "figure_type": "figure",
                "figure_id": "fig_2",
                "figure_caption": "Figure 3 :3Figure 3: Distribution of translation types when selecting the worst 10% of the dataset according to each metric. While in the original dataset the annotations are multilabel (e.g. a translation could be annotated both as oscillatory hal. and as a NE error), we label with the most severe pathology type (with severity increasing clockwise from \"Correct\" to \"Fully detached\").",
                "figure_data": ""
            },
            {
                "figure_label": "4",
                "figure_type": "figure",
                "figure_id": "fig_3",
                "figure_caption": "Figure 4 :4Figure 4: Recalls by translation types when selecting the worst 20% of the dataset according to each metric.Here, the types are presented in a multilabel manner, i.e. one translation may contribute to multiple axes.",
                "figure_data": ""
            },
            {
                "figure_label": "5",
                "figure_type": "figure",
                "figure_id": "fig_4",
                "figure_caption": "Figure 5 :5Figure 5: For all combinations of a generation strategy and a reranker, heatmaps show scores for the final translations (darker is better).",
                "figure_data": ""
            },
            {
                "figure_label": "6",
                "figure_type": "figure",
                "figure_id": "fig_5",
                "figure_caption": "Figure 6 :6Figure 6: COMET scores for each generation method and number of hypotheses. For each group of generation strategies, we show the best representative.",
                "figure_data": ""
            },
            {
                "figure_label": "7",
                "figure_type": "figure",
                "figure_id": "fig_6",
                "figure_caption": "Figure 7 :7Figure 7: Human annotation results: percentages of translation pathologies for different reranking methods.For hallucinations, all the differences are significant, except the one between ALTI vs COMET-QE. For correct translations, the difference between LaBSE and ALTI is statistically significant.",
                "figure_data": ""
            },
            {
                "figure_label": "2",
                "figure_type": "table",
                "figure_id": "tab_1",
                "figure_caption": "Average COMET scores (\u2191) after reranking MC dropout hypotheses by various methods. Pathologies: fully detached hallucinations (F.), strongly detached hallucinations (S.), other pathologies (O.). See Table3in the appendix for XNLI scores.",
                "figure_data": ""
            },
            {
                "figure_label": "3",
                "figure_type": "table",
                "figure_id": "tab_2",
                "figure_caption": "Average XNLI scores after reranking MC dropout hypotheses by various methods. Pathologies: fully detached hallucinations (F.), strongly detached hallucinations (S.), other pathologies (O.).",
                "figure_data": "RerankerPathologies Correct Avg. F. S. O.No reranking2 30 809351Baseline COMET-QE59 69 859377Ours ALTI64 73 929180LASER72 73 929282LaBSE74 80 929485XNLI (oracle) 75 83 989788"
            },
            {
                "figure_label": "4",
                "figure_type": "table",
                "figure_id": "tab_3",
                "figure_caption": "Human annotations Guidelines",
                "figure_data": "Method 1Method 2Rate 1 Rate 2 P-valueLABSE LABSE LABSE COMET-QE ALTI COMET-QE ALTI Default COMET-QE Default ALTI Default0.56 0.56 0.56 0.54 0.54 0.490.54 0.49 0.20 0.49 0.20 0.200.53 0.02 0.00 0.12 0.00 0.00"
            },
            {
                "figure_label": "5",
                "figure_type": "table",
                "figure_id": "tab_4",
                "figure_caption": "Comparison between manually annotated rates of correct translation.",
                "figure_data": "Method 1Method 2Rate 1 Rate 2 P-valueLABSE LABSE LABSE COMET-QE ALTI COMET-QE ALTI Default COMET-QE Default ALTI Default0.16 0.16 0.16 0.22 0.22 0.220.22 0.22 0.53 0.22 0.53 0.530.01 0.01 0.00 1.00 0.00 0.00"
            },
            {
                "figure_label": "6",
                "figure_type": "table",
                "figure_id": "tab_5",
                "figure_caption": "Comparison between manually annotated rates of hallucinated translation.",
                "figure_data": ""
            }
        ],
        "formulas": [],
        "doi": "10.1162/tacl_a_00288"
    }
}