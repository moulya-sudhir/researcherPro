{
    "title": "Chinese Lexical Substitution: Dataset and Method",
    "authors": "Jipeng Qiang; Kang Liu; Ying Li; Yun Li; Yi Zhu; Yunhao Yuan; Xiaocheng Hu; Xiaoye Ouyang",
    "pub_date": "",
    "abstract": "Existing lexical substitution (LS) benchmarks were collected by asking human annotators to think of substitutes from memory, resulting in benchmarks with limited coverage and relatively small scales. To overcome this problem, we propose a novel annotation method to construct an LS dataset based on human and machine collaboration. Based on our annotation method, we construct the first Chinese LS dataset CHNLS which consists of 33,695 instances and 144,708 substitutes, covering three text genres (News, Novel, and Wikipedia). Specifically, we first combine four unsupervised LS methods as an ensemble method to generate the candidate substitutes, and then let human annotators judge these candidates or add new ones. This collaborative process combines the diversity of machine-generated substitutes with the expertise of human annotators. Experimental results that the ensemble method outperforms other LS methods. To our best knowledge, this is the first study for the Chinese LS task.",
    "sections": [
        {
            "heading": "Introduction",
            "text": [
                "Lexical substitution (LS) aims at finding appropriate substitutes for a target word in a sentence, which can be used as a backbone of various NLP applications such as writing assistance (Lee et al., 2021;Qiang et al., 2023a), word sense disambiguation (McCarthy, 2002), and lexical simplification (Paetzold and Specia, 2016;Qiang et al., 2021a,b). For instance, when presented with the sentence \"I read an amazing paper today\", we aim to select a more descriptive adjective to substitute the word \"amazing\". While options such as \"awesome\" and \"great\" may readily come to mind, it proves arduous for us to conceive of equally fitting alternatives such as \"incredible\" and \"fascinating\". Despite extensive research conducted on Lexical Substitution (LS) in various languages, including * Corresponding author.",
                "English (Hassan et al., 2007;Yuret, 2007;Melamud et al., 2015b;Lee et al., 2021;Qiang et al., 2023b), German (Hintz andBiemann, 2015, 2016), Italian (Toral, 2009), and Croatian (Alagi\u0107 and \u0160najder, 2017), Chinese LS has received limited attention. In this paper, we address this gap by focusing on the Chinese LS task.",
                "To enable the development and evaluation of effective Chinese LS methods, a large-scale dataset is intuitively important. Existing widely used English LS benchmarks, LS07 (McCarthy and Navigli, 2007), CoInCo (Kremer et al., 2014), and SwordS (Lee et al., 2021), were collected by asking human annotators to think of substitutes from memory. The annotation method has the following two problems.",
                "(1) Limited Coverage: Human annotators may have limitations in recalling a comprehensive range of potential substitutes for a given target word, potentially overlooking less common or domainspecific substitutes (Liu et al., 2022). Much work (Lee et al., 2021;Qiang et al., 2023b) have also pointed out the lack of coverage of existing LS datasets. For example, the data collection strategy used in the existing benchmarks might contain words like \"awesome\" and \"great\", but miss words like \"incredible\" and \"fascinating\".",
                "(2) High cost: Annotating lexical substitutes for target words in sentences is a time-consuming and labor-intensive task. It requires human annotators to carefully consider suitable substitutes, taking into account various linguistic and contextual factors. Due to the complexity of the task, annotating a large number of instances becomes challenging within a reasonable timeframe and budget. Consequently, widely used English LS datasets such as LS07, CoInCo, and SwordS comprise a mere 2,010, 2,474, and 1,250 instances, respectively.",
                "To address these challenges, we propose a novel annotation method to construct an LS dataset based on human and machine collaboration. Firstly, we propose an ensemble method that leverages four different unsupervised LS methods to automatically generate substitutes. Automated methods can quickly generate a vast pool of potential substitutes, reducing the burden on human annotators. Secondly, we let human annotators assess the suitability of these alternatives as substitutes. Additionally, we request annotators to suggest new alternatives that are not present in the machine-generated options. This collaborative process harnesses the expertise of human annotators while leveraging the efficiency and scalability of machine-generated candidates. This efficiency allows for the creation of a larger dataset within a reasonable budget.",
                "The annotation method is motivated by the following two findings:",
                "(1) Machine-generated LS methods can introduce a greater diversity of substitutes. By leveraging computational techniques like word embeddings, language models, or paraphrasing models, a wide range of plausible substitutes can be generated. This diversity enriches the dataset by providing a variety of substitution options, capturing different semantic relationships and syntactic patterns.",
                "(2) Assessing the suitability of these substitutes is much simpler for the annotator compared to generating a substitute from memory. Human annotators can focus on selecting the most appropriate substitutes from the machine-generated pool, ensuring high-quality and contextually relevant annotations.",
                "In summary, our contributions are listed below:",
                "(1) We provide a novel approach to construct an LS dataset based on human and machine collaboration. Our approach provides a good idea for constructing large-scale, high-coverage LS datasets. Based on our designing method, we construct the first large-scale Chinese LS dataset CHNLS that consists of 33,695 instances, which cover different text genres, namely News, Novel, and Wikipedia articles. Correspondingly, the latest English LS dataset only contains 1,250 instances.",
                "(2) We present four Chinese LS methods (dictionary-based, embedding-based, BERT-based, and paraphraser-based) by adjusting current English LS methods, and give an ensemble method that combines the four methods. Experimental results on CHNLS show that the ensemble method can be served as a strong baseline for future studies.",
                "The dataset and code is available at github 1 ."
            ],
            "publication_ref": [
                "b11",
                "b21",
                "b14",
                "b20",
                "b5",
                "b28",
                "b18",
                "b11",
                "b23",
                "b26",
                "b0",
                "b15",
                "b8",
                "b11",
                "b13",
                "b11",
                "b23"
            ],
            "figure_ref": [],
            "table_ref": []
        },
        {
            "heading": "Related Work",
            "text": [
                "Lexical Substitution Resources. Existing lexical substitution (LS) datasets are available for various languages, including English and other languages. Each instance in LS dataset is composed of a sentence, a target word, and corresponding substitutes.",
                "In English, the first LS dataset from SemEval 2007 (LS07) (McCarthy and Navigli, 2007), consists of 300 development and 1,710 test instances for 201 polysemous words. For each target word, 10 sentences are provided. The annotators' task deployed by Amazon Mechanical Turk was to give up to 3 possible substitutes. Afterward, Biemnann (Biemann, 2012) created a large-scale dataset (TWSI) that annotates 25K sentences from Wikipedia, which, however, only covers noun targets. To alleviate this limitation, Kremer et al. (Kremer et al., 2014) proposed Concept In Context (ConInCo), a dataset of 2,474 sentences covering 3,874 distinct targets with different part-of-speech tags, which is the current largest LS benchmark. It consists of 15K target instances with a given 35% development and 65% test. Recently, Stanford Word Substitution Benchmark (SwordS) (Lee et al., 2021) is built on CoInCo by asking human annotators for higher coverage and higher quality. SwordS consists of 1250 instances with a given 417 development and 833 test. Considering the size of vocabulary in English, the size of the vocabulary covered by LS datasets is too small. Additionally, we found that many appropriate substitutes for many instances in SwordS are missing, since human annotators frequently utilize repetitive patterns to fabricate instances, leading to a lack of linguistic diversity (Liu et al., 2022).",
                "The German LS dataset from GermEval 2015 consists of 2,040 instances from the German Wikipedia, which contains 153 unique target words. Italian LS dataset from EVALITA 2009 consists of 2,310 instances, which contains 231 unique target words. All the above LS datasets in all languages are constructed by human annotators. Due to their relatively small size, all of these datasets can only be used for evaluation and not for training. Unfortunately, research on Chinese LS is still scarce: to the best of our knowledge, there is currently no publicly available LS corpora for training, even lacking a dataset to evaluate the ability of LS models.",
                "Figure 1: The overview of our approach for building Chinese LS corpus. Our approach is composed of two phrases: machine-generated substitution and manual annotation. The phase of machine-generated substitution combines four different LS methods as an ensemble method to generate the pseudo substitutes. The phase of manual annotation utilizes native Chinese annotators to judge the pseudo substitutes and add new substitutes.",
                "Lexical Substitution. LS methods can be divided into four types: (1) dictionary-based method (Hassan et al., 2007;Yuret, 2007), (2) Embeddingbased method (Melamud et al., 2015a,b), (3) BERT-based method (Zhou et al., 2019;Lacerra et al., 2021a;Michalopoulos et al., 2022), and (4) Paraphraser-based method (Qiang et al., 2023c,b).",
                "The early lexical substitution studies obtain synonyms by searching linguistic resources, such as WordNet. Embedding-based methods utilize word embedding modelings to obtain highly similar words as the substitutions. Since 2019, LS methods based on pretrained language models have attracted much attention (Zhou et al., 2019;Lacerra et al., 2021a;Michalopoulos et al., 2022), in which pretrained BERT is most used. Zhou et al. (Zhou et al., 2019) apply dropout to the embeddings of target words for partially obscuring the word, and obtain a probability distribution over the BERT output vocabulary. Arefyev et al. (Arefyev et al., 2020) present a comparative study of popular pretrained language models, such as ELMo, BERT, and XL-Net. Lacerra et al. (Lacerra et al., 2021b) first merge the development set of two LS datasets (Co-InCo and TWSI), and split it into training and development sets for fine-tuning the encoder-decoder framework. Michalopoulos et al. (Michalopoulos et al., 2022) propose a new mix-up embedding strategy by incorporating the knowledge of Word-Net into the prediction process of BERT. Recently, Qiang et al (Qiang et al., 2023b) propose a method ParaLS that utilizes a pretrained paraphraser to generate the substitutes. Compared to language modeling, paraphraser produces fluent, meaningpreserving paraphrases but contain variations in word choice. ParaLS achieves good results and is considered the state-out-of-art LS method."
            ],
            "publication_ref": [
                "b15",
                "b2",
                "b8",
                "b11",
                "b13",
                "b5",
                "b28",
                "b30",
                "b9",
                "b19",
                "b30",
                "b9",
                "b19",
                "b30",
                "b10",
                "b19",
                "b23"
            ],
            "figure_ref": [],
            "table_ref": []
        },
        {
            "heading": "Creating CHNLS",
            "text": [
                "In this section, we describe our method to build an LS dataset, and the overall architecture for constructing the Chinese LS corpus is illustrated in Figure 1."
            ],
            "publication_ref": [],
            "figure_ref": [],
            "table_ref": []
        },
        {
            "heading": "Data Preparation",
            "text": [
                "In this step, we extract the sentences and the corresponding target words. To ensure diversity and complexity in our dataset, we utilize three distinct text genres: News, Novel, and Wiki. The News category is sourced from the contents of People's Daily, Wiki consists of articles from Wikipedia (encyclopedia), and the Novel category comprises selected Chinese-published novels. By incorporating multiple sources, we aim to capture the richness and intricacy of the Chinese language.",
                "To refine the dataset, we apply a filtering process to eliminate excessively short or long sentences based on their word count. For each sentence, we further segment it into words, considering nouns, verbs, adjectives, and adverbs as the target words for our analysis."
            ],
            "publication_ref": [],
            "figure_ref": [],
            "table_ref": []
        },
        {
            "heading": "Machine-generated Substitution",
            "text": [
                "Considering the sentence w 1 , w 2 , ..., tw, ..., w n containing the target word tw, we employ LS methods to generate a set of 15 pseudo substitutes for each target word. To foster a broader range of substitutes, we adopt an ensemble approach that combines four distinct LS methods: Dictionary-based, Embedding-based, BERT-based, and Paraphraserbased. By leveraging these diverse methods, each of which taps into different semantic knowledge, we aim to enhance the overall diversity of substitutes available for consideration.",
                "Typically, LS methods encompass two essential steps: substitute generation and substitute ranking. The initial objective of substitute generation is to identify and produce potential alternatives that can effectively replace a target word within a given sentence. Once a set of substitute candidates is generated, the subsequent task of substitute ranking comes into play, aiming to ascertain the most appropriate substitute for the target word within the specific sentence.",
                "Substitute Generation. We present four baseline approaches by adapting existing English LS methods:",
                "(1) Dict-based: The dictionary-based method relies on a synonym thesaurus (HIT-Cilin (Mei et al., 1996)) to generate the candidate substitutes.",
                "(2) Embedding-based: The embedding-based method selects substitutes with the highest similarities from word embedding models (Li et al., 2018). Substitutes are chosen based on their proximity, as determined by cosine similarity, to the target word.",
                "(3) BERT-based: The BERT-based method (Qiang et al., 2021b) utilizes Chinese BERT modeling 2 and masks the target word for prediction.",
                "(4) Paraphraser-based: The Paraphraser-based method (Qiang et al., 2023b) leverages a pretrained paraphrase model to generate substitutes. By inputting the sentence into the encoder of the para-phrase model, substitutes are generated using a special decoding strategy that focuses exclusively on the lexical variations of the target word.",
                "Given the absence of a suitable Chinese paraphraser and a sufficiently large-scale paraphrase corpus, we take the initiative to construct a comprehensive Chinese paraphrase corpus. This corpus is then utilized to fine-tune a pretrained Chinese BART model 3 , enhancing its effectiveness for paraphrase generation.",
                "To construct a paraphrase corpus, we leverage a large-scale bilingual English-Chinese translation corpus. The construction process entails the following steps:",
                "(1) Gathering the machine translation corpus: We select a Chinese-English corpus consisting of 5.2 million sentence pairs 4 as our primary source.",
                "(2) Aligning sentence pairs: We utilize a Chinese translator 5 to translate the English sentences into Chinese, thus creating aligned sentence pairs representing paraphrases.",
                "(3) Identifying potential paraphrases: By comparing the aligned sentence pairs, we identify pairs that convey similar or identical meanings while being expressed differently. These pairs serve as potential paraphrases.",
                "(4) Filtering and cleaning paraphrase pairs: We apply filters to remove unsuitable sentence pairs for paraphrase generation. For instance, we exclude pairs with significant length differences, pairs containing mistranslations, or pairs exhibiting inconsistencies.",
                "Through these steps, we construct a high-quality paraphrase corpus that can be used for various natural language processing tasks, including paraphrase generation and LS.",
                "Substitute Ranking. The effectiveness of text generation metrics for substitute ranking has been demonstrated in previous work (Qiang et al., 2023b). Therefore, we employ the BARTScore (Yuan et al., 2021) and BERTScore (Zhang et al., 2019) metrics for substitute ranking. To perform this ranking, we replace the target word in the original sentence with each substitute candidate, thereby creating an updated version of the sentence.",
                "BARTScore leverages pre-trained BART models to calculate the similarity between the original sentence and the updated sentence. BARTScore considers various aspects of text quality, including fluency, grammaticality, and semantic similarity.",
                "BERTScore utilizes pre-trained BERT models to measure the similarity between the original sentence and the updated sentence. BERTScore has shown a strong correlation with human judgments and has been widely used for evaluating text generation tasks.",
                "Finally, our ranking method employs a linear combination of the scores of BARTScore and BERTScore to compute the final score for each candidate substitute. They consider different aspects of text quality and provide comprehensive measures to rank the substitutes based on their similarity to the reference word. By incorporating these metrics, the ranking process can be more robust and accurate, leading to an improved selection of suitable substitutes in lexical substitution tasks.",
                "A ensemble Method. The aforementioned four LS methods utilize substitute generate and substitute ranking to generate 15 substitutes separately for each method. Specifically, the substitutes generated by Dictionary-based, Embeddingbased, BERT-based, and  Taking into consideration that each LS method generates 15 substitutes, the utilization of four LS methods results in a total of 60 candidate substitutes. To avoid overwhelming the annotators and incurring additional costs, as well as to prevent annotator fatigue, we need to limit the number of substitutes for annotation.",
                "To achieve this, we propose a simple ensemble method that combines the above four methods. We assigned voting weights of 1 to Dict-based, Embedding-based, BERT-based, and paraphraserbased methods individually. We select the top 15 candidate substitutes with the highest votes, denoted as {c 1 , c 2 , ..., c 15 }, as pseudo substitutes. This selection process ensures that the substitutes generated by multiple methods are more likely to be chosen as potential substitutes."
            ],
            "publication_ref": [
                "b16",
                "b12",
                "b24",
                "b23",
                "b23",
                "b27",
                "b29"
            ],
            "figure_ref": [],
            "table_ref": []
        },
        {
            "heading": "Manual Annotation",
            "text": [
                "Given the sentence and target word pairs, as well as the corresponding 15 pseudo substitutes {c 1 , c 2 , ..., c 15 }, we engage multiple annotators for annotation. It is noteworthy that all the annotators involved in this process are native Chinese under- graduates.",
                "We have created a specialized website for annotating data. On each page of the website, a sentence is presented with a highlighted target word, along with 15 pseudo substitutes for that target word. Additionally, there is an option to add new substitutes that are not included among the pseudo-substitutes.",
                "For each pseudo substitute, there are two radio buttons labeled \"positive\" and \"negative.\" The annotators' task was to select \"positive\" if they considered the substitute to be a suitable replacement for the target word within the given sentence. Conversely, they were to choose \"negative\" if they determined that the substitute would not be appropriate.",
                "To encourage annotators to contribute new substitutes, we offer higher compensation for providing new substitutes that are not included among the pseudo-substitutes. During the annotation process, each sentence and target word pair in the dataset is annotated three times. The final substitutes are selected from the newly added substitutes and the pseudo-substitutes that have been marked at least once.",
                "We conducted a pilot test with one annotator, and they were able to annotate approximately 150 instances in one hour. The average time required per assignment was approximately 25 seconds, which may seem surprising. However, two factors contribute to this efficiency: (1) Native speakers can quickly make binary judgments regarding substitute words. (2) Annotators only need to read the target sentence once to provide judgments for all substitutes in an assignment. For more information on the interface, instructions, and filtering criteria, please refer to Appendix A.",
                "The dataset consists of a total of 33,695 sentences and target word pairs, with a corresponding 144,708 labeled substitutes. On average, close to 10 words per sentence are selected as target words. We calucate named as High quality. The objective is to evaluate the accuracy of the substitutions made in the given sentence and target word pairs. A total of 300 instances were randomly selected, with 100 instances chosen from one of three text genres. A new annotator, proficient in the Chinese language, was assigned the task of assessing the precision of the substitutions within the selected instances.",
                "This annotator compared each substitute against the original target word to determine if it accurately captured the intended meaning and maintained syntactic and semantic coherence within the sentence. He classified the substitutions as correct or incorrect. The precision of the substitutions was computed by dividing the number of correct substitutes by the total number of substitutes evaluated. The precision would be calculated as 1136/1254, which is equivalent to 90.5%. The high precision rate of above 90% indicates the high quality of the substitutions within the dataset.",
                "High coverage. We show that CHNLS achieves high coverage. The same 300 instances in high quality are selected. Three new human evaluators, proficient in the Chinese language, were asked to independently think of substitutes for each sentence and target word pair in the selected instances.",
                "The substitutes provided by the evaluators are compared against the set of substitutions present in the constructed dataset. Each substitute is evaluated to determine whether it matched any of the substitutions in the dataset. The coverage of the dataset is calculated by dividing the number of substitutions provided by the human annotators that belonged to the dataset's set of substitutions by the total number of substitutions provided.",
                "The human annotators provide 742 substitutions and 723 substitutions belonged to the substitutions provided in the CHNLS. The coverage is calculated as 723/742, which is equivalent to 97%. This verification process demonstrates the extensive coverage of the dataset and its suitability for training and evaluating Chinese LS models. Additionally, it is worth noting that the three annotations only yielded a total of 742 substitutes, which is significantly smaller than the 1254 substitutes present in the dataset. This observation highlights the imprac- ticality of relying solely on manual annotation for generating language substitution word data, as it results in a substantial lack of coverage.",
                "High agreement. We used common agreement metrics such as Cohen's Kappa (Cohen, 1960) and Fleiss' Kappa (Fleiss, 1971) to quantify the level of agreement among annotators. Cohen's Kappa measures agreement between two raters, and Fleiss' Kappa can be used for measuring agreement between multiple raters. The Kappa result be interpreted as follows: values \u2264 0 as indicating no agreement and 0.01-0.20 as none to slight, 0.21-0.40 as fair, 0.41-0.60 as moderate, 0.61-0.80 as substantial, and 0.81-1.00 as almost perfect agreement.",
                "Table 2 lists the agreement scores for three annotators. Specifically, we calculated Fleiss' Kappa for our dataset, yielding a value of 0.594. This statistic underscores a substantial level of agreement among our human annotators, reaffirming the consistency and reliability of the annotations."
            ],
            "publication_ref": [
                "b3",
                "b4"
            ],
            "figure_ref": [],
            "table_ref": [
                "tab_2"
            ]
        },
        {
            "heading": "Experiments",
            "text": "",
            "publication_ref": [],
            "figure_ref": [],
            "table_ref": []
        },
        {
            "heading": "Experimental Setup",
            "text": [
                "Dataset. We split the whole dataset CHNLS into train (80%), valid (10%), test (10%) set. The train/valid/test sets in Wiki, News, and Novel have 8,425/1,065/888, 9,472/1,169/1,110, and 9,379/1,080/11,07 instances, respectively. The experimental results are computed on test sets.",
                "Metrics. We employ the designated official metrics, namely \"best,\" \"best-m,\" \"oot,\" and \"oot-m,\" as outlined in the SemEval 2007 task. In addition, we incorporate Precision@1 (P@1) as an evaluation metric, adhering to the conventions established by previous LS methodologies (Zhang et al., 2019;Qiang et al., 2023b). Notably, \"best,\" \"best-m,\" and \"P@1\" gauge the quality of the most accurate predictions, while both \"oot\" (out-of-ten) and \"oot-m\" assess the extent to which the gold substitutes is encompassed within the top 10 predictions.",
                "Implementation Details. Dict-based(Dict), Embedding-based (Embedding)  construct a large Chinese paraphrase dataset, containing 5,174,152 sentence pairs. Then we finetune Chinese BART on it to train a paraphraser. The initial learning rate is set to lr = 1 \u00d7 10 \u22125 and dropout is set to 0.1. We adopt the Adam optimizer with \u03b2 1 = 0.9, \u03b2 2 = 0.999, \u03f5 = 10 \u22128 . For the above methods, we set the max number of the generated candidates as 50. We use BARTscore and BERTscore to rank the candidates and select the top 10 words to calculate metrics. The weights are set as 1, 0.1 for BARTscore and BERTscore for all the above methods. To validate vLLM's ability on this dataset, we also tested two LLMs: ChatGLM 6 and ChatGPT 7 ,using their official API interfaces."
            ],
            "publication_ref": [
                "b29",
                "b23"
            ],
            "figure_ref": [],
            "table_ref": []
        },
        {
            "heading": "Evaluation Results",
            "text": [
                "Table 3 displays the performance of all methods on the various metrics. To eliminate the impact of substitute ranking, we also provide the results without substitute ranking in parentheses.",
                "Among the individual methods, we observed that BERT and ParaLS outperform the baselines Dict and Embedding. This is because both BERT and ParaLS utilize pretrained models that incorporate contextual information for better predictions. Without substitute ranking, ParaLS achieves better performance than BERT. It also means that ParaLS based on our constructed paraphrase corpus is the best individual LS method. When compared with vLLMs, we found BERT and ParaLS also outperform ChatGPT and ChatGLM.",
                "Experimental results demonstrate that our proposed method Ensemble surpasses the individual LS methods on all metrics with statistical significance. Ensemble expands the coverage of possible substitutes by utilizing multiple LS methods. Each method has its own coverage limitations and biases. By combining them, Ensemble overcomes individual limitations and biases, leading to broader coverage of substitute candidates. This broader coverage increases the likelihood of finding suitable substitutes for a wide range of target words. Additionally, different LS methods may exhibit varying levels of sensitivity to different linguistic contexts, word senses, or syntactic structures. By combining multiple methods, the ensemble approach becomes ;\u770b\u4f5c(look upon as);\u770b\u505a(look upon as);\u770b\u6210(regard as);\u540c\u65e5\u800c\u8bed(talk in the same breath) Embedding \u5f53\u505a;\u5a92\u67d3\u5242(Mordant);\u9009\u4f5c(Selected Works);\u5217\u4f5c(Listed as);\u4e3b\u8981\u7528\u9014(main Uses);\u501f\u4f5c(borrow as);\u7528\u9014(Use);\u7528\u4e8e(For);\u79fb\u4f5c(shift to);\u7528\u6765 Bert \u4f5c\u4e3a;\u7528\u505a;\u4f5c;\u4ee5\u662f(so);\u6210\u4e3a(become);\u505a\u4e3a(act as);\u5f53\u4f5c;\u4e3a(for);\u7528\u4e3a(used as);\u5236\u6210(made to order) ParaLs \u4f5c\u4e3a;\u7528\u4e8e(for);\u7528\u505a;\u4ee5\u662f(so);\u4f5c;\u6210\u4e3a(become);\u4ee5\u4e3a(thought);\u505a\u4e3a(act as);\u5f53\u4f5c;\u4e3a(for) Ensemble \u4f5c\u4e3a;\u5f53\u4f5c;\u7528\u505a;\u4f5c;\u505a\u4e3a(act as);\u5f53\u505a;\u7528\u4e3a(used as);\u5f53;\u7528\u4e8e(for);\u4ee5\u662f(so)",
                "Table 4: The top 10 substitutes of four instances in the Wiki subset of CHNLS using LS methods. The target word is marked in blue, and the substitutes in labels are marked in red.",
                "more robust to such variations, as it can draw on the strengths of different methods to handle different linguistic scenarios effectively. This robustness contributes to the overall improved performance.",
                "These reasons indicate that Ensemble benefits from the diversity, enhanced coverage, and robustness of individual LS methods. The combination of these factors contributes to the significant outperformance of the ensemble approach over the individual LS methods on all evaluation metrics, demonstrating its effectiveness in generating highquality substitutes for the Chinese LS task."
            ],
            "publication_ref": [],
            "figure_ref": [],
            "table_ref": [
                "tab_4"
            ]
        },
        {
            "heading": "Qualitative evaluation",
            "text": [
                "To qualitatively evaluate the effectiveness of the substitutes generated by LS methods, we present four instances of the Wiki subset of CHNLS for analysis. Table 4 displays the top 10 generated substitutes. More instances are shown in Appendix B.",
                "It is evident that the substitutes we have annotated exhibit a considerable level of comprehensiveness, without any significant absence of suitable substitutes. This observation indicates the high cov-erage achieved by our constructed dataset. In comparison, even the latest English lexical substitution datasets, such as SwordS which is the improved version of CoInCo, still exhibit deficiencies in capturing a sufficient number of appropriate substitutes (Qiang et al., 2023b).",
                "Consistent with the findings from the quantitative evaluation, the performance of the Dict-based and Embedding-based methods, which do not take contextual information into account during the substitution generation process, is relatively low compared to other methods.",
                "BERT and ParaLS approaches demonstrate promising results in terms of capturing contextual information and generating semantically similar substitutes. By leveraging the strengths of different approaches, Ensemble has two advantages. Firstly, Ensemble yields a greater number of appropriate alternatives when compared to BERT and ParaLS. Across the five instances, BERT, ParaLS, and Ensemble produce 20, 19, and 24 correct substitutes, respectively. Secondly, certain well-suited alternatives that were initially ranked lower in the individual methods ascend to higher positions. For in-stance, the substitute \"\u8d70\u7ea2\" (meaning \"to famous\") in instance 2 exhibits a notable elevation, securing the second rank."
            ],
            "publication_ref": [
                "b23"
            ],
            "figure_ref": [],
            "table_ref": []
        },
        {
            "heading": "Conclusions",
            "text": [
                "This study presents the first comprehensive exploration of the Chinese Lexical Substitution (LS) task. We propose a novel annotation method to construct a large-scale Chinese LS dataset through a collaborative human-machine approach. The constructed dataset consists of 33,695 instances and 165,105 substitutes with high quality and high coverage. Our proposed ensemble method by leveraging the strengths of each method while mitigating their weaknesses, our ensemble approach significantly outperforms the individual LS methods across all evaluation metrics.",
                "In conclusion, our study fills the research gap on how to construct a large-scale LS dataset with high coverage and low cost, providing a solid foundation for further research and development. The construction of a high-quality dataset and the development of an effective ensemble method showcase the potential for improved lexical substitution in the Chinese language."
            ],
            "publication_ref": [],
            "figure_ref": [],
            "table_ref": []
        },
        {
            "heading": "Limitations",
            "text": [
                "While our proposed collaborative approach successfully constructs a large-scale Chinese Lexical Substitution (LS) dataset, it is important to acknowledge some limitations to provide a balanced perspective.",
                "Despite the large-scale nature of the dataset, it may not cover all possible lexical substitution scenarios in the Chinese language. The dataset's coverage might be limited to three genres (Wiki, News, Novel), which could affect its applicability in certain contexts. Researchers should be cautious when generalizing findings beyond the dataset's scope.",
                "While efforts were made to ensure annotator agreement through guidelines and quality control measures, some level of inconsistency in judgments among human annotators is inevitable. The interannotator agreement might vary for different instances, which could introduce some noise or ambiguity in the dataset."
            ],
            "publication_ref": [],
            "figure_ref": [],
            "table_ref": []
        },
        {
            "heading": "Ethics Statement",
            "text": [
                "The dataset used in our research is constructed using publicly available data sources, ensuring that there are no privacy concerns or violations. We do not collect any personally identifiable information, and all data used in our research is obtained following legal and ethical standards.",
                "An additional ethical concern revolves around the possibility of the Chinese LS method being exploited for malicious intents, including the generation of fabricated or deceptive content. It is imperative to contemplate the potential repercussions arising from the outputs of the LS method and to implement protective measures to deter its exploitation for nefarious objectives.",
                "is selected as a potential target A total of 12,000 target words were selected from each of the three corpora. Subsequently, we employed four distinct lexical substitution methods to generate a set of 15 candidate words for each target word.",
                "Consequently, every sentence, target word, and corresponding collection of 15 candidate words formed a single sample. Ultimately, we accumulated a comprehensive dataset comprising 36,000 samples. To ensure reliable annotations, each sample was presented to three annotators who were instructed to select appropriate alternatives from the provided word list for tagging. The final annotation results constituted the lexical substitution dataset."
            ],
            "publication_ref": [],
            "figure_ref": [],
            "table_ref": []
        },
        {
            "heading": "A.1 Selection of target words",
            "text": [
                "We first divided each type of raw corpus into natural sentences. A natural sentence is a complete sentence that ends with a period, exclamation mark, question mark, or ellipsis and can express a complete meaning. Using a word segmenter, we segment and part-of-speech tag the natural sentences. For each verb, noun, adjective, and adverb in each natural sentence, we select them as potential target words. After removing proper nouns, fixed collocations, and other words that cannot be appropriately substituted, the remaining words are considered target words."
            ],
            "publication_ref": [],
            "figure_ref": [],
            "table_ref": []
        },
        {
            "heading": "A.2 Annotation Website",
            "text": [
                "We have built a website based on JavaWeb+MySQL for annotators' labeling work. We provide a portion of the target words and a list of 15 substitute words to three annotators to collect suitable sets of substitute words from them.",
                "To improve the quality of annotation, we have implemented the following three design strategies.",
                "(1) To reduce costs and ensure annotation quality, we adopted a rotating approach to presenting the substitute word lists to annotators. In the annotation of each target word, not all 15 substitute words in the list were provided to a single annotator. Instead, a selective subset of 11 or 12 substitute words was presented. This approach aimed to maintain the quality of annotations by avoiding overwhelming annotators with too many words to annotate at once, while significantly reducing the time required for annotation.",
                "For these 15 words, they were systematically rotated among the four annotators, ensuring equal opportunities for each word to be assigned to an annotator. This rotation strategy does not compromise the reliability of the annotation results, as each word has an equal chance of being assigned to any annotator. Thus, this approach ensures fairness and avoids potential bias in the annotation process.",
                "(2) We modified the substitute word lists for a selected subset of target words and provided them as confusion sets to the annotators to ensure annotation quality. From the original set of 36,000 target words in three corpora, we randomly selected one-third of the target words. For each selected target word, we made modifications to two substitute words out of the 15-word list. One substitute word was changed to the original target word, which served as a required option for the annotators. The other substitute word was replaced with any Chinese word of the same length as the original target word, sourced from a dictionary, and served as a forbidden option for the annotators.",
                "During the annotation process, we evaluated the quality of annotations by checking whether the annotators correctly labeled the confusion set options. This allowed us to assess the annotation quality based on the annotators' handling of the confusion sets.",
                "(3) We have designed three annotation starting positions to ensure consistency in the annotation progress for the three corpora. Each target word has been assigned a unique identifier. Each annotator begins annotating from a designated starting position, which corresponds to the identifier of the target word. To maintain consistency in the an-progress across all corpora, we have established a starting position for annotation at the beginning of each corpus, evenly distributed among multiple annotators.",
                "Once an annotator successfully annotates a target word, the current annotation identifier increments and the next annotatable content is automatically displayed. Only when an annotator reaches the maximum target word identifier, the annotation cycle restarts from the beginning. This approach offers the advantage of enabling consecutive annotations for target words within the same sentence in most cases, effectively reducing the workload of reading sentences, which is the most time-consuming task.",
                "Finally, we eliminated instances that did not contain any meaningful substitute. The number of instances is 33,695."
            ],
            "publication_ref": [],
            "figure_ref": [],
            "table_ref": []
        },
        {
            "heading": "A.3 Annotation Manual",
            "text": [
                "This manual is designed to facilitate the use of the Chinese lexical substitution dataset annotation system. It provides instructions on how to use the system effectively and serves as a reference for users, clarifying the purpose and functionality of the system. The manual includes an overview of the task, an explanation of the system's features, specific annotation examples, and a section addressing potential issues that may arise."
            ],
            "publication_ref": [],
            "figure_ref": [],
            "table_ref": []
        },
        {
            "heading": "A.4 The Work of Annotators",
            "text": [
                "Annotators are initially instructed to carefully peruse the annotation manual in its entirety. The administrator provides each annotator with a username and password. The administrator also instructs the annotators to annotate the data carefully and explains the website's special features. The system's backend assigns corresponding data to annotators for annotation.",
                "On the annotation website, for each instance, annotators need to determine whether suitable substitute words can be found for the target word in the instance. If an annotator believes that the target word in an instance is not suitable for replacement with any word other than the original word, they can select \"Not Replaceable\" for that sample and mark all substitute words as \"Not Suitable.\" If an annotator believes that suitable substitute words can be found for the target word in an instance, they need to evaluate and select the appropriate substitute words from the given list. Additionally, annotators can provide alternative suitable substitute words for each instance, different from the ones provided in the given substitute word list. The final collection consists of pairs of target words and the selected substitute word sets as annotated by the annotators.",
                "Regarding the wage for each annotator, our principle is 15\u00a5 per hour. We conducted a pilot test with one annotator, and they were able to annotate approximately 150 instances in one hour. Based on this calculation, the average price for annotating one instance is 0.1\u00a5. To incentivize annotators to provide new words, an additional price of 0.1\u00a5 is offered for each new substitute word."
            ],
            "publication_ref": [],
            "figure_ref": [],
            "table_ref": []
        },
        {
            "heading": "B More Examples",
            "text": [
                "Here, we randomly choose 5 instances from News and 5 instances from Novel for analysis in Table 5  and 6.",
                "BERT, ParaLS, and Ensemble provide high coverage and high-quality substitutes compared to Dict and Embedding. These results indicate that Ensemble achieves a little better results.",
                "Table 5: The top 10 substitutes of five instances in the News subset of CHNLS using LS methods. The target word is marked in blue, and the substitutes in labels are marked in red."
            ],
            "publication_ref": [],
            "figure_ref": [],
            "table_ref": []
        },
        {
            "heading": "Acknowledgement",
            "text": [
                "This research is partially supported by the National Natural Science Foundation of China under grants 62076217, U22B2037 and 61906060, and the Blue Project of Yangzhou University."
            ],
            "publication_ref": [],
            "figure_ref": [],
            "table_ref": []
        }
    ],
    "references": [
        {
            "ref_id": "b0",
            "title": "A preliminary study of croatian lexical substitution",
            "journal": "",
            "year": "2017",
            "authors": "Domagoj Alagi\u0107"
        },
        {
            "ref_id": "b1",
            "title": "Alexander Podolskiy, and Alexander Panchenko. 2020. A comparative study of lexical substitution approaches based on neural language models",
            "journal": "",
            "year": "",
            "authors": "Nikolay Arefyev; Boris Sheludko"
        },
        {
            "ref_id": "b2",
            "title": "Turk bootstrap word sense inventory 2.0: A large-scale resource for lexical substitution",
            "journal": "",
            "year": "2012",
            "authors": "Chris Biemann"
        },
        {
            "ref_id": "b3",
            "title": "A coefficient of agreement for nominal scales. Educational and psychological measurement",
            "journal": "",
            "year": "1960",
            "authors": "Jacob Cohen"
        },
        {
            "ref_id": "b4",
            "title": "Measuring nominal scale agreement among many raters",
            "journal": "Psychological bulletin",
            "year": "1971",
            "authors": "L Joseph;  Fleiss"
        },
        {
            "ref_id": "b5",
            "title": "Unt: Subfinder: Combining knowledge sources for automatic lexical substitution",
            "journal": "",
            "year": "2007",
            "authors": "Samer Hassan; Andras Csomai; Carmen Banea; Ravi Sinha; Rada Mihalcea"
        },
        {
            "ref_id": "b6",
            "title": "Delexicalized supervised german lexical substitution",
            "journal": "Proceedings of GermEval",
            "year": "2015",
            "authors": "Gerold Hintz; Chris Biemann"
        },
        {
            "ref_id": "b7",
            "title": "Language transfer learning for supervised lexical substitution",
            "journal": "Long Papers",
            "year": "2016",
            "authors": "Gerold Hintz; Chris Biemann"
        },
        {
            "ref_id": "b8",
            "title": "What substitutes tell us-analysis of an \"all-words\" lexical substitution corpus",
            "journal": "",
            "year": "2014",
            "authors": "Katrin Kremer; Sebastian Erk; Stefan Pad\u00f3;  Thater"
        },
        {
            "ref_id": "b9",
            "title": "Alasca: an automated approach for large-scale lexical substitution",
            "journal": "",
            "year": "2021",
            "authors": "Caterina Lacerra; Tommaso Pasini; Rocco Tripodi; Roberto Navigli"
        },
        {
            "ref_id": "b10",
            "title": "Genesis: A generative approach to substitutes in context",
            "journal": "",
            "year": "2021",
            "authors": "Caterina Lacerra; Rocco Tripodi; Roberto Navigli"
        },
        {
            "ref_id": "b11",
            "title": "Swords: A benchmark for lexical substitution with improved data coverage and quality",
            "journal": "Online. Association for Computational Linguistics",
            "year": "2021",
            "authors": "Mina Lee; Chris Donahue; Robin Jia; Alexander Iyabor; Percy Liang"
        },
        {
            "ref_id": "b12",
            "title": "Analogical reasoning on chinese morphological and semantic relations",
            "journal": "Short Papers",
            "year": "2018",
            "authors": "Shen Li; Zhe Zhao; Renfen Hu; Wensi Li; Tao Liu; Xiaoyong Du"
        },
        {
            "ref_id": "b13",
            "title": "Wanli: Worker and ai collaboration for natural language inference dataset creation",
            "journal": "",
            "year": "2022",
            "authors": "Alisa Liu; Swabha Swayamdipta; A Noah; Yejin Smith;  Choi"
        },
        {
            "ref_id": "b14",
            "title": "Lexical substitution as a task for wsd evaluation",
            "journal": "",
            "year": "2002",
            "authors": "Diana Mccarthy"
        },
        {
            "ref_id": "b15",
            "title": "Semeval-2007 task 10: English lexical substitution task",
            "journal": "",
            "year": "2007",
            "authors": "Diana Mccarthy; Roberto Navigli"
        },
        {
            "ref_id": "b16",
            "title": "Tongyici cilin (extended)",
            "journal": "",
            "year": "1996",
            "authors": "J Mei; Y Zhu;  Gao"
        },
        {
            "ref_id": "b17",
            "title": "Modeling word meaning in context with substitute vectors",
            "journal": "",
            "year": "2015",
            "authors": "Oren Melamud; Ido Dagan; Jacob Goldberger"
        },
        {
            "ref_id": "b18",
            "title": "A simple word embedding model for lexical substitution",
            "journal": "",
            "year": "2015",
            "authors": "Oren Melamud; Omer Levy; Ido Dagan"
        },
        {
            "ref_id": "b19",
            "title": "Lexsubcon: Integrating knowledge from lexical resources into contextual embeddings for lexical substitution",
            "journal": "",
            "year": "2022",
            "authors": "George Michalopoulos; Ian Mckillop; Alexander Wong; Helen Chen"
        },
        {
            "ref_id": "b20",
            "title": "Unsupervised lexical simplification for non-native speakers",
            "journal": "",
            "year": "2016",
            "authors": "H Gustavo; Lucia Paetzold;  Specia"
        },
        {
            "ref_id": "b21",
            "title": "Chinese idiom paraphrasing",
            "journal": "Transactions of the Association for Computational Linguistics",
            "year": "2023",
            "authors": "Jipeng Qiang; Yang Li; Chaowei Zhang; Yun Li; Yi Zhu; Yunhao Yuan; Xindong Wu"
        },
        {
            "ref_id": "b22",
            "title": "Lsbert: Lexical simplification based on bert",
            "journal": "IEEE/ACM Transactions on Audio, Speech, and Language Processing",
            "year": "2021",
            "authors": "Jipeng Qiang; Yun Li; Yi Zhu; Yunhao Yuan; Yang Shi; Xindong Wu"
        },
        {
            "ref_id": "b23",
            "title": "Parals: Lexical substitution via pretrained paraphraser",
            "journal": "",
            "year": "2023",
            "authors": "Jipeng Qiang; Kang Liu; Yun Li; Yunhao Yuan; Yi Zhu"
        },
        {
            "ref_id": "b24",
            "title": "Chinese lexical simplification",
            "journal": "IEEE Transactions on Audio, Speech and Language Processing",
            "year": "2021",
            "authors": "Jipeng Qiang; Xinyu Lv; Yun Li; Yunhao Yuan; Xindong Wu"
        },
        {
            "ref_id": "b25",
            "title": "Natural language watermarking via paraphraser-based lexical substitution",
            "journal": "Artificial Intelligence",
            "year": "2023",
            "authors": "Jipeng Qiang; Shiyu Zhu; Yun Li; Yi Zhu; Yunhao Yuan; Xindong Wu"
        },
        {
            "ref_id": "b26",
            "title": "The lexical substitution task at evalita",
            "journal": "",
            "year": "2009",
            "authors": "Antonio Toral"
        },
        {
            "ref_id": "b27",
            "title": "Bartscore: Evaluating generated text as text generation",
            "journal": "Curran Associates, Inc",
            "year": "2021",
            "authors": "Weizhe Yuan; Graham Neubig; Pengfei Liu"
        },
        {
            "ref_id": "b28",
            "title": "Ku: Word sense disambiguation by substitution",
            "journal": "",
            "year": "2007",
            "authors": "Deniz Yuret"
        },
        {
            "ref_id": "b29",
            "title": "Bertscore: Evaluating text generation with bert",
            "journal": "",
            "year": "2019",
            "authors": "Tianyi Zhang; Varsha Kishore; Felix Wu; Q Kilian; Yoav Weinberger;  Artzi"
        },
        {
            "ref_id": "b30",
            "title": "Bert-based lexical substitution",
            "journal": "",
            "year": "2019",
            "authors": "Wangchunshu Zhou; Tao Ge; Ke Xu; Furu Wei; Ming Zhou"
        },
        {
            "ref_id": "b31",
            "title": "Each document is divided into sentences, and each verb, noun, adjective, and adverb in each sentence Inst. 1 \u6b21\u65e5\uff0c\u5979\u53c8\u53ec\u5f00\u804c\u5de5\u5927\u4f1a\uff0c\u4e0e\u804c\u5de5\u4eec\u4e00\u8d77\u8ba8\u8bba\u51fa\u73b0\u8d28\u91cf\u4e0d\u5408\u683c\u54c1\u7684\u539f\u56e0\u3002 English The next she held another staff meeting to discuss with the staff the reasons for the unqualified quality products",
            "journal": "Labels \u4e3e\u884c",
            "year": "",
            "authors": "\u4e3e\u884c \u53ec\u96c6;\u4e3e\u529e;\u5f00;\u7ec4\u7ec7;\u4e3b\u6301;\u5f00\u5c55 Dict"
        },
        {
            "ref_id": "b32",
            "title": "\u505a(make)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b33",
            "title": "",
            "journal": "Embedding \u5f00\u4f1a\u7814\u8ba8(Meeting discussion",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b34",
            "title": "",
            "journal": "\u5c40\u52a1(bureau affairs",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b35",
            "title": "",
            "journal": "\u515a\u7ec4\u4f1a",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b36",
            "title": "",
            "journal": "\u6269\u5927\u4f1a\u8bae(enlarged meeting",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b37",
            "title": "",
            "journal": "\u5ba1\u8bae(consider",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b38",
            "title": "\u5f00\u4f1a\u8ba8\u8bba(discussing in a Meeting);\u4e3e\u884c;\u73b0\u573a\u4f1a\u8bae(on site meetings",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b39",
            "title": "\u5f00\u5b8c(after driving) Bert \u53ec\u96c6;\u4e3e\u884c;\u5f00;\u7ec4\u7ec7;\u4e3e\u529e;\u53c2\u52a0",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b40",
            "title": "",
            "journal": "\u51fa\u5e2d(attend)",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b41",
            "title": "",
            "journal": "",
            "year": "",
            "authors": " \u8fdb\u884c"
        },
        {
            "ref_id": "b42",
            "title": "\u542f\u52a8(firing) ParaLS \u53ec\u96c6;\u4e3e\u884c;\u5f00;\u7ec4\u7ec7;\u4e3e\u529e;\u53c2\u52a0(participate in);\u5f00\u5c55;\u51fa\u5e2d(attend)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b43",
            "title": "\u5f00\u8d77(start);\u4e3b\u6301 Ensemble \u4e3e\u884c;\u53ec\u96c6;\u5f00;\u4e3e\u529e;\u51fa\u5e2d(attend);\u7ec4\u7ec7;\u5f00\u5c55;\u53c2\u52a0(participate in)",
            "journal": "\u4e3b\u6301",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b44",
            "title": "",
            "journal": "\u5f00\u5b8c",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b45",
            "title": "\u6b21\u65e5\uff0c\u5979\u53c8\u53ec\u5f00\u804c\u5de5\u5927\u4f1a\uff0c\u4e0e\u804c\u5de5\u4eec\u4e00\u8d77\u8ba8\u8bba\u51fa\u73b0\u8d28\u91cf\u4e0d\u5408\u683c\u54c1\u7684\u539f\u56e0\u3002 English The next day, she held another staff meeting to discuss with the staff the reasons for the unqualified quality products",
            "journal": "Labels \u63a2\u8ba8",
            "year": "",
            "authors": "\u63a2\u8ba8;\u8c08\u8bba;\u5546\u8bae;\u8bae\u8bba;\u7814\u8ba8;\u8c08\u8c08; \u8c08\u8bba;\u7814\u8ba8;\u8bae\u8bba;\u5546\u8ba8;\u5546\u8bae;\u7814\u7a76;\u534f\u5546;\u8c08\u8c08 Dict;  \u5ba1\u8bae"
        },
        {
            "ref_id": "b46",
            "title": "\u5ea7\u8c08(have an informal discussion)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b47",
            "title": "",
            "journal": "\u8bb2\u8bba(lectures",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b48",
            "title": "\u8bae\u4e8b(proceedings)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b49",
            "title": "Embedding \u5f00\u4f1a\u7814\u8ba8(meeting discussion)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b50",
            "title": "",
            "journal": "\u4e89\u8fa9(argue",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b51",
            "title": "",
            "journal": "",
            "year": "",
            "authors": "\u8bae "
        },
        {
            "ref_id": "b52",
            "title": "\u4e89\u8bba\u4e0d\u4f11(an endless debate)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b53",
            "title": "\u5f00\u4f1a\u8ba8\u8bba(discussing in a meeting)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b54",
            "title": "\u4e89\u8bba(debate)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b55",
            "title": "dispute);\u5546\u8ba8;\u8fa9\u8bba(debate) Bert \u63a2\u8ba8;\u5546\u8ba8;\u8c08\u8bba;\u5546\u8bae;\u7814\u7a76;\u5546\u91cf(discuss);\u8bae\u8bba;\u5206\u6790(analysis);\u7814\u8ba8;\u4e89\u8bba(debate) ParaLS \u63a2\u8ba8;\u5546\u8ba8;\u8c08\u8bba;\u5546\u8bae;\u7814\u7a76;\u5546\u91cf(discuss)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b56",
            "title": "",
            "journal": "\u5206\u6790(analysis)",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b57",
            "title": "3 \u5728\u5b9e\u8df5\u4e2d\uff0c\u6211\u4eec\u4f53\u4f1a\u5230\uff0c\u4f01\u4e1a\u53ea\u6709\u628a\u4ea7\u54c1\u8d28\u91cf\u770b\u4f5c\u81ea\u5df1\u7684 \u751f\u547d\uff0c\u624d\u80fd\u632f\u5174\u3002 English In practice, we have learned that a company can only be revitalized if it considers product quality to be its life",
            "journal": "Labels \u611f\u53d7",
            "year": "",
            "authors": "\u63a2\u8ba8;\u8c08\u8bba;\u5546\u8bae;\u8bae\u8bba;\u5546\u8ba8; \u5546\u8c08(negotiate);\u534f\u5546 Ensemble; );\u7814\u8ba8;\u7814\u7a76;\u5206\u6790;\u534f\u5546 \u5546\u91cf(discuss; ; \u4f53\u609f;\u4f53\u9a8c;\u9886\u609f;\u9886\u4f1a;\u8ba4\u8bc6;\u4f53\u5473;\u611f\u609f;\u610f\u8bc6 Inst; \u4f53\u9a8c Dict"
        },
        {
            "ref_id": "b58",
            "title": "",
            "journal": "\u8ba4\u77e5(cognition",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b59",
            "title": "",
            "journal": "",
            "year": "",
            "authors": " \u56de\u5473(aftertaste"
        },
        {
            "ref_id": "b60",
            "title": "",
            "journal": "\u5480\u56bc(chew",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b61",
            "title": "",
            "journal": "\u5fc3\u5f97(experience",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b62",
            "title": "\u541f\u5473(recite with relish)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b63",
            "title": "",
            "journal": "",
            "year": "",
            "authors": "\u7406\u89e3 Embedding"
        },
        {
            "ref_id": "b64",
            "title": "",
            "journal": "\u6df1\u5207\u4f53\u4f1a(deep experience",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b65",
            "title": "",
            "journal": "\u4f53\u4f1a\u51fa(experience",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b66",
            "title": "",
            "journal": "\u6df1\u6df1\u611f\u5230(deeply felt)",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b67",
            "title": "",
            "journal": "",
            "year": "",
            "authors": " \u9886\u4f1a\u5230"
        },
        {
            "ref_id": "b68",
            "title": "\u610f\u8bc6;\u4f53\u5473 Inst. 4 \u7531\u4e8e\u4eba\u6587\u5730\u7406\u7684\u539f\u56e0\uff0c\u767d\u6c9f\u4eba\u7ecf\u5546\u786e\u6709\u4f18\u52bf\u3002 English Due to cultural and geographical reasons, the people of Baigou do have advantages through negotiation. sewing machines, so the market boom concealed a potential quality crisis",
            "journal": "Labels \u7f18\u6545",
            "year": "",
            "authors": "\u4f53\u609f;\u8ba4\u8bc6;\u4f53\u9a8c;\u611f\u53d7; \u9886\u7565(appreciate);\u9886\u609f;\u611f\u609f Bert; );\u9886\u609f;\u611f\u609f;\u610f\u8bc6;\u9886\u4f1a; \u4e86\u89e3(understand; \u8ba4\u8bc6;\u4f53\u609f;\u4f53\u9a8c;\u610f\u8bc6;\u4e86\u89e3(\u4e86\u89e3);\u611f\u53d7;\u9886\u609f; \u5b66\u4e60(study) Parals; ) \u611f\u89c9(feelings; \u4f53\u9a8c;\u611f\u53d7;\u4f53\u609f;\u9886\u609f;\u611f\u609f;\u9886\u4f1a;\u8ba4\u8bc6;\u4e86\u89e3 ; \u56e0\u7d20;\u7f18\u7531;\u539f\u6545;\u4e3b\u56e0;\u539f\u7531;\u539f\u59d4 \u611f\u609f;\u9886\u4f1a Ensemble; \u7f18\u6545 Dict"
        },
        {
            "ref_id": "b69",
            "title": "",
            "journal": "",
            "year": "",
            "authors": " \u7531(cause"
        },
        {
            "ref_id": "b70",
            "title": "",
            "journal": "",
            "year": "",
            "authors": "\u6545 "
        },
        {
            "ref_id": "b71",
            "title": "\u56e0\u7531(cause)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b72",
            "title": "Embedding \u79cd\u79cd\u539f\u56e0(various reasons)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b73",
            "title": "",
            "journal": "\u7a76\u5176",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b74",
            "title": "",
            "journal": "",
            "year": "",
            "authors": " \u8bf1\u56e0"
        },
        {
            "ref_id": "b75",
            "title": "",
            "journal": "\u6839\u6e90(root)",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b76",
            "title": "",
            "journal": "\u8d77\u56e0(cause",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b77",
            "title": "",
            "journal": "\u95f4\u63a5\u539f\u56e0(indirect causes)",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b78",
            "title": "",
            "journal": "\u76f4\u63a5\u539f\u56e0",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b79",
            "title": "",
            "journal": "\u51b3\u5b9a\u56e0\u7d20(determinant) Bert \u7f18\u6545",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b80",
            "title": "",
            "journal": "\u4f18\u52bf(advantage",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b81",
            "title": "",
            "journal": "\u5173\u7cfb(relationship",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b82",
            "title": "",
            "journal": "\u7406\u7531(reason",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b83",
            "title": "\u539f\u6545;\u7279\u70b9(characteristic);\u7f18\u7531 ParaLS \u7f18\u6545;\u56e0\u7d20",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b84",
            "title": "",
            "journal": "",
            "year": "",
            "authors": " \u5f71\u54cd"
        },
        {
            "ref_id": "b85",
            "title": "",
            "journal": "\u4f18\u52bf(advantage",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b86",
            "title": "",
            "journal": "\u5173\u7cfb(relationship",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b87",
            "title": "",
            "journal": "\u7406\u7531(reason",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b88",
            "title": "",
            "journal": "\u7279\u6b8a(special",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b89",
            "title": "",
            "journal": "\u7279\u70b9(characteristic",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b90",
            "title": "\u8003\u8651(consider);\u539f\u6545 Ensemble \u7f18\u6545;\u539f\u6545;\u56e0\u7d20;\u7406\u7531(reason)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b91",
            "title": "",
            "journal": "",
            "year": "",
            "authors": " \u5f71\u54cd"
        },
        {
            "ref_id": "b92",
            "title": "",
            "journal": "\u4f18\u52bf(advantage",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b93",
            "title": "\u5173\u7cfb(relationship);\u7f18\u7531;\u7279\u6b8a(special)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b94",
            "title": "\u7279\u70b9(characteristic) Inst. 5 \u767d\u6c9f\u5e02\u573a\u4e00\u4e0b\u5c31\u51b7\u6e05\u4e0b\u6765\uff0c\u6211\u7684\u4e70\u5356\u4e5f\u8ddf\u7740\u8870\u4e86\u3002 English The Baigou market immediately cooled down, and my business also declined",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b95",
            "title": "",
            "journal": "\u7a7a\u8361\u8361(empty",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b96",
            "title": "\u8427\u7d22(desolate)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b97",
            "title": "\u95e8\u53ef\u7f57\u96c0(there are very few people)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b98",
            "title": "",
            "journal": "",
            "year": "",
            "authors": "\u6e05\u9759 Embedding"
        },
        {
            "ref_id": "b99",
            "title": "",
            "journal": "\u9759\u5bc2(silence)",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b100",
            "title": "",
            "journal": "",
            "year": "",
            "authors": " \u51c4\u51c9(dreariness"
        },
        {
            "ref_id": "b101",
            "title": "\u843d\u5bde(lonely);\u51b7\u6de1;\u7a7a\u7a7a\u8361\u8361;\u51b7\u6e05\u6e05;\u51c4\u51b7(cold) Bert \u51b7\u6de1;\u5bc2\u9759",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b102",
            "title": "",
            "journal": "",
            "year": "",
            "authors": "\u51b7 "
        },
        {
            "ref_id": "b103",
            "title": "\u51b7\u9759(calmness);\u6e05\u6de1;\u5e73\u9759(calmness);\u6c89\u5bc2;\u5bd2\u51b7(cold)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b104",
            "title": "",
            "journal": "",
            "year": "",
            "authors": " \u6e05\u9759"
        },
        {
            "ref_id": "b105",
            "title": "",
            "journal": "\u5b89\u9759(quiet) ParaLS \u51b7\u6de1",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b106",
            "title": "",
            "journal": "",
            "year": "",
            "authors": "\u51b7 "
        },
        {
            "ref_id": "b107",
            "title": "\u51b7\u9759(calmness);\u6e05\u6de1;\u51b7\u843d;\u6e05\u51b7(chilly)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b108",
            "title": "",
            "journal": "\u9eef\u6de1(dim",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b109",
            "title": "",
            "journal": "\u51b7\u5374(cooling",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b110",
            "title": "",
            "journal": "\u5e73\u9759(calmness) Ensemble \u51b7\u6de1",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b111",
            "title": "\u51b7\u9759(calmness);\u51b7\u843d;\u6e05\u51b7(chilly);\u6e05\u6de1;\u51b7(cold)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b112",
            "title": "\u9eef\u6de1(dim);\u6c89\u5bc2;\u5e73\u9759(calmness)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b113",
            "title": "He was naked and had a pair of leather pants on underneath, so he got the message in his sleep and came to plead for mercy",
            "journal": "Labels \u6d88\u606f",
            "year": "",
            "authors": "; \u4fe1;\u4fe1\u606f;\u4fe1\u53f7;\u60c5\u62a5;\u8baf\u53f7;\u8d44\u8baf \u4ed6\u4e0a\u8eab\u8d64\u88f8\uff0c\u4e0b\u8eab\u5957\u7740\u4e00\u6761\u76ae\u88e4\uff0c \u60f3\u662f\u7761\u68a6\u4e2d\u5f97\u5230\u8baf\u606f\uff0c\u8d76\u6765\u6c42\u60c5\u3002 English; \u6d88\u606f Dict;  \u8d44\u8baf"
        },
        {
            "ref_id": "b114",
            "title": "\u5feb\u8baf(news flash);\u60c5\u62a5;\u65b0\u95fb(news)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b115",
            "title": "",
            "journal": "",
            "year": "",
            "authors": "\u8baf "
        },
        {
            "ref_id": "b116",
            "title": "",
            "journal": "\u8c0d\u62a5",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b117",
            "title": "",
            "journal": "Embedding \u5c0f\u9053\u6d88\u606f(grapevine)",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b118",
            "title": "",
            "journal": "\u68c0\u5bdf\u4fe1\u606f(Inspection Information",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b119",
            "title": "",
            "journal": "\u65e0\u7528\u4fe1\u606f(Useless information",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b120",
            "title": "",
            "journal": "\u77ed\u6d88\u606f(Short Message",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b121",
            "title": "",
            "journal": "\u6b7b\u8baf(News of death",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b122",
            "title": "",
            "journal": "\u5546\u54c1\u4fe1\u606f(Product Information",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b123",
            "title": "",
            "journal": "\u75c5\u6bd2\u4fe1\u606f(Virus Information",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b124",
            "title": "",
            "journal": "\u4f20\u9001(Transmission)",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b125",
            "title": "\u4f20\u9012\u4fe1\u606f(Delivering information) Bert \u6d88\u606f;\u4fe1\u606f;\u8d44\u8baf;\u901a\u77e5(Notification);\u4fe1\u53f7;\u7ebf\u7d22(Clues);\u60c5\u62a5;\u97f3\u8baf(Audio)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b126",
            "title": "",
            "journal": "",
            "year": "",
            "authors": " \u77ed\u4fe1(sms"
        },
        {
            "ref_id": "b127",
            "title": "\u65b0\u95fb(News) ParaLS \u4fe1\u606f;\u6d88\u606f;\u8d44\u8baf;\u901a\u77e5(Notification);\u4fe1\u53f7;\u7ebf\u7d22(Clues)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b128",
            "title": "",
            "journal": "\u97f3\u8baf(Audio)",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b129",
            "title": "",
            "journal": "",
            "year": "",
            "authors": " \u77ed\u4fe1(sms"
        },
        {
            "ref_id": "b130",
            "title": "\u65b0\u95fb(news) Ensemble \u6d88\u606f;\u8d44\u8baf;\u4fe1\u606f;\u4fe1\u53f7;\u60c5\u62a5;\u901a\u77e5(Notification);\u8baf\u53f7;\u97f3\u8baf(Audio)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b131",
            "title": "",
            "journal": "",
            "year": "",
            "authors": " \u65b0\u95fb"
        },
        {
            "ref_id": "b132",
            "title": "",
            "journal": "\u547c\u5524",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b133",
            "title": "English Guo Jing rushed towards the back tent, grabbed it with his left hand and pulled it hard, pulling down half of the golden tent and covering it over the heads of the generals",
            "journal": "Labels \u4f7f\u52b2",
            "year": "",
            "authors": "\u5927\u529b \u7528\u52b2;\u5f3a\u529b;\u52a0\u529b;\u7aed\u529b;\u5927\u529b Dict"
        },
        {
            "ref_id": "b134",
            "title": "\u4f7f\u52b2;\u6781\u529b(Make an effort",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b135",
            "title": "\u7528\u52b2;\u5c3d\u529b(Try your best",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b136",
            "title": "",
            "journal": "\u4e00\u529b(One Power",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b137",
            "title": "",
            "journal": "\u5168\u529b(Full strength",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b138",
            "title": "\u62fc\u547d(do one's utmost)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b139",
            "title": "",
            "journal": "",
            "year": "",
            "authors": "\u64c2\u6253 Embedding"
        },
        {
            "ref_id": "b140",
            "title": "",
            "journal": "\u8981\u7528\u529b",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b141",
            "title": "",
            "journal": "\u63ff\u4f4f(Snap)",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b142",
            "title": "",
            "journal": "\u6b7b\u52b2(Dead weight",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b143",
            "title": "",
            "journal": "\u72e0\u547d(Tough life",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b144",
            "title": "\u6413\u64e6(Rubbing) Bert \u52aa\u529b(Effort);\u5927\u529b;\u4f7f\u52b2;\u5f3a\u529b;\u7528\u52b2;\u5c3d\u529b(Try your best",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b145",
            "title": "\u62fc\u547d(do one's utmost)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b146",
            "title": "",
            "journal": "\u8f7b\u8f7b(gently",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b147",
            "title": "",
            "journal": "",
            "year": "",
            "authors": " \u731b\u70c8"
        },
        {
            "ref_id": "b148",
            "title": "",
            "journal": "\u72e0\u72e0(Ruthlessly) ParaLS \u5927\u529b",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b149",
            "title": "\u4f7f\u52b2;\u5f3a\u529b;\u6781\u529b(Make an effort",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b150",
            "title": "\u7528\u52b2;\u52a0\u529b;\u5c3d\u529b(Try your best",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b151",
            "title": "\u6709\u529b(Powerful) Ensemble \u4f7f\u52b2;\u7528\u52b2;\u5927\u529b;\u6781\u529b(Make an effort",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b152",
            "title": "",
            "journal": "\u5c3d\u529b(Try your best",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b153",
            "title": "",
            "journal": "\u8f7b\u8f7b(gently",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b154",
            "title": "\u5f3a\u529b;\u594b\u529b(Endeavor)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b155",
            "title": "English Guo Jing rushed towards the back tent, grabbed it with his left hand and pulled it hard, pulling down half of the golden tent and covering it over the heads of the generals",
            "journal": "",
            "year": "",
            "authors": "\u626f;\u6495\u626f;\u62fd;\u62c9;\u62c9\u4f4f;\u7275\u626f Dict; \u62c9 "
        },
        {
            "ref_id": "b156",
            "title": "",
            "journal": "",
            "year": "",
            "authors": " \u62c9\u62c9(lara"
        },
        {
            "ref_id": "b157",
            "title": "\u626f;\u7275\u626f;\u62fd;\u62c9\u957f(Elongation)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b158",
            "title": "",
            "journal": "\u62c9\u6746(Tie Rod",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b159",
            "title": "",
            "journal": "\u6500\u626f(Climbing)",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b160",
            "title": "",
            "journal": "\u76f4\u62c9",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b161",
            "title": "",
            "journal": "Embedding \u626f\u4e0b\u53bb(Pull it down",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b162",
            "title": "",
            "journal": "\u53ae\u6253",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b163",
            "title": "",
            "journal": "",
            "year": "",
            "authors": " \u626f\u62c9(tug"
        },
        {
            "ref_id": "b164",
            "title": "",
            "journal": "\u63a8\u6253(push and beat",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b165",
            "title": "",
            "journal": "",
            "year": "",
            "authors": " \u626f\u4f4f(tug"
        },
        {
            "ref_id": "b166",
            "title": "",
            "journal": "\u63ea\u626f(tug at",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b167",
            "title": "",
            "journal": "\u626f\u65ad(Tear off",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b168",
            "title": "",
            "journal": "\u626d\u53bb(twist off) Bert \u62c9\u62fd",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b169",
            "title": "\u6495\u626f;\u62c9\u4f38(Stretching)",
            "journal": "",
            "year": "",
            "authors": " \u62c9\u62c9(lara"
        },
        {
            "ref_id": "b170",
            "title": "\u62c9\u4f4f;\u62c9\u5f00(Pull away",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b171",
            "title": "",
            "journal": "\u62c9\u62e2(rope in)",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b172",
            "title": "",
            "journal": "\u62c9\u7d27(Tensioning) ParaLS \u62c9\u62fd",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b173",
            "title": "",
            "journal": "",
            "year": "",
            "authors": " \u62c9\u62c9(lara"
        },
        {
            "ref_id": "b174",
            "title": "\u626f\u626f(tug at);\u6495\u626f;\u62c9\u4f38(Stretching)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b175",
            "title": "English After walking for more than ten miles, the two dismounted and worshipped each other, hugging each other for a while, and parting in tears",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b176",
            "title": "",
            "journal": "",
            "year": "",
            "authors": "\u6402\u6402 Embedding"
        },
        {
            "ref_id": "b177",
            "title": "",
            "journal": "\u72c2\u543b(Kissing furiously",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b178",
            "title": "",
            "journal": "",
            "year": "",
            "authors": " \u62e5\u543b(kissing"
        },
        {
            "ref_id": "b179",
            "title": "",
            "journal": "\u629a\u6478(Stroking)",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b180",
            "title": "",
            "journal": "\u6402\u7740(Cuddle up",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b181",
            "title": "",
            "journal": "\u62b1\u8170(lap",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b182",
            "title": "\u4eb2\u70ed(affectionate)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b183",
            "title": "",
            "journal": "\u8e2e\u7740(stand on tiptoe",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b184",
            "title": "\u7d27\u62b1(Hold tightly) Bert \u62e5\u62b1;\u6402;\u62b1;\u62b1\u62b1;\u6402\u4f4f(hold in one's arms",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b185",
            "title": "\u4eb2\u543b(kiss);\u504e\u62b1;\u543b(lips)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b186",
            "title": "",
            "journal": "",
            "year": "",
            "authors": "\u62e5\u62b1;\u6402;\u62b1;\u62b1\u62b1; \u62e5(embrace) Parals;  \u6402\u4f4f"
        },
        {
            "ref_id": "b187",
            "title": "\u4eb2\u543b(kiss)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b188",
            "title": "\u6000\u62b1(embrace);\u504e\u62b1;\u62e5\u543b(Smooch) Ensemble \u6402;\u62e5\u62b1;\u62b1\u62b1",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b189",
            "title": "\u504e\u62b1;\u4eb2\u543b(kiss)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b190",
            "title": "",
            "journal": "",
            "year": "",
            "authors": " \u62e5\u543b(smooch"
        },
        {
            "ref_id": "b191",
            "title": "",
            "journal": "",
            "year": "",
            "authors": " \u6402\u6402(snuggle"
        },
        {
            "ref_id": "b192",
            "title": "",
            "journal": "\u629a\u6478(Stroking)",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b193",
            "title": "\u6402\u4f4f(hold in one's arms) Inst. 5 \u4ed6\u6545\u610f\u66ff\u54f2\u522b\u63a9\u9970\uff0c\u4ee5\u514d\u6210\u5409\u601d\u6c57\u77e5\u6653\u5185\u60c5\u3002 English He deliberately covered up for Zhebei so that Genghis Khan would not know the inside story",
            "journal": "Labels \u6709\u610f",
            "year": "",
            "authors": "\u6709\u610f \u84c4\u610f;\u6210\u5fc3;\u5b58\u5fc3;\u7279\u610f;\u523b\u610f Dict;  \u84c4\u610f"
        },
        {
            "ref_id": "b194",
            "title": "\u5047\u610f(hypocrisy);\u5b58\u5fc3;\u6709\u5fc3",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b195",
            "title": "",
            "journal": "\u6709\u610f\u8bc6(consciously)",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b196",
            "title": "",
            "journal": "",
            "year": "",
            "authors": "\u6545 "
        },
        {
            "ref_id": "b197",
            "title": "Embedding \u5077\u5077(secretly)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b198",
            "title": "",
            "journal": "\u6545\u610f\u6740\u4eba\u7f6a(Intentional Homicide",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b199",
            "title": "",
            "journal": "",
            "year": "",
            "authors": " \u660e\u77e5(knowingly"
        },
        {
            "ref_id": "b200",
            "title": "",
            "journal": "",
            "year": "",
            "authors": " \u8bec\u8d56"
        },
        {
            "ref_id": "b201",
            "title": "",
            "journal": "",
            "year": "",
            "authors": " \u6545\u5f04(plague"
        },
        {
            "ref_id": "b202",
            "title": "\u5356\u5f04\u7384\u865a(make a mystery of something",
            "journal": "Bert \u523b\u610f",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b203",
            "title": "\u6697\u4e2d(secretly)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b204",
            "title": "",
            "journal": "",
            "year": "",
            "authors": " \u8bd5\u56fe"
        },
        {
            "ref_id": "b205",
            "title": "",
            "journal": "",
            "year": "",
            "authors": " \u6253\u7b97"
        },
        {
            "ref_id": "b206",
            "title": "\u6697\u6697(secretly) ParaLS \u523b\u610f",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b207",
            "title": "",
            "journal": "\u8bbe\u6cd5",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b208",
            "title": "\u6697\u4e2d(secretly);\u84c4\u610f;\u6253\u7b97(intend)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b209",
            "title": "",
            "journal": "",
            "year": "",
            "authors": " \u8bd5\u56fe"
        },
        {
            "ref_id": "b210",
            "title": "\u6697\u6697(secretly) Ensemble \u523b\u610f;\u7279\u610f;\u6709\u610f;\u84c4\u610f;\u5047\u610f",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b211",
            "title": "",
            "journal": "",
            "year": "",
            "authors": " \u5047\u88c5"
        },
        {
            "ref_id": "b212",
            "title": "\u51b3\u5b9a(decision)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b213",
            "title": "\u5077\u5077(secretly)",
            "journal": "",
            "year": "",
            "authors": ""
        },
        {
            "ref_id": "b214",
            "title": "The top 10 substitutes of five instances in the Novel subset of CHNLS using LS methods. The target word is marked in blue, and the substitutes in labels are marked in red",
            "journal": "",
            "year": "",
            "authors": ""
        }
    ],
    "figures": [
        {
            "figure_label": "2",
            "figure_type": "figure",
            "figure_id": "fig_0",
            "figure_caption": "Figure 2 :2Figure 2: Screenshot of an annotation example on the annotation Website. The red text indicates added comments.",
            "figure_data": ""
        },
        {
            "figure_label": "",
            "figure_type": "figure",
            "figure_id": "",
            "figure_caption": "",
            "figure_data": ""
        },
        {
            "figure_label": "",
            "figure_type": "table",
            "figure_id": "tab_0",
            "figure_caption": "paraphraser-based methods are denoted as {c 1",
            "figure_data": ""
        },
        {
            "figure_label": "2",
            "figure_type": "table",
            "figure_id": "tab_2",
            "figure_caption": "Cohen's kappa agreement scores for pairs of annotators and Fleiss' kappa agreement for three annotators",
            "figure_data": "Cohen's (A1-A2) Cohen's (A1-A3) Cohen's (A2-A3) Fleiss' kappahline 0.5980.6140.5720.594"
        },
        {
            "figure_label": "3",
            "figure_type": "table",
            "figure_id": "tab_4",
            "figure_caption": "Evaluation results of substitute generation and substitute ranking. The scores in parentheses are only calculated by the substitutes from the substitute generation step. The Best values are bolded and the second values are marked in blue.",
            "figure_data": ""
        }
    ],
    "formulas": [],
    "doi": ""
}